# -*- coding: utf-8 -*-
"""
Langfuse ëª¨ë‹ˆí„°ë§ ë°ëª¨
LangChainê³¼ LangGraph ëª¨ë‹ˆí„°ë§ ì‚¬ìš© ì˜ˆì‹œ
"""

import os
import logging
from typing import Dict, Any, List
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LangChain ê´€ë ¨ import
try:
    from langchain.llms import OpenAI
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    from langchain.prompts import PromptTemplate
    from langchain.schema import HumanMessage, SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install langchainì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# LangGraph ê´€ë ¨ import
try:
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt import ToolNode
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    print("LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install langgraphë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ import
from source.utils.langfuse_monitor import get_langfuse_monitor
from source.utils.langchain_monitor import (
    monitor_chain, monitor_llm, monitor_langgraph,
    get_monitored_callback_manager
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def demo_langchain_monitoring():
    """LangChain ëª¨ë‹ˆí„°ë§ ë°ëª¨"""
    if not LANGCHAIN_AVAILABLE:
        print("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë°ëª¨ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸš€ LangChain ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    # ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸
    monitor = get_langfuse_monitor()
    if not monitor.is_enabled():
        print("âš ï¸ Langfuse ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        print("í™˜ê²½ ë³€ìˆ˜ LANGFUSE_PUBLIC_KEYì™€ LANGFUSE_SECRET_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    print("âœ… Langfuse ëª¨ë‹ˆí„°ë§ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    try:
        # OpenAI LLM ì´ˆê¸°í™” (API í‚¤ í•„ìš”)
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ì‹¤ì œ LLM í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        # LLM ìƒì„± ë° ëª¨ë‹ˆí„°ë§ ì ìš©
        llm = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo")
        monitored_llm = monitor_llm(llm, name="legal_assistant")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
        prompt_template = PromptTemplate(
            input_variables=["question"],
            template="ë‹¤ìŒ ë²•ë¥  ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”: {question}"
        )
        
        # ì²´ì¸ ìƒì„± ë° ëª¨ë‹ˆí„°ë§ ì ìš©
        chain = LLMChain(llm=monitored_llm, prompt=prompt_template)
        monitored_chain = monitor_chain(chain, name="legal_qa_chain")
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì†í•´ë°°ìƒ ì²­êµ¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            "ë¶€ë™ì‚° ë§¤ë§¤ ê³„ì•½ì˜ í•„ìˆ˜ ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ ì§ˆë¬¸ {i}: {question}")
            
            try:
                # ì²´ì¸ ì‹¤í–‰ (ëª¨ë‹ˆí„°ë§ í¬í•¨)
                result = monitored_chain.run(
                    question=question,
                    user_id=f"demo_user_{i}",
                    session_id="demo_session"
                )
                
                print(f"âœ… ë‹µë³€: {result[:100]}...")
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("\nâœ… LangChain ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì™„ë£Œ")
        print("Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def demo_langgraph_monitoring():
    """LangGraph ëª¨ë‹ˆí„°ë§ ë°ëª¨"""
    if not LANGGRAPH_AVAILABLE:
        print("LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë°ëª¨ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\nğŸš€ LangGraph ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    # ëª¨ë‹ˆí„°ë§ ìƒíƒœ í™•ì¸
    monitor = get_langfuse_monitor()
    if not monitor.is_enabled():
        print("âš ï¸ Langfuse ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return
    
    try:
        # ê°„ë‹¨í•œ ìƒíƒœ ì •ì˜
        from typing import TypedDict
        
        class LegalState(TypedDict):
            question: str
            analysis: str
            answer: str
            confidence: float
        
        # ë…¸ë“œ í•¨ìˆ˜ë“¤ ì •ì˜
        def analyze_question(state: LegalState) -> LegalState:
            """ì§ˆë¬¸ ë¶„ì„ ë…¸ë“œ"""
            question = state["question"]
            analysis = f"ì§ˆë¬¸ '{question}'ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤."
            
            return {
                **state,
                "analysis": analysis
            }
        
        def generate_answer(state: LegalState) -> LegalState:
            """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
            question = state["question"]
            analysis = state["analysis"]
            
            # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ì‹¤ì œë¡œëŠ” LLM ì‚¬ìš©)
            answer = f"ì§ˆë¬¸ '{question}'ì— ëŒ€í•œ ë‹µë³€: ì´ëŠ” ë²•ë¥  ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
            confidence = 0.8
            
            return {
                **state,
                "answer": answer,
                "confidence": confidence
            }
        
        # ê·¸ë˜í”„ êµ¬ì„±
        workflow = StateGraph(LegalState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze", analyze_question)
        workflow.add_node("generate", generate_answer)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.add_edge("analyze", "generate")
        workflow.add_edge("generate", END)
        
        # ì‹œì‘ì  ì„¤ì •
        workflow.set_entry_point("analyze")
        
        # ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ëª¨ë‹ˆí„°ë§ ì ìš©
        monitored_graph = monitor_langgraph(workflow, name="legal_workflow")
        compiled_graph = monitored_graph.compile()
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_inputs = [
            {"question": "ê³„ì•½ì„œ ì‘ì„± ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"},
            {"question": "ì†í•´ë°°ìƒ ì²­êµ¬ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"},
            {"question": "ë¶€ë™ì‚° ë§¤ë§¤ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?"}
        ]
        
        for i, input_data in enumerate(test_inputs, 1):
            print(f"\nğŸ“ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ {i}: {input_data['question']}")
            
            try:
                # ê·¸ë˜í”„ ì‹¤í–‰ (ëª¨ë‹ˆí„°ë§ í¬í•¨)
                result = monitored_graph.invoke(
                    input_data,
                    user_id=f"demo_user_{i}",
                    session_id="demo_session"
                )
                
                print(f"âœ… ë¶„ì„: {result['analysis']}")
                print(f"âœ… ë‹µë³€: {result['answer']}")
                print(f"âœ… ì‹ ë¢°ë„: {result['confidence']}")
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("\nâœ… LangGraph ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì™„ë£Œ")
        print("Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ì›Œí¬í”Œë¡œìš° íŠ¸ë ˆì´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"âŒ ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def demo_custom_monitoring():
    """ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ ë°ëª¨"""
    print("\nğŸš€ ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    monitor = get_langfuse_monitor()
    if not monitor.is_enabled():
        print("âš ï¸ Langfuse ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return
    
    try:
        # ì»¤ìŠ¤í…€ íŠ¸ë ˆì´ìŠ¤ ìƒì„±
        trace = monitor.create_trace(
            name="custom_legal_analysis",
            user_id="demo_user",
            session_id="custom_demo"
        )
        
        if trace:
            print(f"âœ… íŠ¸ë ˆì´ìŠ¤ ìƒì„±ë¨: {trace.id}")
            
            # ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ ë¡œê¹…
            monitor.log_event(
                trace_id=trace.id,
                name="question_received",
                input_data={"question": "ê³„ì•½ì„œ ê²€í†  ìš”ì²­"},
                metadata={"source": "demo"}
            )
            
            # ì»¤ìŠ¤í…€ ìƒì„± ë¡œê¹…
            monitor.log_generation(
                trace_id=trace.id,
                name="legal_analysis",
                input_data={"question": "ê³„ì•½ì„œ ê²€í†  ìš”ì²­"},
                output_data={"analysis": "ê³„ì•½ì„œ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."},
                metadata={"model": "custom", "confidence": 0.9}
            )
            
            # ë°ì´í„° í”ŒëŸ¬ì‹œ
            monitor.flush()
            
            print("âœ… ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ ë°ëª¨ í•¨ìˆ˜"""
    print("ğŸ” Langfuse ëª¨ë‹ˆí„°ë§ ë°ëª¨")
    print("=" * 60)
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_vars = ["LANGFUSE_PUBLIC_KEY", "LANGFUSE_SECRET_KEY"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âš ï¸ ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
        print("langfuse.env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•˜ì„¸ìš”.")
        print("\nëª¨ë‹ˆí„°ë§ ì—†ì´ ë°ëª¨ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    
    # ë°ëª¨ ì‹¤í–‰
    demo_langchain_monitoring()
    demo_langgraph_monitoring()
    demo_custom_monitoring()
    
    print("\nğŸ‰ ëª¨ë“  ë°ëª¨ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
