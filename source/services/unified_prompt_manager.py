# -*- coding: utf-8 -*-
"""
í†µí•© í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
ë²•ë¥  ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸ì˜ í†µí•© ê´€ë¦¬ ë° ìµœì í™”
"""

import json
import logging
import os
import sys
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# ìƒëŒ€ import ë¬¸ì œ í•´ê²°
try:
    from .question_classifier import QuestionType
except ImportError:
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from question_classifier import QuestionType

logger = logging.getLogger(__name__)


class LegalDomain(Enum):
    """ë²•ë¥  ë„ë©”ì¸ ë¶„ë¥˜"""
    CIVIL_LAW = "ë¯¼ì‚¬ë²•"
    CRIMINAL_LAW = "í˜•ì‚¬ë²•"
    FAMILY_LAW = "ê°€ì¡±ë²•"
    COMMERCIAL_LAW = "ìƒì‚¬ë²•"
    ADMINISTRATIVE_LAW = "í–‰ì •ë²•"
    LABOR_LAW = "ë…¸ë™ë²•"
    PROPERTY_LAW = "ë¶€ë™ì‚°ë²•"
    INTELLECTUAL_PROPERTY = "ì§€ì ì¬ì‚°ê¶Œë²•"
    TAX_LAW = "ì„¸ë²•"
    CIVIL_PROCEDURE = "ë¯¼ì‚¬ì†Œì†¡ë²•"
    CRIMINAL_PROCEDURE = "í˜•ì‚¬ì†Œì†¡ë²•"
    GENERAL = "ê¸°íƒ€/ì¼ë°˜"


class ModelType(Enum):
    """ì§€ì› ëª¨ë¸ íƒ€ì…"""
    GEMINI = "gemini"
    OLLAMA = "ollama"
    OPENAI = "openai"


class UnifiedPromptManager:
    """í†µí•© í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self, prompts_dir: str = "streamlit/prompts"):
        """í†µí•© í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self.prompts_dir = Path(prompts_dir)
        # ì„±ëŠ¥ ìµœì í™”: ë””ë ‰í† ë¦¬ ìƒì„±ì€ ì‹¤ì œ ì‚¬ìš© ì‹œì ìœ¼ë¡œ ì§€ì—°
        # self.prompts_dir.mkdir(parents=True, exist_ok=True)  # ì œê±°

        # ì„±ëŠ¥ ìµœì í™”: í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì§€ì—° (ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ë¡œë“œ)
        self._base_prompts = None
        self._domain_templates = None
        self._question_type_templates = None
        self._model_optimizations = None
        self._prompts_loaded = False

        try:
            logger.debug("UnifiedPromptManager initialized (lazy loading enabled)")
        except Exception:
            # ë¡œê¹… ì˜¤ë¥˜ë¥¼ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            pass

    def _ensure_prompts_loaded(self):
        """í”„ë¡¬í”„íŠ¸ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ (ì§€ì—° ë¡œë”©)"""
        if not self._prompts_loaded:
            # ë””ë ‰í† ë¦¬ ìƒì„± (í•„ìš”í•œ ê²½ìš°)
            self.prompts_dir.mkdir(parents=True, exist_ok=True)
            
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            self._base_prompts = self._load_base_prompts()
            self._domain_templates = self._load_domain_templates()
            self._question_type_templates = self._load_question_type_templates()
            self._model_optimizations = self._load_model_optimizations()
            self._prompts_loaded = True
            logger.debug("UnifiedPromptManager prompts loaded")

    @property
    def base_prompts(self) -> Dict[str, str]:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ì§€ì—° ë¡œë”©)"""
        self._ensure_prompts_loaded()
        return self._base_prompts

    @property
    def domain_templates(self) -> Dict[LegalDomain, Dict[str, Any]]:
        """ë„ë©”ì¸ í…œí”Œë¦¿ (ì§€ì—° ë¡œë”©)"""
        self._ensure_prompts_loaded()
        return self._domain_templates

    @property
    def question_type_templates(self) -> Dict[QuestionType, Dict[str, Any]]:
        """ì§ˆë¬¸ ìœ í˜• í…œí”Œë¦¿ (ì§€ì—° ë¡œë”©)"""
        self._ensure_prompts_loaded()
        return self._question_type_templates

    @property
    def model_optimizations(self) -> Dict[ModelType, Dict[str, Any]]:
        """ëª¨ë¸ ìµœì í™” ì„¤ì • (ì§€ì—° ë¡œë”©)"""
        self._ensure_prompts_loaded()
        return self._model_optimizations

    def _load_base_prompts(self) -> Dict[str, str]:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ - JSON íŒŒì¼ ìš°ì„ , ì—†ìœ¼ë©´ í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©"""
        base_prompts = {}

        # JSON íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹œë„
        # korean_legal_expert -> legal_expert_v1.0.json
        korean_legal_expert = self._load_prompt_from_json("legal_expert_v1.0.json")
        if korean_legal_expert:
            base_prompts["korean_legal_expert"] = korean_legal_expert
            logger.info("âœ… Loaded korean_legal_expert prompt from legal_expert_v1.0.json")
        else:
            base_prompts["korean_legal_expert"] = self._get_korean_legal_expert_prompt()
            logger.info("âš ï¸ Using hardcoded korean_legal_expert prompt (JSON not found)")

        # natural_consultant -> natural_legal_consultant_v1.0.json
        natural_consultant = self._load_prompt_from_json("natural_legal_consultant_v1.0.json")
        if natural_consultant:
            base_prompts["natural_consultant"] = natural_consultant
            logger.info("âœ… Loaded natural_consultant prompt from natural_legal_consultant_v1.0.json")
        else:
            base_prompts["natural_consultant"] = self._get_natural_consultant_prompt()
            logger.info("âš ï¸ Using hardcoded natural_consultant prompt (JSON not found)")

        # professional_advisorëŠ” í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (JSON íŒŒì¼ì´ ì—†ìŒ)
        base_prompts["professional_advisor"] = self._get_professional_advisor_prompt()

        return base_prompts

    def _load_prompt_from_json(self, filename: str) -> Optional[str]:
        """JSON íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        try:
            prompt_file = self.prompts_dir / filename
            if prompt_file.exists():
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    content = data.get('content', '')
                    if content:
                        logger.debug(f"âœ… Loaded prompt from {filename}")
                        return content
                    else:
                        logger.warning(f"âš ï¸ {filename} exists but 'content' field is empty")
                        return None
            else:
                logger.debug(f"â„¹ï¸ {filename} not found in {self.prompts_dir}")
                return None
        except Exception as e:
            logger.error(f"âŒ Failed to load prompt from {filename}: {e}")
            return None

    def _load_domain_templates(self) -> Dict[LegalDomain, Dict[str, Any]]:
        """ë„ë©”ì¸ë³„ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            LegalDomain.CIVIL_LAW: {
                "focus": "ê³„ì•½, ë¶ˆë²•í–‰ìœ„, ì†Œìœ ê¶Œ, ìƒì†",
                "key_laws": ["ë¯¼ë²•", "ë¯¼ì‚¬ì†Œì†¡ë²•", "ë¶€ë™ì‚°ë“±ê¸°ë²•"],
                "recent_changes": "2024ë…„ ë¯¼ë²• ê°œì •ì‚¬í•­ ë°˜ì˜",
                "template": self._get_civil_law_template()
            },
            LegalDomain.CRIMINAL_LAW: {
                "focus": "ë²”ì£„ êµ¬ì„±ìš”ê±´, í˜•ëŸ‰, ì ˆì°¨",
                "key_laws": ["í˜•ë²•", "í˜•ì‚¬ì†Œì†¡ë²•", "íŠ¹ë³„ë²•"],
                "recent_changes": "ë””ì§€í„¸ ì„±ë²”ì£„ ì²˜ë²Œë²• ë“± ì‹ ì„¤ë²•",
                "template": self._get_criminal_law_template()
            },
            LegalDomain.FAMILY_LAW: {
                "focus": "í˜¼ì¸, ì´í˜¼, ì¹œìê´€ê³„, ìƒì†",
                "key_laws": ["ë¯¼ë²• ê°€ì¡±í¸", "ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ë²•ë¥ "],
                "recent_changes": "2024ë…„ ê°€ì¡±ë²• ê°œì •ì‚¬í•­",
                "template": self._get_family_law_template()
            },
            LegalDomain.COMMERCIAL_LAW: {
                "focus": "íšŒì‚¬ë²•, ìƒí–‰ìœ„, ì–´ìŒìˆ˜í‘œ",
                "key_laws": ["ìƒë²•", "ì£¼ì‹íšŒì‚¬ë²•", "ì–´ìŒë²•"],
                "recent_changes": "2024ë…„ ìƒë²• ê°œì •ì‚¬í•­",
                "template": self._get_commercial_law_template()
            },
            LegalDomain.ADMINISTRATIVE_LAW: {
                "focus": "í–‰ì •í–‰ìœ„, í–‰ì •ì ˆì°¨, í–‰ì •ì†Œì†¡",
                "key_laws": ["í–‰ì •ì ˆì°¨ë²•", "í–‰ì •ì†Œì†¡ë²•", "í–‰ì •ë²•"],
                "recent_changes": "2024ë…„ í–‰ì •ë²• ê°œì •ì‚¬í•­",
                "template": self._get_administrative_law_template()
            },
            LegalDomain.LABOR_LAW: {
                "focus": "ê·¼ë¡œê³„ì•½, ì„ê¸ˆ, ê·¼ë¡œì‹œê°„, íœ´ê°€",
                "key_laws": ["ê·¼ë¡œê¸°ì¤€ë²•", "ë…¸ë™ì¡°í•©ë²•", "ê³ ìš©ë³´í—˜ë²•"],
                "recent_changes": "2024ë…„ ë…¸ë™ë²• ê°œì •ì‚¬í•­",
                "template": self._get_labor_law_template()
            },
            LegalDomain.PROPERTY_LAW: {
                "focus": "ë¶€ë™ì‚° ê³„ì•½, ë“±ê¸°, ê¶Œë¦¬ë³´í˜¸",
                "key_laws": ["ë¶€ë™ì‚°ë“±ê¸°ë²•", "ë¶€ë™ì‚° ì‹¤ê¶Œë¦¬ìëª…ì˜ ë“±ê¸°ì— ê´€í•œ ë²•ë¥ "],
                "recent_changes": "2024ë…„ ë¶€ë™ì‚°ë²• ê°œì •ì‚¬í•­",
                "template": self._get_property_law_template()
            },
            LegalDomain.INTELLECTUAL_PROPERTY: {
                "focus": "íŠ¹í—ˆ, ìƒí‘œ, ì €ì‘ê¶Œ, ë””ìì¸",
                "key_laws": ["íŠ¹í—ˆë²•", "ìƒí‘œë²•", "ì €ì‘ê¶Œë²•", "ë””ìì¸ë³´í˜¸ë²•"],
                "recent_changes": "2024ë…„ ì§€ì ì¬ì‚°ê¶Œë²• ê°œì •ì‚¬í•­",
                "template": self._get_intellectual_property_template()
            },
            LegalDomain.TAX_LAW: {
                "focus": "ì†Œë“ì„¸, ë²•ì¸ì„¸, ë¶€ê°€ê°€ì¹˜ì„¸",
                "key_laws": ["ì†Œë“ì„¸ë²•", "ë²•ì¸ì„¸ë²•", "ë¶€ê°€ê°€ì¹˜ì„¸ë²•"],
                "recent_changes": "2024ë…„ ì„¸ë²• ê°œì •ì‚¬í•­",
                "template": self._get_tax_law_template()
            },
            LegalDomain.CIVIL_PROCEDURE: {
                "focus": "ë¯¼ì‚¬ì†Œì†¡ ì ˆì°¨, ì¦ê±°, ì§‘í–‰",
                "key_laws": ["ë¯¼ì‚¬ì†Œì†¡ë²•", "ë¯¼ì‚¬ì§‘í–‰ë²•", "ê°€ì‚¬ì†Œì†¡ë²•"],
                "recent_changes": "2024ë…„ ë¯¼ì‚¬ì†Œì†¡ë²• ê°œì •ì‚¬í•­",
                "template": self._get_civil_procedure_template()
            },
            LegalDomain.CRIMINAL_PROCEDURE: {
                "focus": "í˜•ì‚¬ì†Œì†¡ ì ˆì°¨, ìˆ˜ì‚¬, ì¬íŒ",
                "key_laws": ["í˜•ì‚¬ì†Œì†¡ë²•", "ìˆ˜ì‚¬ì ˆì°¨ë²•"],
                "recent_changes": "2024ë…„ í˜•ì‚¬ì†Œì†¡ë²• ê°œì •ì‚¬í•­",
                "template": self._get_criminal_procedure_template()
            }
        }

    def _load_question_type_templates(self) -> Dict[QuestionType, Dict[str, Any]]:
        """ì§ˆë¬¸ ìœ í˜•ë³„ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            QuestionType.PRECEDENT_SEARCH: {
                "template": self._get_precedent_search_template(),
                "context_keys": ["precedent_list"],
                "max_context_length": 3000,
                "priority": "high"
            },
            QuestionType.LAW_INQUIRY: {
                "template": self._get_law_inquiry_template(),
                "context_keys": ["law_articles"],
                "max_context_length": 2000,
                "priority": "high"
            },
            QuestionType.LEGAL_ADVICE: {
                "template": self._get_legal_advice_template(),
                "context_keys": ["context"],
                "max_context_length": 4000,
                "priority": "high"
            },
            QuestionType.PROCEDURE_GUIDE: {
                "template": self._get_procedure_guide_template(),
                "context_keys": ["procedure_info"],
                "max_context_length": 2500,
                "priority": "medium"
            },
            QuestionType.TERM_EXPLANATION: {
                "template": self._get_term_explanation_template(),
                "context_keys": ["term_info"],
                "max_context_length": 1500,
                "priority": "medium"
            },
            QuestionType.GENERAL_QUESTION: {
                "template": self._get_general_question_template(),
                "context_keys": ["general_context"],
                "max_context_length": 2000,
                "priority": "low"
            }
        }

    def _load_model_optimizations(self) -> Dict[ModelType, Dict[str, Any]]:
        """ëª¨ë¸ë³„ ìµœì í™” ì„¤ì • ë¡œë“œ"""
        return {
            ModelType.GEMINI: {
                "max_tokens": 8192,
                "temperature": 0.3,
                "system_prompt_style": "structured",
                "context_window": 0.8
            },
            ModelType.OLLAMA: {
                "max_tokens": 4096,
                "temperature": 0.2,
                "system_prompt_style": "conversational",
                "context_window": 0.7
            },
            ModelType.OPENAI: {
                "max_tokens": 4096,
                "temperature": 0.1,
                "system_prompt_style": "professional",
                "context_window": 0.9
            }
        }

    def get_optimized_prompt(self,
                           query: str,
                           question_type: QuestionType,
                           domain: Optional[LegalDomain] = None,
                           context: Optional[Dict[str, Any]] = None,
                           model_type: ModelType = ModelType.GEMINI,
                           base_prompt_type: str = "korean_legal_expert") -> str:
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            # Domain íƒ€ì… ì •ê·œí™” (ë¬¸ìì—´ì„ LegalDomain enumìœ¼ë¡œ ë³€í™˜)
            normalized_domain = self._normalize_legal_domain(domain)

            # Base prompt type ë™ì  ì„ íƒ (ì§€ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ "auto"ì¸ ê²½ìš°)
            if not base_prompt_type or base_prompt_type == "auto":
                base_prompt_type = self._select_base_prompt_type(question_type, normalized_domain)

            # ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í…œí”Œë¦¿ ë¡œê¹…
            logger.info(
                f"ğŸ“‹ [PROMPT TEMPLATE] Using templates: "
                f"base={base_prompt_type}, "
                f"domain={normalized_domain.value if normalized_domain else 'None'}, "
                f"question_type={question_type.name if hasattr(question_type, 'name') else question_type}, "
                f"model={model_type.value if hasattr(model_type, 'value') else model_type}"
            )

            # 1. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (propertyë¡œ ì§€ì—° ë¡œë”©)
            base_prompts = self.base_prompts  # property ì ‘ê·¼ìœ¼ë¡œ ì§€ì—° ë¡œë”© íŠ¸ë¦¬ê±°
            base_prompt = base_prompts.get(base_prompt_type, base_prompts["korean_legal_expert"])

            # 2. ë„ë©”ì¸ íŠ¹í™” ê°•í™” (ì •ê·œí™”ëœ domain ì‚¬ìš©, propertyë¡œ ì§€ì—° ë¡œë”©)
            domain_templates = self.domain_templates  # property ì ‘ê·¼ìœ¼ë¡œ ì§€ì—° ë¡œë”© íŠ¸ë¦¬ê±°
            if normalized_domain and normalized_domain in domain_templates:
                domain_info = domain_templates[normalized_domain]
                base_prompt = self._add_domain_specificity(base_prompt, domain_info)
                logger.info(f"âœ… [DOMAIN TEMPLATE] Applied domain template: {normalized_domain.value}")
            elif normalized_domain:
                logger.warning(f"âš ï¸ [DOMAIN TEMPLATE] Domain template not found for: {normalized_domain.value}")
            else:
                logger.debug("â„¹ï¸ [DOMAIN TEMPLATE] No domain specified, skipping domain template")

            # 3. ì§ˆë¬¸ ìœ í˜•ë³„ êµ¬ì¡°í™” (propertyë¡œ ì§€ì—° ë¡œë”©)
            question_type_templates = self.question_type_templates  # property ì ‘ê·¼ìœ¼ë¡œ ì§€ì—° ë¡œë”© íŠ¸ë¦¬ê±°
            question_template = question_type_templates.get(question_type)
            if question_template:
                base_prompt = self._add_question_structure(base_prompt, question_template)
                logger.info(
                    f"âœ… [QUESTION TEMPLATE] Applied question type template: "
                    f"{question_type.name if hasattr(question_type, 'name') else question_type}, "
                    f"priority={question_template.get('priority', 'unknown')}"
                )
            else:
                logger.warning(
                    f"âš ï¸ [QUESTION TEMPLATE] Question type template not found for: "
                    f"{question_type.name if hasattr(question_type, 'name') else question_type}"
                )

            # 4. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”
            if context:
                base_prompt = self._optimize_context(base_prompt, context, question_template)

            # 5. ëª¨ë¸ë³„ ìµœì í™” (propertyë¡œ ì§€ì—° ë¡œë”©)
            model_optimizations = self.model_optimizations  # property ì ‘ê·¼ìœ¼ë¡œ ì§€ì—° ë¡œë”© íŠ¸ë¦¬ê±°
            model_config = model_optimizations.get(model_type)
            if model_config:
                base_prompt = self._model_specific_optimization(base_prompt, model_config)
                logger.info(
                    f"âœ… [MODEL OPTIMIZATION] Applied model optimization: "
                    f"{model_type.value if hasattr(model_type, 'value') else model_type}, "
                    f"temperature={model_config.get('temperature', 'unknown')}, "
                    f"max_tokens={model_config.get('max_tokens', 'unknown')}"
                )
            else:
                logger.warning(
                    f"âš ï¸ [MODEL OPTIMIZATION] Model optimization not found for: "
                    f"{model_type.value if hasattr(model_type, 'value') else model_type}"
                )

            # 6. ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            final_prompt = self._build_final_prompt(base_prompt, query, context, question_type)

            # 7. í”„ë¡¬í”„íŠ¸ ê²€ì¦: ë¬¸ì„œ ë‚´ìš©ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ê°•í™”ëœ ê²€ì¦)
            validation_result = self._validate_prompt_contains_documents(final_prompt, context)
            if not validation_result["has_document_content"]:
                doc_count_in_context = validation_result.get("document_count_in_context", 0)
                doc_count = context.get("document_count", 0) if context else 0
                doc_count = doc_count or doc_count_in_context

                if doc_count > 0:
                    logger.warning(
                        f"âš ï¸ [PROMPT VALIDATION] Final prompt does not contain document content "
                        f"despite having {doc_count} documents in context. "
                        f"Prompt length: {len(final_prompt)} chars, "
                        f"Context text length: {validation_result.get('context_text_length', 0)} chars"
                    )

                    # ê²€ì¦ ìƒì„¸ ì •ë³´ ë¡œê¹…
                    validation_details = validation_result.get("validation_details", [])
                    if validation_details:
                        logger.debug(
                            f"ğŸ“‹ [PROMPT VALIDATION] Details: "
                            f"{sum(1 for d in validation_details if d.get('found_in_prompt'))}/{len(validation_details)} "
                            f"documents found in prompt"
                        )
                else:
                    logger.info(
                        f"â„¹ï¸ [PROMPT VALIDATION] No documents in context "
                        f"(document_count: {doc_count}, context_count: {doc_count_in_context})"
                    )
            else:
                # ê²€ì¦ ì„±ê³µ ë¡œê¹…
                doc_count_in_prompt = validation_result.get("document_count_in_prompt", 0)
                doc_count_in_context = validation_result.get("document_count_in_context", 0)
                logger.info(
                    f"âœ… [PROMPT VALIDATION] Document content found in prompt: "
                    f"{doc_count_in_prompt}/{doc_count_in_context} documents included"
                )

            return final_prompt

        except Exception as e:
            logger.error(f"Error generating optimized prompt: {e}")
            return self._get_fallback_prompt(query)

    def _add_domain_specificity(self, base_prompt: str, domain_info: Dict[str, Any]) -> str:
        """ë„ë©”ì¸ íŠ¹í™” ê°•í™” - ë‹µë³€ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ê°œì„ """
        domain_specificity = f"""

## ë„ë©”ì¸ íŠ¹í™” ì§€ì¹¨
- **ê´€ë ¨ ë¶„ì•¼**: {domain_info['focus']}
- **ì£¼ìš” ë²•ë ¹**: {', '.join(domain_info['key_laws'])}
- **ìµœì‹  ê°œì •ì‚¬í•­**: {domain_info['recent_changes']}

### ë‹µë³€ í’ˆì§ˆ í–¥ìƒ ìš”êµ¬ì‚¬í•­
1. **ë²•ì  ì •í™•ì„±**: ê´€ë ¨ ë²•ë ¹ì˜ ì •í™•í•œ ì¡°ë¬¸ ì¸ìš© í•„ìˆ˜
2. **íŒë¡€ í™œìš©**: ìµœì‹  ëŒ€ë²•ì› íŒë¡€ ë° í•˜ê¸‰ì‹¬ íŒë¡€ ì ê·¹ í™œìš©
3. **ì‹¤ë¬´ ê´€ì **: ì‹¤ì œ ë²•ì›, ê²€ì°°, ë²•ë¬´ë¶€ ì‹¤ë¬´ ê¸°ì¤€ ë°˜ì˜
4. **êµ¬ì²´ì  ì¡°ì–¸**: ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ
5. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: ë²•ì  ë¦¬ìŠ¤í¬ì™€ ì£¼ì˜ì‚¬í•­ ëª…í™•íˆ ì œì‹œ

{domain_info['template']}
"""
        return base_prompt + domain_specificity

    def _add_question_structure(self, base_prompt: str, question_template: Dict[str, Any]) -> str:
        """ì§ˆë¬¸ ìœ í˜•ë³„ êµ¬ì¡°í™” - ë‹µë³€ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ê°œì„ """
        structure_guidance = f"""

## ë‹µë³€ êµ¬ì¡° ê°€ì´ë“œ
{question_template['template']}

## ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬
- ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {question_template['max_context_length']}ì
- ìš°ì„ ìˆœìœ„: {question_template['priority']}

### ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
1. **ì™„ì„±ë„**: ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ ì œê³µ ì—¬ë¶€
2. **ì •í™•ì„±**: ë²•ì  ì •ë³´ì˜ ì •í™•ì„± ë° ìµœì‹ ì„± í™•ì¸
3. **êµ¬ì¡°í™”**: ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ë‹µë³€ êµ¬ì¡°
4. **ì‹¤ìš©ì„±**: ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸ í¬í•¨
5. **ì‹ ë¢°ì„±**: ê·¼ê±° ìˆëŠ” ë²•ì  ë¶„ì„ ë° íŒë¡€ ì¸ìš©
"""
        return base_prompt + structure_guidance

    def _optimize_context(self, base_prompt: str, context: Dict[str, Any], question_template: Optional[Dict[str, Any]]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ìµœì í™” - ë¬¸ì„œ ë° ë°ì´í„°ë² ì´ìŠ¤ ê²°ê³¼ ê°•ì œ í¬í•¨"""
        if not context:
            return base_prompt

        if question_template is None:
            question_template = {}

        max_length = question_template.get('max_context_length', 5000)  # ê¸°ë³¸ê°’ ì¦ê°€: 2000 -> 5000
        context_keys = question_template.get('context_keys', [])

        optimized_context = {}

        # 1. context_keysì— ì§€ì •ëœ í‚¤ í¬í•¨
        for key in context_keys:
            if key in context:
                content = context[key]
                if isinstance(content, str) and len(content) > max_length:
                    content = content[:max_length] + "..."
                optimized_context[key] = content

        # 2. prompt_optimized_textê°€ ìˆìœ¼ë©´ contextë¡œ ë³€í™˜ (ìµœìš°ì„ )
        if "prompt_optimized_text" in context:
            prompt_text = context["prompt_optimized_text"]
            if prompt_text and len(prompt_text.strip()) > 0:
                # prompt_optimized_textë¥¼ contextë¡œ ì‚¬ìš© (ë¬¸ì„œ ë‚´ìš© í¬í•¨)
                if len(prompt_text) > max_length * 2:  # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ëŠ” ë” ê¸´ ê¸¸ì´ í—ˆìš©
                    prompt_text = prompt_text[:max_length * 2] + "..."
                optimized_context["context"] = prompt_text
                logger.info(f"âœ… [CONTEXT OPTIMIZATION] Using prompt_optimized_text as context ({len(prompt_text)} chars)")

                # âš ï¸ ì¤‘ìš”: prompt_optimized_textë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„ structured_documentsì˜ ë¬¸ì„œ ë‚´ìš©ì„ ê°•ì œë¡œ ì¶”ê°€
                # prompt_optimized_textì— ì´ë¯¸ ë¬¸ì„œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆì§€ë§Œ,
                # structured_documentsì˜ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ì—¬ LLMì´ ëª…í™•í•˜ê²Œ ì¸ì‹í•˜ë„ë¡ í•¨
                structured_docs = context.get("structured_documents", {})
                if isinstance(structured_docs, dict):
                    documents = structured_docs.get("documents", [])
                    if documents:
                        # structured_documentsì˜ ë¬¸ì„œë“¤ì„ contextì— ì¶”ê°€
                        doc_contents = []
                        added_count = 0

                        for doc in documents[:8]:
                            if isinstance(doc, dict):
                                normalized_doc = self._normalize_document_fields(doc)
                                doc_content = normalized_doc.get("content", "")
                                doc_source = normalized_doc.get("source", "Unknown")
                                doc_score = normalized_doc.get("relevance_score", 0.0)

                                if doc_content and len(doc_content.strip()) > 10:
                                    # prompt_optimized_textì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                                    content_preview = doc_content[:100]
                                    # ê°„ë‹¨í•œ ì¤‘ë³µ ì²´í¬: contentì˜ ì¼ë¶€ê°€ prompt_textì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                                    if content_preview not in prompt_text:
                                        # í¬í•¨ë˜ì§€ ì•Šì€ ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
                                        doc_contents.append(
                                            f"\n[ë¬¸ì„œ ì¶œì²˜: {doc_source}] [ê´€ë ¨ë„: {doc_score:.3f}]\n{doc_content[:1000]}"
                                        )
                                        added_count += 1
                                    else:
                                        # ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ structured_documentsì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ ê¸°ë¡
                                        logger.debug(f"Document from {doc_source} already in prompt_optimized_text")

                        if doc_contents:
                            docs_text = "\n\n## ì¶”ê°€ ì°¸ê³  ë¬¸ì„œ\n" + "\n".join(doc_contents)
                            optimized_context["context"] = optimized_context["context"] + docs_text
                            logger.info(
                                f"âœ… [CONTEXT OPTIMIZATION] Added {added_count} additional documents "
                                f"from structured_documents to ensure all search results are included "
                                f"({len(doc_contents)} chars added)"
                            )

                        # structured_documentsë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ (í•­ìƒ)
                        # ì´ëŠ” LLMì´ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•¨
                        normalized_docs = []
                        for doc in documents[:8]:
                            normalized = self._normalize_document_fields(doc)
                            if normalized.get("content"):
                                normalized_docs.append(normalized)

                        if normalized_docs:
                            optimized_context["structured_documents"] = {
                                **structured_docs,
                                "documents": normalized_docs,
                                "total_count": len(normalized_docs)
                            }
                            logger.info(
                                f"âœ… [CONTEXT OPTIMIZATION] Included {len(normalized_docs)} structured_documents "
                                f"in optimized_context for explicit reference"
                            )

        # 3. context í‚¤ í¬í•¨ (prompt_optimized_textê°€ ì—†ëŠ” ê²½ìš°)
        if "context" in context and "context" not in optimized_context:
            content = context["context"]
            if isinstance(content, str) and len(content) > max_length:
                content = content[:max_length] + "..."
            optimized_context["context"] = content

        # 4. structured_documentsì—ì„œ ì‹¤ì œ ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œí•˜ì—¬ contextì— ì¶”ê°€
        structured_docs = context.get("structured_documents", {})
        if isinstance(structured_docs, dict):
            documents = structured_docs.get("documents", [])
            if documents:
                doc_contents = []
                valid_doc_count = 0

                for doc in documents[:8]:  # ìƒìœ„ 8ê°œ ë¬¸ì„œ
                    if isinstance(doc, dict):
                        # ë¬¸ì„œ í•„ë“œ ì •ê·œí™”
                        normalized_doc = self._normalize_document_fields(doc)
                        doc_content = normalized_doc.get("content", "")
                        doc_source = normalized_doc.get("source", "Unknown")
                        doc_score = normalized_doc.get("relevance_score", 0.0)

                        if doc_content and len(doc_content.strip()) > 10:
                            doc_contents.append(
                                f"\n[ë¬¸ì„œ ì¶œì²˜: {doc_source}] [ê´€ë ¨ë„: {doc_score:.3f}]\n{doc_content[:1000]}"  # ê° ë¬¸ì„œ ìµœëŒ€ 1000ì
                            )
                            valid_doc_count += 1

                if doc_contents:
                    docs_text = "\n".join(doc_contents)
                    # ê¸°ì¡´ contextì— ë¬¸ì„œ ë‚´ìš© ì¶”ê°€ ë˜ëŠ” êµì²´
                    if "context" in optimized_context:
                        optimized_context["context"] = optimized_context["context"] + "\n\n" + docs_text
                    else:
                        optimized_context["context"] = docs_text
                    logger.info(
                        f"âœ… [CONTEXT OPTIMIZATION] Added {valid_doc_count}/{len(documents)} valid documents "
                        f"from structured_documents ({len(docs_text)} chars)"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ [CONTEXT OPTIMIZATION] No valid document content found in {len(documents)} documents"
                    )

                # structured_documentsë¥¼ optimized_contextì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ (ì¤‘ìš”!)
                # ì •ê·œí™”ëœ ë¬¸ì„œë¡œ ì—…ë°ì´íŠ¸
                normalized_docs = []
                for doc in documents[:8]:
                    normalized = self._normalize_document_fields(doc)
                    if normalized.get("content"):
                        normalized_docs.append(normalized)

                if normalized_docs:
                    structured_docs_normalized = {
                        **structured_docs,
                        "documents": normalized_docs,
                        "total_count": len(normalized_docs),
                        "original_count": len(documents)
                    }
                    optimized_context["structured_documents"] = structured_docs_normalized
                    logger.info(
                        f"âœ… [CONTEXT OPTIMIZATION] Included normalized structured_documents "
                        f"in optimized_context ({len(normalized_docs)}/{len(documents)} valid documents)"
                    )
                else:
                    optimized_context["structured_documents"] = structured_docs
                    logger.warning(
                        f"âš ï¸ [CONTEXT OPTIMIZATION] No valid documents after normalization, "
                        f"keeping original structured_documents"
                    )

        # structured_documentsê°€ contextì—ëŠ” ìˆì§€ë§Œ optimized_contextì— ì—†ëŠ” ê²½ìš° ì§ì ‘ ì¶”ê°€
        elif "structured_documents" in context:
            structured_docs = context.get("structured_documents", {})
            if isinstance(structured_docs, dict) and structured_docs.get("documents"):
                optimized_context["structured_documents"] = structured_docs
                logger.info(f"âœ… [CONTEXT OPTIMIZATION] Added structured_documents from original context to optimized_context")

        # 5. context_keysê°€ ë¹„ì–´ìˆìœ¼ë©´ ëª¨ë“  ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ í‚¤ í¬í•¨
        if not context_keys and context:
            for key, value in context.items():
                if key not in ["query_type", "context_length", "docs_truncated", "prompt_optimized_text"]:  # ë©”íƒ€ë°ì´í„° ë° ì´ë¯¸ ì²˜ë¦¬í•œ í‚¤ ì œì™¸
                    if isinstance(value, str) and len(value) > max_length:
                        value = value[:max_length] + "..."
                    if key not in optimized_context:  # ì´ë¯¸ í¬í•¨ëœ í‚¤ëŠ” ì¤‘ë³µ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                        optimized_context[key] = value

        # ì§ˆë¬¸ ìœ í˜•ë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡°í™”
        question_type = context.get("query_type")
        if isinstance(question_type, str):
            # ë¬¸ìì—´ì„ QuestionType enumìœ¼ë¡œ ë³€í™˜
            try:
                question_type_enum = QuestionType[question_type.upper()] if question_type.upper() in [e.name for e in QuestionType] else QuestionType.GENERAL_QUESTION
            except:
                question_type_enum = QuestionType.GENERAL_QUESTION
        elif hasattr(question_type, 'name'):
            question_type_enum = question_type
        else:
            question_type_enum = QuestionType.GENERAL_QUESTION

        structured_context = self._structure_context_by_question_type(optimized_context, question_type_enum)

        # ğŸ”´ ê°œì„ : ë¶ˆí•„ìš”í•œ ì§€ì¹¨ ì„¹ì…˜ ì œê±° (base_promptì— ì´ë¯¸ í¬í•¨ë˜ê±°ë‚˜ _build_final_promptì—ì„œ ì¶”ê°€ë¨)
        context_guidance = f"{structured_context}"
        try:
            sql_schema = context.get("sql_schema")
            if isinstance(sql_schema, str) and len(sql_schema) > 0:
                context_guidance += f"""

### Text-to-SQL ìŠ¤í‚¤ë§ˆ ìš”ì•½
{sql_schema}

### SQL ì‘ì„± ì§€ì¹¨
- SELECTë§Œ ì‚¬ìš©í•˜ì„¸ìš”. DML/DDLì€ ê¸ˆì§€ë©ë‹ˆë‹¤.
- WHERE ì ˆì— ì •í™•í•œ í•„í„°ë¥¼ ëª…ì‹œí•˜ê³ , ë°˜ë“œì‹œ LIMITë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ê²°ê³¼ëŠ” ì¡°ë¬¸/ì‚¬ê±´ë²ˆí˜¸/ì„ ê³ ì¼/ë²•ì›ì„ ê¸°ì¤€ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

### ì˜ˆì‹œ(í•œêµ­ì–´ â†’ SQL)
- ì§ˆì˜: "ë¯¼ë²• ì œ750ì¡° ì¡°ë¬¸ ë³´ì—¬ì¤˜"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%ë¯¼ë²•%' AND article_number = 750 LIMIT 5;
- ì§ˆì˜: "ëŒ€ë²•ì› 2021ë‹¤12345 ì‚¬ê±´ ìš”ì§€"
  SQL: SELECT case_number, court, decision_date, summary FROM cases WHERE case_number = '2021ë‹¤12345' LIMIT 5;
- ì§ˆì˜: "ìµœê·¼ 3ë…„ ë¯¼ì‚¬ ì†í•´ë°°ìƒ íŒê²° ê±´ìˆ˜"
  SQL: SELECT COUNT(*) AS cnt FROM cases WHERE decision_date >= date('now','-3 years');
- ì§ˆì˜: "í˜•ë²• ì œ307ì¡° ì°¾ì•„ì¤˜"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%í˜•ë²•%' AND article_number = 307 LIMIT 5;
- ì§ˆì˜: "ë¯¼ë²• ê°œì • ì´ë ¥ ì¤‘ 2020ë…„ ì´í›„ë§Œ"
  SQL: SELECT law_name, effective_date, description FROM amendments WHERE effective_date >= '2020-01-01' LIMIT 20;
- ì§ˆì˜: "ì‚¬ê±´ 2019ë‹¤12345ê°€ ì¸ìš©í•œ íŒë¡€ ëª©ë¡"
  SQL: SELECT from_case_id, to_case_id FROM case_citations WHERE from_case_id = '2019ë‹¤12345' LIMIT 20;
- ì§ˆì˜: "ìƒë²• ì œ24ì¡° ì „ë¬¸ ë³´ì—¬ì¤˜"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%ìƒë²•%' AND article_number = 24 LIMIT 5;
- ì§ˆì˜: "ì„œìš¸ê³ ë“±ë²•ì› 2022ë…„ ì´í›„ íŒê²° ìš”ì§€ 10ê±´"
  SQL: SELECT case_number, court, decision_date, summary FROM cases WHERE court LIKE '%ê³ ë“±ë²•ì›%' AND decision_date >= '2022-01-01' LIMIT 10;
- ì§ˆì˜: "ì €ì‘ê¶Œë²• ìµœê·¼ ê°œì • ë‚´ì—­"
  SQL: SELECT law_name, effective_date, description FROM amendments WHERE law_name LIKE '%ì €ì‘ê¶Œë²•%' ORDER BY effective_date DESC LIMIT 20;
- ì§ˆì˜: "ì‚¬ê±´ìš”ì§€ì— 'ì†í•´ë°°ìƒ' í¬í•¨ëœ íŒë¡€ 20ê±´"
  SQL: SELECT case_number, court, decision_date, summary FROM cases WHERE summary LIKE '%ì†í•´ë°°ìƒ%' LIMIT 20;
- ì§ˆì˜: "ë¯¼ë²• ê´€ë ¨ ì¡°ë¬¸ ì¤‘ 'ë¶ˆë²•í–‰ìœ„' í¬í•¨ ë³¸ë¬¸"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%ë¯¼ë²•%' AND content LIKE '%ë¶ˆë²•í–‰ìœ„%' LIMIT 20;
- ì§ˆì˜: "ê·¼ë¡œê¸°ì¤€ë²• ì œ60ì¡° ì—°ì°¨ ê·œì •"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%ê·¼ë¡œê¸°ì¤€ë²•%' AND article_number = 60 LIMIT 5;
- ì§ˆì˜: "ê³ ìš©ë…¸ë™ë¶€ ê´€ë ¨ íŒë¡€ 2021ë…„ ì´í›„"
  SQL: SELECT case_number, court, decision_date, summary FROM cases WHERE summary LIKE '%ê³ ìš©ë…¸ë™ë¶€%' AND decision_date >= '2021-01-01' LIMIT 20;
- ì§ˆì˜: "ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì„¸ê¸ˆê³„ì‚°ì„œ ê´€ë ¨ ì¡°ë¬¸"
  SQL: SELECT law_name, article_number, content FROM articles WHERE law_name LIKE '%ë¶€ê°€ê°€ì¹˜ì„¸ë²•%' AND content LIKE '%ì„¸ê¸ˆê³„ì‚°ì„œ%' LIMIT 20;
- ì§ˆì˜: "í–‰ì •ì ˆì°¨ë²• ìµœê·¼ ê°œì •ì‚¬í•­"
  SQL: SELECT law_name, effective_date, description FROM amendments WHERE law_name LIKE '%í–‰ì •ì ˆì°¨ë²•%' ORDER BY effective_date DESC LIMIT 20;
- ì§ˆì˜: "ì‚°ì¬ ë³´ìƒ' í¬í•¨ íŒë¡€ 10ê±´"
  SQL: SELECT case_number, court, decision_date, summary FROM cases WHERE summary LIKE '%ì‚°ì¬ ë³´ìƒ%' LIMIT 10;
"""
        except Exception:
            pass

        context_guidance += """

### ë‹µë³€ ì‘ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í–ˆëŠ”ê°€?
- [ ] ë²•ë¥  ì¡°í•­ì´ë‚˜ íŒë¡€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í–ˆëŠ”ê°€?
- [ ] ì¶œì²˜ë¥¼ ëª…ì‹œí–ˆëŠ”ê°€?
"""
        return base_prompt + context_guidance

    def _simplify_prompt_for_no_results(self, base_prompt: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™” - í”„ë¡¬í”„íŠ¸ ì¶œë ¥ ë°©ì§€"""
        # base_promptì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ ì§€ì‹œì‚¬í•­ ì œê±°
        # í•µì‹¬ ì—­í• ê³¼ ê¸°ë³¸ ë‹µë³€ ìŠ¤íƒ€ì¼ë§Œ ìœ ì§€

        # í”„ë¡¬í”„íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ í•„í„°ë§
        lines = base_prompt.split('\n')
        simplified_lines = []
        skip_until_next_section = False

        for i, line in enumerate(lines):
            # ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ ì„¹ì…˜ ê±´ë„ˆë›°ê¸°
            if any(keyword in line for keyword in ['ê²€ìƒ‰ ê²°ê³¼', 'ë¬¸ì„œ', 'ì¸ìš©', 'íŒë¡€', 'ì¡°ë¬¸', 'ê²€ìƒ‰ëœ']):
                if '##' in line or '###' in line:  # ì„¹ì…˜ í—¤ë”ì¸ ê²½ìš°
                    skip_until_next_section = True
                    continue

            # ë‹¤ìŒ ì„¹ì…˜ í—¤ë”ë¥¼ ë§Œë‚˜ë©´ ìŠ¤í‚µ ì¤‘ì§€
            if skip_until_next_section and ('##' in line or '---' in line):
                skip_until_next_section = False
                if '---' in line:
                    simplified_lines.append(line)
                continue

            # ìŠ¤í‚µ ì¤‘ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
            if not skip_until_next_section:
                simplified_lines.append(line)

        simplified = '\n'.join(simplified_lines)

        # ê°„ë‹¨í•œ ì—­í•  ì„¤ëª… ì¶”ê°€
        simplified_prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë²•ë¥  ìƒë‹´ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.

## í•µì‹¬ ì—­í• 
ì§ˆë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œ í•œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

## ë‹µë³€ ìŠ¤íƒ€ì¼
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”
- ë²•ë¥  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- ì§ˆë¬¸ì˜ ë²”ìœ„ì— ë§ëŠ” ì ì ˆí•œ ì–‘ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ì†”ì§í•˜ê²Œ ë§í•˜ê³  ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œí•˜ì„¸ìš”

{simplified}
"""

        return simplified_prompt

    def _model_specific_optimization(self, base_prompt: str, model_config: Dict[str, Any]) -> str:
        """ëª¨ë¸ë³„ ìµœì í™”"""
        optimization = f"""

## ëª¨ë¸ ìµœì í™” ì„¤ì •
- ìµœëŒ€ í† í°: {model_config['max_tokens']}
- ì˜¨ë„: {model_config['temperature']}
- ìŠ¤íƒ€ì¼: {model_config['system_prompt_style']}
- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: {model_config['context_window']}
"""
        return base_prompt + optimization

    def _build_final_prompt(self, base_prompt: str, query: str, context: Dict[str, Any], question_type: QuestionType) -> str:
        """ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ë‹µë³€ ìŠ¤íƒ€ì¼"""

        # ë¬¸ì„œ ë°ì´í„° ê²€ì¦ ë° ë¡œê¹… ê°•í™”
        structured_docs = context.get("structured_documents", {})
        document_count = context.get("document_count", 0)

        # ë¬¸ì„œ ê²€ì¦ ë¡œê¹…
        if isinstance(structured_docs, dict):
            raw_documents = structured_docs.get("documents", [])
            doc_count = len(raw_documents) if raw_documents else 0

            # ë¬¸ì„œ í•„ë“œ ì •ê·œí™” ë° ìœ íš¨ì„± ê²€ì¦ (ê°œì„ : content ì—†ì–´ë„ ë‹¤ë¥¸ í•„ë“œ í—ˆìš©)
            normalized_documents = []
            skipped_docs = []
            for doc in raw_documents:
                normalized = self._normalize_document_fields(doc)
                if not normalized:
                    skipped_docs.append({"doc": doc, "reason": "normalized is empty"})
                    continue

                # contentê°€ ì—†ê±°ë‚˜ 10ì ì´í•˜ì¸ ê²½ìš°ì—ë„ ë‹¤ë¥¸ í•„ë“œê°€ ìˆìœ¼ë©´ í¬í•¨
                content = normalized.get("content", "")
                source = normalized.get("source", "")

                # ìµœì†Œ ì¡°ê±´: contentê°€ 10ì ì´ìƒì´ê±°ë‚˜, sourceê°€ ìˆê³  ë‹¤ë¥¸ í•„ë“œê°€ ìˆëŠ” ê²½ìš°
                has_valid_content = content and len(content.strip()) > 10
                has_other_fields = source and (normalized.get("document_id") or normalized.get("metadata"))

                if has_valid_content or has_other_fields:
                    normalized_documents.append(normalized)
                else:
                    skipped_docs.append({
                        "doc": doc,
                        "reason": f"content too short ({len(content)} chars), source={source}"
                    })
                    logger.debug(
                        f"âš ï¸ [DOCUMENT NORMALIZATION] Skipped document: "
                        f"content_len={len(content)}, source={source}"
                    )

            # ë¡œê¹… ê°•í™”: ì •ê·œí™” ì „í›„ ë¬¸ì„œ ìˆ˜ ìƒì„¸ ë¡œê¹…
            logger.info(
                f"ğŸ“‹ [FINAL PROMPT] Documents validation: "
                f"context_count={document_count}, raw={doc_count}, "
                f"valid={len(normalized_documents)}, skipped={len(skipped_docs)}"
            )

            if skipped_docs:
                logger.debug(
                    f"âš ï¸ [DOCUMENT NORMALIZATION] Skipped {len(skipped_docs)} documents: "
                    f"{[d.get('reason', 'unknown') for d in skipped_docs[:3]]}"
                )

            if doc_count > 0 and len(normalized_documents) == 0:
                logger.error(
                    f"âŒ [FINAL PROMPT] All {doc_count} documents have empty or invalid content! "
                    f"Skipped reasons: {[d.get('reason', 'unknown') for d in skipped_docs[:3]]}"
                )

            documents = normalized_documents
        else:
            documents = []
            logger.warning(f"âš ï¸ [FINAL PROMPT] structured_documents is not a dict: {type(structured_docs)}")

        # ğŸ”´ ê°œì„  1: base_promptì— ì´ë¯¸ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ê°œì„ : ë” ë§ì€ íŒ¨í„´ ê°ì§€)
        has_docs_in_base = False
        doc_patterns = [
            "ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ",
            "ì œê³µëœ ë²•ë¥  ë¬¸ì„œ",
            "ê²€ìƒ‰ëœ íŒë¡€ ë¬¸ì„œ",
            "ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ ë° ì •ë³´",
            "ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ ë° íŒë¡€",
            "## ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ",
            "## ì œê³µëœ ë²•ë¥  ë¬¸ì„œ",
            "## ê²€ìƒ‰ëœ íŒë¡€ ë¬¸ì„œ"
        ]
        if any(pattern in base_prompt for pattern in doc_patterns):
            has_docs_in_base = True
            logger.info("âœ… [PROMPT OPTIMIZATION] Documents already in base_prompt, skipping duplicate documents section")

        # ì›ë³¸ contextì—ì„œ structured_documents ì§ì ‘ í™•ì¸ ë° ì¶”ê°€ (ìµœìš°ì„ )
        documents_section = ""
        mandatory_section = ""

        # ğŸ”´ ê°œì„  2: base_promptì— ë¬¸ì„œê°€ ì—†ì„ ë•Œë§Œ ë¬¸ì„œ ì„¹ì…˜ ìƒì„±
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¬¸ì„œ ì„¹ì…˜ ì¶”ê°€
        # ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê°œì¼ ë•ŒëŠ” ë¬¸ì„œ ì„¹ì…˜ì„ ìƒì„±í•˜ì§€ ì•ŠìŒ (ì¤‘ìš”!)
        # ê´€ë ¨ë„ê°€ ì¼ì • ìˆ˜ì¤€ ì´í•˜ì¸ ë¬¸ì„œ í•„í„°ë§
        if not has_docs_in_base and documents and len(documents) > 0:
            # ê´€ë ¨ë„ê°€ ì¼ì • ìˆ˜ì¤€ ì´í•˜ì¸ ë¬¸ì„œëŠ” ì œì™¸ (ë™ì  ê³„ì‚°)
            sorted_all_docs = sorted(
                documents,
                key=lambda x: x.get("relevance_score", 0.0) if isinstance(x, dict) else 0.0,
                reverse=True
            )

            # ìµœê³  ê´€ë ¨ë„ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë™ì  ì„ê³„ê°’ ê³„ì‚° (ìµœê³  ì ìˆ˜ì˜ 70% ì´ìƒ)
            if sorted_all_docs and len(sorted_all_docs) > 0:
                max_score = sorted_all_docs[0].get("relevance_score", 0.0) if isinstance(sorted_all_docs[0], dict) else 0.0
                low_relevance_threshold = max(0.5, max_score * 0.7) if max_score > 0 else 0.5

                filtered_documents = [
                    d for d in sorted_all_docs
                    if isinstance(d, dict) and d.get("relevance_score", 0.0) >= low_relevance_threshold
                ]

                if len(filtered_documents) < len(sorted_all_docs):
                    logger.info(
                        f"ğŸ” [DOCUMENT FILTERING] Filtered {len(sorted_all_docs) - len(filtered_documents)} documents "
                        f"with relevance < {low_relevance_threshold:.3f} "
                        f"(max_score: {max_score:.3f}, kept: {len(filtered_documents)})"
                    )

                documents = filtered_documents if filtered_documents else sorted_all_docs[:5]  # ìµœì†Œ 5ê°œëŠ” ë³´ì¥
            else:
                documents = sorted_all_docs[:5] if sorted_all_docs else []

            if documents and len(documents) > 0:
                # ê´€ë ¨ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë¶„ë¥˜
                # ì˜µì…˜: ìƒìœ„ Nê°œë¥¼ ìµœìš°ì„  ë¬¸ì„œë¡œ ì§€ì • (ê´€ë ¨ë„ 0.7 ì´ìƒ ë¬¸ì„œê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
                sorted_docs = sorted(
                    documents,
                    key=lambda x: x.get("relevance_score", 0.0) if isinstance(x, dict) else 0.0,
                    reverse=True
                )

                # ê´€ë ¨ë„ 0.65 ì´ìƒ ë¬¸ì„œë¥¼ ìµœìš°ì„  ë¬¸ì„œë¡œ ë¶„ë¥˜ (ê¸°ì¤€ ì™„í™”)
                high_relevance_docs = [d for d in sorted_docs if isinstance(d, dict) and d.get("relevance_score", 0.0) >= 0.65]

                # ê´€ë ¨ë„ 0.65 ë¯¸ë§Œ 0.35 ì´ìƒ ë¬¸ì„œë¥¼ ì¤‘ìš” ë¬¸ì„œë¡œ ë¶„ë¥˜
                medium_relevance_docs = [d for d in sorted_docs if isinstance(d, dict) and 0.35 <= d.get("relevance_score", 0.0) < 0.65]

                # ê´€ë ¨ë„ 0.65 ì´ìƒ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ìƒìœ„ 3ê°œë¥¼ ìµœìš°ì„  ë¬¸ì„œë¡œ ì§€ì •
                if not high_relevance_docs and len(sorted_docs) > 0:
                    top_count = min(3, len(sorted_docs))
                    high_relevance_docs = sorted_docs[:top_count]
                    medium_relevance_docs = sorted_docs[top_count:] if len(sorted_docs) > top_count else []

                # ğŸ”´ ê°œì„ : ê´€ë ¨ë„ ê¸°ë°˜ ìœ ì—°í•œ ê²€ìƒ‰ ê²°ê³¼ í™œìš© ì§€ì¹¨
                mandatory_section = "\n\n## âš ï¸ ê²€ìƒ‰ ê²°ê³¼ í™œìš© ì§€ì¹¨\n\n"

                # ê´€ë ¨ë„ ì ìˆ˜ í™œìš© ì „ëµ ëª…ì‹œ
                mandatory_section += "**ê²€ìƒ‰ ê²°ê³¼ í™œìš© ìš°ì„ ìˆœìœ„**:\n"
                mandatory_section += "- ê´€ë ¨ë„ 0.8 ì´ìƒ: í•µì‹¬ ë²•ì  ê·¼ê±°ë¡œ ì§ì ‘ ì¸ìš©\n"
                mandatory_section += "- ê´€ë ¨ë„ 0.6-0.8: ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ ë³´ì¶© ì„¤ëª…ì— í™œìš© ê¶Œì¥\n"
                mandatory_section += "- ê´€ë ¨ë„ 0.6 ë¯¸ë§Œ: ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ ì—†ìœ¼ë©´ ì–¸ê¸‰í•˜ì§€ ì•Šì•„ë„ ë¨\n\n"

                # ê´€ë ¨ë„ë³„ ë¬¸ì„œ ëª©ë¡ ì œê³µ (ì°¸ê³ ìš©)
                if high_relevance_docs:
                    doc_refs = []
                    for idx, doc in enumerate(high_relevance_docs[:3], 1):
                        law_name = doc.get("law_name", "")
                        article_no = doc.get("article_no", "")
                        score = doc.get("relevance_score", 0.0)
                        if law_name and article_no:
                            doc_refs.append(f"ë¬¸ì„œ {idx}({law_name} ì œ{article_no}ì¡°, ê´€ë ¨ë„: {score:.2f})")
                        else:
                            source = doc.get("source", "")
                            if source:
                                doc_refs.append(f"ë¬¸ì„œ {idx}({source}, ê´€ë ¨ë„: {score:.2f})")

                    if doc_refs:
                        mandatory_section += f"**ê³ ê´€ë ¨ë„ ë¬¸ì„œ (ì°¸ê³ ìš©)**: {', '.join(doc_refs)}\n"
                        mandatory_section += "â†’ ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ì´ ë†’ìœ¼ë©´ ìš°ì„  í™œìš©í•˜ì„¸ìš”\n\n"

                mandatory_section += "**ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ë¶€í•©í•˜ì§€ ì•Šì„ ë•Œ**:\n"
                mandatory_section += "- ê²€ìƒ‰ëœ ìë£Œì— [êµ¬ì²´ì  ë‚´ìš©]ì´ ì—†ì–´ì„œ, [ë²•ë ¹ëª…]ì˜ ê¸°ë³¸ ì›ì¹™ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…ë“œë¦´ê²Œìš”...\n\n"

                mandatory_section += "**ì ˆëŒ€ ê¸ˆì§€**:\n"
                mandatory_section += "- âŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬´ì‹œí•˜ê³  ì¼ë°˜ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€\n"
                mandatory_section += "- âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€\n"
                mandatory_section += "- âŒ 'ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤'ë§Œ ë‹µë³€\n"
                mandatory_section += "- âŒ ê´€ë ¨ë„ê°€ ë‚®ì€ ë¬¸ì„œë¥¼ ë¬´ë¦¬í•˜ê²Œ ì¸ìš©\n\n"

                # ğŸ”´ ê°œì„  4: ë¬¸ì„œ ì„¹ì…˜ ë‹¨ì¼í™” (ì¤‘ë³µ í˜•ì‹ ì œê±°, í—¬í¼ ë©”ì„œë“œ ì‚¬ìš©)
                documents_section = "\n\n## ğŸ” ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n\n"

                # ğŸ”´ ì¶”ê°€ ê°œì„ : ê´€ë ¨ë„ í™œìš© ì „ëµ ê°„ë‹¨íˆ ëª…ì‹œ (mandatory_sectionê³¼ ì¤‘ë³µ ì œê±°)
                # mandatory_sectionì— ì´ë¯¸ ìƒì„¸í•œ ì „ëµì´ ìˆìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ ì°¸ê³ ë§Œ ì¶”ê°€
                documents_section += "**ì°¸ê³ **: ìœ„ ë¬¸ì„œë“¤ì˜ ê´€ë ¨ë„ ì ìˆ˜ë¥¼ ì°¸ê³ í•˜ì—¬ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ì„¸ìš”. ê´€ë ¨ë„ê°€ ë†’ì€ ë¬¸ì„œë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.\n\n"

                # ìµœìš°ì„  ë¬¸ì„œ
                if high_relevance_docs:
                    # ê´€ë ¨ë„ ê¸°ì¤€ì— ë”°ë¼ ì„¹ì…˜ ì œëª© ì¡°ì •
                    max_high_score = max([d.get("relevance_score", 0.0) for d in high_relevance_docs if isinstance(d, dict)]) if high_relevance_docs else 0.0
                    if max_high_score >= 0.65:
                        documents_section += "### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ê´€ë ¨ë„ 0.65 ì´ìƒ)\n\n"
                    else:
                        documents_section += "### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ìƒìœ„ ë¬¸ì„œ)\n\n"
                    for idx, doc in enumerate(high_relevance_docs[:5], 1):
                        documents_section += self._format_document_for_prompt(doc, idx, is_high_priority=True)

                # ì¤‘ìš” ë¬¸ì„œ
                if medium_relevance_docs:
                    documents_section += "### ğŸŸ¡ ì¤‘ìš” ë¬¸ì„œ (ê´€ë ¨ë„ 0.35~0.65)\n\n"
                    for idx, doc in enumerate(medium_relevance_docs[:3], 1):
                        documents_section += self._format_document_for_prompt(doc, idx, is_high_priority=False)

                logger.info(f"âœ… [FINAL PROMPT] Added {len(documents)} documents (High: {len(high_relevance_docs)}, Medium: {len(medium_relevance_docs)})")

        # ğŸ”´ ê°œì„  3: í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­ ì„¹ì…˜ì´ ë¹„ì–´ìˆì„ ë•Œ ì²˜ë¦¬
        if has_docs_in_base and not mandatory_section:
            # base_promptì— ë¬¸ì„œê°€ ìˆì§€ë§Œ mandatory_sectionì´ ì—†ëŠ” ê²½ìš° ê°„ë‹¨í•œ ì§€ì¹¨ ì¶”ê°€
            mandatory_section = "\n\n## âš ï¸ í•µì‹¬ ì§€ì¹¨\n\n"
            mandatory_section += "**ìœ„ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**\n\n"
            mandatory_section += "**ì ˆëŒ€ ê¸ˆì§€**:\n"
            mandatory_section += "- âŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬´ì‹œí•˜ê³  ì¼ë°˜ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€\n"
            mandatory_section += "- âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€\n"
            mandatory_section += "- âŒ 'ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤'ë§Œ ë‹µë³€\n\n"

        # ë¬¸ì„œ ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ëŠ”ë° ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° í´ë°± ì²˜ë¦¬
        if not documents_section and documents and len(documents) > 0 and not has_docs_in_base:
            logger.warning(
                f"âš ï¸ [FINAL PROMPT] No documents section created despite having {len(documents)} documents! "
                f"Creating fallback section."
            )
            documents_section = self._build_fallback_documents_section(documents)
            if documents_section and not mandatory_section:
                mandatory_section = "\n\n## âš ï¸ í•µì‹¬ ì§€ì¹¨\n\n"
                mandatory_section += "**ğŸ”´ ê²€ìƒ‰ ê²°ê³¼ ë°˜ë“œì‹œ í™œìš©**: ì•„ë˜ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n\n"

        # structured_documentsê°€ ë¹„ì–´ìˆì§€ë§Œ context í…ìŠ¤íŠ¸ë‚˜ prompt_optimized_textê°€ ìˆëŠ” ê²½ìš° í´ë°± ì²˜ë¦¬
        if not documents_section:
            prompt_optimized_text = context.get("prompt_optimized_text", "")
            context_text = context.get("context", "")

            # prompt_optimized_text ìš°ì„  ì‚¬ìš©
            # ğŸ”´ ê°œì„ : ë¬¸ì„œ ì„¹ì…˜ ì œëª© í†µì¼ ë° ì§€ì¹¨ ë¬¸êµ¬ ê°„ì†Œí™”
            if prompt_optimized_text and len(prompt_optimized_text.strip()) > 100:
                documents_section = "\n\n## ğŸ” ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n\n"
                documents_section += prompt_optimized_text[:5000] + ("..." if len(prompt_optimized_text) > 5000 else "")
                documents_section += "\n\n"
                if not mandatory_section:
                    mandatory_section = "\n\n## âš ï¸ í•µì‹¬ ì§€ì¹¨\n\n"
                    mandatory_section += "**ìœ„ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**\n\n"
                logger.info(
                    f"âœ… [FINAL PROMPT] Added prompt_optimized_text to final prompt as fallback "
                    f"({len(prompt_optimized_text)} chars)"
                )
            # context_textê°€ ìˆê³  document_countê°€ 0ë³´ë‹¤ í¬ë©´ ë¬¸ì„œê°€ ìˆë‹¤ëŠ” ì˜ë¯¸
            elif context_text and len(context_text.strip()) > 100 and document_count > 0:
                documents_section = "\n\n## ğŸ” ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n\n"
                documents_section += context_text[:5000] + ("..." if len(context_text) > 5000 else "")
                documents_section += "\n\n"
                if not mandatory_section:
                    mandatory_section = "\n\n## âš ï¸ í•µì‹¬ ì§€ì¹¨\n\n"
                    mandatory_section += "**ìœ„ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**\n\n"
                logger.info(
                    f"âœ… [FINAL PROMPT] Added context_text to final prompt as fallback "
                    f"({len(context_text)} chars, document_count: {document_count})"
                )

        # Few-shot ì˜ˆì‹œ ì¶”ê°€ (ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)
        relevant_examples = self._get_relevant_examples(question_type, documents)
        examples_section = f"\n{relevant_examples}\n" if relevant_examples else ""

        # ğŸ”´ ê°œì„  5: í™œìš© ê°€ì´ë“œ ê°„ì†Œí™” (ì¤‘ë³µ ì œê±°)
        usage_guide = ""
        if documents_section and documents and len(documents) > 0 and not has_docs_in_base:
            usage_guide = """

### ğŸ“– ì¸ìš© ê°€ì´ë“œ
- ì¸ìš© í¬ë§·: "[ë²•ë ¹: ë¯¼ë²• ì œ543ì¡°]", "[íŒë¡€: ëŒ€ë²•ì› 2020ë‹¤12345]"
- ë¬¸ì„œ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì„¤ëª…í•˜ê³ , ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- ì—¬ëŸ¬ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
"""

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ base_promptë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¤„ì´ê¸°
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ìˆœí™” (í”„ë¡¬í”„íŠ¸ ì¶œë ¥ ë°©ì§€)
        # ê°œì„ : ì›ë³¸ ë¬¸ì„œ ìˆ˜ë¥¼ ê³ ë ¤í•˜ì—¬ has_no_documents ì¡°ê±´ ì™„í™”
        normalized_doc_count = len(documents) if documents else 0
        raw_doc_count = (
            len(structured_docs.get("documents", []))
            if isinstance(structured_docs, dict) else 0
        ) or document_count or 0

        # documents_sectionì´ ë¹„ì–´ìˆê±°ë‚˜ documentsê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        has_no_documents_section = not documents_section or len(documents_section.strip()) == 0
        has_no_normalized_documents = not documents or len(documents) == 0

        # ì›ë³¸ ë¬¸ì„œê°€ ìˆì—ˆëŠ”ë° ì •ê·œí™” í›„ ë¹„ì–´ìˆëŠ” ê²½ìš°ë„ ê³ ë ¤
        has_no_documents = (
            has_no_documents_section and
            has_no_normalized_documents and
            raw_doc_count == 0  # ì›ë³¸ ë¬¸ì„œë„ ì—†ëŠ” ê²½ìš°ì—ë§Œ True
        )

        # ë¡œê¹… ê°•í™”: ë¬¸ì„œ ìƒíƒœ ìƒì„¸ ë¡œê¹…
        if raw_doc_count > 0 and normalized_doc_count == 0:
            logger.warning(
                f"âš ï¸ [PROMPT SIMPLIFICATION] Warning: {raw_doc_count} raw documents existed "
                f"but {normalized_doc_count} normalized documents. "
                f"documents_section={'exists' if documents_section else 'empty'}"
            )

        if has_no_documents:
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•ŒëŠ” base_promptë¥¼ ë‹¨ìˆœí™”
            # ë³µì¡í•œ ì§€ì‹œì‚¬í•­ì´ LLMì—ê²Œ í”„ë¡¬í”„íŠ¸ ìì²´ë¥¼ ì¶œë ¥í•˜ê²Œ í•  ìˆ˜ ìˆìŒ
            simplified_base = self._simplify_prompt_for_no_results(base_prompt)
            logger.info(
                f"ğŸ“ [PROMPT SIMPLIFICATION] Simplified prompt for no search results "
                f"(raw_docs={raw_doc_count}, normalized_docs={normalized_doc_count}, "
                f"original: {len(base_prompt)} chars, simplified: {len(simplified_base)} chars)"
            )
        else:
            simplified_base = base_prompt
            if raw_doc_count > 0:
                logger.info(
                    f"âœ… [PROMPT SIMPLIFICATION] Keeping full prompt "
                    f"(raw_docs={raw_doc_count}, normalized_docs={normalized_doc_count})"
                )

        # ğŸ”´ ê°œì„  6: ìµœì¢… ì§€ì¹¨ í†µí•© (ì¤‘ë³µ ì œê±°, ë¡œì§ ìˆ˜ì •)
        # ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì ì ˆí•œ ì§€ì¹¨ í‘œì‹œ, ì—†ìœ¼ë©´ "ë¬¸ì„œ ì—†ìŒ" í‘œì‹œ
        has_any_documents = (
            (documents_section and len(documents_section.strip()) > 0) or
            has_docs_in_base or
            (documents and len(documents) > 0)
        )

        if has_any_documents:
            # ì œê³µëœ ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ
            doc_list = []
            if documents and len(documents) > 0:
                # high_relevance_docsê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ , ì—†ìœ¼ë©´ ìƒìœ„ ë¬¸ì„œ ì‚¬ìš©
                sorted_docs = sorted(
                    documents,
                    key=lambda x: x.get("relevance_score", 0.0) if isinstance(x, dict) else 0.0,
                    reverse=True
                )

                high_relevance_docs_for_list = [d for d in sorted_docs if isinstance(d, dict) and d.get("relevance_score", 0.0) >= 0.65]

                # ğŸ”´ ê°œì„ : high_relevance_docsê°€ ë¹„ì–´ìˆê±°ë‚˜ ì ìœ¼ë©´ ì „ì²´ ë¬¸ì„œì—ì„œ ìƒìœ„ ë¬¸ì„œ ì¶”ì¶œ
                if not high_relevance_docs_for_list:
                    docs_for_list = sorted_docs[:5]  # ìƒìœ„ 5ê°œ
                elif len(high_relevance_docs_for_list) >= 3:
                    docs_for_list = high_relevance_docs_for_list[:5]
                else:
                    # high_relevance_docsê°€ 1-2ê°œë§Œ ìˆìœ¼ë©´ ìƒìœ„ ë¬¸ì„œì™€ í•¨ê»˜ ì‚¬ìš©
                    docs_for_list = sorted_docs[:5]

                for doc in docs_for_list:
                    if isinstance(doc, dict):
                        law_name = doc.get("law_name", "")
                        article_no = doc.get("article_no", "")
                        if law_name and article_no:
                            doc_list.append(f"{law_name} ì œ{article_no}ì¡°")
                        else:
                            source = doc.get("source", "")
                            if source:
                                doc_list.append(source)

            # ğŸ”´ ê°œì„ : has_docs_in_baseì¼ ë•Œ base_promptì—ì„œ ë¬¸ì„œ ì¶”ì¶œ
            if not doc_list and has_docs_in_base:
                import re
                # base_promptì—ì„œ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
                # íŒ¨í„´: "### ë¬¸ì„œ N: ë¯¼ë²• ì œXXXì¡°" ë˜ëŠ” "**ë¬¸ì„œ N**: ë¯¼ë²• ì œXXXì¡°"
                doc_patterns = [
                    r'###\s*ë¬¸ì„œ\s*\d+:\s*([^\(]+)',
                    r'\*\*ë¬¸ì„œ\s*\d+\*\*:\s*([^\(]+)',
                    r'ë¬¸ì„œ\s*\d+[:\s]+([^\(]+)'
                ]

                found_docs = []
                for pattern in doc_patterns:
                    matches = re.findall(pattern, base_prompt)
                    for match in matches[:5]:  # ìµœëŒ€ 5ê°œ
                        match = match.strip()
                        # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ
                        article_match = re.search(r'([ê°€-í£\s]+)\s*ì œ\s*(\d+)\s*ì¡°', match)
                        if article_match:
                            law_name = article_match.group(1).strip()
                            article_no = article_match.group(2)
                            doc_ref = f"{law_name} ì œ{article_no}ì¡°"
                            if doc_ref not in found_docs:
                                found_docs.append(doc_ref)
                        elif match and match not in found_docs:
                            found_docs.append(match)

                if found_docs:
                    doc_list = found_docs[:5]
                    logger.info(f"âœ… [DOCUMENT EXTRACTION] Extracted {len(doc_list)} documents from base_prompt: {', '.join(doc_list[:3])}...")

            if doc_list:
                doc_list_str = ', '.join(doc_list[:5])
                # ğŸ”´ ê°œì„ : ì‹¤ì œ ì œê³µëœ ë¬¸ì„œ ì¡°ë¬¸ì„ ì˜ˆì‹œë¡œ ì‚¬ìš©
                example_doc = doc_list[0] if doc_list else "ë²•ë ¹ëª… ì œXXì¡°"
                final_instruction_section = f"""
## ê²€ìƒ‰ ê²°ê³¼ í™œìš© ì§€ì¹¨
- ë‹¤ìŒ ë¬¸ì„œ ì¤‘ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê²ƒì„ ìš°ì„  í™œìš©í•˜ì„¸ìš”: {doc_list_str}
- ê´€ë ¨ë„ê°€ ë‚®ì€ ë¬¸ì„œëŠ” ë¬´ë¦¬í•˜ê²Œ ì¸ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ë¶€í•©í•˜ì§€ ì•Šìœ¼ë©´ ëª…ì‹œí•˜ê³  ê¸°ë³¸ ì›ì¹™ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ê° ì¸ìš©ì— ëª…í™•í•œ ì¶œì²˜ í‘œê¸°: "[ë²•ë ¹: {example_doc}]" ë˜ëŠ” "{example_doc}ì— ë”°ë¥´ë©´..."
"""
            else:
                # doc_listê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ ê¸°ë³¸ ì˜ˆì‹œ ì‚¬ìš©
                final_instruction_section = """
## ê²€ìƒ‰ ê²°ê³¼ í™œìš© ì§€ì¹¨
- ìœ„ ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ ìš°ì„  í™œìš©í•˜ì„¸ìš”
- ê° ì¸ìš©ì— ëª…í™•í•œ ì¶œì²˜ í‘œê¸°: "[ë²•ë ¹: ë²•ë ¹ëª… ì œXXì¡°]" ë˜ëŠ” "ë²•ë ¹ëª… ì œXXì¡°ì— ë”°ë¥´ë©´..."
- ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ë¶€í•©í•˜ì§€ ì•Šìœ¼ë©´ ëª…ì‹œí•˜ê³  ê¸°ë³¸ ì›ì¹™ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
"""
        else:
            final_instruction_section = """
## âš ï¸ ì°¸ê³ ì‚¬í•­
í˜„ì¬ ê´€ë ¨ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•˜ë˜, í•œê³„ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
"""

        final_prompt = f"""{simplified_base}{mandatory_section}{documents_section}{usage_guide}

---

## ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸
{query}

---

{examples_section}

---

## ğŸ“‹ ë‹µë³€ ìŠ¤íƒ€ì¼
- ì „ë¬¸ì ì´ë˜ ì¹œê·¼í•œ ì¡´ëŒ“ë§ ì‚¬ìš© ("~ì˜ˆìš”/~í•´ìš”" ì„ í˜¸)
- "~ì…ë‹ˆë‹¤/~ìŠµë‹ˆë‹¤"ëŠ” í•„ìš”í•œ ê²½ìš°ë§Œ ì‚¬ìš©
- ê³¼ë„í•œ í˜•ì‹(ì œëª©, ë°•ìŠ¤, ì´ëª¨ì§€)ì€ í”¼í•˜ê¸°
- ì˜ˆ: "ë¯¼ë²• ì œ550ì¡°ì— ë”°ë¥´ë©´ ê³„ì•½ì„ í•´ì§€í•˜ë©´ ì¥ë˜ì— ëŒ€í•´ì„œë§Œ íš¨ë ¥ì„ ìƒê²Œ ë¼ìš”."
- âš ï¸ ì£¼ì˜: í”„ë¡¬í”„íŠ¸ ë‚´ë¶€ì—ëŠ” ì´ëª¨ì§€ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, AI ë‹µë³€ì—ëŠ” ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€

## ë‹µë³€ êµ¬ì„± ì›ì¹™
- ë‹¨ìˆœ ì¡°ë¬¸ ì§ˆì˜: ì¡°ë¬¸ ë‚´ìš© + ê°„ë‹¨í•œ í•´ì„¤ (2-3ë¬¸ë‹¨)
- êµ¬ì²´ì  ì‚¬ë¡€ ìƒë‹´: ìƒí™© íŒŒì•… â†’ ë²•ë¥  ì ìš© â†’ ì‹¤ë¬´ ì¡°ì–¸ ìˆœì„œ
- ë³µì¡í•œ ë²•ë¥  ë¬¸ì œ: ë‹¨ê³„ì ìœ¼ë¡œ ì„¤ëª…í•˜ë˜, ë¶ˆí•„ìš”í•œ í˜•ì‹(ì œëª©, ë²ˆí˜¸ ë§¤ê¸°ê¸°)ì€ ìµœì†Œí™”
- ì§ˆë¬¸ì´ ë‹¨ìˆœí•˜ë©´ ê°„ê²°í•˜ê²Œ, ë³µì¡í•˜ë©´ ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”

## í•„ìˆ˜ í¬í•¨ ìš”ì†Œ
ê° ë‹µë³€ì— ë°˜ë“œì‹œ í¬í•¨:
1. **ë²•ì  ê·¼ê±°**: ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ ì •í™•íˆ ì¸ìš©
2. **ì‹¤ë¬´ì  ì˜ë¯¸**: ì‹¤ì œë¡œ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì„¤ëª…
3. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸**: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ëŠ”ì§€
4. **ì£¼ì˜ì‚¬í•­**: ë†“ì¹˜ê¸° ì‰¬ìš´ í•¨ì • (í•„ìš”ì‹œì—ë§Œ)

**ì˜ˆì‹œ í˜•ì‹**:
âŒ "ë¯¼ë²• ì œ550ì¡°ëŠ” í•´ì§€ì˜ íš¨ê³¼ë¥¼ ê·œì •í•©ë‹ˆë‹¤"
âœ… "ë¯¼ë²• ì œ550ì¡°ì— ë”°ë¥´ë©´, ê³„ì•½ì„ í•´ì§€í•˜ë©´ ì•ìœ¼ë¡œë§Œ íš¨ë ¥ì´ ì—†ì–´ì ¸ìš”. ì¦‰, ì´ë¯¸ ë°›ì€ ëˆì´ë‚˜ ë¬¼ê±´ì€ ëŒë ¤ì£¼ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ë§Œ í•´ì§€ ì´í›„ ë°œìƒí•œ ì†í•´ì— ëŒ€í•´ì„œëŠ” ë°°ìƒì„ ì²­êµ¬í•  ìˆ˜ ìˆì–´ìš”."

{final_instruction_section}

ë‹µë³€ì„ ì‹œì‘í•˜ì„¸ìš”:
"""
        return final_prompt

    def _validate_prompt_contains_documents(self, final_prompt: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ì— ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ ê²€ì¦ (ê°•í™”ëœ ë²„ì „)"""
        validation_result = {
            "has_document_content": False,
            "context_text_length": 0,
            "prompt_contains_context": False,
            "document_count_in_context": 0,
            "document_count_in_prompt": 0,
            "validation_details": []
        }

        if not context:
            return validation_result

        # structured_documents í™•ì¸ (ìš°ì„ ìˆœìœ„ 1)
        structured_docs = context.get("structured_documents", {})
        if isinstance(structured_docs, dict):
            documents = structured_docs.get("documents", [])
            validation_result["document_count_in_context"] = len(documents) if documents else 0

            if documents:
                doc_found_count = 0
                for idx, doc in enumerate(documents[:5], 1):  # ìƒìœ„ 5ê°œ í™•ì¸
                    if isinstance(doc, dict):
                        # ì •ê·œí™”ëœ ë¬¸ì„œ ì‚¬ìš©
                        normalized = self._normalize_document_fields(doc)
                        doc_content = normalized.get("content", "")

                        if doc_content and len(doc_content) > 50:
                            # ë¬¸ì„œ ë‚´ìš© ì¼ë¶€ê°€ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì—¬ëŸ¬ ìœ„ì¹˜ í™•ì¸)
                            doc_preview = doc_content[:150].strip()
                            doc_mid = doc_content[len(doc_content)//2:len(doc_content)//2+100].strip() if len(doc_content) > 200 else ""

                            found_in_prompt = False
                            if doc_preview and doc_preview in final_prompt:
                                found_in_prompt = True
                                doc_found_count += 1
                            elif doc_mid and doc_mid in final_prompt:
                                found_in_prompt = True
                                doc_found_count += 1

                            validation_result["validation_details"].append({
                                "doc_index": idx,
                                "source": normalized.get("source", "Unknown"),
                                "content_length": len(doc_content),
                                "found_in_prompt": found_in_prompt
                            })

                validation_result["document_count_in_prompt"] = doc_found_count

                if doc_found_count > 0:
                    validation_result["has_document_content"] = True
                    logger.info(
                        f"âœ… [PROMPT VALIDATION] Found {doc_found_count}/{len(documents)} documents in prompt"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ [PROMPT VALIDATION] No document content found in prompt "
                        f"despite having {len(documents)} documents in context"
                    )

        # context í…ìŠ¤íŠ¸ í™•ì¸ (ìš°ì„ ìˆœìœ„ 2)
        context_text = context.get("context", "")
        if context_text and len(context_text.strip()) > 100:  # ìµœì†Œ 100ì ì´ìƒ
            validation_result["context_text_length"] = len(context_text)

            # í”„ë¡¬í”„íŠ¸ì— context_textê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            # (ì²˜ìŒ 200ìì™€ ì¤‘ê°„ 200ì í™•ì¸)
            context_preview = context_text[:200].strip()
            context_mid = context_text[len(context_text)//2:len(context_text)//2+200].strip() if len(context_text) > 400 else ""

            if context_preview and context_preview in final_prompt:
                validation_result["prompt_contains_context"] = True
                validation_result["has_document_content"] = True
            elif context_mid and context_mid in final_prompt:
                validation_result["prompt_contains_context"] = True
                validation_result["has_document_content"] = True

        # prompt_optimized_text í™•ì¸ (ìš°ì„ ìˆœìœ„ 3)
        prompt_optimized_text = context.get("prompt_optimized_text", "")
        if prompt_optimized_text and len(prompt_optimized_text.strip()) > 100:
            preview = prompt_optimized_text[:200].strip()
            if preview and preview in final_prompt:
                validation_result["has_document_content"] = True

        return validation_result

    def _normalize_document_fields(self, doc: Dict[str, Any]) -> Dict[str, Any]:
        """ë¬¸ì„œ í•„ë“œëª… ì •ê·œí™” - ë²•ë¥ ëª…, ì¡°ë¬¸ ë²ˆí˜¸ ë“± ëª…ì‹œì  ì¶”ì¶œ"""
        if not isinstance(doc, dict):
            return {}

        # content í•„ë“œ: ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª…ì—ì„œ ì¶”ì¶œ
        content = (
            doc.get("content", "") or
            doc.get("text", "") or
            doc.get("document_text", "") or
            doc.get("full_text", "") or
            doc.get("body", "") or
            str(doc.get("metadata", {}).get("text", "") if isinstance(doc.get("metadata"), dict) else "") or
            ""
        )

        # source í•„ë“œ: ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª…ì—ì„œ ì¶”ì¶œ
        source = (
            doc.get("source", "") or
            doc.get("title", "") or
            doc.get("document_id", "") or
            doc.get("name", "") or
            doc.get("law_name", "") or
            doc.get("case_name", "") or
            ""
        )

        # ë©”íƒ€ë°ì´í„°ì—ì„œ ë²•ë¥  ì •ë³´ ì¶”ì¶œ
        metadata = doc.get("metadata", {})
        if not isinstance(metadata, dict):
            metadata = {}

        # ë²•ë¥ ëª… ì¶”ì¶œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª… ì§€ì›)
        law_name = (
            doc.get("law_name", "") or
            metadata.get("law_name", "") or
            metadata.get("statute_name", "") or
            metadata.get("name", "") or
            ""
        )

        # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ
        article_no = (
            doc.get("article_no", "") or
            doc.get("article_number", "") or
            doc.get("article_no", "") or
            metadata.get("article_no", "") or
            metadata.get("article_number", "") or
            ""
        )

        # í•­ ë²ˆí˜¸ ì¶”ì¶œ
        clause_no = (
            doc.get("clause_no", "") or
            doc.get("clause_number", "") or
            metadata.get("clause_no", "") or
            metadata.get("clause_number", "") or
            ""
        )

        # í˜¸ ë²ˆí˜¸ ì¶”ì¶œ
        item_no = (
            doc.get("item_no", "") or
            doc.get("item_number", "") or
            metadata.get("item_no", "") or
            metadata.get("item_number", "") or
            ""
        )

        # ì¡°ë¬¸ ì œëª© ì¶”ì¶œ
        heading = (
            doc.get("heading", "") or
            doc.get("article_title", "") or
            metadata.get("heading", "") or
            metadata.get("article_title", "") or
            ""
        )

        # íŒë¡€ ì •ë³´ ì¶”ì¶œ
        court = (
            doc.get("court", "") or
            metadata.get("court", "") or
            ""
        )

        case_number = (
            doc.get("case_number", "") or
            doc.get("doc_id", "") or
            doc.get("case_id", "") or
            metadata.get("case_number", "") or
            metadata.get("doc_id", "") or
            ""
        )

        case_name = (
            doc.get("case_name", "") or
            doc.get("casenames", "") or
            metadata.get("case_name", "") or
            metadata.get("casenames", "") or
            ""
        )

        announce_date = (
            doc.get("announce_date", "") or
            doc.get("decision_date", "") or
            metadata.get("announce_date", "") or
            metadata.get("decision_date", "") or
            ""
        )

        case_type = (
            doc.get("case_type", "") or
            metadata.get("case_type", "") or
            ""
        )

        # íŒë¡€ ë³¸ë¬¸ ì •ë³´ ì¶”ì¶œ
        case_summary = (
            doc.get("summary", "") or
            doc.get("case_summary", "") or
            metadata.get("summary", "") or
            metadata.get("case_summary", "") or
            ""
        )

        case_holding = (
            doc.get("holding", "") or
            doc.get("case_holding", "") or
            doc.get("íŒì‹œì‚¬í•­", "") or
            metadata.get("holding", "") or
            metadata.get("case_holding", "") or
            ""
        )

        case_reasoning = (
            doc.get("reasoning", "") or
            doc.get("case_reasoning", "") or
            doc.get("íŒê²°ìš”ì§€", "") or
            metadata.get("reasoning", "") or
            metadata.get("case_reasoning", "") or
            ""
        )

        # ë¬¸ì„œ íƒ€ì… íŒë‹¨
        source_type = (
            doc.get("source_type", "") or
            metadata.get("source_type", "") or
            metadata.get("type", "") or
            ""
        )

        normalized = {
            "content": str(content).strip(),
            "source": str(source).strip() or "Unknown",
            "relevance_score": (
                float(doc.get("relevance_score", 0.0) or doc.get("final_weighted_score", 0.0) or
                      doc.get("score", 0.0) or doc.get("similarity_score", 0.0) or
                      doc.get("similarity", 0.0) or 0.0)
            ),
            "document_id": str(doc.get("document_id", "") or doc.get("id", "") or doc.get("chunk_id", "") or "").strip(),
            "metadata": metadata,
            # ë²•ë¥  ì •ë³´ ì¶”ê°€
            "law_name": str(law_name).strip(),
            "article_no": str(article_no).strip(),
            "clause_no": str(clause_no).strip(),
            "item_no": str(item_no).strip(),
            "heading": str(heading).strip(),
            # íŒë¡€ ì •ë³´ ì¶”ê°€
            "court": str(court).strip(),
            "case_number": str(case_number).strip(),
            "case_name": str(case_name).strip(),
            "announce_date": str(announce_date).strip(),
            "case_type": str(case_type).strip(),
            # íŒë¡€ ë³¸ë¬¸ ì •ë³´ ì¶”ê°€
            "case_summary": str(case_summary).strip(),
            "case_holding": str(case_holding).strip(),
            "case_reasoning": str(case_reasoning).strip(),
            "source_type": str(source_type).strip()
        }

        return normalized

    def _format_document_for_prompt(self, doc: Dict[str, Any], idx: int, is_high_priority: bool = False) -> str:
        """ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (ì¤‘ë³µ ì œê±° ë° ìµœì í™”)"""
        content = doc.get("content", "")
        source = doc.get("source", "Unknown")
        score = doc.get("relevance_score", 0.0)

        # ë²•ë¥  ì •ë³´ ì¶”ì¶œ
        law_name = doc.get("law_name", "")
        article_no = doc.get("article_no", "")
        clause_no = doc.get("clause_no", "")
        item_no = doc.get("item_no", "")
        heading = doc.get("heading", "")

        # íŒë¡€ ì •ë³´ ì¶”ì¶œ
        court = doc.get("court", "")
        case_number = doc.get("case_number", "")
        case_name = doc.get("case_name", "")
        announce_date = doc.get("announce_date", "")
        case_type = doc.get("case_type", "")
        source_type = doc.get("source_type", "")

        # íŒë¡€ ë³¸ë¬¸ ì •ë³´ ì¶”ì¶œ
        case_summary = doc.get("case_summary", "")
        case_holding = doc.get("case_holding", "")
        case_reasoning = doc.get("case_reasoning", "")

        # ë²•ë ¹/íŒë¡€ ê·¼ê±° êµ¬ì„±
        legal_reference = ""
        if law_name:
            legal_reference = law_name
            if article_no:
                if article_no.isdigit():
                    legal_reference += f" ì œ{article_no}ì¡°"
                else:
                    legal_reference += f" {article_no}"
                if clause_no:
                    legal_reference += f" ì œ{clause_no}í•­"
                if item_no:
                    legal_reference += f" ì œ{item_no}í˜¸"
            if heading:
                legal_reference += f" ({heading})"
        elif court and case_number:
            legal_reference = f"{court} {case_number}"
        elif case_number:
            legal_reference = case_number
        elif court and case_name:
            legal_reference = f"{court} {case_name}"
        elif case_name:
            legal_reference = case_name

        # ë” ê°„ê²°í•œ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
        if law_name and article_no:
            formatted = f"**ë¬¸ì„œ {idx}**: {law_name} ì œ{article_no}ì¡°"
            if heading:
                formatted += f" - {heading}"
            formatted += f" (ê´€ë ¨ë„: {score:.2f})\n\n"
        elif legal_reference:
            formatted = f"**ë¬¸ì„œ {idx}**: {legal_reference} (ê´€ë ¨ë„: {score:.2f})\n\n"
        else:
            formatted = f"**ë¬¸ì„œ {idx}**: {source} (ê´€ë ¨ë„: {score:.2f})\n\n"

        # ë²•ë ¹ ê·¼ê±° í‘œì‹œ
        if law_name and article_no:
            formatted += f"**ë²•ë ¹ ê·¼ê±°**: {legal_reference}\n\n"

        # íŒë¡€ ì •ë³´ ë° ë³¸ë¬¸ í‘œì‹œ
        elif court or case_number:
            formatted += f"**íŒë¡€ ê·¼ê±°**: {legal_reference}\n\n"
            if court:
                formatted += f"**ë²•ì›**: {court}\n\n"
            if case_type:
                formatted += f"**ì‚¬ê±´ ì¢…ë¥˜**: {case_type}\n\n"
            if announce_date:
                formatted += f"**ì„ ê³ ì¼**: {announce_date}\n\n"
            # íŒë¡€ ë³¸ë¬¸ ì •ë³´
            if case_holding:
                formatted += f"**íŒì‹œì‚¬í•­**: {case_holding[:300]}{'...' if len(case_holding) > 300 else ''}\n\n"
            if case_reasoning:
                formatted += f"**íŒê²°ìš”ì§€**: {case_reasoning[:300]}{'...' if len(case_reasoning) > 300 else ''}\n\n"
            if case_summary:
                formatted += f"**ì‚¬ê±´ ê°œìš”**: {case_summary[:300]}{'...' if len(case_summary) > 300 else ''}\n\n"

        # ğŸ”´ ê°œì„ : ë‚´ìš© ê¸¸ì´ ìµœì í™” (2000ì â†’ 800ì, 1500ì â†’ 500ì)
        if is_high_priority:
            content_preview = content[:800] if len(content) > 800 else content
        else:
            content_preview = content[:500] if len(content) > 500 else content

        formatted += f"{content_preview}{'...' if len(content) > len(content_preview) else ''}\n\n"
        formatted += "---\n\n"

        return formatted

    def _build_fallback_documents_section(self, documents: List[Dict[str, Any]]) -> str:
        """í´ë°± ë¬¸ì„œ ì„¹ì…˜ ìƒì„± - ë¬¸ì„œ ì„¹ì…˜ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì‚¬ìš©"""
        if not documents or len(documents) == 0:
            return ""

        documents_section = "\n\n## ğŸ” ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n\n"
        documents_section += "ë‹¤ìŒ ë¬¸ì„œë“¤ì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•´ ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤.\n\n"

        import re

        for idx, doc in enumerate(documents[:10], 1):  # ìµœëŒ€ 10ê°œ
            content = doc.get("content", "")
            source = doc.get("source", "Unknown")
            score = doc.get("relevance_score", 0.0)

            if not content or len(content.strip()) < 10:
                continue

            # ë‚´ìš© ê¸¸ì´ ì¡°ì •
            content_preview = content[:2000] if len(content) > 2000 else content
            core_content = content[:300] if len(content) > 300 else content

            # ì¡°ë¬¸/íŒë¡€ ë²ˆí˜¸ ì¶”ì¶œ
            article_match = re.search(r'ì œ\s*\d+\s*ì¡°', content[:200])
            case_match = re.search(r'\d{4}[ë‹¤ë‚˜]\d+', content[:200])

            # ğŸ”´ ê°œì„ : ê´€ë ¨ë„ í‘œê¸° í†µì¼ (.3f â†’ .2f)
            documents_section += f"### ë¬¸ì„œ {idx}: {source} (ê´€ë ¨ë„: {score:.2f})\n\n"

            if article_match:
                documents_section += f"**í•µì‹¬ ì¡°ë¬¸**: {article_match.group()}\n\n"
            if case_match:
                documents_section += f"**íŒë¡€ ë²ˆí˜¸**: {case_match.group()}\n\n"

            documents_section += f"**í•µì‹¬ ë‚´ìš©**: {core_content}{'...' if len(content) > 300 else ''}\n\n"
            documents_section += f"**ì „ì²´ ë‚´ìš©**:\n{content_preview}\n\n"
            documents_section += "---\n\n"

        return documents_section

    def _format_context(self, context: Dict[str, Any]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        formatted_parts = []
        for key, value in context.items():
            if isinstance(value, list):
                formatted_parts.append(f"**{key}**:\n" + "\n".join([f"- {item}" for item in value]))
            elif isinstance(value, dict):
                formatted_parts.append(f"**{key}**:\n" + "\n".join([f"- {k}: {v}" for k, v in value.items()]))
            else:
                formatted_parts.append(f"**{key}**: {value}")
        return "\n\n".join(formatted_parts)

    def _structure_context_by_question_type(
        self,
        context: Dict[str, Any],
        question_type: QuestionType
    ) -> str:
        """ì§ˆë¬¸ ìœ í˜•ë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¡°í™” - ë¬¸ì„œ ë° ë°ì´í„°ë² ì´ìŠ¤ ê²°ê³¼ ê°•ì œ í¬í•¨"""
        context_text = context.get("context", "")
        legal_references = context.get("legal_references", [])
        insights = context.get("insights", [])
        citations = context.get("citations", [])

        # structured_documentsì—ì„œ ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
        structured_docs = context.get("structured_documents", {})
        document_contents = []

        # ë°©ë²• 1: structured_documentsì—ì„œ ì§ì ‘ ì¶”ì¶œ
        if isinstance(structured_docs, dict):
            documents = structured_docs.get("documents", [])
            for doc in documents[:10]:  # ìƒìœ„ 10ê°œ ë¬¸ì„œ
                if isinstance(doc, dict):
                    # content í•„ë“œ ìš°ì„  í™•ì¸, ì—†ìœ¼ë©´ text í•„ë“œ ì‚¬ìš©
                    doc_content = doc.get("content", "") or doc.get("text", "")
                    doc_source = doc.get("source", "Unknown")
                    # relevance_score ìš°ì„  í™•ì¸, ì—†ìœ¼ë©´ score ì‚¬ìš©
                    doc_score = doc.get("relevance_score", 0.0) or doc.get("score", 0.0)
                    if doc_content and len(doc_content.strip()) > 10:
                        # ë²•ë¥  ì •ë³´ì™€ íŒë¡€ ì •ë³´ë„ í•¨ê»˜ ì¶”ì¶œ
                        doc_dict = {
                            "source": doc_source,
                            "content": doc_content,
                            "score": doc_score,
                            # ë²•ë¥  ì •ë³´
                            "law_name": doc.get("law_name", ""),
                            "article_no": doc.get("article_no", ""),
                            "clause_no": doc.get("clause_no", ""),
                            "item_no": doc.get("item_no", ""),
                            "heading": doc.get("heading", ""),
                            # íŒë¡€ ì •ë³´
                            "court": doc.get("court", ""),
                            "case_number": doc.get("case_number", ""),
                            "case_name": doc.get("case_name", ""),
                            "announce_date": doc.get("announce_date", ""),
                            "case_type": doc.get("case_type", ""),
                            # íŒë¡€ ë³¸ë¬¸ ì •ë³´
                            "case_summary": doc.get("case_summary", ""),
                            "case_holding": doc.get("case_holding", ""),
                            "case_reasoning": doc.get("case_reasoning", ""),
                            "source_type": doc.get("source_type", "")
                        }
                        document_contents.append(doc_dict)

        # ë°©ë²• 2: structured_documentsê°€ ì—†ìœ¼ë©´ context í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì„œ íŒ¨í„´ ì¶”ì¶œ
        if not document_contents:
            context_text = context.get("context", "")
            if context_text and len(context_text) > 100:
                # context í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì„œ íŒ¨í„´ ì¶”ì¶œ ([ë¬¸ì„œ ì¶œì²˜: ...] íŒ¨í„´)
                import re
                doc_pattern = r'\[ë¬¸ì„œ ì¶œì²˜:\s*([^\]]+)\]\s*\[ê´€ë ¨ë„:\s*([\d.]+)\]\s*\n(.*?)(?=\n\[ë¬¸ì„œ ì¶œì²˜:|$)'
                matches = re.findall(doc_pattern, context_text, re.DOTALL)
                for match in matches[:10]:
                    if len(match) == 3:
                        doc_source = match[0].strip()
                        doc_score = float(match[1]) if match[1] else 0.0
                        doc_content = match[2].strip()
                        if doc_content and len(doc_content) > 10:
                            document_contents.append({
                                "source": doc_source,
                                "content": doc_content,
                                "score": doc_score
                            })

                if document_contents:
                    logger.info(f"âœ… [DOCUMENT EXTRACTION] Extracted {len(document_contents)} documents from context text")

        structured_parts = []

        # ê°œì„ : ë¬¸ì„œ ë‚´ìš©ì„ ê°€ì¥ ë¨¼ì € ì¶”ê°€í•˜ì—¬ ê²½ê³  ë°©ì§€
        # ì§ˆë¬¸ ìœ í˜•ê³¼ ê´€ê³„ì—†ì´ document_contentsê°€ ìˆìœ¼ë©´ í•­ìƒ ë¨¼ì € í¬í•¨
        if document_contents:
            # ë¬¸ì„œ ë‚´ìš©ì„ ì§ˆë¬¸ ìœ í˜•ì— ë§ê²Œ êµ¬ì¡°í™”í•˜ë˜, í•­ìƒ í¬í•¨ë˜ë„ë¡ ë³´ì¥
            sorted_docs = sorted(
                document_contents,
                key=lambda x: x.get("score", 0.0) if isinstance(x, dict) else 0.0,
                reverse=True
            )
            
            high_relevance = [d for d in sorted_docs if d.get("score", 0.0) >= 0.65]
            medium_relevance = [d for d in sorted_docs if 0.35 <= d.get("score", 0.0) < 0.65]

        try:
            # ì§ˆë¬¸ ìœ í˜•ë³„ êµ¬ì¡°í™”
            if question_type == QuestionType.PRECEDENT_SEARCH:
                # íŒë¡€ ì •ë³´ ìš°ì„  ë°°ì¹˜
                # ë¬¸ì„œ ë‚´ìš© ê°•ì œ í¬í•¨ (ê°€ì¥ ì¤‘ìš”) - ì´ë¯¸ ìœ„ì—ì„œ ì •ë ¬ë¨
                if document_contents:

                    structured_parts.append("## ê²€ìƒ‰ëœ íŒë¡€ ë¬¸ì„œ\n")
                    structured_parts.append("ë‹¤ìŒì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•´ ê²€ìƒ‰ëœ ê´€ë ¨ íŒë¡€ ë¬¸ì„œì…ë‹ˆë‹¤. **ë°˜ë“œì‹œ ì´ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**\n")

                    if high_relevance:
                        structured_parts.append("### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ê´€ë ¨ë„ 0.65 ì´ìƒ)\n")
                        for idx, doc in enumerate(high_relevance[:5], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=True)
                            structured_parts.append(formatted_doc)

                    if medium_relevance:
                        structured_parts.append("### ğŸŸ¡ ì¤‘ìš” ë¬¸ì„œ (ê´€ë ¨ë„ 0.35~0.65)\n")
                        for idx, doc in enumerate(medium_relevance[:3], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=False)
                            structured_parts.append(formatted_doc)

                    structured_parts.append("")

                if citations:
                    precedent_citations = [cit for cit in citations if isinstance(cit, dict) and cit.get("type") == "precedent"]
                    if precedent_citations:
                        structured_parts.append("## ê´€ë ¨ íŒë¡€\n")
                        for cit in precedent_citations[:5]:
                            structured_parts.append(f"- {cit.get('text', '')}")
                        structured_parts.append("")

                if context_text:
                    structured_parts.append("## íŒë¡€ ê´€ë ¨ ì •ë³´\n")
                    structured_parts.append(context_text)
                    structured_parts.append("")

                if legal_references:
                    structured_parts.append("## ê´€ë ¨ ë²•ë ¹\n")
                    for ref in legal_references[:5]:
                        if isinstance(ref, str):
                            structured_parts.append(f"- {ref}")
                        else:
                            structured_parts.append(f"- {ref.get('text', '') if isinstance(ref, dict) else str(ref)}")

            elif question_type == QuestionType.LAW_INQUIRY:
                # ë²•ë¥  ì¡°ë¬¸ ì¤‘ì‹¬ êµ¬ì¡°
                if legal_references:
                    structured_parts.append("## ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸\n")
                    for ref in legal_references[:5]:
                        if isinstance(ref, str):
                            structured_parts.append(f"- {ref}")
                        else:
                            structured_parts.append(f"- {ref.get('text', '') if isinstance(ref, dict) else str(ref)}")
                    structured_parts.append("")

                if citations:
                    law_citations = [cit for cit in citations if isinstance(cit, dict) and cit.get("type") == "law_article"]
                    if law_citations:
                        structured_parts.append("## ë²•ë¥  ì¡°í•­ ìƒì„¸\n")
                        for cit in law_citations[:5]:
                            structured_parts.append(f"- {cit.get('text', '')}")
                        structured_parts.append("")

                # ë¬¸ì„œ ë‚´ìš© ê°•ì œ í¬í•¨ - ì´ë¯¸ ìœ„ì—ì„œ ì •ë ¬ë¨
                if document_contents:
                    structured_parts.append("## ê²€ìƒ‰ëœ ë²•ë¥  ì¡°ë¬¸ ë¬¸ì„œ\n")

                    if high_relevance:
                        structured_parts.append("### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ê´€ë ¨ë„ 0.65 ì´ìƒ)\n")
                        for idx, doc in enumerate(high_relevance[:5], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜ (score â†’ relevance_score)
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=True)
                            structured_parts.append(formatted_doc)

                    if medium_relevance:
                        structured_parts.append("### ğŸŸ¡ ì¤‘ìš” ë¬¸ì„œ (ê´€ë ¨ë„ 0.35~0.65)\n")
                        for idx, doc in enumerate(medium_relevance[:3], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=False)
                            structured_parts.append(formatted_doc)

                    structured_parts.append("")

                if context_text:
                    structured_parts.append("## ì¡°ë¬¸ í•´ì„¤\n")
                    structured_parts.append(context_text)

            elif question_type == QuestionType.LEGAL_ADVICE:
                # ë²•ë ¹ + íŒë¡€ + ì‹¤ë¬´ ì¡°ì–¸ ê· í˜• ë°°ì¹˜
                if legal_references:
                    structured_parts.append("## ê´€ë ¨ ë²•ë ¹\n")
                    for ref in legal_references[:3]:
                        if isinstance(ref, str):
                            structured_parts.append(f"- {ref}")
                        else:
                            structured_parts.append(f"- {ref.get('text', '') if isinstance(ref, dict) else str(ref)}")
                    structured_parts.append("")

                if citations:
                    precedent_cits = [cit for cit in citations if isinstance(cit, dict) and cit.get("type") == "precedent"]
                    if precedent_cits:
                        structured_parts.append("## ê´€ë ¨ íŒë¡€\n")
                        for cit in precedent_cits[:3]:
                            structured_parts.append(f"- {cit.get('text', '')}")
                        structured_parts.append("")

                # ë¬¸ì„œ ë‚´ìš© ê°•ì œ í¬í•¨ - ì´ë¯¸ ìœ„ì—ì„œ ì •ë ¬ë¨
                if document_contents:
                    structured_parts.append("## ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ ë° íŒë¡€\n")

                    if high_relevance:
                        structured_parts.append("### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ê´€ë ¨ë„ 0.65 ì´ìƒ)\n")
                        for idx, doc in enumerate(high_relevance[:5], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=True)
                            structured_parts.append(formatted_doc)

                    if medium_relevance:
                        structured_parts.append("### ğŸŸ¡ ì¤‘ìš” ë¬¸ì„œ (ê´€ë ¨ë„ 0.35~0.65)\n")
                        for idx, doc in enumerate(medium_relevance[:3], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=False)
                            structured_parts.append(formatted_doc)

                    structured_parts.append("")

                if context_text:
                    structured_parts.append("## ë²•ë¥  ë¶„ì„ ë° ì‹¤ë¬´ ì¡°ì–¸\n")
                    structured_parts.append(context_text)

                if insights:
                    structured_parts.append("\n## í•µì‹¬ ìš”ì•½\n")
                    for insight in insights[:3]:
                        structured_parts.append(f"- {insight}")
            else:
                # ê¸°ë³¸ êµ¬ì¡°: ë¬¸ì„œ ë‚´ìš© ìš°ì„  í¬í•¨ - ì´ë¯¸ ìœ„ì—ì„œ ì •ë ¬ë¨
                if document_contents:
                    structured_parts.append("## ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n")
                    structured_parts.append("ë‹¤ìŒì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•´ ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë¥  ë¬¸ì„œì…ë‹ˆë‹¤.\n")

                    if high_relevance:
                        structured_parts.append("### ğŸ”´ ìµœìš°ì„  ë¬¸ì„œ (ê´€ë ¨ë„ 0.65 ì´ìƒ)\n")
                        for idx, doc in enumerate(high_relevance[:5], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=True)
                            structured_parts.append(formatted_doc)

                    if medium_relevance:
                        structured_parts.append("### ğŸŸ¡ ì¤‘ìš” ë¬¸ì„œ (ê´€ë ¨ë„ 0.35~0.65)\n")
                        for idx, doc in enumerate(medium_relevance[:3], 1):
                            # ê´€ë ¨ë„ ì ìˆ˜ë¥¼ relevance_scoreë¡œ ë³€í™˜
                            doc_for_format = doc.copy()
                            doc_for_format["relevance_score"] = doc.get("score", 0.0)
                            formatted_doc = self._format_document_for_prompt(doc_for_format, idx, is_high_priority=False)
                            structured_parts.append(formatted_doc)

                    structured_parts.append("")

                if legal_references:
                    structured_parts.append("## ê´€ë ¨ ë²•ë ¹\n")
                    for ref in legal_references[:5]:
                        if isinstance(ref, str):
                            structured_parts.append(f"- {ref}")
                        else:
                            structured_parts.append(f"- {ref.get('text', '') if isinstance(ref, dict) else str(ref)}")
                    structured_parts.append("")

                # ğŸ”´ ê°œì„ : "ì¶”ê°€ ê´€ë ¨ ì •ë³´" ì„¹ì…˜ ì œê±° (ì¤‘ë³µ ë°©ì§€)
                # if context_text:
                #     structured_parts.append("## ì¶”ê°€ ê´€ë ¨ ì •ë³´\n")
                #     structured_parts.append(context_text)
                #     structured_parts.append("")
                # context_textëŠ” ì´ë¯¸ ë‹¤ë¥¸ ê³³ì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ ì—¬ê¸°ì„œ ì¤‘ë³µ ì œê±°

            # ìµœì¢… ê²€ì¦: structured_partsì— ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
            result_text = "\n".join(structured_parts)
            
            # ê°œì„ : ë¬¸ì„œ ë‚´ìš© í¬í•¨ ê²€ì¦ ê°•í™”
            # 1. document_contentsê°€ ìˆëŠ”ë° result_textì— ë¬¸ì„œ ë‚´ìš©ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš°
            # 2. result_text ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš° (500ì ë¯¸ë§Œ)
            # 3. result_textì— "ë¬¸ì„œ", "document", "content" ë“±ì˜ í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš°
            has_doc_content = document_contents and len(document_contents) > 0
            has_doc_keywords = any(keyword in result_text.lower() for keyword in ["ë¬¸ì„œ", "document", "content", "ë²•ë¥ ", "íŒë¡€"])
            text_too_short = len(result_text) < 500
            
            if has_doc_content and (text_too_short or not has_doc_keywords):
                # ë¬¸ì„œ ë‚´ìš©ì´ ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš° ê°•ì œ ì¶”ê°€
                logger.warning(
                    f"âš ï¸ [CONTEXT STRUCTURE] Document contents not properly included in structured context. "
                    f"Force adding {len(document_contents)} documents. (text_len={len(result_text)}, has_keywords={has_doc_keywords})"
                )
                doc_section = "\n## ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ\n"
                doc_section += "ë‹¤ìŒì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìœ„í•´ ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë¥  ë¬¸ì„œì…ë‹ˆë‹¤.\n\n"
                
                # ìƒìœ„ 5ê°œ ë¬¸ì„œ ì¶”ê°€ (ê´€ë ¨ë„ ìˆœ)
                sorted_docs = sorted(
                    document_contents,
                    key=lambda x: x.get("score", 0.0) if isinstance(x, dict) else 0.0,
                    reverse=True
                )
                
                for idx, doc in enumerate(sorted_docs[:5], 1):
                    content = doc.get("content", "")[:2000] if len(doc.get("content", "")) > 2000 else doc.get("content", "")
                    if content and len(content.strip()) > 10:
                        doc_source = doc.get("source", "Unknown")
                        doc_score = doc.get("score", 0.0)
                        # ë¬¸ì„œ í˜•ì‹í™”
                        doc_section += f"\n### ë¬¸ì„œ {idx}: {doc_source} (ê´€ë ¨ë„: {doc_score:.2f})\n{content}\n---\n"
                
                # ë¬¸ì„œ ì„¹ì…˜ì„ ì•ìª½ì— ì¶”ê°€
                result_text = doc_section + "\n" + result_text

            return result_text

        except Exception as e:
            logger.warning(f"Context structuring failed: {e}, using default format")
            # í´ë°±: ê¸°ë³¸ í¬ë§·
            return self._format_context(context)

    def _get_relevant_examples(
        self,
        question_type: QuestionType,
        documents: Optional[List[Dict[str, Any]]] = None
    ) -> str:
        """Few-shot í•™ìŠµì„ ìœ„í•œ ì§ˆë¬¸ ìœ í˜•ë³„ ë‹µë³€ ì˜ˆì‹œ (ê²€ìƒ‰ ê²°ê³¼ í™œìš© ê°•ì¡°)"""
        examples = []

        # ğŸ”´ ê°œì„ : ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì˜ˆì‹œ ìƒì„±
        if documents and len(documents) > 0:
            # ì‹¤ì œ ë¬¸ì„œë¥¼ ì˜ˆì‹œë¡œ ì‚¬ìš©
            sorted_docs = sorted(
                documents,
                key=lambda x: x.get("relevance_score", 0.0) if isinstance(x, dict) else 0.0,
                reverse=True
            )
            example_docs = sorted_docs[:2]  # ìƒìœ„ 2ê°œë§Œ ì˜ˆì‹œë¡œ ì‚¬ìš©
        else:
            example_docs = None

        try:
            if question_type == QuestionType.PRECEDENT_SEARCH:
                # ì‹¤ì œ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¼ë°˜ ì˜ˆì‹œ ì‚¬ìš©
                if example_docs and any(doc.get("court") or doc.get("case_number") for doc in example_docs if isinstance(doc, dict)):
                    # ì‹¤ì œ íŒë¡€ ë¬¸ì„œë¡œ ì˜ˆì‹œ ìƒì„±
                    example_text = "## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ\n\n"
                    example_text += "**ë‹µë³€ ì‘ì„± ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì„¸ìš”**:\n\n"
                    for idx, doc in enumerate(example_docs[:2], 1):
                        if isinstance(doc, dict):
                            case_number = doc.get("case_number", "")
                            court = doc.get("court", "")
                            case_name = doc.get("case_name", "")
                            score = doc.get("relevance_score", 0.0)

                            ref = case_number or (f"{court} {case_name}" if court and case_name else case_name or "íŒë¡€")
                            example_text += f"**ë¬¸ì„œ {idx}**: {ref} (ê´€ë ¨ë„: {score:.2f}) - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ì°¸ê³ \n"
                    example_text += "\n**ì¢‹ì€ ë‹µë³€ í˜•ì‹**:\n"
                    example_text += "- ê²€ìƒ‰ëœ íŒë¡€ë¥¼ ì¸ìš©í•˜ì—¬ ë‹µë³€: \"[íŒë¡€: íŒë¡€ë²ˆí˜¸]ì— ë”°ë¥´ë©´...\"\n"
                    example_text += "- íŒë¡€ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì„¤ëª…\n"
                    example_text += "- ì‹¤ë¬´ì  ì˜ë¯¸ë¥¼ í•¨ê»˜ ì„¤ëª…\n\n"
                    examples.append(example_text)
                else:
                    # ì¼ë°˜ ì˜ˆì‹œ (íŠ¹ì • íŒë¡€ ë²ˆí˜¸ ì—†ì´)
                    examples.append("""
## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ

**ì¢‹ì€ ë‹µë³€ í˜•ì‹**:
- ê²€ìƒ‰ëœ íŒë¡€ë¥¼ ëª…í™•íˆ ì¸ìš©í•˜ì—¬ ë‹µë³€
- íŒë¡€ì˜ í•µì‹¬ ë‚´ìš©(íŒì‹œì‚¬í•­, íŒê²°ìš”ì§€) ìš”ì•½
- ì‹¤ë¬´ì  ì˜ë¯¸ ì„¤ëª…

**ë‚˜ìœ ë‹µë³€**: ì¶œì²˜ ì—†ì´ ì¼ë°˜ ì§€ì‹ë§Œ ì‚¬ìš©
""")
            elif question_type == QuestionType.LAW_INQUIRY:
                # ì‹¤ì œ ë²•ë ¹ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                if example_docs and any(doc.get("law_name") and doc.get("article_no") for doc in example_docs if isinstance(doc, dict)):
                    example_text = "## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ\n\n"
                    example_text += "**ë‹µë³€ ì‘ì„± ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì„¸ìš”**:\n\n"
                    for idx, doc in enumerate(example_docs[:2], 1):
                        if isinstance(doc, dict):
                            law_name = doc.get("law_name", "")
                            article_no = doc.get("article_no", "")
                            score = doc.get("relevance_score", 0.0)
                            if law_name and article_no:
                                example_text += f"**ë¬¸ì„œ {idx}**: {law_name} ì œ{article_no}ì¡° (ê´€ë ¨ë„: {score:.2f}) - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ì°¸ê³ \n"
                    example_text += "\n**ì¢‹ì€ ë‹µë³€ í˜•ì‹**:\n"
                    example_text += "- ì¡°ë¬¸ ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ì„¤ëª…: \"[ë²•ë ¹: ë²•ë ¹ëª… ì œXXì¡°]ì— ë”°ë¥´ë©´...\"\n"
                    example_text += "- ì¡°ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…\n"
                    example_text += "- í•„ìš”ì‹œ ì‹¤ë¬´ì  ì¡°ì–¸ í¬í•¨\n\n"
                    examples.append(example_text)
                else:
                    # ì¼ë°˜ ì˜ˆì‹œ
                    examples.append("""
## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ

**ì¢‹ì€ ë‹µë³€ í˜•ì‹**:
- ê²€ìƒ‰ëœ ì¡°ë¬¸ì„ ëª…í™•íˆ ì¸ìš©: "[ë²•ë ¹: ë²•ë ¹ëª… ì œXXì¡°]"
- ì¡°ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
- í•„ìš”ì‹œ ì‹¤ë¬´ì  ì˜ë¯¸ í¬í•¨

**ë‚˜ìœ ë‹µë³€**: ì¶œì²˜ ì—†ì´ ì¼ë°˜ ì§€ì‹ë§Œ ì‚¬ìš©
""")
            elif question_type == QuestionType.LEGAL_ADVICE:
                # ì‹¤ì œ ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                if example_docs:
                    example_text = "## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ\n\n"
                    example_text += "**ë‹µë³€ ì‘ì„± ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì„¸ìš”**:\n\n"
                    example_text += "**ì¢‹ì€ ë‹µë³€ êµ¬ì„±**:\n"
                    example_text += "1. ìƒí™© íŒŒì•… ë° ë²•ì  ê·¼ê±° ì œì‹œ\n"
                    example_text += "2. ê²€ìƒ‰ëœ ë²•ë ¹/íŒë¡€ ì¸ìš©í•˜ì—¬ ì„¤ëª…\n"
                    example_text += "3. ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸\n"
                    example_text += "4. ì£¼ì˜ì‚¬í•­ (í•„ìš”ì‹œ)\n\n"
                    example_text += "**ì¸ìš© í˜•ì‹**:\n"
                    for idx, doc in enumerate(example_docs[:2], 1):
                        if isinstance(doc, dict):
                            law_name = doc.get("law_name", "")
                            article_no = doc.get("article_no", "")
                            case_number = doc.get("case_number", "")
                            if law_name and article_no:
                                example_text += f"- ë²•ë ¹: \"[ë²•ë ¹: {law_name} ì œ{article_no}ì¡°]ì— ë”°ë¥´ë©´...\"\n"
                            elif case_number:
                                example_text += f"- íŒë¡€: \"[íŒë¡€: {case_number}]ì— ë”°ë¥´ë©´...\"\n"
                    example_text += "\n**ë‚˜ìœ ë‹µë³€**: ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€\n"
                    examples.append(example_text)
                else:
                    # ì¼ë°˜ ì˜ˆì‹œ
                    examples.append("""
## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ

**ì¢‹ì€ ë‹µë³€ êµ¬ì„±**:
1. ìƒí™© íŒŒì•… ë° ë²•ì  ê·¼ê±° ì œì‹œ
2. ê²€ìƒ‰ëœ ë²•ë ¹/íŒë¡€ë¥¼ ì¸ìš©í•˜ì—¬ ì„¤ëª…
3. ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸
4. ì£¼ì˜ì‚¬í•­ (í•„ìš”ì‹œ)

**ë‚˜ìœ ë‹µë³€**: ê²€ìƒ‰ ê²°ê³¼ ì—†ì´ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€
""")
            else:
                # ì¼ë°˜ ì§ˆë¬¸ìš© ì˜ˆì‹œ
                if example_docs:
                    example_text = "## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ\n\n"
                    example_text += "**ë‹µë³€ ì‘ì„± ì‹œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”**:\n"
                    example_text += "- ê²€ìƒ‰ëœ ë²•ë ¹/íŒë¡€ë¥¼ ëª…í™•íˆ ì¸ìš©\n"
                    example_text += "- ì¡°ë¬¸/íŒë¡€ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…\n"
                    example_text += "- í•„ìš”ì‹œ ì‹¤ë¬´ì  ì¡°ì–¸ í¬í•¨\n\n"
                    examples.append(example_text)
                else:
                    examples.append("""
## ğŸ“š ë‹µë³€ í˜•ì‹ ê°€ì´ë“œ

**ì¢‹ì€ ë‹µë³€**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë²•ì  ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³  ëª…í™•íˆ ì„¤ëª…
**ë‚˜ìœ ë‹µë³€**: ì¶œì²˜ ì—†ì´ ì¼ë°˜ ì§€ì‹ë§Œ ì‚¬ìš©
""")

            return "\n".join(examples) if examples else ""

        except Exception as e:
            logger.warning(f"Example generation failed: {e}")
            return ""

    def _get_fallback_prompt(self, query: str) -> str:
        """í´ë°± í”„ë¡¬í”„íŠ¸"""
        return f"""ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
1. ê´€ë ¨ ë²•ë ¹ê³¼ íŒë¡€ë¥¼ ì •í™•íˆ ì¸ìš©
2. ì‹¤ë¬´ì  ê´€ì ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ ì œê³µ
3. ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ëª…í™•íˆ í‘œì‹œ
4. ì „ë¬¸ê°€ ìƒë‹´ ê¶Œìœ 

ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    def _normalize_legal_domain(self, domain) -> Optional[LegalDomain]:
        """LegalDomain ì •ê·œí™” - ë¬¸ìì—´ì„ enumìœ¼ë¡œ ë³€í™˜"""
        if domain is None:
            return None

        # ì´ë¯¸ LegalDomain enumì¸ ê²½ìš°
        if isinstance(domain, LegalDomain):
            return domain

        # ë¬¸ìì—´ì¸ ê²½ìš° enumìœ¼ë¡œ ë³€í™˜
        if isinstance(domain, str):
            # ë¬¸ìì—´ ê°’ìœ¼ë¡œ ë§¤í•‘
            domain_mapping = {
                "ë¯¼ì‚¬ë²•": LegalDomain.CIVIL_LAW,
                "í˜•ì‚¬ë²•": LegalDomain.CRIMINAL_LAW,
                "ê°€ì¡±ë²•": LegalDomain.FAMILY_LAW,
                "ìƒì‚¬ë²•": LegalDomain.COMMERCIAL_LAW,
                "í–‰ì •ë²•": LegalDomain.ADMINISTRATIVE_LAW,
                "ë…¸ë™ë²•": LegalDomain.LABOR_LAW,
                "ë¶€ë™ì‚°ë²•": LegalDomain.PROPERTY_LAW,
                "ì§€ì ì¬ì‚°ê¶Œë²•": LegalDomain.INTELLECTUAL_PROPERTY,
                "ì„¸ë²•": LegalDomain.TAX_LAW,
                "ë¯¼ì‚¬ì†Œì†¡ë²•": LegalDomain.CIVIL_PROCEDURE,
                "í˜•ì‚¬ì†Œì†¡ë²•": LegalDomain.CRIMINAL_PROCEDURE,
                "ê¸°íƒ€/ì¼ë°˜": LegalDomain.GENERAL,
                "ì¼ë°˜": LegalDomain.GENERAL,
                "ê¸°íƒ€": LegalDomain.GENERAL,
            }

            # ì§ì ‘ ë§¤í•‘ ì‹œë„
            if domain in domain_mapping:
                return domain_mapping[domain]

            # LegalDomain enumì˜ valueë¡œ ì°¾ê¸°
            for legal_domain in LegalDomain:
                if legal_domain.value == domain:
                    return legal_domain

            # LegalDomain enumì˜ nameìœ¼ë¡œ ì°¾ê¸°
            try:
                return LegalDomain[domain.upper()]
            except (KeyError, AttributeError):
                pass

            logger.warning(f"âš ï¸ [DOMAIN NORMALIZATION] Unknown domain string: '{domain}', defaulting to GENERAL")
            return LegalDomain.GENERAL

        logger.warning(f"âš ï¸ [DOMAIN NORMALIZATION] Unknown domain type: {type(domain)}, defaulting to None")
        return None

    def _select_base_prompt_type(self, question_type: QuestionType, domain: Optional[LegalDomain] = None) -> str:
        """ì§ˆë¬¸ ìœ í˜•ê³¼ ë„ë©”ì¸ì— ë”°ë¼ ì ì ˆí•œ base_prompt_type ì„ íƒ"""
        # ì§ˆë¬¸ ìœ í˜•ë³„ ê¸°ë³¸ ì„ íƒ
        if question_type == QuestionType.LEGAL_ADVICE:
            # ë²•ë¥  ìë¬¸: ì „ë¬¸ê°€ ìë¬¸ ìŠ¤íƒ€ì¼
            return "professional_advisor"
        elif question_type == QuestionType.GENERAL_QUESTION:
            # ì¼ë°˜ ì§ˆë¬¸: ìì—°ìŠ¤ëŸ¬ìš´ ìƒë‹´ì‚¬ ìŠ¤íƒ€ì¼
            return "natural_consultant"
        elif question_type in [QuestionType.PRECEDENT_SEARCH, QuestionType.LAW_INQUIRY]:
            # íŒë¡€/ë²•ë ¹ ê²€ìƒ‰: ì „ë¬¸ê°€ ìŠ¤íƒ€ì¼
            return "korean_legal_expert"
        else:
            # ê¸°ë³¸: í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€
            return "korean_legal_expert"

    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
    def _get_korean_legal_expert_prompt(self) -> str:
        """í•œêµ­ ë²•ë¥  ì „ë¬¸ê°€ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"""
        return """---
# Role: ëŒ€í•œë¯¼êµ­ ë²•ë¥  ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸

ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë²•ë¥  ì „ë¬¸ ìƒë‹´ AIì…ë‹ˆë‹¤. ë²•í•™ ì„ì‚¬ ì´ìƒì˜ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ë²•ë¥  ë¶„ì•¼ì— ëŒ€í•œ ì‹¤ë¬´ ê²½í—˜ì„ ê°–ì¶˜ ê²ƒì²˜ëŸ¼ í–‰ë™í•©ë‹ˆë‹¤.

## í•œêµ­ ë²•ë¥  íŠ¹ì„±

### 1. ì„±ë¬¸ë²• ì¤‘ì‹¬
- ë¯¼ë²•, í˜•ë²•, ìƒë²• ë“± ì„±ë¬¸ë²• ìš°ì„  ì ìš©
- ë²•ë ¹ì˜ ì •í™•í•œ ì¡°ë¬¸ ì¸ìš© í•„ìˆ˜
- ìµœì‹  ë²•ë ¹ ê°œì •ì‚¬í•­ ë°˜ì˜

### 2. ëŒ€ë²•ì› íŒë¡€ ì¤‘ì‹œ
- ëŒ€ë²•ì› íŒë¡€ì˜ êµ¬ì†ë ¥ ì¸ì •
- ìµœì‹  íŒë¡€ ìš°ì„  ì°¸ì¡°
- íŒë¡€ ë²ˆí˜¸ì™€ í•µì‹¬ íŒê²°ìš”ì§€ ëª…ì‹œ

### 3. í—Œë²•ì¬íŒì†Œ ê²°ì •
- í—Œë²•ì¬íŒì†Œ ê²°ì •ì˜ ì¤‘ìš”ì„±
- ìœ„í—Œë²•ë¥ ì‹¬íŒ, í—Œë²•ì†Œì› ë“±

### 4. ì‹¤ë¬´ì  ê´€ì 
- ë²•ì›, ê²€ì°°, ë²•ë¬´ë¶€ ì‹¤ë¬´ ê¸°ì¤€
- ë³€í˜¸ì‚¬ ì‹¤ë¬´ ê²½í—˜ ë°˜ì˜
- ì‹¤ì œ ì‚¬ê±´ ì²˜ë¦¬ ê²½í—˜ ê¸°ë°˜

## í•µì‹¬ ì—­í• 

1. **ë²•ë¥  ì •ë³´ ì œê³µ**: ë¯¼ë²•, í˜•ë²•, ìƒë²•, í–‰ì •ë²• ë“± ê°ì¢… ë²•ë¥ ì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ ì œê³µ
2. **ë²•ì  ì¡°ì–¸**: ì‚¬ìš©ìì˜ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë²•ì  ëŒ€ì‘ ë°©í–¥ ì œì‹œ
3. **íŒë¡€ ë° ë²•ë ¹ í•´ì„¤**: ê´€ë ¨ íŒë¡€ì™€ ë²•ë ¹ì„ ì‰½ê²Œ ì„¤ëª…
4. **ì ˆì°¨ ì•ˆë‚´**: ì†Œì†¡, ê³ ì†Œ, ê³„ì•½ ë“± ë²•ì  ì ˆì°¨ì— ëŒ€í•œ ì•ˆë‚´

## ë‹µë³€ ì›ì¹™

### 1. ì •í™•ì„±ê³¼ ì‹ ì¤‘ì„±
- í™•ì‹¤í•œ ë²•ë¥  ì •ë³´ë§Œ ì œê³µí•˜ë©°, ë¶ˆí™•ì‹¤í•œ ê²½ìš° ëª…í™•íˆ í‘œì‹œ
- ë²•ë¥ ì€ í•´ì„ì˜ ì—¬ì§€ê°€ ìˆìŒì„ ì¸ì§€í•˜ê³  ë‹¨ì •ì  í‘œí˜„ ìì œ
- ìµœì‹  ë²•ë ¹ ê°œì • ì‚¬í•­ì— ëŒ€í•´ì„œëŠ” í™•ì¸ì´ í•„ìš”í•¨ì„ ì•ˆë‚´

### 2. ëª…í™•í•œ í•œê³„ ì„¤ì •
- ë‹µë³€ ì‹œì‘ ë˜ëŠ” ì¢…ë£Œ ì‹œ ë‹¤ìŒ ë©´ì±… ë¬¸êµ¬ í¬í•¨:
  > "ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•œ ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

### 3. êµ¬ì¡°í™”ëœ ë‹µë³€
- **ìƒí™© ì •ë¦¬**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë‚´ìš©ì„ ìš”ì•½ ì •ë¦¬
- **ê´€ë ¨ ë²•ë¥ **: ì ìš© ê°€ëŠ¥í•œ ë²•ë¥  ë° ì¡°í•­ ëª…ì‹œ
- **ë²•ì  ë¶„ì„**: ìŸì ê³¼ ë²•ë¦¬ ì„¤ëª…
- **ì‹¤ì§ˆì  ì¡°ì–¸**: ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒ€ì‘ ë°©ì•ˆ ì œì‹œ
- **ì¶”ê°€ ê³ ë ¤ì‚¬í•­**: ì£¼ì˜ì‚¬í•­ ë° ì°¸ê³ ì‚¬í•­

### 4. ì ‘ê·¼ì„± ìˆëŠ” ì–¸ì–´
- ì „ë¬¸ ë²•ë¥  ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…
- í•„ìš”ì‹œ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì´í•´ë¥¼ ë•ê¸°
- ë³µì¡í•œ ê°œë…ì€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…

### 5. ë„ì–´ì“°ê¸° í•„ìˆ˜ ì¤€ìˆ˜
- **ë°˜ë“œì‹œ ëª¨ë“  ë¬¸ì¥ì— ì ì ˆí•œ ë„ì–´ì“°ê¸°ë¥¼ ì ìš©í•˜ì„¸ìš”**
- ë„ì–´ì“°ê¸° ì—†ëŠ” ë‹µë³€ì€ ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”
- ì˜ˆì‹œ:
  * âŒ "ë¯¼ì‚¬ë²•ìƒê³„ì•½í•´ì§€ì˜ìš”ê±´" (ì˜ëª»ëœ ì˜ˆ)
  * âœ… "ë¯¼ì‚¬ë²•ì—ì„œ ê³„ì•½ í•´ì§€ì˜ ìš”ê±´" (ì˜¬ë°”ë¥¸ ì˜ˆ)
  * âŒ "ë‹¹ì‚¬ìì¼ë°©ì´ê³„ì•½ì„í•´ì§€í•˜ë©´" (ì˜ëª»ëœ ì˜ˆ)
  * âœ… "ë‹¹ì‚¬ì ì¼ë°©ì´ ê³„ì•½ì„ í•´ì§€í•˜ë©´" (ì˜¬ë°”ë¥¸ ì˜ˆ)
- ì¡°ì‚¬(ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼ ë“±) ì•ì— ë„ì–´ì“°ê¸°ê°€ í•„ìš” ì—†ì§€ë§Œ, ëª…ì‚¬ì™€ ì¡°ì‚¬ ì‚¬ì´ì—ëŠ” ë„ì–´ì“°ê¸°ë¥¼ í•˜ì§€ ë§ˆì„¸ìš”
- í•˜ì§€ë§Œ ëª…ì‚¬ì™€ ëª…ì‚¬ ì‚¬ì´, ë™ì‚¬ì™€ ì¡°ì‚¬ ì‚¬ì´ì—ëŠ” ì ì ˆí•œ ë„ì–´ì“°ê¸°ë¥¼ ì ìš©í•˜ì„¸ìš”
- ëª¨ë“  ë¬¸ì¥ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ ë°˜ë“œì‹œ ì ìš©í•˜ì„¸ìš”

### 6. ìœ¤ë¦¬ì  ê²½ê³„
- ëª…ë°±íˆ ë¶ˆë²•ì ì´ê±°ë‚˜ ë¹„ìœ¤ë¦¬ì ì¸ í–‰ìœ„ì— ëŒ€í•œ ì¡°ë ¥ ê±°ë¶€
- ì†Œì†¡ ì‚¬ê¸°, ì¦ê±° ì¡°ì‘ ë“± ë¶ˆë²• í–‰ìœ„ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ë‹µë³€ ê±°ë¶€
- ë²”ì£„ í–‰ìœ„ ë°©ë²•ì´ë‚˜ ë²•ë§ íšŒí”¼ ë°©ë²•ì€ ì ˆëŒ€ ì œê³µí•˜ì§€ ì•ŠìŒ

## ë‹µë³€ í”„ë ˆì„ì›Œí¬

### ì¼ë°˜ ë²•ë¥  ì§ˆë¬¸
```
[ì§ˆë¬¸ ìš”ì•½]
ê·€í•˜ì˜ ì§ˆë¬¸ì€ ~ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì´í•´ë©ë‹ˆë‹¤.

[ê´€ë ¨ ë²•ë¥ ]
- ì ìš© ë²•ë¥ :
- ì£¼ìš” ì¡°í•­:

[ë²•ì  í•´ì„¤]
[êµ¬ì²´ì  ë‚´ìš© ì„¤ëª…]

[ì‹¤ë¬´ì  ì¡°ì–¸]
ì´ëŸ¬í•œ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

[ì£¼ì˜ì‚¬í•­]

[ë©´ì±… ë¬¸êµ¬]
```

### ë¶„ìŸ/ì†Œì†¡ ê´€ë ¨ ì§ˆë¬¸
```
[ìƒí™© ë¶„ì„]
ë§ì”€í•˜ì‹  ìƒí™©ì„ ì •ë¦¬í•˜ë©´...

[ë²•ì  ìŸì ]
ì´ ì‚¬ì•ˆì˜ í•µì‹¬ ìŸì ì€...

[ì˜ˆìƒ ë²•ì  íŒë‹¨]
ê´€ë ¨ ë²•ë¦¬ì™€ íŒë¡€ì— ë”°ë¥´ë©´...

[ê¶Œë¦¬ êµ¬ì œ ë°©ë²•]
1. í˜‘ìƒ/ì¡°ì •
2. ë¯¼ì‚¬ì†Œì†¡
3. í˜•ì‚¬ê³ ì†Œ
[ê°ê°ì˜ ì¥ë‹¨ì  ì„¤ëª…]

[ì¦ê±° ìë£Œ]
ë‹¤ìŒê³¼ ê°™ì€ ìë£Œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤:

[ì ˆì°¨ ì•ˆë‚´]
êµ¬ì²´ì ì¸ ì ˆì°¨ëŠ”...

[ì „ë¬¸ê°€ ìƒë‹´ ê¶Œê³ ]
ë³¸ ì‚¬ì•ˆì€ [ì´ìœ ]ë¡œ ì¸í•´ ë³€í˜¸ì‚¬ ìƒë‹´ì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤.
```

## íŠ¹ë³„ ì§€ì¹¨

### ê¸´ê¸‰ ìƒí™© ëŒ€ì‘
- ê¸´ê¸‰í•œ ë²•ì  ìœ„í—˜ì´ ìˆëŠ” ê²½ìš° ì¦‰ì‹œ ì „ë¬¸ê°€ ìƒë‹´ ê¶Œê³ 
- í˜•ì‚¬ ì‚¬ê±´ì˜ ê²½ìš° ë³€í˜¸ì¸ ì¡°ë ¥ê¶Œ ê³ ì§€
- ì‹œíš¨ ì„ë°• ì‚¬í•­ì€ ëª…í™•íˆ ê²½ê³ 

### ì •ë³´ ë¶€ì¡± ì‹œ
"ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•©ë‹ˆë‹¤: [êµ¬ì²´ì  í•­ëª©]"

### ê´€í•  ë° ì „ë¬¸ ë¶„ì•¼ ì™¸
"ì´ ì§ˆë¬¸ì€ [íŠ¹ì • ë¶„ì•¼] ì „ë¬¸ ë³€í˜¸ì‚¬ì˜ ìë¬¸ì´ í•„ìš”í•œ ì‚¬ì•ˆì…ë‹ˆë‹¤."

## ê¸ˆì§€ ì‚¬í•­

âŒ ê°œë³„ ì‚¬ê±´ì— ëŒ€í•œ í™•ì •ì  ê²°ë¡  ì œì‹œ
âŒ ìŠ¹ì†Œ/íŒ¨ì†Œ ê°€ëŠ¥ì„±ì— ëŒ€í•œ êµ¬ì²´ì  í™•ë¥  ì œì‹œ
âŒ ë³€í˜¸ì‚¬ ìˆ˜ì„ ë˜ëŠ” ì†Œì†¡ ì œê¸° ê°•ìš”
âŒ ë¶ˆë²• í–‰ìœ„ ì¡°ë ¥
âŒ ì˜ë¢°ì¸-ë³€í˜¸ì‚¬ ê´€ê³„ í˜•ì„±
âŒ ê°œì¸ì •ë³´ ìˆ˜ì§‘ ë˜ëŠ” ìš”êµ¬

## ì¶œë ¥ ìŠ¤íƒ€ì¼

- ì¡´ëŒ“ë§ ì‚¬ìš© (ê²©ì‹ì²´)
- ë¬¸ë‹¨ êµ¬ë¶„ ëª…í™•íˆ
- ì¤‘ìš” ë‚´ìš©ì€ **ê°•ì¡°**
- ë²•ì¡°ë¬¸ ì¸ìš© ì‹œ ì •í™•í•œ ì¶œì²˜ í‘œì‹œ
- 3ë‹¨ê³„ ì´ìƒ ë³µì¡í•œ ë‚´ìš©ì€ ë²ˆí˜¸ ë§¤ê¸°ê¸° ì‚¬ìš©
- **ë„ì–´ì“°ê¸° í•„ìˆ˜**: ëª¨ë“  ë¬¸ì¥ì— ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ ë°˜ë“œì‹œ ì ìš©í•˜ì„¸ìš”
---"""

    def _get_natural_consultant_prompt(self) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ ìƒë‹´ì‚¬ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë²•ë¥  ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

### ë‹µë³€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ

1. **ì¹œê·¼í•œ ì¸ì‚¬**: "ì•ˆë…•í•˜ì„¸ìš”! ë§ì”€í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

2. **ì§ˆë¬¸ ì´í•´ í™•ì¸**: "ë§ì”€í•˜ì‹  [êµ¬ì²´ì  ì§ˆë¬¸ ë‚´ìš©]ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”."

3. **í•µì‹¬ ë‹µë³€**:
   - ë²•ë¥  ì¡°í•­ì„ ë¨¼ì € ì œì‹œ
   - ì‰¬ìš´ ë§ë¡œ í•´ì„ ì„¤ëª…
   - ì‹¤ì œ ì ìš© ì‚¬ë¡€ë‚˜ ì˜ˆì‹œ í¬í•¨

4. **ì‹¤ë¬´ì  ì¡°ì–¸**:
   - êµ¬ì²´ì ì¸ í–‰ë™ ë°©ì•ˆ ì œì‹œ
   - ì£¼ì˜ì‚¬í•­ì„ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´
   - ì¶”ê°€ ê³ ë ¤ì‚¬í•­ ì–¸ê¸‰

5. **ë§ˆë¬´ë¦¬**:
   - ìš”ì•½ ì •ë¦¬
   - ì¶”ê°€ ì§ˆë¬¸ ìœ ë„
   - ì „ë¬¸ê°€ ìƒë‹´ ê¶Œìœ 

### ì–¸ì–´ ìŠ¤íƒ€ì¼
- ì¡´ëŒ“ë§ ì‚¬ìš©í•˜ë˜ ë”±ë”±í•˜ì§€ ì•Šê²Œ
- ë²•ë¥  ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…
- ì‚¬ìš©ìì˜ ì…ì¥ì—ì„œ ì´í•´í•˜ê¸° ì‰½ê²Œ
- ê°ì •ì  ê³µê°ê³¼ ì „ë¬¸ì„±ì„ ê· í˜•ìˆê²Œ

### ë‹µë³€ êµ¬ì¡° ì˜ˆì‹œ
```
ì•ˆë…•í•˜ì„¸ìš”! [ì§ˆë¬¸ ë‚´ìš©]ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ğŸ“‹ ê´€ë ¨ ë²•ë¥  ì¡°í•­
[ë²•ë¥ ëª…] ì œXì¡°ì— ë”°ë¥´ë©´...

ğŸ’¡ ì‰½ê²Œ ì„¤ëª…í•˜ë©´
ì´ ì¡°í•­ì€ [ì‰¬ìš´ ì„¤ëª…]ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

ğŸ” ì‹¤ì œ ì ìš© ì˜ˆì‹œ
ì˜ˆë¥¼ ë“¤ì–´, [êµ¬ì²´ì  ì‚¬ë¡€]ì˜ ê²½ìš°...

âš ï¸ ì£¼ì˜ì‚¬í•­
ì´ëŸ° ê²½ìš°ì—ëŠ” [ì£¼ì˜ì‚¬í•­]ì„ ê³ ë ¤í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.

ğŸ“ ì¶”ê°€ ë„ì›€
ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!
```

### íŠ¹ë³„ ì§€ì¹¨
- í•­ìƒ ì‚¬ìš©ìì˜ ìƒí™©ì„ ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í•˜ì„¸ìš”
- ë³µì¡í•œ ë²•ë¥  ê°œë…ì€ ì¼ìƒì ì¸ ì˜ˆì‹œë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ì†”ì§í•˜ê²Œ ë§í•˜ê³  ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œí•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ê±±ì •í•˜ê³  ìˆë‹¤ë©´ ê³µê°í•˜ê³  ì•ˆì‹¬ì‹œì¼œ ì£¼ì„¸ìš”

### ë©´ì±… ë¬¸êµ¬
ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•œ ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

    def _get_professional_advisor_prompt(self) -> str:
        """ì „ë¬¸ê°€ ìë¬¸ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒê³¼ ê°™ì€ ì „ë¬¸ì  ìë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤:

### ì „ë¬¸ê°€ ìë¬¸ ìŠ¤íƒ€ì¼

1. **ì „ë¬¸ì„± ê°•ì¡°**: ë²•í•™ì  ê·¼ê±°ì™€ ì‹¤ë¬´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë¶„ì„
2. **ì²´ê³„ì  ì ‘ê·¼**: ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ë²•ì  ë¶„ì„
3. **ì‹¤ë¬´ ì¤‘ì‹¬**: ì‹¤ì œ ë²•ì›, ê²€ì°°, ë²•ë¬´ë¶€ ì‹¤ë¬´ ê¸°ì¤€ ë°˜ì˜
4. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: ë²•ì  ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ì•ˆ ì œì‹œ

### ë‹µë³€ êµ¬ì¡°
```
## ë²•ì  ë¶„ì„
[ë²•ë¥ ì  ê·¼ê±°ì™€ ë¶„ì„]

## ì‹¤ë¬´ì  ê´€ì 
[ì‹¤ë¬´ì—ì„œì˜ ì ìš© ë°©ë²•]

## ë¦¬ìŠ¤í¬ í‰ê°€
[ì ì¬ì  ë²•ì  ë¦¬ìŠ¤í¬]

## ê¶Œì¥ì‚¬í•­
[êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ]

## ì¶”ê°€ ê³ ë ¤ì‚¬í•­
[ì£¼ì˜ì‚¬í•­ ë° ì°¸ê³ ì‚¬í•­]
```

### ì „ë¬¸ì„± í‘œì‹œ
- ê´€ë ¨ ë²•ë ¹ì˜ ì •í™•í•œ ì¡°ë¬¸ ì¸ìš©
- ìµœì‹  ëŒ€ë²•ì› íŒë¡€ ì°¸ì¡°
- ì‹¤ë¬´ ê²½í—˜ ê¸°ë°˜ ì¡°ì–¸
- ë²•ì  ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ

### ë©´ì±… ë¬¸êµ¬
ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•œ ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

    # ë„ë©”ì¸ë³„ í…œí”Œë¦¿ë“¤
    def _get_civil_law_template(self) -> str:
        """ë¯¼ì‚¬ë²• í…œí”Œë¦¿"""
        return """
## ë¯¼ì‚¬ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: ê³„ì•½, ë¶ˆë²•í–‰ìœ„, ì†Œìœ ê¶Œ, ìƒì†
- **ì£¼ìš” ë²•ë ¹**: ë¯¼ë²•, ë¯¼ì‚¬ì†Œì†¡ë²•, ë¶€ë™ì‚°ë“±ê¸°ë²•
- **ìµœì‹  ê°œì •**: 2024ë…„ ë¯¼ë²• ê°œì •ì‚¬í•­ ë°˜ì˜

### ë‹µë³€ êµ¬ì¡°
1. **ë²•ë¥ ê´€ê³„ ë¶„ì„**: ë‹¹ì‚¬ì ê°„ ë²•ë¥ ê´€ê³„ ëª…í™•í™”
2. **ê¶Œë¦¬ì™€ ì˜ë¬´**: ê° ë‹¹ì‚¬ìì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ ë¶„ì„
3. **êµ¬ì œ ë°©ë²•**: ê¶Œë¦¬ êµ¬ì œë¥¼ ìœ„í•œ êµ¬ì²´ì  ë°©ë²•
4. **ë²•ì  ê·¼ê±°**: ê´€ë ¨ ë¯¼ë²• ì¡°í•­ê³¼ íŒë¡€ ì¸ìš©
5. **ì‹¤ë¬´ ì£¼ì˜ì‚¬í•­**: ì‹¤ì œ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- ì‹œíš¨ ì œë„ (ë¯¼ë²• ì œ162ì¡° ì´í•˜)
- ë¶ˆë²•í–‰ìœ„ì˜ ì„±ë¦½ìš”ê±´ (ë¯¼ë²• ì œ750ì¡°)
- ê³„ì•½ì˜ í•´ì œì™€ í•´ì§€ (ë¯¼ë²• ì œ543ì¡° ì´í•˜)
- ìƒì†ì˜ ê°œì‹œì™€ ìƒì†ë¶„ (ë¯¼ë²• ì œ997ì¡° ì´í•˜)
"""

    def _get_criminal_law_template(self) -> str:
        """í˜•ì‚¬ë²• í…œí”Œë¦¿"""
        return """
## í˜•ì‚¬ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: ë²”ì£„ êµ¬ì„±ìš”ê±´, í˜•ëŸ‰, ì ˆì°¨
- **ì£¼ìš” ë²•ë ¹**: í˜•ë²•, í˜•ì‚¬ì†Œì†¡ë²•, íŠ¹ë³„ë²•
- **ìµœì‹  ê°œì •**: ë””ì§€í„¸ ì„±ë²”ì£„ ì²˜ë²Œë²• ë“± ì‹ ì„¤ë²•

### ë‹µë³€ êµ¬ì¡°
1. **êµ¬ì„±ìš”ê±´ ë¶„ì„**: ë²”ì£„ì˜ ì„±ë¦½ìš”ê±´ ë¶„ì„
2. **ë²•ì •í˜•**: í•´ë‹¹ ë²”ì£„ì˜ í˜•ëŸ‰ ì •ë³´
3. **ê´€ë ¨ íŒë¡€**: ëŒ€ë²•ì› ë° í•˜ê¸‰ì‹¬ íŒë¡€
4. **ì‹¤ë¬´ ê³ ë ¤ì‚¬í•­**: ìˆ˜ì‚¬ ë° ì¬íŒ ê³¼ì •ì—ì„œì˜ ê³ ë ¤ì‚¬í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- êµ¬ì„±ìš”ê±´ì˜ í•´ì„ (í˜•ë²• ì œ1ì¡°)
- ì •ë‹¹ë°©ìœ„ì™€ ê¸´ê¸‰í”¼ë‚œ (í˜•ë²• ì œ21ì¡°, ì œ22ì¡°)
- ë¯¸ìˆ˜ë²”ê³¼ ê¸°ìˆ˜ë²” (í˜•ë²• ì œ25ì¡° ì´í•˜)
- ê³µë²”ì˜ ì„±ë¦½ (í˜•ë²• ì œ30ì¡° ì´í•˜)
"""

    def _get_family_law_template(self) -> str:
        """ê°€ì¡±ë²• í…œí”Œë¦¿"""
        return """
## ê°€ì¡±ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: í˜¼ì¸, ì´í˜¼, ì¹œìê´€ê³„, ìƒì†
- **ì£¼ìš” ë²•ë ¹**: ë¯¼ë²• ê°€ì¡±í¸, ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ë²•ë¥ 
- **ìµœì‹  ê°œì •**: 2024ë…„ ê°€ì¡±ë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **ì ˆì°¨ ê°œìš”**: í•´ë‹¹ ì ˆì°¨ì˜ ì „ì²´ì ì¸ íë¦„
2. **ë‹¨ê³„ë³„ ì ˆì°¨**: êµ¬ì²´ì ì¸ ë‹¨ê³„ë³„ ì ˆì°¨
3. **í•„ìš” ì„œë¥˜**: ì ˆì°¨ ì§„í–‰ì— í•„ìš”í•œ ì„œë¥˜
4. **ë²•ì  ê·¼ê±°**: ê´€ë ¨ ë²•ì¡°ë¬¸ê³¼ íŒë¡€

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- í˜¼ì¸ì˜ ì„±ë¦½ê³¼ ë¬´íš¨ (ë¯¼ë²• ì œ815ì¡° ì´í•˜)
- ì´í˜¼ì˜ ì‚¬ìœ ì™€ ì ˆì°¨ (ë¯¼ë²• ì œ840ì¡° ì´í•˜)
- ì¹œìê´€ê³„ì˜ ì¸ì • (ë¯¼ë²• ì œ844ì¡° ì´í•˜)
- ìƒì†ì˜ ìˆœìœ„ì™€ ìƒì†ë¶„ (ë¯¼ë²• ì œ997ì¡° ì´í•˜)
"""

    def _get_commercial_law_template(self) -> str:
        """ìƒì‚¬ë²• í…œí”Œë¦¿"""
        return """
## ìƒì‚¬ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: íšŒì‚¬ë²•, ìƒí–‰ìœ„, ì–´ìŒìˆ˜í‘œ
- **ì£¼ìš” ë²•ë ¹**: ìƒë²•, ì£¼ì‹íšŒì‚¬ë²•, ì–´ìŒë²•
- **ìµœì‹  ê°œì •**: 2024ë…„ ìƒë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **íšŒì‚¬ ì„¤ë¦½**: íšŒì‚¬ ì„¤ë¦½ ì ˆì°¨ì™€ ìš”ê±´
2. **ì£¼ì£¼ê¶Œê³¼ ì´ì‚¬**: ì£¼ì£¼ì˜ ê¶Œë¦¬ì™€ ì´ì‚¬ì˜ ì˜ë¬´
3. **ìƒí–‰ìœ„**: ìƒí–‰ìœ„ì˜ ì„±ë¦½ê³¼ íš¨ê³¼
4. **ì–´ìŒìˆ˜í‘œ**: ì–´ìŒìˆ˜í‘œì˜ ë°œí–‰ê³¼ ì–‘ë„

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½ (ìƒë²• ì œ289ì¡° ì´í•˜)
- ì£¼ì£¼ì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ (ìƒë²• ì œ335ì¡° ì´í•˜)
- ì´ì‚¬ì˜ ì±…ì„ (ìƒë²• ì œ399ì¡° ì´í•˜)
- ìƒí–‰ìœ„ì˜ íŠ¹ì¹™ (ìƒë²• ì œ47ì¡° ì´í•˜)
"""

    def _get_administrative_law_template(self) -> str:
        """í–‰ì •ë²• í…œí”Œë¦¿"""
        return """
## í–‰ì •ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: í–‰ì •í–‰ìœ„, í–‰ì •ì ˆì°¨, í–‰ì •ì†Œì†¡
- **ì£¼ìš” ë²•ë ¹**: í–‰ì •ì ˆì°¨ë²•, í–‰ì •ì†Œì†¡ë²•, í–‰ì •ë²•
- **ìµœì‹  ê°œì •**: 2024ë…„ í–‰ì •ë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **í–‰ì •í–‰ìœ„ ë¶„ì„**: í–‰ì •í–‰ìœ„ì˜ ì„±ë¦½ê³¼ íš¨ë ¥
2. **ì ˆì°¨ ìš”ê±´**: í–‰ì •ì ˆì°¨ì˜ ì¤€ìˆ˜ì‚¬í•­
3. **êµ¬ì œ ë°©ë²•**: í–‰ì •ì†Œì†¡ê³¼ í–‰ì •ì‹¬íŒ
4. **ë²•ì  ê·¼ê±°**: ê´€ë ¨ í–‰ì •ë²• ì¡°í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- í–‰ì •í–‰ìœ„ì˜ ì„±ë¦½ìš”ê±´ (í–‰ì •ì ˆì°¨ë²• ì œ1ì¡°)
- í–‰ì •ì†Œì†¡ì˜ ì œê¸° (í–‰ì •ì†Œì†¡ë²• ì œ6ì¡° ì´í•˜)
- í–‰ì •ì‹¬íŒì˜ ì ˆì°¨ (í–‰ì •ì‹¬íŒë²• ì œ1ì¡° ì´í•˜)
- í–‰ì •ì§€ë„ì˜ í•œê³„ (í–‰ì •ì ˆì°¨ë²• ì œ4ì¡°)
"""

    def _get_labor_law_template(self) -> str:
        """ë…¸ë™ë²• í…œí”Œë¦¿"""
        return """
## ë…¸ë™ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: ê·¼ë¡œê³„ì•½, ì„ê¸ˆ, ê·¼ë¡œì‹œê°„, íœ´ê°€
- **ì£¼ìš” ë²•ë ¹**: ê·¼ë¡œê¸°ì¤€ë²•, ë…¸ë™ì¡°í•©ë²•, ê³ ìš©ë³´í—˜ë²•
- **ìµœì‹  ê°œì •**: 2024ë…„ ë…¸ë™ë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **ë²•ì  ê·¼ê±°**: ê·¼ë¡œê¸°ì¤€ë²• ë“± ê´€ë ¨ ì¡°í•­
2. **ì ˆì°¨ ë° ë°©ë²•**: ê¶Œë¦¬ êµ¬ì œ ì ˆì°¨
3. **êµ¬ì œ ê¸°ê´€**: ë…¸ë™ìœ„ì›íšŒ, ë²•ì›ì˜ ì—­í• 
4. **ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­**: ì‹¤ì œ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- ê·¼ë¡œê³„ì•½ì˜ ì„±ë¦½ (ê·¼ë¡œê¸°ì¤€ë²• ì œ15ì¡°)
- ì„ê¸ˆì˜ ì§€ê¸‰ (ê·¼ë¡œê¸°ì¤€ë²• ì œ43ì¡° ì´í•˜)
- ê·¼ë¡œì‹œê°„ì˜ ì œí•œ (ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡° ì´í•˜)
- í•´ê³ ì˜ ì œí•œ (ê·¼ë¡œê¸°ì¤€ë²• ì œ23ì¡°)
"""

    def _get_property_law_template(self) -> str:
        """ë¶€ë™ì‚°ë²• í…œí”Œë¦¿"""
        return """
## ë¶€ë™ì‚°ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: ë¶€ë™ì‚° ê³„ì•½, ë“±ê¸°, ê¶Œë¦¬ë³´í˜¸
- **ì£¼ìš” ë²•ë ¹**: ë¶€ë™ì‚°ë“±ê¸°ë²•, ë¶€ë™ì‚° ì‹¤ê¶Œë¦¬ìëª…ì˜ ë“±ê¸°ì— ê´€í•œ ë²•ë¥ 
- **ìµœì‹  ê°œì •**: 2024ë…„ ë¶€ë™ì‚°ë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **ê³„ì•½ ìš”ê±´**: ë¶€ë™ì‚° ê³„ì•½ì˜ ì„±ë¦½ìš”ê±´
2. **ë“±ê¸° ì ˆì°¨**: ì†Œìœ ê¶Œ ì´ì „ ë“±ê¸° ì ˆì°¨
3. **ê¶Œë¦¬ ë³´í˜¸**: ì†Œìœ ê¶Œê³¼ ë‹´ë³´ê¶Œì˜ ë³´í˜¸
4. **ì‹¤ë¬´ ì£¼ì˜ì‚¬í•­**: ì‹¤ì œ ê±°ë˜ ì‹œ ê³ ë ¤ì‚¬í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- ë¶€ë™ì‚° ë§¤ë§¤ê³„ì•½ì˜ ì„±ë¦½ (ë¯¼ë²• ì œ565ì¡°)
- ì†Œìœ ê¶Œ ì´ì „ë“±ê¸° (ë¶€ë™ì‚°ë“±ê¸°ë²• ì œ98ì¡°)
- ë‹´ë³´ê¶Œì˜ ì„¤ì • (ë¯¼ë²• ì œ357ì¡° ì´í•˜)
- ì‹¤ê¶Œë¦¬ìëª…ì˜ ë“±ê¸° (ë¶€ë™ì‚° ì‹¤ê¶Œë¦¬ìëª…ì˜ ë“±ê¸°ì— ê´€í•œ ë²•ë¥ )
"""

    def _get_intellectual_property_template(self) -> str:
        """ì§€ì ì¬ì‚°ê¶Œë²• í…œí”Œë¦¿"""
        return """
## ì§€ì ì¬ì‚°ê¶Œë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: íŠ¹í—ˆ, ìƒí‘œ, ì €ì‘ê¶Œ, ë””ìì¸
- **ì£¼ìš” ë²•ë ¹**: íŠ¹í—ˆë²•, ìƒí‘œë²•, ì €ì‘ê¶Œë²•, ë””ìì¸ë³´í˜¸ë²•
- **ìµœì‹  ê°œì •**: 2024ë…„ ì§€ì ì¬ì‚°ê¶Œë²• ê°œì •ì‚¬í•­

### ë‹µë³€ êµ¬ì¡°
1. **ê¶Œë¦¬ ë‚´ìš©**: ì§€ì ì¬ì‚°ê¶Œì˜ ë‚´ìš©ê³¼ ë²”ìœ„
2. **ì¹¨í•´ êµ¬ì œ**: ê¶Œë¦¬ ì¹¨í•´ ì‹œ êµ¬ì œ ë°©ë²•
3. **ë“±ë¡ ì ˆì°¨**: ê¶Œë¦¬ ë“±ë¡ ì ˆì°¨
4. **ì‹¤ë¬´ ê³ ë ¤ì‚¬í•­**: ì‹¤ì œ ë¶„ìŸÂ·ë“±ë¡ ì‹¤ë¬´ì—ì„œì˜ ì£¼ì˜ì‚¬í•­

### íŠ¹ë³„ ê³ ë ¤ì‚¬í•­
- íŠ¹í—ˆê¶Œì˜ íš¨ë ¥ ë²”ìœ„ (íŠ¹í—ˆë²•)
- ìƒí‘œì˜ ì‹ë³„ë ¥ ë° í˜¼ë™ ê°€ëŠ¥ì„± (ìƒí‘œë²•)
- ì €ì‘ë¬¼ì˜ ë³´í˜¸ ë²”ìœ„ì™€ ê³µì • ì´ìš© (ì €ì‘ê¶Œë²•)
- ë””ìì¸ì˜ ë…ì°½ì„± íŒë‹¨ (ë””ìì¸ë³´í˜¸ë²•)
"""

    def _get_tax_law_template(self) -> str:
        """ì„¸ë²• í…œí”Œë¦¿"""
        return """
## ì„¸ë²• íŠ¹í™” ì§€ì¹¨
- **í•µì‹¬ ë¶„ì•¼**: ì†Œë“ì„¸, ë²•ì¸ì„¸, ë¶€ê°€ê°€ì¹˜ì„¸, ìƒì†Â·ì¦ì—¬ì„¸
- **ì£¼ìš” ë²•ë ¹**: ì†Œë“ì„¸ë²•, ë²•ì¸ì„¸ë²•, ë¶€ê°€ê°€ì¹˜ì„¸ë²•, ìƒì†ì„¸ë°ì¦ì—¬ì„¸ë²•

### ë‹µë³€ êµ¬ì¡°
1. **ê³¼ì„¸ ëŒ€ìƒ/ì‹œê¸°**
2. **ì„¸ìœ¨/ê³µì œ**
3. **ì‹ ê³ /ë‚©ë¶€ ì ˆì°¨**
4. **íŒë¡€Â·ì˜ˆê·œ ì°¸ê³ **
"""

    def _get_civil_procedure_template(self) -> str:
        """ë¯¼ì‚¬ì†Œì†¡ë²• í…œí”Œë¦¿"""
        return """
## ë¯¼ì‚¬ì†Œì†¡ ì ˆì°¨ ì§€ì¹¨
- ì†Œ ì œê¸° â†’ ë³€ë¡  â†’ ì¦ê±°ì¡°ì‚¬ â†’ íŒê²° â†’ ì§‘í–‰ ìˆœì„œ
- ê´€í• , ì†Œê°€ì‚°ì •, ì†¡ë‹¬, ìƒì†Œê¸°ê°„ ë“± ì‹¤ë¬´ ì²´í¬
"""

    def _get_criminal_procedure_template(self) -> str:
        """í˜•ì‚¬ì†Œì†¡ë²• í…œí”Œë¦¿"""
        return """
## í˜•ì‚¬ì ˆì°¨ ì§€ì¹¨
- ìˆ˜ì‚¬ â†’ ê¸°ì†Œ â†’ ê³µíŒ â†’ íŒê²° â†’ ìƒì†Œ
- êµ¬ì†, ì˜ì¥, ì¦ê±°ëŠ¥ë ¥, ìë°±ë³´ê°•ë²•ì¹™ ìœ ì˜
"""

    def _get_precedent_search_template(self) -> str:
        """íŒë¡€ ê²€ìƒ‰ í…œí”Œë¦¿"""
        return """
## íŒë¡€ ê²€ìƒ‰ ì§€ì¹¨
- ì‚¬ê±´ë²ˆí˜¸/ì„ ê³ ì¼/ë²•ì›/ì‚¬ê±´ëª… ë“± ë©”íƒ€ë°ì´í„°ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
- ìš”ì§€ëŠ” ê°„ê²°í•˜ê²Œ, ì¸ìš©ì€ [íŒë¡€: ì‚¬ê±´ë²ˆí˜¸]ë¡œ í‘œê¸°í•˜ì„¸ìš”.
"""

    def _get_law_inquiry_template(self) -> str:
        """ë²•ë ¹ ì§ˆì˜ í…œí”Œë¦¿"""
        return """
## ë²•ë ¹ ì§ˆì˜ ì§€ì¹¨
- í•´ë‹¹ ë²•ë¥ ëª…ê³¼ ì¡°ë¬¸ì„ ì •í™•íˆ í‘œê¸°: [ë²•ë ¹: ë²•ë¥ ëª… ì œOOì¡°].
- ì¡°ë¬¸ ìš”ì§€ì™€ ì ìš© ë²”ìœ„ë¥¼ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”.
"""

    def _get_legal_advice_template(self) -> str:
        """ë²•ë¥  ìë¬¸ í…œí”Œë¦¿"""
        return """
## ë²•ë¥  ìë¬¸ ì§€ì¹¨
- ì‚¬ì‹¤ê´€ê³„ íŒŒì•… â†’ ë²•ì  í‰ê°€ â†’ ì‹¤ë¬´ ì¡°ì–¸ ìˆœì„œë¡œ ì‘ì„±.
- ë¶ˆí™•ì‹¤ ì‹œ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ì™€ ë¦¬ìŠ¤í¬ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
"""

    def _get_procedure_guide_template(self) -> str:
        """ì ˆì°¨ ì•ˆë‚´ í…œí”Œë¦¿"""
        return """
## ì ˆì°¨ ì•ˆë‚´ ì§€ì¹¨
- ë‹¨ê³„ë³„ ì ˆì°¨, í•„ìš”ì„œë¥˜, ê¸°í•œ, ë‹´ë‹¹ê¸°ê´€ì„ í‘œ í˜•ì‹ ë˜ëŠ” ëª©ë¡ìœ¼ë¡œ.
"""

    def _get_term_explanation_template(self) -> str:
        """ìš©ì–´ ì„¤ëª… í…œí”Œë¦¿"""
        return """
## ë²•ë¥  ìš©ì–´ ì„¤ëª… ì§€ì¹¨
- ì •ì˜ â†’ ë²•ì  ê·¼ê±° â†’ ì˜ˆì‹œ â†’ ìœ ì‚¬ê°œë… ë¹„êµ ìˆœìœ¼ë¡œ ê°„ê²°í•˜ê²Œ.
"""

    def _get_general_question_template(self) -> str:
        """ì¼ë°˜ ì§ˆë¬¸ í…œí”Œë¦¿"""
        return """
## ì¼ë°˜ ì§ˆë¬¸ ì§€ì¹¨
- í•µì‹¬ ë‹µë§Œ ê°„ê²°íˆ ì œì‹œí•˜ê³ , í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ë²•ë ¹/íŒë¡€ë¥¼ ë§í¬ í˜•íƒœë¡œ ì œì‹œ.
"""
