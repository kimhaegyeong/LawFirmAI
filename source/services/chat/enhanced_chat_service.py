# -*- coding: utf-8 -*-
"""
Enhanced Chat Service
ê°œì„ ëœ ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ ì„œë¹„ìŠ¤
"""

import hashlib
import os
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

# ìƒëŒ€ê²½ë¡œ import
from ...data.database import DatabaseManager
from ...data.vector_store import LegalVectorStore
from ...utils.config import Config
from ...utils.logger import get_logger
from ...utils.memory_manager import get_memory_manager
from ...utils.monitoring.realtime_memory_monitor import (
    get_memory_monitor,
)
from ...utils.weakref_cleanup import get_weakref_registry

# í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ë¡œ ì™„ì „ ëŒ€ì²´ë¨ - í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì œê±° ì™„ë£Œ
# ëª¨ë“  í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë„ë©”ì¸ ë¶„ë¥˜ ê¸°ëŠ¥ì€ IntegratedHybridQuestionClassifierì—ì„œ ì²˜ë¦¬

# Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™” ëª¨ë“ˆ
# from .integrated_session_manager import IntegratedSessionManager
# from .multi_turn_handler import MultiTurnQuestionHandler
# from .context_compressor import ContextCompressor

# Phase 2: ê°œì¸í™” ë° ì§€ëŠ¥í˜• ë¶„ì„ ëª¨ë“ˆ
# from .user_profile_manager import UserProfileManager
# from .emotion_intent_analyzer import EmotionIntentAnalyzer
# from .conversation_flow_tracker import ConversationFlowTracker

# Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ
# from .contextual_memory_manager import ContextualMemoryManager
# from .conversation_quality_monitor import ConversationQualityMonitor

# ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ
# from .intelligent_response_style_system import IntelligentResponseStyleSystem, ResponseStyle

# ResponseStyleì„ ê°„ë‹¨íˆ ì •ì˜ (í…ŒìŠ¤íŠ¸ìš©)
class ResponseStyle:
    FRIENDLY = "friendly"
    PROFESSIONAL = "professional"
    CONCISE = "concise"
    DETAILED = "detailed"

# ëŒ€í™”í˜• ê³„ì•½ì„œ ì‘ì„± ëª¨ë“ˆ
# from .interactive_contract_assistant import InteractiveContractAssistant
# from .contract_query_handler import ContractQueryHandler

# ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ê°œì„  ëª¨ë“ˆ
# from .conversation_connector import ConversationConnector
# from .emotional_tone_adjuster import EmotionalToneAdjuster
# from .personalized_style_learner import PersonalizedStyleLearner
# from ..realtime_feedback_system import RealtimeFeedbackSystem
# from ..naturalness_evaluator import NaturalnessEvaluator

# ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ
# from ..cache_manager import get_cache_manager, cached
# from .optimized_search_engine import OptimizedSearchEngine

# ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ ëª¨ë“ˆ (ML í†µí•© ìµœì‹  ë²„ì „) - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
# from .ml_integrated_validation_system import MLIntegratedValidationSystem
# from .improved_legal_restriction_system import ImprovedLegalRestrictionSystem, ImprovedRestrictionResult
# from .intent_based_processor import IntentBasedProcessor, ProcessingResult
# from .content_filter_engine import ContentFilterEngine, FilterResult
# from .response_validation_system import ResponseValidationSystem, ValidationResult, ValidationStatus, ValidationLevel
# from .safe_response_generator import SafeResponseGenerator, SafeResponse
# from .legal_compliance_monitor import LegalComplianceMonitor, ComplianceStatus
# from .user_education_system import UserEducationSystem, WarningMessage
# from .multi_stage_validation_system import MultiStageValidationSystem, MultiStageValidationResult

logger = get_logger(__name__)


class EnhancedChatService:
    """í–¥ìƒëœ ì±„íŒ… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, config: Config):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # Google Cloud ê²½ê³  ì„¤ì •
        self._setup_google_cloud_warnings()

        self.config = config
        self.logger = get_logger(__name__)

        # LangGraph ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (í™œì„±í™”)
        self.use_langgraph = True

        # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_memory_management()

        # ì‚¬ìš©ì ì„¤ì • ê´€ë¦¬ì ì´ˆê¸°í™” (ì•ˆì „í•œ ì´ˆê¸°í™”)
        try:
            from ..user_preference_manager import preference_manager
            self.user_preferences = preference_manager
        except ImportError:
            self.logger.warning("User preference managerë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            self.user_preferences = None

        # ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ì ì´ˆê¸°í™” (ì•ˆì „í•œ ì´ˆê¸°í™”)
        try:
            from ..answer_completion_validator import completion_validator
            self.completion_validator = completion_validator
        except ImportError:
            self.logger.warning("Answer completion validatorë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            self.completion_validator = None

        # í–¥ìƒëœ ì™„ì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì•ˆì „í•œ ì´ˆê¸°í™”)
        try:
            from ..enhanced_completion_system import enhanced_completion_system
            self.enhanced_completion_system = enhanced_completion_system
        except ImportError:
            self.logger.warning("Enhanced completion systemì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            self.enhanced_completion_system = None

        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_core_components()

        # ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_legal_restriction_systems()

        # ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        self._initialize_advanced_search_engines()

        # í˜„ì¬ë²• ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        self._initialize_current_law_search_engine()

        # í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í˜„ì¬ë²• ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” í›„)
        self._initialize_unified_services()

        # Phase ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_phase_systems()

        # ëŒ€í™”í˜• ê³„ì•½ì„œ ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™”
        self._initialize_interactive_contract_assistant()

        # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_natural_conversation_systems()

        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_performance_monitoring()

        # ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_performance_systems()

        # í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_quality_enhancement_systems()

        # í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self.logger.info("ğŸ” í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            self._initialize_enhanced_law_search()
            self.logger.info("âœ… í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        # ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self.logger.info("ğŸ” ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            self._initialize_intelligent_style_system()
            self.logger.info("âœ… ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        # LangGraph ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        try:
            self.logger.info("ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì‹œì‘...")
            self._initialize_langgraph_workflow()
            self.logger.info(f"ğŸ” LangGraph ì´ˆê¸°í™” ì™„ë£Œ - ì„œë¹„ìŠ¤ ìƒíƒœ: {self.langgraph_service is not None}")
        except Exception as e:
            self.logger.error(f"âŒ LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        # ğŸ†• LangGraph ì´ˆê¸°í™” ê²€ì¦ ë° ìƒíƒœ ë¡œê¹…
        self._validate_langgraph_initialization()

        self.logger.info("EnhancedChatService ì´ˆê¸°í™” ì™„ë£Œ")

    def _validate_langgraph_initialization(self):
        """LangGraph ì´ˆê¸°í™” ìƒíƒœ ê²€ì¦ ë° ìƒì„¸ ë¡œê¹…"""
        self.logger.info("=" * 70)
        self.logger.info("ğŸ” LangGraph ì´ˆê¸°í™” ìƒíƒœ ê²€ì¦")
        self.logger.info("=" * 70)

        # í˜„ì¬ ìƒíƒœ í™•ì¸
        self.logger.info("ğŸ“Š í˜„ì¬ ìƒíƒœ:")
        self.logger.info(f"   - use_langgraph: {self.use_langgraph}")
        self.logger.info(f"   - langgraph_service: {self.langgraph_service is not None}")

        if self.langgraph_service is not None:
            self.logger.info(f"   - langgraph_service íƒ€ì…: {type(self.langgraph_service).__name__}")
            self.logger.info(f"   - process_query ë©”ì„œë“œ: {hasattr(self.langgraph_service, 'process_query')}")

        # ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° ì¬ì‹œë„
        if self.use_langgraph and self.langgraph_service is None:
            self.logger.warning("âš ï¸ LangGraph í™œì„±í™”ë˜ì—ˆìœ¼ë‚˜ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            self.logger.info("ğŸ”„ LangGraph ì¬ì´ˆê¸°í™” ì‹œë„...")

            try:
                self._initialize_langgraph_workflow()

                if self.langgraph_service and self.use_langgraph:
                    self.logger.info("âœ… LangGraph ì¬ì´ˆê¸°í™” ì„±ê³µ")
                    self.logger.info(f"   - use_langgraph: {self.use_langgraph}")
                    self.logger.info(f"   - langgraph_service: {self.langgraph_service is not None}")
                else:
                    self.logger.error("âŒ LangGraph ì¬ì´ˆê¸°í™” ì‹¤íŒ¨")
                    self.logger.error("ğŸ’¡ í•´ê²° ë°©ë²•:")
                    self.logger.error("   1. pip install langgraph langchain-core langchain-community")
                    self.logger.error("   2. .env íŒŒì¼ì— GOOGLE_API_KEY ì„¤ì •")
                    self.logger.error("   3. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ íŒŒì•…")

            except Exception as e:
                self.logger.error(f"âŒ ì¬ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        # ìµœì¢… ìƒíƒœ
        if self.langgraph_service and self.use_langgraph:
            self.logger.info("=" * 70)
            self.logger.info("âœ… LangGraph ì‚¬ìš© ê°€ëŠ¥ - ì›Œí¬í”Œë¡œìš°ê°€ í™œì„±í™”ë©ë‹ˆë‹¤")
            self.logger.info("=" * 70)
        else:
            self.logger.info("=" * 70)
            self.logger.warning("âš ï¸ LangGraph ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ RAG ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±ë©ë‹ˆë‹¤")
            self.logger.info("=" * 70)

    def _setup_google_cloud_warnings(self):
        """Google Cloud ê²½ê³  ì„¤ì •"""
        os.environ['GRPC_DNS_RESOLVER'] = 'native'
        os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '0'
        os.environ['GOOGLE_CLOUD_PROJECT'] = ''
        os.environ['GCLOUD_PROJECT'] = ''
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''
        os.environ['GOOGLE_CLOUD_DISABLE_GRPC'] = 'true'
        os.environ['GRPC_VERBOSITY'] = 'ERROR'
        os.environ['GRPC_TRACE'] = ''

        # gRPC ë¡œê·¸ ë ˆë²¨ ì„¤ì •
        import logging
        logging.getLogger('grpc').setLevel(logging.ERROR)
        logging.getLogger('google').setLevel(logging.ERROR)
        logging.getLogger('google.auth').setLevel(logging.ERROR)
        logging.getLogger('google.auth.transport').setLevel(logging.ERROR)
        logging.getLogger('google.auth.transport.grpc').setLevel(logging.ERROR)
        logging.getLogger('google.auth.transport.requests').setLevel(logging.ERROR)
        logging.getLogger('google.cloud').setLevel(logging.ERROR)
        logging.getLogger('google.api_core').setLevel(logging.ERROR)

    def _initialize_memory_management(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™” - ë©”ëª¨ë¦¬ ì œí•œ ì¦ê°€
            self.memory_manager = get_memory_manager(max_memory_mb=2048)  # 1024ì—ì„œ 2048ë¡œ ì¦ê°€

            # WeakRef ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”
            self.weakref_registry = get_weakref_registry()

            # ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
            self.memory_monitor = get_memory_monitor()

            # ë©”ëª¨ë¦¬ ì•Œë¦¼ ì½œë°± ë“±ë¡
            self.memory_manager.add_alert_callback(self._on_memory_alert)

            # ì»´í¬ë„ŒíŠ¸ ì¶”ì ìš© WeakRef ë“±ë¡ í•¨ìˆ˜
            self._track_component = self._create_component_tracker()

            self.logger.info("ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            self.memory_manager = None
            self.weakref_registry = None
            self.memory_monitor = None
            self._track_component = lambda obj, name: None

    def _create_component_tracker(self):
        """ì»´í¬ë„ŒíŠ¸ ì¶”ì  í•¨ìˆ˜ ìƒì„±"""
        def track_component(obj: Any, name: str) -> str:
            """ì»´í¬ë„ŒíŠ¸ë¥¼ WeakRefë¡œ ë“±ë¡"""
            if self.weakref_registry:
                return self.weakref_registry.register_object(obj, name)
            return name
        return track_component

    def _on_memory_alert(self, alert):
        """ë©”ëª¨ë¦¬ ì•Œë¦¼ ì²˜ë¦¬"""
        self.logger.warning(f"ë©”ëª¨ë¦¬ ì•Œë¦¼ [{alert.severity}]: {alert.message}")

        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ê°•ì œ ì •ë¦¬ (ê¸°ì¤€ ì™„í™”)
        if alert.severity in ['medium', 'high', 'critical']:  # medium ì¶”ê°€
            self.logger.info("ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
            cleanup_result = self.perform_memory_cleanup()
            self.logger.info(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {cleanup_result.get('memory_freed_mb', 0):.1f}MB í•´ì œ")

    def perform_memory_cleanup(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ ìˆ˜í–‰ (ê³ ê¸‰ ìµœì í™” í¬í•¨)"""
        try:
            import gc
            import os

            import psutil

            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
            process = psutil.Process(os.getpid())
            memory_before = process.memory_info().rss / 1024 / 1024  # MB

            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
            collected = gc.collect()
            # ì¶”ê°€ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (3íšŒ ë°˜ë³µ)
            for _ in range(3):
                collected += gc.collect()

            # ì»´í¬ë„ŒíŠ¸ë³„ ë©”ëª¨ë¦¬ ì •ë¦¬
            cleanup_count = 0

            # ëª¨ë¸ ë§¤ë‹ˆì € ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self, 'model_manager') and self.model_manager:
                try:
                    if hasattr(self.model_manager, 'clear_cache'):
                        self.model_manager.clear_cache()
                        cleanup_count += 1
                    # ì¶”ê°€: ëª¨ë¸ ì–¸ë¡œë“œ ì‹œë„
                    if hasattr(self.model_manager, 'unload_unused_models'):
                        self.model_manager.unload_unused_models()
                except Exception as e:
                    self.logger.debug(f"Model manager cleanup failed: {e}")

            # ë²¡í„° ìŠ¤í† ì–´ ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self, 'vector_store') and self.vector_store:
                try:
                    if hasattr(self.vector_store, 'clear_cache'):
                        self.vector_store.clear_cache()
                        cleanup_count += 1
                    # ì¶”ê°€: ì¸ë±ìŠ¤ ìºì‹œ ì •ë¦¬
                    if hasattr(self.vector_store, 'clear_index_cache'):
                        self.vector_store.clear_index_cache()
                except Exception as e:
                    self.logger.debug(f"Vector store cleanup failed: {e}")

            # ë‹µë³€ ìƒì„±ê¸° ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self, 'answer_generator') and self.answer_generator:
                try:
                    if hasattr(self.answer_generator, 'clear_cache'):
                        self.answer_generator.clear_cache()
                        cleanup_count += 1
                except Exception as e:
                    self.logger.debug(f"Answer generator cleanup failed: {e}")

            # RAG ì„œë¹„ìŠ¤ ë©”ëª¨ë¦¬ ì •ë¦¬
            if hasattr(self, 'unified_rag_service') and self.unified_rag_service:
                try:
                    if hasattr(self.unified_rag_service, 'clear_cache'):
                        self.unified_rag_service.clear_cache()
                        cleanup_count += 1
                except Exception as e:
                    self.logger.debug(f"RAG service cleanup failed: {e}")

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬ì¸¡ì •
            memory_after = process.memory_info().rss / 1024 / 1024  # MB
            memory_freed = memory_before - memory_after

            self.logger.info(f"ì „ì²´ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {memory_freed:.1f}MB í•´ì œ, {collected}ê°œ ê°ì²´ ìˆ˜ì§‘, {cleanup_count}ê°œ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬")

            return {
                'memory_before_mb': memory_before,
                'memory_after_mb': memory_after,
                'memory_freed_mb': memory_freed,
                'objects_collected': collected,
                'components_cleaned': cleanup_count,
                'success': True
            }

        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'memory_freed_mb': 0,
                'objects_collected': 0,
                'components_cleaned': 0,
                'success': False,
                'error': str(e)
            }

    def _initialize_core_components(self):
        """í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
            self.db_manager = DatabaseManager("data/lawfirm.db")
            self._track_component(self.db_manager, "db_manager")

            # ë²¡í„° ìŠ¤í† ì–´
            self.vector_store = LegalVectorStore(
                model_name="jhgan/ko-sroberta-multitask",
                dimension=768,
                index_type="flat",
                enable_quantization=True,
                enable_lazy_loading=True,
                memory_threshold_mb=3000
            )
            self._track_component(self.vector_store, "vector_store")

            # ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ - ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
            index_paths = [
                "data/embeddings/ml_enhanced_ko_sroberta/ml_enhanced_faiss_index",  # ê°€ì¥ í° ë°ì´í„°ì…‹
                "data/embeddings/ml_enhanced_ko_sroberta_precedents/ml_enhanced_faiss_index",  # íŒë¡€ ë°ì´í„°
                "data/embeddings/legal_vector_index"  # ê¸°ë³¸ ë°ì´í„°
            ]

            index_loaded = False
            for index_path in index_paths:
                try:
                    if self.vector_store.load_index(index_path):
                        self.logger.info(f"ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ: {index_path}")
                        index_loaded = True
                        break
                    else:
                        self.logger.warning(f"ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {index_path}")
                except Exception as e:
                    self.logger.warning(f"ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì˜¤ë¥˜ {index_path}: {e}")
                    continue

            if not index_loaded:
                self.logger.warning("ëª¨ë“  ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨, í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´")
                # ë²¡í„° ì¸ë±ìŠ¤ê°€ ì—†ì–´ë„ ì„œë¹„ìŠ¤ëŠ” ê³„ì† ë™ì‘í•˜ë„ë¡ í•¨
                self.logger.info("ë²¡í„° ì¸ë±ìŠ¤ ì—†ì´ ì„œë¹„ìŠ¤ ê³„ì† ì§„í–‰")

            # ëª¨ë¸ ë§¤ë‹ˆì € (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                from ..optimized_model_manager import OptimizedModelManager
                self.model_manager = OptimizedModelManager()
                self._track_component(self.model_manager, "model_manager")
            except ImportError:
                self.logger.warning("OptimizedModelManagerë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
                self.model_manager = None

            # RAG ì„œë¹„ìŠ¤ (MLEnhancedRAGServiceë¥¼ ëŒ€ì²´í•˜ê³  UnifiedRAGServiceë¡œ í†µí•©)
            # self.rag_service = MLEnhancedRAGService(...)

            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                from ..search.hybrid_search_engine import HybridSearchEngine
                self.hybrid_search_engine = HybridSearchEngine()
                self._track_component(self.hybrid_search_engine, "hybrid_search_engine")
            except ImportError:
                self.logger.warning("HybridSearchEngineì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
                self.hybrid_search_engine = None

            # ì§ˆë¬¸ ë¶„ë¥˜ê¸° (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                from ..question_classifier import QuestionClassifier
                self.question_classifier = QuestionClassifier()
                self._track_component(self.question_classifier, "question_classifier")
            except ImportError:
                self.logger.warning("QuestionClassifierë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
                self.question_classifier = None

            # í–¥ìƒëœ ë‹µë³€ ìƒì„±ê¸° (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                self.logger.debug("ImprovedAnswerGenerator import ì‹œë„ ì¤‘...")
                from ..improved_answer_generator import ImprovedAnswerGenerator
                self.logger.debug(f"ImprovedAnswerGenerator import ì„±ê³µ: {ImprovedAnswerGenerator}")

                self.logger.debug("ImprovedAnswerGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œë„ ì¤‘...")
                self.improved_answer_generator = ImprovedAnswerGenerator()
                self.logger.debug("ImprovedAnswerGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")

                self._track_component(self.improved_answer_generator, "improved_answer_generator")
                self.logger.info("ImprovedAnswerGenerator ì´ˆê¸°í™” ì™„ë£Œ")
            except ImportError as e:
                self.logger.warning(
                    f"ImprovedAnswerGeneratorë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ImportError). "
                    f"ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ìƒì„¸ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
                )
                self.logger.debug(f"ImportError ìƒì„¸ ì •ë³´: {e.__traceback__}")
                self.improved_answer_generator = None
            except Exception as e:
                self.logger.error(
                    f"ImprovedAnswerGenerator ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: "
                    f"{type(e).__name__}: {str(e)}"
                )
                self.logger.debug(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´: {e.__traceback__}", exc_info=True)
                self.improved_answer_generator = None

            self.logger.info("í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            self.db_manager = None
            self.vector_store = None
            self.model_manager = None
            self.rag_service = None
            self.hybrid_search_engine = None
            self.question_classifier = None
            self.improved_answer_generator = None

        # í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” (try ë¸”ë¡ ì™¸ë¶€ì—ì„œ)
        self._initialize_hybrid_classifier()

    def _initialize_hybrid_classifier(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”"""
        try:
            self.logger.debug("IntegratedHybridQuestionClassifier import ì‹œë„ ì¤‘...")
            # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” (ì•ˆì „í•œ import)
            from ..integrated_hybrid_classifier import (
                IntegratedHybridQuestionClassifier,
            )
            self.logger.debug(f"IntegratedHybridQuestionClassifier import ì„±ê³µ: {IntegratedHybridQuestionClassifier}")

            self.logger.debug("IntegratedHybridQuestionClassifier ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œë„ ì¤‘...")
            self.hybrid_classifier = IntegratedHybridQuestionClassifier(
                confidence_threshold=0.7  # ê¸°ë³¸ ì„ê³„ê°’
            )
            self.logger.debug("IntegratedHybridQuestionClassifier ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")

            self._track_component(self.hybrid_classifier, "hybrid_classifier")

            self.logger.info("âœ… í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

        except ImportError as e:
            self.logger.warning(
                f"IntegratedHybridQuestionClassifierë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ImportError). "
                f"ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ìƒì„¸ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
            )
            self.logger.debug(f"ImportError ìƒì„¸ ì •ë³´: {e.__traceback__}", exc_info=True)
            self.hybrid_classifier = None
        except Exception as e:
            self.logger.error(
                f"í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: "
                f"{type(e).__name__}: {str(e)}"
            )
            self.logger.debug(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´: {e.__traceback__}", exc_info=True)
            self.hybrid_classifier = None

    def _initialize_unified_services(self):
        """í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì´ˆê¸°í™”
            if not self.vector_store:
                from ..data.vector_store import LegalVectorStore
                self.vector_store = LegalVectorStore()
                try:
                    self.vector_store.load_index()
                    self.logger.info("ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    self.logger.warning(f"ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")

            # í†µí•© ê²€ìƒ‰ ì—”ì§„ (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                from ..unified_search_engine import UnifiedSearchEngine
                self.unified_search_engine = UnifiedSearchEngine(
                    vector_store=self.vector_store,
                    current_law_search_engine=self.current_law_search_engine
                )
                self.logger.info("âœ… UnifiedSearchEngine ì´ˆê¸°í™” ì„±ê³µ")
            except ImportError as e:
                self.logger.warning(f"UnifiedSearchEngineì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                self.unified_search_engine = None
            except Exception as e:
                self.logger.error(f"UnifiedSearchEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.unified_search_engine = None

            # í†µí•© RAG ì„œë¹„ìŠ¤ (ì•ˆì „í•œ ì´ˆê¸°í™”)
            try:
                self.logger.debug("UnifiedRAGService import ì‹œë„ ì¤‘...")
                from ..unified_rag_service import UnifiedRAGService
                self.logger.debug(f"UnifiedRAGService import ì„±ê³µ: {UnifiedRAGService}")

                self.logger.debug("UnifiedRAGService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œë„ ì¤‘...")
                self.unified_rag_service = UnifiedRAGService(
                    model_manager=self.model_manager,
                    search_engine=self.unified_search_engine,
                    answer_generator=self.improved_answer_generator,
                    question_classifier=self.question_classifier
                )
                self.logger.debug("UnifiedRAGService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")

                self.logger.info("âœ… UnifiedRAGService ì´ˆê¸°í™” ì™„ë£Œ")
            except ImportError as e:
                self.logger.warning(
                    f"UnifiedRAGServiceë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ImportError). "
                    f"ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ìƒì„¸ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
                )
                self.logger.debug(f"ImportError ìƒì„¸ ì •ë³´: {e.__traceback__}", exc_info=True)
                self.unified_rag_service = None
            except Exception as e:
                self.logger.error(
                    f"UnifiedRAGService ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: "
                    f"{type(e).__name__}: {str(e)}"
                )
                self.logger.debug(f"ì˜¤ë¥˜ ìƒì„¸ ì •ë³´: {e.__traceback__}", exc_info=True)
                self.unified_rag_service = None

            self.logger.info("í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.unified_search_engine = None
            self.unified_rag_service = None

    def _initialize_legal_restriction_systems(self):
        """ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.ml_validation_system = None
            self.improved_legal_restriction_system = None
            self.intent_based_processor = None
            self.content_filter_engine = None
            self.response_validation_system = None
            self.safe_response_generator = None
            self.legal_compliance_monitor = None
            self.user_education_system = None
            self.multi_stage_validation_system = None

            self.logger.info("ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            self.ml_validation_system = None
            self.improved_legal_restriction_system = None
            self.intent_based_processor = None
            self.content_filter_engine = None
            self.response_validation_system = None
            self.safe_response_generator = None
            self.legal_compliance_monitor = None
            self.user_education_system = None
            self.multi_stage_validation_system = None

    def _initialize_advanced_search_engines(self):
        """ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.optimized_search_engine = None
            self.exact_search_engine = None
            self.semantic_search_engine = None
            self.precedent_search_engine = None

            self.logger.info("ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì—”ì§„ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.optimized_search_engine = None
            self.exact_search_engine = None
            self.semantic_search_engine = None
            self.precedent_search_engine = None

    def _initialize_current_law_search_engine(self):
        """í˜„ì¬ë²•ë ¹ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” - ì•ˆì „í•œ ì´ˆê¸°í™”"""
        try:
            from ..current_law_search_engine import CurrentLawSearchEngine

            self.current_law_search_engine = CurrentLawSearchEngine(
                db_path="data/lawfirm.db",
                vector_store=self.vector_store
            )

            self.logger.info("í˜„ì¬ë²•ë ¹ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

        except ImportError as e:
            self.logger.warning(f"CurrentLawSearchEngineì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            self.current_law_search_engine = None
        except Exception as e:
            self.logger.error(f"í˜„ì¬ë²•ë ¹ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.current_law_search_engine = None

    def _initialize_phase_systems(self):
        """Phase ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  Phase ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.integrated_session_manager = None
            self.multi_turn_handler = None
            self.context_compressor = None
            self.user_profile_manager = None
            self.emotion_intent_analyzer = None
            self.conversation_flow_tracker = None
            self.contextual_memory_manager = None
            self.conversation_quality_monitor = None

            self.logger.info("Phase ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"Phase ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            self.integrated_session_manager = None
            self.multi_turn_handler = None
            self.context_compressor = None
            self.user_profile_manager = None
            self.emotion_intent_analyzer = None
            self.conversation_flow_tracker = None
            self.contextual_memory_manager = None
            self.conversation_quality_monitor = None

    def _initialize_natural_conversation_systems(self):
        """ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°œì„  ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.conversation_connector = None
            self.emotional_tone_adjuster = None
            self.personalized_style_learner = None

            self.logger.info("ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°œì„  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
            self.conversation_connector = None
            self.emotional_tone_adjuster = None
            self.personalized_style_learner = None

    def _initialize_performance_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ì•ˆì „í•œ ì´ˆê¸°í™”"""
        try:
            from ...utils.monitoring.performance_monitor import PerformanceMonitor

            # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
            self.performance_monitor = PerformanceMonitor(self.config)

            # ë©”ì„œë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if hasattr(self.performance_monitor, 'log_response_metrics'):
                self.logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.logger.warning("PerformanceMonitor ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë‚˜ log_response_metrics ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                self.performance_monitor = None

        except ImportError as e:
            self.logger.warning(f"PerformanceMonitorë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            self.performance_monitor = None
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.performance_monitor = None

    def _initialize_interactive_contract_assistant(self):
        """ëŒ€í™”í˜• ê³„ì•½ì„œ ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  ëŒ€í™”í˜• ê³„ì•½ì„œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.interactive_contract_assistant = None
            self.contract_query_handler = None

            self.logger.info("ëŒ€í™”í˜• ê³„ì•½ì„œ ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"ëŒ€í™”í˜• ê³„ì•½ì„œ ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.interactive_contract_assistant = None
            self.contract_query_handler = None

    def _initialize_performance_systems(self):
        """ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.performance_monitor = None
            self.memory_optimizer = None

            self.logger.info("ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.performance_monitor = None
            self.memory_optimizer = None

    def _initialize_quality_enhancement_systems(self):
        """í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.answer_quality_enhancer = None
            self.answer_structure_enhancer = None
            self.confidence_calculator = None
            self.prompt_optimizer = None
            self.unified_prompt_manager = None

            self.logger.info("í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ í–¥ìƒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.answer_quality_enhancer = None
            self.answer_structure_enhancer = None
            self.confidence_calculator = None
            self.prompt_optimizer = None
            self.unified_prompt_manager = None

    async def process_message(self,
                            message: str,
                            context: Optional[str] = None,
                            session_id: Optional[str] = None,
                            user_id: Optional[str] = None) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        self.logger.info(f"EnhancedChatService.process_message called for: {message}")
        start_time = time.time()

        # ì„¸ì…˜ IDì™€ ì‚¬ìš©ì ID ìƒì„±
        if not session_id:
            session_id = f"session_{int(time.time())}_{hashlib.md5(message.encode()).hexdigest()[:8]}"
        if not user_id:
            user_id = f"user_{int(time.time())}"

        try:
            # ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ìš°ì„  ì²˜ë¦¬
            if self._is_law_article_query(message):
                self.logger.info(f"ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ê°ì§€: {message}")
                return await self._handle_law_article_query(message, user_id, session_id)

            # ê³„ì•½ì„œ ê´€ë ¨ ì¿¼ë¦¬ ìš°ì„  ì²˜ë¦¬
            if self.contract_query_handler and self.contract_query_handler.is_contract_related_query(message):
                self.logger.info(f"ê³„ì•½ì„œ ê´€ë ¨ ì¿¼ë¦¬ ê°ì§€: {message}")
                return await self.contract_query_handler.handle_interactive_contract_query(message, session_id, user_id)

            # ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬
            validation_result = self._validate_and_preprocess_input(message)
            if not validation_result["valid"]:
                return self._create_simple_error_response(
                    validation_result["error"], session_id, user_id, start_time
                )

            # ìºì‹œ í™•ì¸ - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
            # cache_key = self._generate_cache_key(message, user_id, context)
            # cached_result = self.cache_manager.get(cache_key) if self.cache_manager else None
            # if cached_result:
            #     cached_result["processing_time"] = time.time() - start_time
            #     cached_result["cached"] = True
            #     return cached_result

            # ì¿¼ë¦¬ ë¶„ì„
            query_analysis = await self._analyze_query(message, context, user_id, session_id)
            self.logger.debug(f"process_messageì—ì„œ query_analysis: {query_analysis}")

            # ë²•ë¥  ì œí•œ ê²€ì¦
            restriction_result = await self._validate_legal_restrictions(
                message, query_analysis, user_id, session_id
            )

            if restriction_result and restriction_result.get("restricted", False):
                return self._create_restricted_response(
                    restriction_result, session_id, user_id, start_time
                )

            # Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™”
            phase1_info = await self._process_phase1_context(message, session_id, user_id)

            # Phase 2: ê°œì¸í™” ë° ì§€ëŠ¥í˜• ë¶„ì„
            phase2_info = await self._process_phase2_personalization(
                message, session_id, user_id, phase1_info
            )

            # Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
            phase3_info = await self._process_phase3_memory_quality(
                message, session_id, user_id, phase1_info, phase2_info
            )

            # ë‹µë³€ ìƒì„± ì‹¤í–‰
            self.logger.info(f"About to call _generate_enhanced_response for: {message}")
            response_result = await self._generate_enhanced_response(
                message, query_analysis, restriction_result, user_id, session_id,
                phase1_info, phase2_info, phase3_info
            )
            self.logger.info(f"_generate_enhanced_response completed, method: {response_result.get('generation_method', 'unknown')}")

            # response_resultê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            if isinstance(response_result, str):
                self.logger.debug(f"_generate_enhanced_responseê°€ ë¬¸ìì—´ì„ ë°˜í™˜í•¨: {type(response_result)}")
                response_result = {"response": response_result, "confidence": 0.5, "generation_method": "string_fallback"}

            # ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ë° ë³´ì™„ (ì•ˆì „í•œ ì²˜ë¦¬)
            if response_result.get("response") and self.enhanced_completion_system:
                response_text = response_result["response"]
                if isinstance(response_text, str):
                    try:
                        # ê°•í™”ëœ ì™„ì„± ì‹œìŠ¤í…œ ì‚¬ìš©
                        completion_result = self.enhanced_completion_system.force_complete_answer(
                            response_text, message, query_analysis.get("category", "ì¼ë°˜")
                        )

                        if completion_result.was_truncated:
                            self.logger.info(f"ë‹µë³€ì´ ì¶”ê°€ë¡œ ë³´ì™„ë¨. ì™„ì„± ë°©ë²•: {completion_result.completion_method}")
                            response_result["response"] = completion_result.completed_answer
                            response_result["completion_improved"] = True
                            response_result["completion_method"] = completion_result.completion_method
                            response_result["completion_confidence"] = completion_result.confidence
                    except Exception as e:
                        self.logger.debug(f"ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ì‹¤íŒ¨: {e}")
                        # ì™„ì„±ë„ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‘ë‹µ ìœ ì§€

                    # ì˜ˆì œ ì¶”ê°€ ê¸°ëŠ¥ ì œê±° (ì˜ì¡´ì„± ë¬¸ì œë¡œ ë¹„í™œì„±í™”ë¨)
                    # if self.user_preferences.get_preference("example_preference"):
                    #     enhanced_response = self._add_examples_to_response(
                    #         response_result["response"], message, query_analysis
                    #     )
                    #     if enhanced_response != response_result["response"]:
                    #         response_result["response"] = enhanced_response
                    #         response_result["examples_added"] = True

            # ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ë©´ì±… ì¡°í•­ ì²˜ë¦¬ (ì•ˆì „í•œ ì²˜ë¦¬)
            if self.user_preferences and hasattr(self.user_preferences, 'add_disclaimer_to_response'):
                try:
                    final_response_text = self.user_preferences.add_disclaimer_to_response(
                        response_result["response"], message
                    )
                    response_result["response"] = final_response_text
                except Exception as e:
                    self.logger.debug(f"ë©´ì±… ì¡°í•­ ì¶”ê°€ ì‹¤íŒ¨: {e}")
                    # ë©´ì±… ì¡°í•­ ì¶”ê°€ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‘ë‹µ ìœ ì§€
            else:
                # ê¸°ë³¸ ë©´ì±… ì¡°í•­ ì¶”ê°€
                if response_result["response"] and not response_result["response"].endswith("."):
                    response_result["response"] += "\n\nâ€» ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, êµ¬ì²´ì ì¸ ë²•ë¥  ìë¬¸ì€ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

            # ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€ (ìŒìˆ˜ ë°©ì§€)
            processing_time = max(0.0, time.time() - start_time)
            response_result["processing_time"] = processing_time
            response_result["session_id"] = session_id
            response_result["user_id"] = user_id

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë” ì ê·¹ì ìœ¼ë¡œ)
            if processing_time > 3.0:  # 3ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš°ì— ë©”ëª¨ë¦¬ ì •ë¦¬
                try:
                    cleanup_result = self.perform_memory_cleanup()
                    if cleanup_result.get('success'):
                        response_result["memory_cleanup"] = {
                            "memory_freed_mb": cleanup_result.get('memory_freed_mb', 0),
                            "objects_collected": cleanup_result.get('objects_collected', 0)
                        }
                except Exception as e:
                    self.logger.warning(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")

            # ì¶”ê°€ ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ë²ˆ ì‹¤í–‰)
            try:
                import gc
                collected = gc.collect()
                if collected > 0:
                    self.logger.debug(f"Garbage collection freed {collected} objects")
            except Exception as e:
                self.logger.warning(f"Garbage collection failed: {e}")

            # ìºì‹œ ì €ì¥ (ì¶”ê°€ ìµœì í™” - ìºì‹œ ì‹œê°„ ì¦ê°€) - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
            # if self.cache_manager:
            #     self.cache_manager.set(cache_key, response_result, ttl_seconds=7200)  # 1ì‹œê°„ì—ì„œ 2ì‹œê°„ìœ¼ë¡œ ì¦ê°€

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸
            if self.performance_monitor and hasattr(self.performance_monitor, 'log_response_metrics'):
                try:
                    query_type = response_result.get('generation_method', 'unknown')
                    processing_time = response_result.get('processing_time', 0)
                    confidence = response_result.get('confidence', 0)
                    response_length = len(response_result.get('response', ''))

                    self.performance_monitor.log_response_metrics(
                        query_type=query_type,
                        processing_time=processing_time,
                        confidence=confidence,
                        response_length=response_length,
                        success=True
                    )
                except Exception as e:
                    self.logger.error(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸ ì‹¤íŒ¨: {e}")
            elif self.performance_monitor:
                self.logger.warning("PerformanceMonitorê°€ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë‚˜ log_response_metrics ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                self.logger.debug("PerformanceMonitorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            return response_result

        except Exception as e:
            self.logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            self.logger.error(f"ì „ì²´ ìŠ¤íƒ: {traceback.format_exc()}")

            # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸
            if self.performance_monitor and hasattr(self.performance_monitor, 'log_response_metrics'):
                try:
                    processing_time = time.time() - start_time
                    self.performance_monitor.log_response_metrics(
                        query_type='error',
                        processing_time=processing_time,
                        confidence=0.0,
                        response_length=0,
                        success=False,
                        error_message=str(e)
                    )
                except Exception as metric_error:
                    self.logger.error(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê·¸ ì‹¤íŒ¨: {metric_error}")
            elif self.performance_monitor:
                self.logger.warning("PerformanceMonitorê°€ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë‚˜ log_response_metrics ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                self.logger.debug("PerformanceMonitorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            return self._create_simple_error_response(
                f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                session_id, user_id, start_time
            )

    def _validate_and_preprocess_input(self, message: str) -> Dict[str, Any]:
        """ì…ë ¥ ê²€ì¦ ë° ì „ì²˜ë¦¬"""
        if not message or not message.strip():
            return {"valid": False, "error": "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}

        if len(message) > 10000:
            return {"valid": False, "error": "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤."}

        return {"valid": True, "message": message.strip()}

    def _generate_cache_key(self, message: str, user_id: str, context: Optional[str] = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{message}_{user_id}_{context or ''}"
        return hashlib.md5(key_data.encode()).hexdigest()

    def _create_simple_error_response(self, error_message: str, session_id: str, user_id: str, start_time: float) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. {error_message}",
            "confidence": 0.0,
            "sources": [],
            "processing_time": time.time() - start_time,
            "session_id": session_id,
            "user_id": user_id,
            "error": error_message,
            "generation_method": "error"
        }

    def _create_restricted_response(self, restriction_result: Dict[str, Any], session_id: str, user_id: str, start_time: float) -> Dict[str, Any]:
        """ì œí•œëœ ì‘ë‹µ ìƒì„±"""
        return {
            "response": restriction_result.get("safe_response", "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "confidence": 0.0,
            "sources": [],
            "processing_time": time.time() - start_time,
            "session_id": session_id,
            "user_id": user_id,
            "restricted": True,
            "restriction_reason": restriction_result.get("reason", "ë²•ë¥  ì œí•œ"),
            "generation_method": "restricted"
        }

    async def _analyze_query(self, message: str, context: Optional[str], user_id: str, session_id: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë¶„ì„ - í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ìš°ì„  ì‚¬ìš©"""
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì‚¬ìš© (ìš°ì„ )
            if self.hybrid_classifier:
                try:
                    classification_result = self.hybrid_classifier.classify(message)

                    # í–¥ìƒëœ ë„ë©”ì¸ ë¶„ì„ ìˆ˜í–‰
                    domain_analysis = self.hybrid_classifier.get_enhanced_domain_analysis(message, classification_result)

                    # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§• ì •ë³´ í™œìš©
                    features = classification_result.features or {}

                    # í†µí•©ëœ ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì •ë³´ ìš°ì„  ì‚¬ìš©)
                    query_analysis = {
                        "query_type": classification_result.question_type_value,
                        "intent": "unknown",  # ê¸°ë³¸ê°’
                        "confidence": classification_result.confidence,
                        "context": context,
                        "keywords": features.get("keywords", []),  # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ì—ì„œ ì¶”ì¶œ
                        "statute_match": features.get("statute_match"),
                        "statute_law": features.get("statute_law"),
                        "statute_article": features.get("statute_article"),
                        "domain": domain_analysis.get("domain", classification_result.question_type.to_domain()),
                        "domain_confidence": domain_analysis.get("domain_confidence", classification_result.confidence),
                        "domain_scores": domain_analysis.get("domain_scores", {}),
                        "domain_info": domain_analysis.get("domain_info", {}),
                        "timestamp": datetime.now(),
                        "session_id": session_id,
                        "user_id": user_id,
                        "classification_method": classification_result.method,
                        "classification_reasoning": classification_result.reasoning,
                        "law_weight": classification_result.law_weight,
                        "precedent_weight": classification_result.precedent_weight,
                        "features": features,  # ì¶”ê°€ íŠ¹ì§• ì •ë³´
                        "hybrid_analysis": True  # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‚¬ìš© í‘œì‹œ
                    }

                    self.logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ ê²°ê³¼: {classification_result.question_type_value} "
                                   f"(ì‹ ë¢°ë„: {classification_result.confidence:.3f}, ë°©ë²•: {classification_result.method}, "
                                   f"ë„ë©”ì¸: {domain_analysis.get('domain', 'unknown')})")

                    return query_analysis

                except Exception as e:
                    self.logger.warning(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ì¡´ ë¶„ë¥˜ê¸° ì‚¬ìš©: {e}")

            # í´ë°±: ê¸°ì¡´ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì‚¬ìš© (í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ê°ì†Œ)
            if self.question_classifier:
                classification = self.question_classifier.classify_question(message)
                query_type = classification.question_type
                intent = "unknown"
                confidence = classification.confidence
            else:
                query_type = "general"
                intent = "unknown"
                confidence = 0.5

            # ê°„ì†Œí™”ëœ í´ë°± ë¶„ì„ (í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ìµœì†Œí™”)
            fallback_analysis = self._perform_fallback_analysis(message, query_type, confidence)

            return {
                "query_type": query_type,
                "intent": intent,
                "confidence": confidence,
                "context": context,
                "keywords": fallback_analysis.get("keywords", []),
                "statute_match": fallback_analysis.get("statute_match"),
                "statute_law": fallback_analysis.get("statute_law"),
                "statute_article": fallback_analysis.get("statute_article"),
                "domain": fallback_analysis.get("domain", "general"),
                "domain_confidence": fallback_analysis.get("domain_confidence", confidence),
                "domain_scores": fallback_analysis.get("domain_scores", {}),
                "timestamp": datetime.now(),
                "session_id": session_id,
                "user_id": user_id,
                "classification_method": "legacy_fallback",
                "classification_reasoning": "í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± ì‚¬ìš©",
                "hybrid_analysis": False  # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ë¯¸ì‚¬ìš© í‘œì‹œ
            }

        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "query_type": "general",
                "intent": "unknown",
                "confidence": 0.5,
                "context": context,
                "keywords": [],
                "statute_match": None,
                "statute_law": None,
                "statute_article": None,
                "domain": "general",
                "domain_confidence": 0.5,
                "domain_scores": {},
                "timestamp": datetime.now(),
                "session_id": session_id,
                "user_id": user_id,
                "classification_method": "error",
                "classification_reasoning": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "error": str(e),
                "hybrid_analysis": False
            }

    def _perform_fallback_analysis(self, message: str, query_type: str, confidence: float) -> Dict[str, Any]:
        """ê°„ì†Œí™”ëœ í´ë°± ë¶„ì„ (í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ìµœì†Œí™”)"""
        try:
            message_lower = message.lower()

            # ê¸°ë³¸ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ìµœì†Œí•œì˜ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì‚¬ìš©)
            basic_keywords = []
            basic_domain_scores = {}

            # ê°„ì†Œí™”ëœ ë„ë©”ì¸ ë¶„ë¥˜ (í•µì‹¬ í‚¤ì›Œë“œë§Œ ì‚¬ìš©)
            core_keywords = {
                "civil_law": ["ë¯¼ë²•", "ê³„ì•½", "ì†í•´ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„"],
                "criminal_law": ["í˜•ë²•", "ë²”ì£„", "ì²˜ë²Œ", "í˜•ëŸ‰"],
                "family_law": ["ì´í˜¼", "ìƒì†", "ì–‘ìœ¡ê¶Œ", "ì¬ì‚°ë¶„í• "],
                "commercial_law": ["ìƒë²•", "íšŒì‚¬", "ì£¼ì‹", "ì´ì‚¬"],
                "labor_law": ["ë…¸ë™ë²•", "ê·¼ë¡œ", "ì„ê¸ˆ", "í•´ê³ "],
                "real_estate": ["ë¶€ë™ì‚°", "ë§¤ë§¤", "ì„ëŒ€ì°¨", "ë“±ê¸°"],
                "general": ["ë²•ë¥ ", "ë²•ë ¹", "ì¡°ë¬¸", "íŒë¡€"]
            }

            for domain, keywords in core_keywords.items():
                score = 0
                for keyword in keywords:
                    if keyword in message_lower:
                        score += 1
                        basic_keywords.append(keyword)
                basic_domain_scores[domain] = score

            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë„ë©”ì¸ ì„ íƒ
            best_domain = max(basic_domain_scores.items(), key=lambda x: x[1])[0] if basic_domain_scores else "general"
            domain_confidence = min(1.0, basic_domain_scores.get(best_domain, 0) / 4.0)  # ì •ê·œí™”

            # ë²•ë¥  ì¡°ë¬¸ íŒ¨í„´ ê²€ìƒ‰ (ê°„ì†Œí™”)
            import re
            statute_patterns = [
                r'(ë¯¼ë²•|í˜•ë²•|ìƒë²•|ë…¸ë™ë²•|ê°€ì¡±ë²•|í–‰ì •ë²•|í—Œë²•)\s*ì œ\s*(\d+)\s*ì¡°',
                r'ì œ\s*(\d+)\s*ì¡°',
                r'(\d+)\s*ì¡°'
            ]

            statute_match = None
            statute_law = None
            statute_article = None

            for pattern in statute_patterns:
                match = re.search(pattern, message)
                if match:
                    statute_match = match
                    groups = match.groups()

                    if len(groups) == 2:
                        statute_law = groups[0]
                        statute_article = groups[1]
                    elif len(groups) == 1:
                        statute_article = groups[0]
                    break

            return {
                "keywords": list(set(basic_keywords)),
                "domain": best_domain,
                "domain_confidence": domain_confidence,
                "domain_scores": basic_domain_scores,
                "statute_match": statute_match.group(0) if statute_match else None,
                "statute_law": statute_law,
                "statute_article": statute_article
            }

        except Exception as e:
            self.logger.error(f"í´ë°± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "keywords": [],
                "domain": "general",
                "domain_confidence": 0.5,
                "domain_scores": {},
                "statute_match": None,
                "statute_law": None,
                "statute_article": None
            }

    async def _validate_legal_restrictions(self, message: str, query_analysis: Dict[str, Any], user_id: str, session_id: str) -> Dict[str, Any]:
        """ë²•ë¥  ì œí•œ ê²€ì¦"""
        try:
            if self.multi_stage_validation_system:
                try:
                    validation_result = await self.multi_stage_validation_system.validate_message(
                        message, query_analysis, user_id, session_id
                    )
                    return {
                        "restricted": validation_result.is_restricted,
                        "reason": validation_result.restriction_reason,
                        "safe_response": validation_result.safe_response,
                        "confidence": validation_result.confidence
                    }
                except AttributeError:
                    self.logger.debug("MultiStageValidationSystemì— validate_message ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ë²•ë¥  ì œí•œ ê²€ì¦ ì‹¤íŒ¨: {e}")
            else:
                return {"restricted": False, "reason": None, "safe_response": None, "confidence": 1.0}

        except Exception as e:
            self.logger.error(f"ë²•ë¥  ì œí•œ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"restricted": False, "reason": None, "safe_response": None, "confidence": 0.5}

    async def _process_phase1_context(self, message: str, session_id: str, user_id: str) -> Dict[str, Any]:
        """Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™”"""
        try:
            phase1_info = {
                "session_context": None,
                "multi_turn_context": None,
                "compressed_context": None,
                "enabled": False
            }

            if self.integrated_session_manager:
                try:
                    session_context = await self.integrated_session_manager.get_session_context(session_id)
                    phase1_info["session_context"] = session_context
                    phase1_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("IntegratedSessionManagerì— get_session_context ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

            if self.multi_turn_handler:
                try:
                    multi_turn_context = await self.multi_turn_handler.process_message(message, session_id)
                    phase1_info["multi_turn_context"] = multi_turn_context
                    phase1_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("MultiTurnQuestionHandlerì— process_message ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ë‹¤ì¤‘ í„´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

            if self.context_compressor:
                try:
                    compressed_context = await self.context_compressor.compress_context(message, session_id)
                    phase1_info["compressed_context"] = compressed_context
                except AttributeError:
                    self.logger.debug("ContextCompressorì— compress_context ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ì‹¤íŒ¨: {e}")
                phase1_info["enabled"] = True

            return phase1_info

        except Exception as e:
            self.logger.error(f"Phase 1 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"enabled": False, "error": str(e)}

    async def _process_phase2_personalization(self, message: str, session_id: str, user_id: str, phase1_info: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 2: ê°œì¸í™” ë° ì§€ëŠ¥í˜• ë¶„ì„"""
        try:
            phase2_info = {
                "user_profile": None,
                "emotion_intent": None,
                "conversation_flow": None,
                "enabled": False
            }

            if self.user_profile_manager:
                try:
                    user_profile = await self.user_profile_manager.get_user_profile(user_id)
                    phase2_info["user_profile"] = user_profile
                    phase2_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("UserProfileManagerì— get_user_profile ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ì‚¬ìš©ì í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

            if self.emotion_intent_analyzer:
                try:
                    emotion_intent = await self.emotion_intent_analyzer.analyze_emotion_intent(message, user_id)
                    phase2_info["emotion_intent"] = emotion_intent
                    phase2_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("EmotionIntentAnalyzerì— analyze_emotion_intent ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ê°ì • ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")

            if self.conversation_flow_tracker:
                try:
                    # ConversationTurn ê°ì²´ ìƒì„±
                    from datetime import datetime

                    from .conversation_manager import ConversationTurn
                    turn = ConversationTurn(
                        user_query=message,
                        bot_response="",
                        timestamp=datetime.now(),
                        question_type="general",
                        intent="unknown",
                        entities=[],
                        confidence=0.5
                    )
                    conversation_flow = await self.conversation_flow_tracker.track_conversation_flow(session_id, turn)
                    phase2_info["conversation_flow"] = conversation_flow
                except AttributeError as e:
                    self.logger.debug(f"ConversationFlowTracker ë©”ì„œë“œ ì—†ìŒ: {e}")
                except Exception as e:
                    self.logger.debug(f"ëŒ€í™” íë¦„ ì¶”ì  ì‹¤íŒ¨: {e}")
                phase2_info["enabled"] = True

            return phase2_info

        except Exception as e:
            self.logger.error(f"Phase 2 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"enabled": False, "error": str(e)}

    async def _process_phase3_memory_quality(self, message: str, session_id: str, user_id: str, phase1_info: Dict[str, Any], phase2_info: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§"""
        try:
            phase3_info = {
                "contextual_memory": None,
                "quality_metrics": None,
                "enabled": False
            }

            if self.contextual_memory_manager:
                try:
                    contextual_memory = await self.contextual_memory_manager.manage_contextual_memory(
                        message, session_id, user_id, phase1_info, phase2_info
                    )
                    phase3_info["contextual_memory"] = contextual_memory
                    phase3_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("ContextualMemoryManagerì— manage_contextual_memory ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹¤íŒ¨: {e}")

            if self.conversation_quality_monitor:
                try:
                    quality_metrics = await self.conversation_quality_monitor.monitor_conversation_quality(
                        message, session_id, user_id
                    )
                    phase3_info["quality_metrics"] = quality_metrics
                    phase3_info["enabled"] = True
                except AttributeError:
                    self.logger.debug("ConversationQualityMonitorì— monitor_conversation_quality ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                except Exception as e:
                    self.logger.debug(f"ëŒ€í™” í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")

            return phase3_info

        except Exception as e:
            self.logger.error(f"Phase 3 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"enabled": False, "error": str(e)}

    async def _generate_enhanced_response(self, message: str, query_analysis: Dict[str, Any],
                                         restriction_result: Dict[str, Any], user_id: str, session_id: str,
                                         phase1_info: Dict[str, Any], phase2_info: Dict[str, Any], phase3_info: Dict[str, Any]) -> Dict[str, Any]:
        """í–¥ìƒëœ ë‹µë³€ ìƒì„± - LangGraph ì›Œí¬í”Œë¡œìš° ìš°ì„  ì‚¬ìš©"""
        self.logger.info(f"_generate_enhanced_response called for: {message}")
        start_time = time.time()  # start_time ë³€ìˆ˜ ì¶”ê°€
        try:
            # ìŠ¤íƒ€ì¼ ë¶„ì„ ë° ê²°ì •
            detected_style = None
            if self.intelligent_style_system:
                try:
                    detected_style = self.intelligent_style_system.determine_optimal_style(
                        message, query_analysis, session_id
                    )
                    self.logger.info("Detected response style: " + detected_style.value)
                except Exception as e:
                    self.logger.debug(f"Style detection failed: {e}")
                    detected_style = ResponseStyle.FRIENDLY  # ê¸°ë³¸ê°’

            # ğŸ”¥ 1ìˆœìœ„: LangGraph ì›Œí¬í”Œë¡œìš° (ê°€ì¥ ê³ ë„í™”ëœ ì²˜ë¦¬) - ê°•ì œ í™œì„±í™”
            self.logger.info("ğŸ” LangGraph ì‹¤í–‰ ì¡°ê±´ í™•ì¸:")
            self.logger.info(f"  - use_langgraph: {self.use_langgraph}")
            self.logger.info(f"  - langgraph_service: {self.langgraph_service is not None}")

            if self.use_langgraph:
                # LangGraph ì„œë¹„ìŠ¤ê°€ Noneì´ë©´ ì¬ì´ˆê¸°í™” ì‹œë„
                if not self.langgraph_service:
                    self.logger.warning("âš ï¸ LangGraph ì„œë¹„ìŠ¤ê°€ Noneì…ë‹ˆë‹¤. ì¬ì´ˆê¸°í™” ì‹œë„...")
                    self._initialize_langgraph_workflow()

                if self.langgraph_service:
                    try:
                        self.logger.info(f"ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš°ë¡œ ì²˜ë¦¬ ì‹œì‘: {message}")
                        self.logger.info(f"ğŸ“Š LangGraph ì„œë¹„ìŠ¤ ìƒíƒœ: {self.langgraph_service is not None}")
                        self.logger.info(f"âš™ï¸ LangGraph ì‚¬ìš© ì„¤ì •: {self.use_langgraph}")

                        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                        self.logger.info("ğŸ” LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì „ ìƒíƒœ í™•ì¸:")
                        self.logger.info(f"  - langgraph_service: {self.langgraph_service is not None}")
                        self.logger.info(f"  - use_langgraph: {self.use_langgraph}")
                        self.logger.info(f"  - message: {message}")
                        self.logger.info(f"  - langgraph_service type: {type(self.langgraph_service)}")

                        langgraph_result = await self.langgraph_service.process_query(
                            query=message,
                            context=query_analysis.get("context"),
                            session_id=session_id,
                            user_id=user_id
                        )

                        self.logger.info(f"âœ… LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {langgraph_result is not None}")
                        self.logger.info("ğŸ” LangGraph ê²°ê³¼ í‚¤: " + str(list(langgraph_result.keys()) if langgraph_result else 'None'))
                        self.logger.info(f"ğŸ” LangGraph ì‘ë‹µ í…ìŠ¤íŠ¸: {langgraph_result.get('response', 'NOT_FOUND')[:100] if langgraph_result else 'None'}")
                        self.logger.info(f"ğŸ” LangGraph ì „ì²´ ê²°ê³¼: {langgraph_result}")

                        if langgraph_result and langgraph_result.get('response'):
                            self.logger.info("ğŸ‰ LangGraphì—ì„œ ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤!")
                            return {
                                'response': langgraph_result['response'],
                                'confidence': langgraph_result.get('confidence', 0.8),
                                'sources': langgraph_result.get('sources', []),
                                'workflow_steps': langgraph_result.get('workflow_steps', []),
                                'processing_time': time.time() - start_time,
                                'session_id': session_id,
                                'user_id': user_id,
                                'quality_metrics': langgraph_result.get('quality_metrics', {}),
                                'error_messages': langgraph_result.get('error_messages', []),
                                'intermediate_results': langgraph_result.get('intermediate_results', {}),
                                'langgraph_enabled': True,
                                'generation_method': 'langgraph_workflow'
                            }
                        else:
                            self.logger.warning("âš ï¸ LangGraphì—ì„œ ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            self.logger.warning(f"LangGraph ê²°ê³¼: {langgraph_result}")

                    except Exception as e:
                        self.logger.error(f"âŒ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                        self.logger.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                        import traceback
                        self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                else:
                    self.logger.error("âŒ LangGraph service initialization failed completely")
            else:
                self.logger.warning("âš ï¸ LangGraph ì‚¬ìš©ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

            # 2ìˆœìœ„: íŠ¹ì • ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ (LangGraph ì‹¤íŒ¨ ì‹œ)
            statute_law = query_analysis.get("statute_law")
            statute_article = query_analysis.get("statute_article")

            if statute_law and statute_article and self.current_law_search_engine:
                try:
                    self.logger.info(f"Searching specific law article: {statute_law} ì œ{statute_article}ì¡°")
                    specific_result = self.current_law_search_engine.search_by_law_article(
                        statute_law, statute_article
                    )

                    if specific_result and specific_result.article_content:
                        return {
                            "response": specific_result.article_content,
                            "confidence": 0.95,  # íŠ¹ì • ì¡°ë¬¸ ê²€ìƒ‰ì€ ë†’ì€ ì‹ ë¢°ë„
                            "sources": [{
                                "content": specific_result.article_content,
                                "law_name": specific_result.law_name_korean,
                                "article_number": statute_article,
                                "similarity": 1.0,
                                "source": "specific_article",
                                "type": "current_law"
                            }],
                            "query_analysis": query_analysis,
                            "generation_method": "specific_article",
                            "session_id": session_id,
                            "user_id": user_id
                        }
                    elif specific_result:
                        # ë²•ë¥  ì •ë³´ëŠ” ìˆì§€ë§Œ ì¡°ë¬¸ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                        return {
                            "response": f"'{statute_law} ì œ{statute_article}ì¡°'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ, í•´ë‹¹ ì¡°ë¬¸ì˜ ì „ì²´ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì°¾ì€ ë²•ë¥  ì •ë³´:\n- ë²•ë ¹ëª…: {specific_result.law_name_korean}\n- ì†Œê´€ë¶€ì²˜: {specific_result.ministry_name}\n- ì‹œí–‰ì¼: {specific_result.effective_date}\n\në” ì „ì²´ì ì¸ ì¡°ë¬¸ ë‚´ìš©ì´ í•„ìš”í•˜ì‹œë©´ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°(www.law.go.kr)ì—ì„œ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                            "confidence": 0.7,
                            "sources": [{
                                "content": f"ë²•ë ¹ëª…: {specific_result.law_name_korean}, ì†Œê´€ë¶€ì²˜: {specific_result.ministry_name}",
                                "law_name": specific_result.law_name_korean,
                                "article_number": statute_article,
                                "similarity": 0.8,
                                "source": "law_info_only",
                                "type": "current_law"
                            }],
                            "query_analysis": query_analysis,
                            "generation_method": "law_info_only",
                            "session_id": session_id,
                            "user_id": user_id
                        }
                except Exception as e:
                    self.logger.debug(f"Specific law article search failed: {e}")

            # 3ìˆœìœ„: UnifiedSearchEngine ì‚¬ìš© (LangGraph ë° íŠ¹ì • ì¡°ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ)
            if self.unified_search_engine:
                try:
                    self.logger.info(f"ğŸ” UnifiedSearchEngineìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰: {message}")

                    # UnifiedSearchEngineìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
                    search_result = await self.unified_search_engine.search(
                        query=message,
                        top_k=5,
                        search_types=['vector', 'exact', 'current_law'],
                        category='all',
                        use_cache=True
                    )

                    self.logger.info(f"âœ… UnifiedSearchEngine ê²€ìƒ‰ ì™„ë£Œ: {len(search_result.results)}ê°œ ê²°ê³¼")

                    if search_result.results:
                        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
                        sources = []
                        for result in search_result.results:
                            sources.append({
                                'content': result.get('content', ''),
                                'score': result.get('score', 0.0),
                                'source': result.get('source', 'unknown'),
                                'metadata': result.get('metadata', {})
                            })

                        # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ì‹¤ì œ LLM ì‚¬ìš©)
                        if self.model_manager and hasattr(self.model_manager, 'generate_response'):
                            try:
                                context_text = "\n".join([f"- {source['content'][:200]}..." for source in sources[:3]])
                                prompt = f"""
ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {message}

ì°¸ê³  ë¬¸ì„œ:
{context_text}

ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""

                                response_text = await self.model_manager.generate_response(prompt)

                                return {
                                    'response': response_text,
                                    'confidence': search_result.confidence,
                                    'sources': sources,
                                    'workflow_steps': ['unified_search_engine'],
                                    'processing_time': time.time() - start_time,
                                    'session_id': session_id,
                                    'user_id': user_id,
                                    'quality_metrics': {'search_results_count': len(sources)},
                                    'error_messages': [],
                                    'intermediate_results': {'search_result': search_result},
                                    'langgraph_enabled': False,
                                    'generation_method': 'unified_search_engine'
                                }
                            except Exception as e:
                                self.logger.warning(f"LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")

                        # LLMì´ ì—†ìœ¼ë©´ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜
                        response_text = f"'{message}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
                        for i, source in enumerate(sources[:3], 1):
                            response_text += f"{i}. {source['content'][:150]}...\n"

                        return {
                            'response': response_text,
                            'confidence': search_result.confidence,
                            'sources': sources,
                            'workflow_steps': ['unified_search_engine'],
                            'processing_time': time.time() - start_time,
                            'session_id': session_id,
                            'user_id': user_id,
                            'quality_metrics': {'search_results_count': len(sources)},
                            'error_messages': [],
                            'intermediate_results': {'search_result': search_result},
                            'langgraph_enabled': False,
                            'generation_method': 'unified_search_engine'
                        }
                    else:
                        self.logger.warning("UnifiedSearchEngineì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                except Exception as e:
                    self.logger.error(f"UnifiedSearchEngine ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    import traceback
                    self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

            # 4ìˆœìœ„: ê¸°ë³¸ RAG ì„œë¹„ìŠ¤ (UnifiedSearchEngine ì‹¤íŒ¨ ì‹œ)
            if self.unified_rag_service:
                try:
                    self.logger.info(f"Calling RAG service for query: {message}")
                    rag_response = await self.unified_rag_service.generate_response(
                        query=message,
                        context=query_analysis.get("context"),
                        max_length=800,  # í† í° ì œí•œì„ 300ì—ì„œ 800ìœ¼ë¡œ ì¦ê°€
                        top_k=3,  # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ 2ì—ì„œ 3ìœ¼ë¡œ ì¦ê°€ (ë” ë§ì€ ì†ŒìŠ¤ í™•ë³´)
                        use_cache=True
                    )

                    # ì™„í™”ëœ ì†ŒìŠ¤ ê²€ì¦ - ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
                    if rag_response and rag_response.response and self._has_meaningful_sources_relaxed(rag_response.sources):
                        # ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°
                        confidence = self._calculate_confidence(rag_response.sources, "good")

                        # ìŠ¤íƒ€ì¼ ì ìš©ëœ ì‘ë‹µ ìƒì„±
                        final_response = rag_response.response
                        if detected_style and self.intelligent_style_system:
                            try:
                                final_response = self.intelligent_style_system.generate_adaptive_response(
                                    rag_response.response, message, query_analysis, session_id
                                )
                            except Exception as e:
                                self.logger.debug(f"Style application failed: {e}")

                        return {
                            "response": final_response,
                            "confidence": confidence,
                            "sources": rag_response.sources,
                            "query_analysis": query_analysis,
                            "generation_method": "rag_with_style",
                            "session_id": session_id,
                            "user_id": user_id,
                            "detected_style": detected_style.value if detected_style else "unknown"
                        }
                    else:
                        # ì˜ë¯¸ ìˆëŠ” ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´í•˜ê³  ì•Œë ¤ì¤Œ
                        return self._create_no_sources_response(message, query_analysis, session_id, user_id)

                except Exception as e:
                    self.logger.debug(f"Simple RAG service failed: {e}")
            else:
                self.logger.warning("unified_rag_service is None, skipping RAG generation")

            # 4ìˆœìœ„: í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ (ìµœí›„ ìˆ˜ë‹¨)
            template_response = self._generate_improved_template_response(message, query_analysis, detected_style)
            if template_response and template_response.get("response"):
                self.logger.info("Using template-based response as fallback")
                return {
                    "response": template_response["response"],
                    "confidence": template_response.get("confidence", 0.8),
                    "sources": template_response.get("sources", []),
                    "query_analysis": query_analysis,
                    "generation_method": template_response.get("generation_method", "template"),
                    "session_id": session_id,
                    "user_id": user_id,
                    "detected_style": detected_style.value if detected_style else "unknown"
                }

            # ì˜ë¯¸ ìˆëŠ” ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë‹µë³€ìœ¼ë¡œ ì²˜ë¦¬
            return self._create_no_sources_response(message, query_analysis, session_id, user_id)

        except Exception as e:
            self.logger.error(f"Enhanced response generation failed: {e}")
            return self._create_error_response(message, query_analysis, session_id, user_id, str(e))

    def _has_meaningful_sources(self, sources: List[Dict[str, Any]]) -> bool:
        """ì˜ë¯¸ìˆëŠ” ë²•ë¥  ì†ŒìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸ - ê¸°ì¤€ì¹˜ ê°•í™” ì ìš©"""
        if not sources:
            return False

        # ë” ì—„ê²©í•œ ê´€ë ¨ë„ ì„ê³„ê°’ ì ìš©
        MIN_RELEVANCE_THRESHOLD = 0.4  # 0.3ì—ì„œ 0.4ë¡œ ì¦ê°€
        MIN_CONTENT_LENGTH = 60  # 50ì—ì„œ 60ìœ¼ë¡œ ì¦ê°€

        meaningful_sources = []
        high_relevance_sources = []

        for source in sources:
            relevance_score = source.get("similarity", source.get("score", 0.0))
            content = source.get("content", "")

            # ê´€ë ¨ë„ê°€ ë†’ê³  ë‚´ìš©ì´ ì¶©ë¶„í•œ ì†ŒìŠ¤ë§Œ ìœ íš¨í•œ ì†ŒìŠ¤ë¡œ íŒë‹¨
            if relevance_score >= MIN_RELEVANCE_THRESHOLD and len(content.strip()) > MIN_CONTENT_LENGTH:
                meaningful_sources.append(source)

                # ë§¤ìš° ë†’ì€ ê´€ë ¨ë„ ì†ŒìŠ¤ ë³„ë„ ì¹´ìš´íŠ¸
                if relevance_score >= 0.6:
                    high_relevance_sources.append(source)

        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ì†ŒìŠ¤ê°€ ìˆì–´ì•¼ ìœ íš¨
        if len(meaningful_sources) >= 1:
            # ì¶”ê°€ ê²€ì¦: ë²•ë¥  ê´€ë ¨ ì½˜í…ì¸ ì¸ì§€ í™•ì¸ (ê°•í™”ëœ í‚¤ì›Œë“œ)
            legal_keywords = ["ë²•ë¥ ", "ì¡°ë¬¸", "íŒë¡€", "ë²•ë ¹", "ê·œì •", "ì†Œì†¡", "ê³„ì•½", "ê¶Œë¦¬", "ì˜ë¬´",
                           "ë¯¼ë²•", "í˜•ë²•", "ìƒë²•", "í—Œë²•", "í–‰ì •", "í˜•ì‚¬", "ë¯¼ì‚¬", "ì´í˜¼", "ìƒì†", "ì¬ì‚°ë¶„í• ",
                           "ì†í•´ë°°ìƒ", "ì±„ê¶Œ", "ì±„ë¬´", "ë¶ˆë²•í–‰ìœ„", "ì„ê¸ˆ", "ê·¼ë¡œ", "í•´ê³ ", "ì„ëŒ€ì°¨", "ë§¤ë§¤"]
            legal_content_count = 0

            for source in meaningful_sources:
                content = source.get("content", "").lower()
                if any(keyword in content for keyword in legal_keywords):
                    legal_content_count += 1

            # ë²•ë¥  ê´€ë ¨ ë‚´ìš©ì´ 1ê°œ ì´ìƒì´ê³  ë†’ì€ ê´€ë ¨ë„ ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ìœ íš¨
            return legal_content_count >= 1 and len(high_relevance_sources) >= 1

        return False

    def _has_meaningful_sources_relaxed(self, sources: List[Dict[str, Any]]) -> bool:
        """ì™„í™”ëœ ì˜ë¯¸ìˆëŠ” ë²•ë¥  ì†ŒìŠ¤ í™•ì¸ - ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©"""
        if not sources:
            return False

        # ì™„í™”ëœ ê´€ë ¨ë„ ì„ê³„ê°’ ì ìš©
        MIN_RELEVANCE_THRESHOLD = 0.2  # 0.4ì—ì„œ 0.2ë¡œ ì™„í™”
        MIN_CONTENT_LENGTH = 30  # 60ì—ì„œ 30ìœ¼ë¡œ ì™„í™”

        meaningful_sources = []
        high_relevance_sources = []

        for source in sources:
            relevance_score = source.get("similarity", source.get("score", 0.0))
            content = source.get("content", "")

            # ì™„í™”ëœ ê¸°ì¤€ìœ¼ë¡œ ì†ŒìŠ¤ ê²€ì¦
            if relevance_score >= MIN_RELEVANCE_THRESHOLD and len(content.strip()) > MIN_CONTENT_LENGTH:
                meaningful_sources.append(source)

                # ë†’ì€ ê´€ë ¨ë„ ì†ŒìŠ¤ ë³„ë„ ì¹´ìš´íŠ¸
                if relevance_score >= 0.4:  # 0.6ì—ì„œ 0.4ë¡œ ì™„í™”
                    high_relevance_sources.append(source)

        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ìœ íš¨
        if len(meaningful_sources) >= 1:
            # ë²•ë¥  ê´€ë ¨ ì½˜í…ì¸  í™•ì¸ (ì™„í™”ëœ í‚¤ì›Œë“œ)
            legal_keywords = ["ë²•ë¥ ", "ì¡°ë¬¸", "íŒë¡€", "ë²•ë ¹", "ê·œì •", "ì†Œì†¡", "ê³„ì•½", "ê¶Œë¦¬", "ì˜ë¬´",
                           "ë¯¼ë²•", "í˜•ë²•", "ìƒë²•", "í—Œë²•", "í–‰ì •", "í˜•ì‚¬", "ë¯¼ì‚¬", "ì´í˜¼", "ìƒì†", "ì¬ì‚°ë¶„í• ",
                           "ì†í•´ë°°ìƒ", "ì±„ê¶Œ", "ì±„ë¬´", "ë¶ˆë²•í–‰ìœ„", "ì„ê¸ˆ", "ê·¼ë¡œ", "í•´ê³ ", "ì„ëŒ€ì°¨", "ë§¤ë§¤",
                           "ë¶€ë™ì‚°", "ê°€ì¡±", "íšŒì‚¬", "ì£¼ì‹", "ì´ì‚¬", "ë…¸ë™", "ê·¼ë¡œê¸°ì¤€ë²•"]
            legal_content_count = 0

            for source in meaningful_sources:
                content = source.get("content", "").lower()
                if any(keyword in content for keyword in legal_keywords):
                    legal_content_count += 1

            # ë²•ë¥  ê´€ë ¨ ë‚´ìš©ì´ ìˆê±°ë‚˜ ë†’ì€ ê´€ë ¨ë„ ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ìœ íš¨
            return legal_content_count >= 1 or len(high_relevance_sources) >= 1

        return False

    def _calculate_confidence(self, sources: List[Dict[str, Any]], response_quality: str = "good") -> float:
        """ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚° - ê¸°ì¤€ì¹˜ ê°•í™”"""
        if not sources:
            return 0.0

        # ê¸°ë³¸ ì‹ ë¢°ë„ (ê°•í™”)
        base_confidence = 0.3  # 0.25ì—ì„œ 0.3ìœ¼ë¡œ ì¦ê°€

        # ì†ŒìŠ¤ í’ˆì§ˆì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ê°•í™”ëœ ê¸°ì¤€)
        avg_relevance = sum(source.get("similarity", source.get("score", 0.0)) for source in sources) / len(sources)

        # ê´€ë ¨ë„ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤ (ê°•í™”ëœ ê¸°ì¤€)
        if avg_relevance >= 0.7:
            relevance_bonus = 0.4  # ë§¤ìš° ë†’ì€ ê´€ë ¨ë„ (0.35ì—ì„œ 0.4ë¡œ ì¦ê°€)
        elif avg_relevance >= 0.5:
            relevance_bonus = 0.25  # ì¤‘ê°„ ê´€ë ¨ë„ (0.15ì—ì„œ 0.25ë¡œ ì¦ê°€)
        elif avg_relevance >= 0.3:
            relevance_bonus = 0.15  # ë‚®ì€ ê´€ë ¨ë„ (0.05ì—ì„œ 0.15ë¡œ ì¦ê°€)
        else:
            relevance_bonus = 0.05  # ë§¤ìš° ë‚®ì€ ê´€ë ¨ë„ (0.0ì—ì„œ 0.05ë¡œ ì¦ê°€)

        # ì†ŒìŠ¤ ê°œìˆ˜ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ (ê°•í™”ëœ ê¸°ì¤€)
        if len(sources) >= 3:
            source_count_bonus = 0.15  # ë§ì€ ì†ŒìŠ¤ (0.1ì—ì„œ 0.15ë¡œ ì¦ê°€)
        elif len(sources) >= 2:
            source_count_bonus = 0.1  # ì¤‘ê°„ ì†ŒìŠ¤ (0.05ì—ì„œ 0.1ë¡œ ì¦ê°€)
        else:
            source_count_bonus = 0.05  # ì ì€ ì†ŒìŠ¤ (0.0ì—ì„œ 0.05ë¡œ ì¦ê°€)

        # ì‘ë‹µ í’ˆì§ˆì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        quality_bonus = 0.15 if response_quality == "excellent" else 0.1 if response_quality == "good" else 0.05

        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        final_confidence = base_confidence + relevance_bonus + source_count_bonus + quality_bonus

        # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì œí•œ
        return max(0.0, min(1.0, final_confidence))

    def _create_no_sources_response(self, message: str, query_analysis: Dict[str, Any], session_id: str, user_id: str) -> Dict[str, Any]:
        """ì˜ë¯¸ ìˆëŠ” ì†ŒìŠ¤ê°€ ì—†ì„ ë•Œì˜ ì‘ë‹µ ìƒì„±"""
        query_type = query_analysis.get("query_type", "general")

        # ì¿¼ë¦¬ íƒ€ì…ë³„ ë§ì¶¤ ë©”ì‹œì§€
        if query_type == "legal_advice":
            response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ì „ì²´ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸ì„ êµ¬ì²´í™”í•´ ì£¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?
- ë” ì „ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš” (ì˜ˆ: "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒ ì²­êµ¬ê¶Œ")
- ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ì´ë‚˜ íŒë¡€ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”
- ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ ì•ˆë‚´í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤

ì „ì²´ì ì¸ ë²•ë¥  ìë¬¸ì€ ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

        elif query_type == "precedent":
            response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ê´€ë ¨ëœ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸ì„ êµ¬ì²´í™”í•´ ì£¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?
- íŒê²°ë²ˆí˜¸ë‚˜ ì‚¬ê±´ëª…ì„ ì •í™•í•˜ê²Œ ì•Œë ¤ì£¼ì„¸ìš”
- ë” ì „ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”
- ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ì„ í•¨ê»˜ í™•ì¸í•´ë³´ì„¸ìš”

íŒë¡€ ê²€ìƒ‰ì´ ì–´ë ¤ìš°ì‹œë©´ ëŒ€ë²•ì› í™ˆí˜ì´ì§€ë‚˜ ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ìš©í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."""

        elif query_type == "law_inquiry":
            response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ë²•ë ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸ì„ êµ¬ì²´í™”í•´ ì£¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?
- ì •í™•í•œ ë²•ë ¹ëª…ê³¼ ì¡°ë¬¸ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš” (ì˜ˆ: "ë¯¼ë²• ì œ750ì¡°")
- ë²•ë ¹ì˜ ê³µì‹ ëª…ì¹­ì„ í™•ì¸í•´ì£¼ì„¸ìš”
- ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ë” ì „ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

ë²•ë ¹ ì •ë³´ëŠ” êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°(www.law.go.kr)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

        else:
            response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸ì„ êµ¬ì²´í™”í•´ ì£¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆê¹Œ?
- ì§ˆë¬¸ì„ ë” ì „ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ê´€ë ¨ ë²•ë ¹ ì¡°ë¬¸ì´ë‚˜ íŒë¡€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”
- í‚¤ì›Œë“œë¥¼ ë” ì •í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”

ì¼ë°˜ì ì¸ ë²•ë¥  ì•ˆë‚´ë‚˜ ì •ë³´ì— ëŒ€í•´ì„œëŠ” ì•ˆë‚´í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

        # ê²€ìƒ‰ ì œì•ˆ ìƒì„±
        suggestions = self._generate_search_suggestions(message, query_analysis)
        suggestion_text = suggestions[0] if suggestions else "ì§ˆë¬¸ì„ ë” ì „ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”"

        return {
            "response": response,
            "confidence": 0.1,  # 0.0ì—ì„œ 0.1ë¡œ ì¦ê°€ - ì•ˆë‚´ë¬¸ ì œê³µ ì‹œ ê¸°ë³¸ ì‹ ë¢°ë„
            "sources": [],
            "query_analysis": query_analysis,
            "generation_method": "no_sources",
            "session_id": session_id,
            "user_id": user_id,
            "no_sources": True,
            "suggestion": suggestion_text
        }

    def _create_error_response(self, message: str, query_analysis: Dict[str, Any], session_id: str, user_id: str, error: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: {error}\n\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "confidence": 0.0,
            "sources": [],
            "query_analysis": query_analysis,
            "generation_method": "error",
            "session_id": session_id,
            "user_id": user_id,
            "error": error
        }

    def _generate_search_suggestions(self, message: str, query_analysis: Dict[str, Any]) -> List[str]:
        """ê²€ìƒ‰ ì œì•ˆ ìƒì„± - ê°„ì†Œí™”ëœ ë°©ë²•"""
        suggestions = []

        # ì •ê·œì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë°©ë²•)
        import re

        # ë²•ë¥  ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ (í™•ì‹¤í•œ íŒ¨í„´)
        law_patterns = [
            r'(ë¯¼ë²•|í˜•ë²•|ìƒë²•|ë…¸ë™ë²•|ê°€ì¡±ë²•|í–‰ì •ë²•|í—Œë²•|ë¯¼ì‚¬ì†Œì†¡ë²•|í˜•ì‚¬ì†Œì†¡ë²•)',
            r'(ê³„ì•½|ì†í•´ë°°ìƒ|ë¶ˆë²•í–‰ìœ„|ì±„ê¶Œ|ì±„ë¬´)',
            r'(ì´í˜¼|ìƒì†|ì–‘ìœ¡ê¶Œ|ì¬ì‚°ë¶„í• |ê°€ì¡±)',
            r'(íšŒì‚¬|ì£¼ì‹|ì´ì‚¬|ìƒë²•|ìƒí–‰ìœ„)',
            r'(ê·¼ë¡œ|ì„ê¸ˆ|í•´ê³ |ë…¸ë™ë²•|ê·¼ë¡œê¸°ì¤€ë²•)',
            r'(ë¶€ë™ì‚°|ë§¤ë§¤|ì„ëŒ€ì°¨|ë“±ê¸°|ë¶€ë™ì‚°ë“±ê¸°ë²•)',
            r'(ë²•ë¥ |ë²•ë ¹|ì¡°ë¬¸|íŒë¡€|ë²•ì›|ë²•ì •)'
        ]

        extracted_keywords = []
        for pattern in law_patterns:
            matches = re.findall(pattern, message)
            if matches:
                if isinstance(matches[0], tuple):
                    extracted_keywords.extend([match for match in matches[0] if match])
                else:
                    extracted_keywords.extend(matches)

        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        extracted_keywords = list(set(extracted_keywords))

        # í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ì •ë ¬ (ë²•ë¥ ëª… > ë²•ì¡°ë¬¸ > ì¼ë°˜ ì¡°ë¬¸)
        priority_keywords = []
        specific_keywords = []
        general_keywords = []

        for keyword in extracted_keywords:
            if keyword in ["ë¯¼ë²•", "í˜•ë²•", "ìƒë²•", "ë…¸ë™ë²•", "ê°€ì¡±ë²•", "í–‰ì •ë²•", "í—Œë²•", "ë¯¼ì‚¬ì†Œì†¡ë²•", "í˜•ì‚¬ì†Œì†¡ë²•"]:
                priority_keywords.append(keyword)
            elif keyword in ["ê³„ì•½", "ì†í•´ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„", "ì±„ê¶Œ", "ì±„ë¬´", "ì´í˜¼", "ìƒì†", "ì–‘ìœ¡ê¶Œ", "ì¬ì‚°ë¶„í• ", "ê°€ì¡±", "íšŒì‚¬", "ì£¼ì‹", "ì´ì‚¬", "ìƒë²•", "ìƒí–‰ìœ„", "ê·¼ë¡œ", "ì„ê¸ˆ", "í•´ê³ ", "ë…¸ë™ë²•", "ê·¼ë¡œê¸°ì¤€ë²•", "ë¶€ë™ì‚°", "ë§¤ë§¤", "ì„ëŒ€ì°¨", "ë“±ê¸°", "ë¶€ë™ì‚°ë“±ê¸°ë²•"]:
                specific_keywords.append(keyword)
            else:
                general_keywords.append(keyword)

        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë¨¼ì €, ê·¸ ë‹¤ìŒ íŠ¹ì • ë²•ì¡°ë¬¸ í‚¤ì›Œë“œ, ë§ˆì§€ë§‰ì— ì¼ë°˜ í‚¤ì›Œë“œ
        extracted_keywords = priority_keywords + specific_keywords + general_keywords

        # ì§ˆë¬¸ ë¶„ì„ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„ (fallback) - ìš°ì„ ìˆœìœ„ ì •ë ¬ ì ìš©
        if not extracted_keywords:
            keywords = query_analysis.get("keywords", [])
            if keywords:
                # fallback í‚¤ì›Œë“œë„ ìš°ì„ ìˆœìœ„ ì •ë ¬ ì ìš©
                priority_keywords = []
                specific_keywords = []
                general_keywords = []

                for keyword in keywords:
                    if keyword in ["ë¯¼ë²•", "í˜•ë²•", "ìƒë²•", "ë…¸ë™ë²•", "ê°€ì¡±ë²•", "í–‰ì •ë²•", "í—Œë²•", "ë¯¼ì‚¬ì†Œì†¡ë²•", "í˜•ì‚¬ì†Œì†¡ë²•"]:
                        priority_keywords.append(keyword)
                    elif keyword in ["ê³„ì•½", "ì†í•´ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„", "ì±„ê¶Œ", "ì±„ë¬´", "ì´í˜¼", "ìƒì†", "ì–‘ìœ¡ê¶Œ", "ì¬ì‚°ë¶„í• ", "ê°€ì¡±", "íšŒì‚¬", "ì£¼ì‹", "ì´ì‚¬", "ìƒë²•", "ìƒí–‰ìœ„", "ê·¼ë¡œ", "ì„ê¸ˆ", "í•´ê³ ", "ë…¸ë™ë²•", "ê·¼ë¡œê¸°ì¤€ë²•", "ë¶€ë™ì‚°", "ë§¤ë§¤", "ì„ëŒ€ì°¨", "ë“±ê¸°", "ë¶€ë™ì‚°ë“±ê¸°ë²•"]:
                        specific_keywords.append(keyword)
                    else:
                        general_keywords.append(keyword)

                # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë¨¼ì €, ê·¸ ë‹¤ìŒ íŠ¹ì • ë²•ì¡°ë¬¸ í‚¤ì›Œë“œ, ë§ˆì§€ë§‰ì— ì¼ë°˜ í‚¤ì›Œë“œ
                extracted_keywords = priority_keywords + specific_keywords + general_keywords

        # ì¶”ì¶œëœ í‚¤ì›Œë“œë¡œ ì œì•ˆ ìƒì„± (ì´ë¯¸ ìš°ì„ ìˆœìœ„ ì •ë ¬ë¨)
        if extracted_keywords:
            main_keyword = extracted_keywords[0]
            suggestions.append(f"'{main_keyword}' ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì„ ê²€ìƒ‰í•´ë³´ì„¸ìš”")
            suggestions.append(f"'{main_keyword}' íŒë¡€ë¥¼ ì°¾ì•„ë³´ì„¸ìš”")
            if len(extracted_keywords) > 1:
                suggestions.append(f"'{extracted_keywords[1]}'ë„ í•¨ê»˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”")

        # ì§ˆë¬¸ ìœ í˜•ë³„ ì œì•ˆ
        query_type = query_analysis.get("query_type", "general")
        if query_type == "legal_advice":
            suggestions.extend([
                "ë²•ë¥  ì¡°ë¬¸ ìƒí™©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "ê´€ë ¨ ë²•ë ¹ì´ë‚˜ íŒë¡€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”"
            ])
        elif query_type == "precedent":
            suggestions.extend([
                "íŒë¡€ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”",
                "í•´ë‹¹ ë²•ì¡°ë¬¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”"
            ])
        elif query_type == "law_inquiry":
            suggestions.extend([
                "ì •í™•í•œ ë²•ë¥ ëª…ê³¼ ì¡°ë¬¸ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
                "ë²•ë¥ ì˜ ê³µì‹ ëª…ì¹­ì„ í™•ì¸í•´ì£¼ì„¸ìš”"
            ])

        # ì¼ë°˜ì ì¸ ì œì•ˆ (í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°)
        if not suggestions:
            suggestions.extend([
                "êµ¬ì²´ì ì¸ ë²•ë¥  ì¡°ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”",
                "ê´€ë ¨ ë²•ë ¹ì´ë‚˜ íŒë¡€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”",
                "í‚¤ì›Œë“œë¥¼ ë” ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”"
            ])

        return suggestions[:3]  # ìµœëŒ€ 3ê°œ ì œì•ˆ

    def _generate_improved_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ê°œì„ ëœ í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„± - ìŠ¤íƒ€ì¼ ì§€ì›"""
        self.logger.info(f"_generate_improved_template_response called for: {message}")

        # ë„ë©”ì¸ë³„ íŠ¹í™” í…œí”Œë¦¿ ë‹µë³€ ìƒì„±
        message_lower = message.lower()

        # ê³„ì•½ì„œ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
        if any(keyword in message_lower for keyword in ["ê³„ì•½ì„œ", "ê³„ì•½", "ì‘ì„±", "ì²´ê²°"]):
            return self._generate_contract_template_response(message, query_analysis, detected_style)

        # ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
        elif any(keyword in message_lower for keyword in ["ë¶€ë™ì‚°", "ë§¤ë§¤", "ì„ëŒ€ì°¨", "ë“±ê¸°"]):
            return self._generate_real_estate_template_response(message, query_analysis, detected_style)

        # ê°€ì¡±ë²• ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
        elif any(keyword in message_lower for keyword in ["ì´í˜¼", "ìƒì†", "ì–‘ìœ¡ê¶Œ", "ì¬ì‚°ë¶„í• "]):
            return self._generate_family_law_template_response(message, query_analysis, detected_style)

        # ë²•ë¥  ì¡°ë¬¸ ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
        elif query_analysis.get("statute_match"):
            return self._generate_statute_template_response(message, query_analysis, detected_style)

        # ê¸°ë³¸ í…œí”Œë¦¿ ë‹µë³€
        return self._generate_general_template_response(message, query_analysis, detected_style)

    def _generate_contract_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ê³„ì•½ì„œ ê´€ë ¨ í…œí”Œë¦¿ ë‹µë³€ ìƒì„±"""
        response = """ğŸ“‹ **ê³„ì•½ì„œ ì‘ì„±ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!**

ì–´ë–¤ ì¢…ë¥˜ì˜ ê³„ì•½ì„œë¥¼ ì‘ì„±í•˜ì‹œë‚˜ìš”?

â—‹ **ìš©ì—­ê³„ì•½** (ë””ìì¸, ê°œë°œ, ì»¨ì„¤íŒ… ë“±)
â—‹ **ê·¼ë¡œê³„ì•½** (ì§ì› ì±„ìš©)
â—‹ **ë¶€ë™ì‚°ê³„ì•½** (ë§¤ë§¤, ì„ëŒ€ì°¨)
â—‹ **ì§€ì ì¬ì‚°ê¶Œê³„ì•½** (ì €ì‘ê¶Œ, íŠ¹í—ˆ ë“±)
â—‹ **ì œíœ´ê³„ì•½** (ì—…ë¬´ í˜‘ë ¥)
â—‹ **ê¸°íƒ€**

## ğŸ“ ê³„ì•½ì„œ ì‘ì„± ê¸°ë³¸ ì›ì¹™

1. **ë‹¹ì‚¬ì ì •ë³´**: ì •í™•í•œ ì´ë¦„, ì£¼ì†Œ, ì—°ë½ì²˜
2. **ê³„ì•½ ëª©ì **: êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ë‚´ìš©
3. **ëŒ€ê¸ˆ ë° ì§€ê¸‰**: ê¸ˆì•¡, ì§€ê¸‰ ì‹œê¸°, ë°©ë²•
4. **ê³„ì•½ ê¸°ê°„**: ì‹œì‘ì¼, ì¢…ë£Œì¼, ì—°ì¥ ì¡°ê±´
5. **ìœ„ì•½ ì¡°í•­**: ê³„ì•½ ìœ„ë°˜ ì‹œ ì†í•´ë°°ìƒ
6. **ë¶„ìŸ í•´ê²°**: ì¡°ì •, ì¤‘ì¬, ê´€í•  ë²•ì›

## âš ï¸ ì¤‘ìš” ì•ˆë‚´
- ê³„ì•½ì„œëŠ” ë‚˜ì¤‘ì— í•´ì„ì˜ ì—¬ì§€ê°€ ì—†ë„ë¡ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
- ì¤‘ìš”í•œ ê³„ì•½ì€ ë³€í˜¸ì‚¬ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤
- ê³„ì•½ ê¸ˆì•¡ì´ í° ê²½ìš° ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤

êµ¬ì²´ì ì¸ ê³„ì•½ ìœ í˜•ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ê°€ì´ë“œë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""

        return {
            "response": response,
            "confidence": 0.90,
            "generation_method": "contract_template",
            "sources": [],
            "query_analysis": query_analysis
        }

    def _generate_real_estate_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ë¶€ë™ì‚° ê´€ë ¨ í…œí”Œë¦¿ ë‹µë³€ ìƒì„±"""
        response = """ğŸ  **ë¶€ë™ì‚° ê´€ë ¨ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!**

ì–´ë–¤ ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?

â—‹ **ë§¤ë§¤ ì ˆì°¨** (ë¶€ë™ì‚° êµ¬ë§¤/íŒë§¤)
â—‹ **ì„ëŒ€ì°¨ ê³„ì•½** (ì „ì„¸, ì›”ì„¸)
â—‹ **ë“±ê¸° ì ˆì°¨** (ì†Œìœ ê¶Œ ì´ì „)
â—‹ **ë¶€ë™ì‚° ì„¸ê¸ˆ** (ì·¨ë“ì„¸, ì–‘ë„ì„¸)
â—‹ **ë¶€ë™ì‚° ë¶„ìŸ** (ê³„ì•½ ë¶„ìŸ, ê¶Œë¦¬ ë¶„ìŸ)
â—‹ **ê¸°íƒ€**

## ğŸ“‹ ë¶€ë™ì‚° ê±°ë˜ ê¸°ë³¸ ì ˆì°¨

### ë§¤ë§¤ ê±°ë˜
1. **ë¬¼ê±´ í™•ì¸** â†’ ë“±ê¸°ë¶€ë“±ë³¸, ê±´ì¶•ë¬¼ëŒ€ì¥ í™•ì¸
2. **ê³„ì•½ ì²´ê²°** â†’ ë§¤ë§¤ê³„ì•½ì„œ ì‘ì„±, ê³„ì•½ê¸ˆ ì§€ê¸‰
3. **ì¤‘ë„ê¸ˆ ì§€ê¸‰** â†’ ì¤‘ë„ê¸ˆ ì§€ê¸‰, ê·¼ì €ë‹¹ í•´ì§€
4. **ì”ê¸ˆ ì§€ê¸‰** â†’ ì”ê¸ˆ ì§€ê¸‰, ì†Œìœ ê¶Œ ì´ì „ ë“±ê¸°
5. **ì„¸ê¸ˆ ë‚©ë¶€** â†’ ì·¨ë“ì„¸, ë“±ë¡ë©´í—ˆì„¸ ë‚©ë¶€

### ì„ëŒ€ì°¨ ê³„ì•½
1. **ë¬¼ê±´ í™•ì¸** â†’ ì „ì„¸ê¸ˆ í™•ì¸, ì›”ì„¸ê¸ˆ í™•ì¸
2. **ê³„ì•½ ì²´ê²°** â†’ ì„ëŒ€ì°¨ê³„ì•½ì„œ ì‘ì„±, ë³´ì¦ê¸ˆ ì§€ê¸‰
3. **ì…ì£¼** â†’ ì „ì…ì‹ ê³ , í™•ì •ì¼ì ë°›ê¸°
4. **ê³„ì•½ ì¢…ë£Œ** â†’ ë³´ì¦ê¸ˆ ë°˜í™˜, ì›ìƒë³µêµ¬

êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""

        return {
            "response": response,
            "confidence": 0.90,
            "generation_method": "real_estate_template",
            "sources": [],
            "query_analysis": query_analysis
        }

    def _generate_family_law_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ê°€ì¡±ë²• ê´€ë ¨ í…œí”Œë¦¿ ë‹µë³€ ìƒì„±"""
        response = """ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **ê°€ì¡±ë²• ê´€ë ¨ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!**

ì–´ë–¤ ê°€ì¡±ë²• ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?

â—‹ **ì´í˜¼ ì ˆì°¨** (í˜‘ì˜ì´í˜¼, ì¬íŒì´í˜¼)
â—‹ **ìƒì† ë¬¸ì œ** (ìƒì†ë¶„, ìœ ì–¸, ìƒì†í¬ê¸°)
â—‹ **ì–‘ìœ¡ê¶Œ** (ìë…€ ì–‘ìœ¡ê¶Œ ë¬¸ì œ, ì–‘ìœ¡ë¹„)
â—‹ **ì¬ì‚°ë¶„í• ** (ì´í˜¼ ì‹œ ì¬ì‚° ë¶„í• , ìœ„ìë£Œ)
â—‹ **ì…ì–‘** (ì…ì–‘ ì ˆì°¨, ì¹œì–‘ì ì…ì–‘)
â—‹ **ê¸°íƒ€**

## ğŸ“‹ ì£¼ìš” ê°€ì¡±ë²• ì ˆì°¨

### ì´í˜¼ ì ˆì°¨
1. **í˜‘ì˜ì´í˜¼**: ì´í˜¼ í•©ì˜ì„œ ì‘ì„± í›„ ì´í˜¼ ì‹ ê³ 
2. **ì¬íŒì´í˜¼**: ë²•ì›ì— ì´í˜¼ ì†Œì†¡ ì œê¸°

### ìƒì† ë¬¸ì œ
1. **ìƒì†ì¸ í™•ì¸**: ë²•ì •ìƒì†ì¸, ìœ ì–¸ìƒì†ì¸ í™•ì¸
2. **ìƒì†ë¶„ ê²°ì •**: ìƒì†ë¶„ ê³„ì‚°, ë¶„í•  í˜‘ì˜
3. **ìœ ì‚° ë¶„í• **: ìœ ì‚°ëª©ë¡ ì‘ì„±, ìƒì†ì¬ì‚° ë¶„í• 
4. **ìœ ì–¸ì§‘í–‰**: ìœ ì–¸ì§‘í–‰ì ì„ ì„, ìœ ì–¸ ì§‘í–‰

### ì–‘ìœ¡ê¶Œ ë¬¸ì œ
1. **ìë…€ ì–‘ìœ¡ê¶Œ**: ì¹œê¶Œì ê²°ì •, ì–‘ìœ¡ë¹„ ê²°ì •
2. **ì–‘ìœ¡ë¹„ ì§€ê¸‰**: ì–‘ìœ¡ë¹„ ì§€ê¸‰, ë©´ì ‘êµì„­ê¶Œ
3. **ì¹œê¶Œìë³€ê²½**: ì¹œê¶Œì ë³€ê²½ ì‹ ì²­

êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""

        return {
            "response": response,
            "confidence": 0.90,
            "generation_method": "family_law_template",
            "sources": [],
            "query_analysis": query_analysis
        }

    def _generate_statute_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ë²•ë¥  ì¡°ë¬¸ ê´€ë ¨ í…œí”Œë¦¿ ë‹µë³€ ìƒì„±"""
        statute_law = query_analysis.get("statute_law")
        statute_article = query_analysis.get("statute_article")

        response = f"""ğŸ“– **ë²•ë¥  ì¡°ë¬¸ ê´€ë ¨ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!**

{'**' + statute_law + ' ì œ' + statute_article + 'ì¡°**' if statute_law and statute_article else '**í•´ë‹¹ ë²•ë¥  ì¡°ë¬¸**'}ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## ğŸ“‹ ë²•ë¥  ì¡°ë¬¸ í•µì‹¬ ê°€ì´ë“œ

### ì¡°ë¬¸ ê¸°ë³¸ ì •ë³´
1. **ì¡°ë¬¸ ë²ˆí˜¸**: í•´ë‹¹ ì¡°ë¬¸
2. **ì¡°ë¬¸ ë‚´ìš©**: ì¡°ë¬¸ì˜ ë‚´ìš©
3. **ì¡°ë¬¸ í•´ì„**: ë²•ì¡°ë¬¸ì˜ ì˜ë¯¸ í•´ì„
4. **ì¡°ë¬¸ ì ìš©**: ì¡°ë¬¸ì˜ ë‹¤ë¥¸ ì¡°ë¬¸ê³¼ì˜ ê´€ê³„

### í•µì‹¬ í¬ì¸íŠ¸
1. **ë¬¸ì–¸í•´ì„**: ì¡°ë¬¸ì˜ ë¬¸ì–¸ì˜ ì˜ë¯¸ íŒŒì•…
2. **ëª©ì í•´ì„**: ì¡°ë¬¸ì˜ ì…ë²• ëª©ì  ê³ ë ¤
3. **ì²´ê³„í•´ì„**: ë‹¤ë¥¸ ì¡°ë¬¸ë“¤ê³¼ì˜ ê´€ê³„ ê³ ë ¤
4. **íŒë¡€í•´ì„**: ê´€ë ¨ íŒë¡€ì˜ í•´ì„ ë°©ë²•

## âš ï¸ ë²•ë¥  íŒë¡€ ë° í•µì‹¬
- í•´ë‹¹ ì¡°ë¬¸ì˜ ì£¼ìš” íŒë¡€
- ì¡°ë¬¸ì˜ í•µì‹¬ ë‚´ìš©
- ì˜ë¯¸ ìˆëŠ” ì‚¬ë¡€ë“¤

êµ¬ì²´ì ì¸ ë²•ë¥  ì¡°ë¬¸ì´ë‚˜ ê´€ë ¨ íŒë¡€ì— ëŒ€í•´ ë” ìì„¸í•œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""

        return {
            "response": response,
            "confidence": 0.85,
            "generation_method": "statute_template",
            "sources": [],
            "query_analysis": query_analysis
        }

    def _generate_general_template_response(self, message: str, query_analysis: Dict[str, Any], detected_style: ResponseStyle = None) -> Dict[str, Any]:
        """ì¼ë°˜ í…œí”Œë¦¿ ë‹µë³€ ìƒì„±"""
        response = """âš–ï¸ **ë²•ë¥  ê´€ë ¨ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!**

ì–´ë–¤ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì´ í•„ìš”í•˜ì‹ ê°€ìš”?

â—‹ **ë¯¼ì‚¬ë²•** (ê³„ì•½, ì†í•´ë°°ìƒ, ë¶ˆë²•í–‰ìœ„)
â—‹ **í˜•ì‚¬ë²•** (ë²”ì£„, ì²˜ë²Œ, í˜•ëŸ‰)
â—‹ **ê°€ì¡±ë²•** (ì´í˜¼, ìƒì†, ì–‘ìœ¡ê¶Œ)
â—‹ **ìƒë²•** (íšŒì‚¬, ì£¼ì‹, ì´ì‚¬)
â—‹ **ë…¸ë™ë²•** (ê·¼ë¡œ, ì„ê¸ˆ, í•´ê³ )
â—‹ **ë¶€ë™ì‚°ë²•** (ë§¤ë§¤, ì„ëŒ€ì°¨, ë“±ê¸°)
â—‹ **ê¸°íƒ€**

## ğŸ“‹ ë²•ë¥  ì§ˆë¬¸ ê°€ì´ë“œ

### íš¨ê³¼ì ì¸ ì§ˆë¬¸ ì‘ì„± ë°©ë²•
1. **ë²•ë¥  ì¡°ë¬¸ ìƒí™© ì„¤ëª…**: êµ¬ì²´ì ì¸ ìƒí™©, ì‹œê°„, ì¥ì†Œ
2. **ê´€ë ¨ë²•ë ¹ ì°¾ê¸°**: ê³„ì•½ì„œ, íŒë¡€, ë²•ì›íŒê²° ë“±
3. **ì •í™•í•œ ì§ˆë¬¸**: êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì›í•˜ëŠ” ì§ˆë¬¸
4. **ìƒí™©ë³„ ëŒ€ì‘**: ë²•ë¥ ì  ë¬¸ì œì˜ ìƒí™©ë³„ ëŒ€ì‘

### ë²•ë¥  ì •ë³´ í™œìš© íŒ
- **ë²•ë ¹**: ì •í™•í•œ ë²•ë¥  ì¡°ë¬¸ í™•ì¸
- **íŒë¡€**: ê´€ë ¨ íŒë¡€ í•´ì„ ë°©ë²• íŒŒì•…
- **ì‚¬ë¡€**: ë²•ë¥  ì ìš© ì‚¬ë¡€ë“¤ ì°¸ê³ 

êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"""

        return {
            "response": response,
            "confidence": 0.80,
            "generation_method": "general_template",
            "sources": [],
            "query_analysis": query_analysis
        }

    def _generate_recommendations(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []

        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
            memory_usage = analysis_result.get('memory_usage', {})
            if memory_usage.get('usage_percent', 0) > 80:
                recommendations.append({
                    'type': 'warning',
                    'title': 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²½ê³ ',
                    'description': f"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory_usage.get('usage_percent', 0):.1f}%",
                    'action': 'ë©”ëª¨ë¦¬ ì •ë¦¬ ê¶Œì¥',
                    'command': 'service.perform_memory_cleanup()'
                })

            # ì‘ë‹µ ì‹œê°„ ë¶„ì„
            response_time = analysis_result.get('response_time', 0)
            if response_time > 10:
                recommendations.append({
                    'type': 'performance',
                    'title': 'ì‘ë‹µ ì‹œê°„ ê°œì„  í•„ìš”',
                    'description': f"í‰ê·  ì‘ë‹µ ì‹œê°„: {response_time:.2f}ì´ˆ",
                    'action': 'ì„±ëŠ¥ ìµœì í™” ê¶Œì¥',
                    'command': 'service._optimize_performance()'
                })

            # ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ë¶„ì„
            components = analysis_result.get('components', {})
            for comp_name, comp_info in components.items():
                if comp_info.get('status') == 'error':
                    recommendations.append({
                        'type': 'error',
                        'title': f'{comp_name} ì»´í¬ë„ŒíŠ¸ ì˜¤ë¥˜',
                        'description': comp_info.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'),
                        'action': 'ì»´í¬ë„ŒíŠ¸ ì¬ì‹œì‘',
                        'command': f'service._restart_component("{comp_name}")'
                    })

            # ê¸°ë³¸ ì¶”ì²œì‚¬í•­
            if not recommendations:
                recommendations.append({
                    'type': 'info',
                    'title': 'ì‹œìŠ¤í…œ ìƒíƒœ ì–‘í˜¸',
                    'description': 'í˜„ì¬ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                    'action': 'ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ìœ ì§€',
                    'command': 'service._cleanup_components()'
                })

        except Exception as e:
            recommendations.append({
                'type': 'error',
                'title': 'ì¶”ì²œì‚¬í•­ ìƒì„± ì˜¤ë¥˜',
                'description': str(e),
                'action': 'ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”',
                'command': None
            })

        return recommendations

    def _add_fallback_ending(self, response: str) -> str:
        """ë‹µë³€ ë§ˆë¬´ë¦¬ ì¶”ê°€"""
        try:
            # ë¶ˆì™„ì „í•œ ë¬¸ì¥ íŒ¨í„´ ê²€ì‚¬
            incomplete_patterns = [
                r'ë‹¤$', r'ê·¸ë˜ì„œ$', r'ë•Œë¬¸$', r'ìˆìŠµë‹ˆë‹¤$', r'ë©ë‹ˆë‹¤$',
                r'í•´ì•¼ í• $', r'ì „ì²´ì ìœ¼ë¡œ$', r'íŠ¹íˆ$', r'ë˜í•œ$',
                r'[ê°€-í£]+ë©°$', r'[ê°€-í£]+ê³ $', r'[ê°€-í£]+ë©´$'
            ]

            import re
            for pattern in incomplete_patterns:
                if re.search(pattern, response.strip()):
                    # ë¶ˆì™„ì „í•œ ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬
                    if response.strip().endswith('ë‹¤'):
                        return f"{response.strip()} ì´ë ‡ê²Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
                    elif response.strip().endswith(('ê·¸ë˜ì„œ', 'ë•Œë¬¸')):
                        return f"{response.strip()} ë“± ì‚¬í•­ì„ ê³ ë ¤ í•˜ì‹œë©´ í•´ê²°ë°©ë²•ì„ ì°¾ìœ¼ì‹¤ê²ë‹ˆë‹¤."
                    else:
                        return f"{response.strip()} ì´ë ‡ê²Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤."

            # ì •ìƒì  ë§ˆë¬´ë¦¬ê°€ ì—†ëŠ”ì§€ ê²€ì‚¬
            if not response.strip().endswith(('.', '!', '?', 'ë‹ˆë‹¤.', 'ìŠµë‹ˆë‹¤.', 'ìš”.')):
                return f"{response.strip()} ì´ë ‡ê²Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤."

            return response

        except Exception as e:
            self.logger.error(f"ë‹µë³€ ë§ˆë¬´ë¦¬ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return response

    # ìƒˆë¡œìš´ ë²•ë¥  ê²€ìƒ‰ ë° ë‹µë³€ ìµœì í™” ë©”ì„œë“œë“¤

    def _initialize_enhanced_law_search(self):
        """í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”"""
        try:
            # ëª¨ë“  í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œì„ Noneìœ¼ë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
            self.precedent_service = None
            self.enhanced_law_search_engine = None
            self.integrated_law_search = None
            self.adaptive_response_manager = None
            self.progressive_response_system = None

            # ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ íŒ¨í„´ (ê¸°ë³¸ íŒ¨í„´ë§Œ ìœ ì§€)
            self.law_query_patterns = [
                r'(\w+ë²•)\s*ì œ\s*(\d+)ì¡°',
                r'ì œ\s*(\d+)ì¡°',
                r'(\w+ë²•)\s*(\d+)ì¡°',
                r'(\w+ë²•)\s*ì œ\s*(\d+)ì¡°\s*ì œ\s*(\d+)í•­'
            ]

            self.logger.info("í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ëª¨ë“  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”)")

        except Exception as e:
            self.logger.error(f"í–¥ìƒëœ ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.precedent_service = None
            self.enhanced_law_search_engine = None
            self.integrated_law_search = None
            self.adaptive_response_manager = None
            self.progressive_response_system = None

    def _initialize_langgraph_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ” _initialize_langgraph_workflow ë©”ì„œë“œ í˜¸ì¶œë¨")
        self.logger.info("=" * 70)
        self.logger.info("ğŸ” LangGraph ì´ˆê¸°í™” ì§„ë‹¨ ì‹œì‘")
        self.logger.info("=" * 70)

        try:
            self.logger.info("ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
            self.logger.info("ğŸ“ ë‹¨ê³„ 1: ê¸°ë³¸ LangGraph ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸")

            # ë¨¼ì € ê¸°ë³¸ LangGraph ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸ (ê°•í™”ëœ ë°©ì‹)
            try:
                # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ import ì‹œë„
                import os
                import sys

                # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
                current_dir = os.path.dirname(os.path.abspath(__file__))
                if current_dir not in sys.path:
                    sys.path.insert(0, current_dir)

                # LangGraph import ì‹œë„
                self.logger.info("   â†’ langgraph.graphì—ì„œ END, StateGraph import ì‹œë„...")
                from langgraph.graph import END, StateGraph
                self.logger.info("âœ… ê¸°ë³¸ LangGraph ëª¨ë“ˆ import ì„±ê³µ")
                self.logger.info(f"   â†’ StateGraph í´ë˜ìŠ¤: {StateGraph}")
                self.logger.info(f"   â†’ END ìƒìˆ˜: {END}")

                # langgraph ë²„ì „ í™•ì¸
                try:
                    import langgraph
                    version = getattr(langgraph, '__version__', 'unknown')
                    self.logger.info(f"   â†’ langgraph ë²„ì „: {version}")
                except Exception as e:
                    self.logger.debug(f"ë²„ì „ í™•ì¸ ì‹¤íŒ¨: {e}")

            except ImportError as e:
                self.logger.error(f"âŒ ê¸°ë³¸ LangGraph ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
                self.logger.error(f"Python ê²½ë¡œ: {sys.path[:3]}...")  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                self.logger.error(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")

                # ì¶”ê°€ ë””ë²„ê¹… ì •ë³´
                try:
                    import langgraph
                    self.logger.error(f"langgraph ëª¨ë“ˆì€ ì¡´ì¬: {langgraph}")
                    self.logger.error(f"langgraph ê²½ë¡œ: {getattr(langgraph, '__path__', 'No path')}")
                except Exception as debug_e:
                    self.logger.error(f"langgraph ëª¨ë“ˆë„ ì—†ìŒ: {debug_e}")

                self.langgraph_service = None
                self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
                return

            # í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
            self.logger.info("ğŸ“ ë‹¨ê³„ 2: í”„ë¡œì íŠ¸ LangGraph ëª¨ë“ˆ import")
            try:
                self.logger.info("   â†’ langgraph_config import ì‹œë„...")
                from ...utils.langgraph_config import langgraph_config
                self.logger.info("   â†’ langgraph_config import ì„±ê³µ")

                self.logger.info("   â†’ IntegratedWorkflowService import ì‹œë„...")
                from ..langgraph_workflow.integrated_workflow_service import (
                    IntegratedWorkflowService,
                )
                self.logger.info("âœ… í”„ë¡œì íŠ¸ LangGraph ëª¨ë“ˆ import ì„±ê³µ")
            except ImportError as e:
                self.logger.error(f"âŒ í”„ë¡œì íŠ¸ LangGraph ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
                self.langgraph_service = None
                self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
                return

            # ì„¤ì • ê²€ì¦
            self.logger.info("ğŸ“ ë‹¨ê³„ 3: LangGraph ì„¤ì • ê²€ì¦")
            config_errors = langgraph_config.validate()
            if config_errors:
                self.logger.warning(f"âš ï¸ LangGraph ì„¤ì • ì˜¤ë¥˜: {config_errors}")
            else:
                self.logger.info("âœ… ì„¤ì • ê²€ì¦ í†µê³¼")

            # LangGraph í™œì„±í™” ì—¬ë¶€ í™•ì¸
            self.logger.info(f"   â†’ langgraph_enabled: {langgraph_config.langgraph_enabled}")
            if not langgraph_config.langgraph_enabled:
                self.logger.warning("âš ï¸ LangGraphê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                self.langgraph_service = None
                self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
                return

            self.logger.info(f"ğŸ“‹ LangGraph ì„¤ì •: {langgraph_config.to_dict()}")

            # ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            self.logger.info("ğŸ“ ë‹¨ê³„ 4: IntegratedWorkflowService ì´ˆê¸°í™”")
            try:
                self.logger.info("   â†’ IntegratedWorkflowService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
                self.langgraph_service = IntegratedWorkflowService(langgraph_config)
                self.logger.info("ğŸ‰ LangGraph ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
                self.logger.info(f"   â†’ LangGraph ì„œë¹„ìŠ¤ íƒ€ì…: {type(self.langgraph_service).__name__}")
                self.logger.info(f"   â†’ process_query ë©”ì„œë“œ ì¡´ì¬: {hasattr(self.langgraph_service, 'process_query')}")
                self.use_langgraph = True  # LangGraph ì •ìƒ ì´ˆê¸°í™”ë¨
            except Exception as init_e:
                self.logger.error(f"âŒ IntegratedWorkflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {init_e}")
                import traceback
                self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                self.langgraph_service = None
                self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
                return

        except ImportError as e:
            self.logger.error(f"âŒ LangGraph ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
            self.logger.error("LangGraph ê´€ë ¨ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install langgraph langchain-core langchain-community")
            self.langgraph_service = None
            self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •
        except Exception as e:
            self.logger.error(f"âŒ LangGraph ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.logger.error(f"ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            self.langgraph_service = None
            self.use_langgraph = False  # LangGraph ì‚¬ìš© ë¶ˆê°€ë¡œ ì„¤ì •

    def _initialize_intelligent_style_system(self):
        """ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬"""
        try:
            # self.intelligent_style_system = IntelligentResponseStyleSystem()
            self.intelligent_style_system = None  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ None ì„¤ì •
            self.logger.info("ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
        except Exception as e:
            self.logger.error(f"ì§€ëŠ¥í˜• ì‘ë‹µ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.intelligent_style_system = None

    def _is_law_article_query(self, query: str) -> bool:
        """ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        try:
            import re
            for pattern in self.law_query_patterns:
                if re.search(pattern, query):
                    return True
            return False
        except Exception as e:
            self.logger.error(f"ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    async def _handle_law_article_query(self, message: str, user_id: str, session_id: str) -> Dict[str, Any]:
        """ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬"""
        start_time = time.time()

        try:
            # ğŸ†• current_law_search_engine ì‚¬ìš© (ì ê·¹ì  í™œìš©)
            if self.current_law_search_engine:
                # ë²•ë¥  ì¡°ë¬¸ ì¶”ì¶œ
                article_info = self._extract_law_article_from_query(message)

                if article_info and article_info.get('law_name') and article_info.get('article_number'):
                    self.logger.info(f"ğŸ” íŠ¹ì • ì¡°ë¬¸ ê²€ìƒ‰: {article_info['law_name']} ì œ{article_info['article_number']}ì¡°")

                    # ì¡°ë¬¸ ê²€ìƒ‰
                    search_result = self.current_law_search_engine.search_by_law_article(
                        article_info['law_name'],
                        article_info['article_number']
                    )

                    if search_result and search_result.article_content:
                        return {
                            'response': search_result.article_content,
                            'confidence': 0.95,
                            'sources': [{
                                'content': search_result.article_content,
                                'law_name': search_result.law_name_korean,
                                'article_number': article_info['article_number'],
                                'similarity': 1.0,
                                'source': 'current_law'
                            }],
                            'processing_time': time.time() - start_time,
                            'generation_method': 'law_article',
                            'session_id': session_id,
                            'user_id': user_id
                        }

            # í´ë°±: integrated_law_search ì‚¬ìš©
            if self.integrated_law_search:
                # ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ ì‹¤í–‰
                search_result = await self.integrated_law_search.search_law_article(message)

            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            user_context = await self._analyze_user_context(user_id, session_id)

            # ì ì‘í˜• ë‹µë³€ ê¸¸ì´ ì¡°ì • (ë²•ë¥  í•´ì„ ì œì™¸)
            if self.adaptive_response_manager and "ë²•ë¥  í•´ì„:" not in search_result.response:
                optimized_response = self.adaptive_response_manager.adapt_response_length(
                    search_result.response, user_context
                )
            else:
                optimized_response = search_result.response

            # ë‹¨ê³„ë³„ ë‹µë³€ ìƒì„± (ë²•ë¥  í•´ì„ ì œì™¸)
            if self.progressive_response_system and "ë²•ë¥  í•´ì„:" not in optimized_response:
                progressive_response = self.progressive_response_system.generate_progressive_response(
                    optimized_response, user_context.get('response_level', 'standard')
                )
                final_response = progressive_response.response
                additional_options = progressive_response.additional_options
            else:
                final_response = optimized_response
                additional_options = []

            return {
                'response': final_response,
                'confidence': search_result.confidence,
                'sources': search_result.sources,
                'processing_time': time.time() - start_time,
                'generation_method': 'integrated_law_search',
                'restricted': False,
                'context_info': search_result.context_info,
                'additional_options': additional_options,
                'has_more_detail': len(search_result.response) > len(final_response)
            }

        except Exception as e:
            self.logger.error(f"ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return await self._fallback_response(message)

    async def _analyze_user_context(self, user_id: str, session_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            context = {
                'user_id': user_id,
                'session_id': session_id,
                'expertise_level': 'beginner',
                'response_level': 'standard',
                'device_info': {'type': 'desktop'},
                'preferred_length': 1000
            }

            # ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if hasattr(self, 'user_preferences') and self.user_preferences:
                try:
                    user_profile = self.user_preferences.get_user_profile(user_id)
                    if user_profile:
                        context.update({
                            'expertise_level': user_profile.get('expertise_level', 'beginner'),
                            'response_level': user_profile.get('preferred_detail_level', 'standard'),
                            'device_info': user_profile.get('device_info', {'type': 'desktop'}),
                            'preferred_length': self._get_preferred_length(user_profile)
                        })
                except Exception as e:
                    self.logger.debug(f"ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

            return context

        except Exception as e:
            self.logger.error(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'user_id': user_id,
                'session_id': session_id,
                'expertise_level': 'beginner',
                'response_level': 'standard',
                'device_info': {'type': 'desktop'},
                'preferred_length': 1000
            }

    def _get_preferred_length(self, user_profile: Dict[str, Any]) -> int:
        """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ ì„ í˜¸ ê¸¸ì´ ê³„ì‚°"""
        try:
            expertise_level = user_profile.get('expertise_level', 'beginner')
            detail_level = user_profile.get('preferred_detail_level', 'medium')
            device_type = user_profile.get('device_info', {}).get('type', 'desktop')

            # ê¸°ë³¸ ê¸¸ì´ ì„¤ì • (ì¶”ê°€ ìµœì í™” - ë” ê¸´ ë‹µë³€ ì œê³µ)
            base_lengths = {
                'mobile': 800,   # ëª¨ë°”ì¼ì—ì„œ ë” ê¸´ ë‹µë³€ ì œê³µ
                'desktop': 2000, # ë°ìŠ¤í¬í†±ì—ì„œ ë” ê¸´ ë‹µë³€ ì œê³µ
                'tablet': 1200   # íƒœë¸”ë¦¿ì—ì„œ ë” ê¸´ ë‹µë³€ ì œê³µ
            }

            base_length = base_lengths.get(device_type, 2000)

            # ì „ë¬¸ì„± ìˆ˜ì¤€ì— ë”°ë¥¸ ë°°ìœ¨
            expertise_multipliers = {
                'beginner': 0.8,
                'intermediate': 1.0,
                'expert': 1.2,
                'professional': 1.3
            }

            multiplier = expertise_multipliers.get(expertise_level, 1.0)

            # ìƒì„¸ë„ì— ë”°ë¥¸ ë°°ìœ¨
            detail_multipliers = {
                'low': 0.7,
                'medium': 1.0,
                'high': 1.3
            }

            detail_multiplier = detail_multipliers.get(detail_level, 1.0)

            return int(base_length * multiplier * detail_multiplier)

        except Exception as e:
            self.logger.error(f"ì„ í˜¸ ê¸¸ì´ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1500  # ê¸°ë³¸ ê¸¸ì´ë¥¼ 1000ì—ì„œ 1500ìœ¼ë¡œ ì¦ê°€

    async def get_expanded_response(self, base_response: str, option_type: str, user_id: str = None) -> str:
        """í™•ì¥ëœ ë‹µë³€ ìƒì„±"""
        try:
            if not self.progressive_response_system:
                return base_response

            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            user_context = await self._analyze_user_context(user_id, None)

            # í™•ì¥ëœ ë‹µë³€ ìƒì„±
            expanded_response = self.progressive_response_system.generate_expanded_response(
                base_response, option_type, base_response
            )

            # ì ì‘í˜• ê¸¸ì´ ì¡°ì •
            if self.adaptive_response_manager:
                optimized_response = self.adaptive_response_manager.adapt_response_length(
                    expanded_response, user_context
                )
                return optimized_response

            return expanded_response

        except Exception as e:
            self.logger.error(f"í™•ì¥ëœ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return base_response

    async def _fallback_response(self, message: str) -> Dict[str, Any]:
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        return {
            'response': f"ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?",
            'confidence': 0.1,
            'sources': [],
            'processing_time': 0.0,
            'generation_method': 'fallback',
            'restricted': False,
            'session_id': '',
            'user_id': ''
        }

    def get_hybrid_classifier_stats(self) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° í†µê³„ ë°˜í™˜"""
        if self.hybrid_classifier:
            return self.hybrid_classifier.get_stats()
        return {"error": "í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"}

    def adjust_classifier_threshold(self, new_threshold: float):
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì„ê³„ê°’ ì¡°ì •"""
        if self.hybrid_classifier:
            self.hybrid_classifier.adjust_threshold(new_threshold)
            self.logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì„ê³„ê°’ ì¡°ì •: {new_threshold}")
        else:
            self.logger.warning("í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")

    def train_hybrid_classifier(self, training_data: List[Tuple[str, str]]):
        """í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ML ëª¨ë¸ í•™ìŠµ"""
        if not self.hybrid_classifier:
            self.logger.error("í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return False

        try:
            # ë¬¸ìì—´ì„ UnifiedQuestionTypeìœ¼ë¡œ ë³€í™˜
            from .unified_question_types import UnifiedQuestionType
            converted_data = []
            for question, question_type_str in training_data:
                question_type = UnifiedQuestionType.from_string(question_type_str)
                converted_data.append((question, question_type))

            # ML ëª¨ë¸ í•™ìŠµ
            self.hybrid_classifier.train_ml_model(converted_data)
            self.logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ML ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {len(training_data)}ê°œ ë°ì´í„°")
            return True

        except Exception as e:
            self.logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False

    def _extract_law_article_from_query(self, message: str) -> Dict[str, Any]:
        """ë©”ì‹œì§€ì—ì„œ ë²•ë¥  ì¡°ë¬¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            import re

            # í™•ì¥ëœ ë²•ë¥  ì¡°ë¬¸ íŒ¨í„´
            statute_patterns = {
                'standard': r'([\wê°€-í£]+ë²•)\s*ì œ\s*(\d+)\s*ì¡°',  # ë¯¼ë²• ì œ750ì¡°
                'compact': r'([\wê°€-í£]+ë²•)ì œ(\d+)ì¡°',           # ë¯¼ë²•ì œ750ì¡°
                'with_clause': r'([\wê°€-í£]+ë²•)\s*ì œ\s*(\d+)\s*ì¡°\s*ì œ\s*(\d+)\s*í•­',  # ë¯¼ë²• ì œ750ì¡° ì œ1í•­
                'simple': r'ì œ\s*(\d+)\s*ì¡°',                      # ì œ750ì¡°
                'number_only': r'(\d+)\s*ì¡°'                       # 750ì¡°
            }

            for pattern_name, pattern in statute_patterns.items():
                match = re.search(pattern, message)
                if match:
                    groups = match.groups()

                    if pattern_name == 'with_clause' and len(groups) == 3:
                        return {
                            'law_name': groups[0],
                            'article_number': groups[1],
                            'clause_number': groups[2],
                            'pattern_type': pattern_name,
                            'full_match': match.group(0)
                        }
                    elif len(groups) == 2:
                        return {
                            'law_name': groups[0],
                            'article_number': groups[1],
                            'clause_number': None,
                            'pattern_type': pattern_name,
                            'full_match': match.group(0)
                        }
                    elif len(groups) == 1:
                        return {
                            'law_name': None,
                            'article_number': groups[0],
                            'clause_number': None,
                            'pattern_type': pattern_name,
                            'full_match': match.group(0)
                        }

            return None

        except Exception as e:
            self.logger.error(f"Error extracting law article: {e}")
            return None
