# -*- coding: utf-8 -*-
"""
Integrated Law Search Service
í†µí•© ì¡°ë¬¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤
"""

import logging
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from .enhanced_law_search_engine import EnhancedLawSearchEngine, ArticleSearchResult
from .law_context_search_engine import LawContextSearchEngine, RelatedArticle, LawDefinition

logger = logging.getLogger(__name__)


@dataclass
class IntegratedSearchResult:
    """í†µí•© ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ëž˜ìŠ¤"""
    response: str
    confidence: float
    sources: List[Dict[str, Any]]
    search_method: str
    context_info: Dict[str, Any]
    processing_time: float


class IntegratedLawSearchService:
    """í†µí•© ì¡°ë¬¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        from ..data.database import DatabaseManager
        from ..data.vector_store import LegalVectorStore
        
        self.db_manager = DatabaseManager()
        self.vector_store = LegalVectorStore()
        
        # íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.precedent_service = None
        self.hybrid_precedent_service = None
        
        try:
            from .dynamic_precedent_search_service import DynamicPrecedentSearchService
            from .precedent_api_service import PrecedentAPIService
            from .hybrid_precedent_search_service import HybridPrecedentSearchService
            
            # ë™ì  íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            self.precedent_service = DynamicPrecedentSearchService(self.db_manager)
            
            # API íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            precedent_api_service = PrecedentAPIService()
            
            # í•˜ì´ë¸Œë¦¬ë“œ íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            self.hybrid_precedent_service = HybridPrecedentSearchService(
                self.precedent_service, precedent_api_service
            )
            
            self.logger.info("í•˜ì´ë¸Œë¦¬ë“œ íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"í•˜ì´ë¸Œë¦¬ë“œ íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.precedent_service = None
            self.hybrid_precedent_service = None
        
        # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ íŒë¡€ ì„œë¹„ìŠ¤ í¬í•¨)
        self.law_search_engine = EnhancedLawSearchEngine(
            self.db_manager, 
            self.vector_store,
            precedent_service=self.precedent_service,
            hybrid_precedent_service=self.hybrid_precedent_service
        )
        self.context_search_engine = LawContextSearchEngine(self.db_manager, self.vector_store)
        
        # ê²€ìƒ‰ ì „ëžµ ì„¤ì •
        self.search_strategies = {
            'exact_match': self._exact_match_search,
            'fuzzy_match': self._fuzzy_match_search,
            'semantic_search': self._semantic_search,
            'hybrid_search': self._hybrid_search
        }
        
        # ì‹ ë¢°ë„ ìž„ê³„ê°’ ì„¤ì •
        self.confidence_thresholds = {
            'exact_match': 0.95,
            'fuzzy_match': 0.85,
            'semantic_search': 0.75,
            'hybrid_search': 0.70
        }
        
        self.logger.info("Integrated Law Search Service ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def search_law_article(self, query: str, strategy: str = 'hybrid') -> IntegratedSearchResult:
        """í†µí•© ì¡°ë¬¸ ê²€ìƒ‰"""
        start_time = time.time()
        
        try:
            # 1. ê²€ìƒ‰ ì „ëžµ ì„ íƒ
            search_func = self.search_strategies.get(strategy, self._hybrid_search)
            
            # 2. ì¡°ë¬¸ ê²€ìƒ‰ ì‹¤í–‰
            search_result = await search_func(query)
            
            if not search_result:
                return IntegratedSearchResult(
                    response=f"'{query}'ì— ëŒ€í•œ ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ìŒê³¼ ê°™ì´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤:\nâ€¢ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”\nâ€¢ ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ì´ë‚˜ íŒë¡€ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”\nâ€¢ í‚¤ì›Œë“œë¥¼ ë” ëª…í™•í•˜ê²Œ í•´ì£¼ì„¸ìš”",
                    confidence=0.0,
                    sources=[],
                    search_method=strategy,
                    context_info={},
                    processing_time=time.time() - start_time
                )
            
            # 3. ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            context_info = await self._add_context_info(search_result)
            
            # 4. ì‘ë‹µ ìƒì„±
            response = await self._generate_enhanced_response(search_result, context_info)
            
            # 5. ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(search_result, strategy)
            
            return IntegratedSearchResult(
                response=response,
                confidence=confidence,
                sources=[self._convert_to_dict(search_result)],
                search_method=strategy,
                context_info=context_info,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            self.logger.error(f"Integrated law search failed: {e}")
            return IntegratedSearchResult(
                response=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                confidence=0.0,
                sources=[],
                search_method=strategy,
                context_info={},
                processing_time=time.time() - start_time
            )
    
    async def _exact_match_search(self, query: str) -> Optional[ArticleSearchResult]:
        """ì •í™• ë§¤ì¹­ ê²€ìƒ‰"""
        return await self.law_search_engine.search_specific_article(query)
    
    async def _fuzzy_match_search(self, query: str) -> Optional[ArticleSearchResult]:
        """í¼ì§€ ë§¤ì¹­ ê²€ìƒ‰ (FTS í™œìš©)"""
        try:
            # 1. í˜„í–‰ë²•ë ¹ ì¡°ë¬¸ FTS ê²€ìƒ‰ (ìš°ì„ ìˆœìœ„)
            try:
                current_laws_fts_results = self.db_manager.search_current_laws_articles_fts(query, limit=5)
                if current_laws_fts_results:
                    best_result = current_laws_fts_results[0]
                    
                    # ì¡°ë¬¸ ë‚´ìš© êµ¬ì„±
                    content_parts = [best_result['article_content']]
                    if best_result.get('paragraph_content'):
                        content_parts.append(f"í•­: {best_result['paragraph_content']}")
                    if best_result.get('sub_paragraph_content'):
                        content_parts.append(f"í˜¸: {best_result['sub_paragraph_content']}")
                    
                    return ArticleSearchResult(
                        content="\n".join(content_parts),
                        law_name=best_result['law_name_korean'],
                        article_number=str(best_result['article_number']),
                        article_title=best_result.get('article_title', ''),
                        similarity=0.9,  # FTS ê²°ê³¼ëŠ” ë†’ì€ ì‹ ë¢°ë„
                        source='current_laws_fts_search',
                        type='current_law',
                        metadata={
                            'law_id': best_result['law_id'],
                            'article_id': best_result['article_id'],
                            'quality_score': best_result.get('quality_score', 0.9),
                            'ministry_name': best_result.get('ministry_name', ''),
                            'parsing_method': best_result.get('parsing_method', 'batch_parser')
                        }
                    )
            except Exception as e:
                self.logger.warning(f"í˜„í–‰ë²•ë ¹ ì¡°ë¬¸ FTS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            
            # 2. Assembly ì¡°ë¬¸ FTS ê²€ìƒ‰ (í´ë°±)
            fts_results = self.db_manager.search_current_laws_articles_fts(query, limit=5)
            
            if fts_results:
                # ê°€ìž¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ ì„ íƒ
                best_result = fts_results[0]
                return ArticleSearchResult(
                    content=best_result['article_content'],
                    law_name=best_result['law_name'],
                    article_number=str(best_result['article_number']),
                    article_title=best_result.get('article_title', ''),
                    similarity=0.9,  # FTS ê²°ê³¼ëŠ” ë†’ì€ ì‹ ë¢°ë„
                    source='assembly_fts_search',
                    type='current_law',
                    metadata={
                        'law_id': best_result['law_id'],
                        'article_id': best_result['article_id'],
                        'parsing_quality_score': best_result.get('parsing_quality_score', 0.0)
                    }
                )
            
            return None
            
        except Exception as e:
            self.logger.error(f"Fuzzy match search failed: {e}")
            return None
    
    async def _semantic_search(self, query: str) -> Optional[ArticleSearchResult]:
        """ì˜ë¯¸ì  ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰)"""
        try:
            vector_results = self.vector_store.search(query, top_k=3)
            
            if vector_results:
                best_result = vector_results[0]
                metadata = best_result.get('metadata', {})
                
                return ArticleSearchResult(
                    content=best_result['content'],
                    law_name=metadata.get('law_name', ''),
                    article_number=str(metadata.get('article_number', '')),
                    article_title=metadata.get('article_title', ''),
                    similarity=best_result.get('similarity', 0.7),
                    source='semantic_search',
                    type='current_law',
                    metadata=metadata
                )
            
            return None
            
        except Exception as e:
            self.logger.error(f"Semantic search failed: {e}")
            return None
    
    async def _hybrid_search(self, query: str) -> Optional[ArticleSearchResult]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì •í™•ë„ + ì˜ë¯¸ì  ê²€ìƒ‰)"""
        try:
            # 1. ì •í™• ë§¤ì¹­ ì‹œë„
            exact_result = await self._exact_match_search(query)
            if exact_result and exact_result.similarity >= 0.9:
                return exact_result
            
            # 2. í¼ì§€ ë§¤ì¹­ ì‹œë„
            fuzzy_result = await self._fuzzy_match_search(query)
            if fuzzy_result and fuzzy_result.similarity >= 0.8:
                return fuzzy_result
            
            # 3. ì˜ë¯¸ì  ê²€ìƒ‰ ì‹œë„
            semantic_result = await self._semantic_search(query)
            if semantic_result and semantic_result.similarity >= 0.7:
                return semantic_result
            
            return None
            
        except Exception as e:
            self.logger.error(f"Hybrid search failed: {e}")
            return None
    
    async def _add_context_info(self, search_result: ArticleSearchResult) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€"""
        try:
            law_name = search_result.law_name
            article_number = search_result.article_number
            
            context_info = {}
            
            # ë²•ë ¹ ê¸°ë³¸ ì •ë³´
            if law_name:
                law_definition = await self.context_search_engine.search_law_definition(law_name)
                if law_definition:
                    context_info['law_definition'] = {
                        'law_name': law_definition.law_name,
                        'law_type': law_definition.law_type,
                        'ministry': law_definition.ministry,
                        'summary': law_definition.summary,
                        'keywords': law_definition.keywords,
                        'main_article_count': law_definition.main_article_count,
                        'supplementary_article_count': law_definition.supplementary_article_count
                    }
            
            # ê´€ë ¨ ì¡°ë¬¸
            if law_name and article_number.isdigit():
                try:
                    article_num = int(article_number)
                    related_articles = await self.context_search_engine.search_related_articles(
                        law_name, article_num, context_range=2
                    )
                    context_info['related_articles'] = [
                        {
                            'article_number': article.article_number,
                            'article_title': article.article_title,
                            'is_target': article.is_target,
                            'distance': article.distance
                        }
                        for article in related_articles
                    ]
                except ValueError:
                    pass
            
            # ìœ ì‚¬í•œ ë²•ë ¹
            if law_name:
                similar_laws = await self.context_search_engine.search_similar_laws(law_name, top_k=3)
                context_info['similar_laws'] = similar_laws
            
            return context_info
            
        except Exception as e:
            self.logger.error(f"Context info addition failed: {e}")
            return {}
    
    async def _generate_enhanced_response(self, search_result: ArticleSearchResult, context_info: Dict[str, Any]) -> str:
        """í–¥ìƒëœ ì‘ë‹µ ìƒì„± - ì¤‘ë³µ ì œê±° ë° ë™ì  í•´ì„ í™œìš©"""
        try:
            # EnhancedLawSearchEngineì˜ _format_article_responseë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
            if hasattr(self.law_search_engine, '_format_article_response'):
                # ArticleSearchResultë¥¼ Dict í˜•íƒœë¡œ ë³€í™˜
                result_dict = {
                    'law_name_korean': search_result.law_name,
                    'article_number': search_result.article_number,
                    'article_title': getattr(search_result, 'article_title', ''),
                    'article_content': search_result.content,
                    'paragraph_content': getattr(search_result, 'paragraph_content', ''),
                    'sub_paragraph_content': getattr(search_result, 'sub_paragraph_content', ''),
                    'effective_date': getattr(search_result, 'effective_date', ''),
                    'ministry_name': getattr(search_result, 'ministry_name', '')
                }
                
                # EnhancedLawSearchEngineì˜ í¬ë§·íŒ… ë©”ì„œë“œ ì‚¬ìš©
                formatted_response = await self.law_search_engine._format_article_response(result_dict)
                self.logger.info(f"Using EnhancedLawSearchEngine formatting, length: {len(formatted_response)}")
                return formatted_response
            
            # ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ í¬ë§·íŒ… ì ìš©
            law_name = search_result.law_name
            article_number = search_result.article_number
            content = search_result.content
            
            response_parts = []
            
            # 1. ì¡°ë¬¸ ì œëª©
            if law_name and article_number:
                response_parts.append(f"**{law_name} ì œ{article_number}ì¡°**")
                if search_result.article_title:
                    response_parts.append(f" ({search_result.article_title})")
            
            # 2. ì¡°ë¬¸ ë‚´ìš©
            if content:
                response_parts.append(f"\n{content}")
            
            # 3. ë²•ë ¹ ê¸°ë³¸ ì •ë³´
            if 'law_definition' in context_info:
                law_def = context_info['law_definition']
                if law_def.get('summary'):
                    response_parts.append(f"\n**ë²•ë ¹ ê°œìš”:** {law_def['summary']}")
                
                if law_def.get('ministry'):
                    response_parts.append(f"**ì†Œê´€ë¶€ì²˜:** {law_def['ministry']}")
            
            # 4. ê´€ë ¨ ì¡°ë¬¸
            if 'related_articles' in context_info:
                related = context_info['related_articles']
                if len(related) > 1:
                    response_parts.append("\n**ê´€ë ¨ ì¡°ë¬¸:**")
                    for article in related[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                        if not article['is_target']:
                            title_text = f" - {article['article_title']}" if article['article_title'] else ""
                            response_parts.append(f"- ì œ{article['article_number']}ì¡°{title_text}")
            
            # 5. ìœ ì‚¬í•œ ë²•ë ¹
            if 'similar_laws' in context_info:
                similar = context_info['similar_laws']
                if similar:
                    response_parts.append("\n**ê´€ë ¨ ë²•ë ¹:**")
                    for law in similar[:2]:  # ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ
                        response_parts.append(f"- {law['law_name']} (ìœ ì‚¬ë„: {law['similarity']:.2f})")
            
            # 6. ê²€ìƒ‰ ë°©ë²• ì •ë³´
            method_info = {
                'exact_article': 'ì •í™•í•œ ì¡°ë¬¸ ê²€ìƒ‰',
                'fts_search': 'ì „ë¬¸ ê²€ìƒ‰',
                'semantic_search': 'ì˜ë¯¸ì  ê²€ìƒ‰',
                'similar_article': 'ìœ ì‚¬ ì¡°ë¬¸ ê²€ìƒ‰'
            }
            
            method_text = method_info.get(search_result.source, 'í†µí•© ê²€ìƒ‰')
            response_parts.append(f"*({method_text} ê²°ê³¼)*")
            
            # 7. ì¡°ë¬¸ í•´ì„ ì¶”ê°€ (ìƒˆë¡œ ì¶”ê°€)
            interpretation = await self._generate_article_interpretation(search_result)
            if interpretation:
                response_parts.append(f"\n## ðŸ“– ì¡°ë¬¸ í•´ì„\n{interpretation}")
            
            # 8. êµ¬ì„±ìš”ê±´ ë¶„ì„ ì¶”ê°€ (ìƒˆë¡œ ì¶”ê°€)
            elements = await self._analyze_legal_elements(search_result)
            if elements:
                response_parts.append(f"\n## âš–ï¸ êµ¬ì„±ìš”ê±´ ë¶„ì„\n{elements}")
            
            # 9. ê´€ë ¨ íŒë¡€ ì¶”ê°€ (ìƒˆë¡œ ì¶”ê°€)
            precedents = await self._get_related_precedents(search_result)
            if precedents:
                response_parts.append(f"\n## ðŸ“š ê´€ë ¨ íŒë¡€\n{precedents}")
            
            return "\n\n".join(response_parts)
            
        except Exception as e:
            self.logger.error(f"Enhanced response generation failed: {e}")
            return search_result.content
    
    async def _generate_article_interpretation(self, search_result: ArticleSearchResult) -> str:
        """ì¡°ë¬¸ í•´ì„ ìƒì„±"""
        try:
            law_name = search_result.law_name
            article_number = search_result.article_number
            content = search_result.content
            
            if not content:
                return ""
            
            # ê¸°ë³¸ í•´ì„ í…œí”Œë¦¿
            interpretation_parts = []
            
            # ì¡°ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…
            if "ê³ ì˜" in content or "ê³¼ì‹¤" in content:
                interpretation_parts.append("â€¢ **ì£¼ê´€ì  ìš”ê±´**: ê³ ì˜ ë˜ëŠ” ê³¼ì‹¤ì´ ìžˆì–´ì•¼ í•¨")
            
            if "ì†í•´" in content or "ë°°ìƒ" in content:
                interpretation_parts.append("â€¢ **ì†í•´ ë°œìƒ**: ì‹¤ì œ ì†í•´ê°€ ë°œìƒí•´ì•¼ í•¨")
            
            if "ìœ„ë²•" in content or "ìœ„ë²•í–‰ìœ„" in content:
                interpretation_parts.append("â€¢ **ìœ„ë²•ì„±**: ìœ„ë²•í•œ í–‰ìœ„ì—¬ì•¼ í•¨")
            
            if "ì¸ê³¼ê´€ê³„" in content or "ì¸ê³¼" in content:
                interpretation_parts.append("â€¢ **ì¸ê³¼ê´€ê³„**: í–‰ìœ„ì™€ ì†í•´ ì‚¬ì´ì— ì¸ê³¼ê´€ê³„ê°€ ìžˆì–´ì•¼ í•¨")
            
            # ë²•ë¥ ë³„ íŠ¹í™” í•´ì„
            if law_name == "ë¯¼ë²•":
                if article_number == "750":
                    interpretation_parts.append("â€¢ **ë¶ˆë²•í–‰ìœ„ì˜ ì¼ë°˜ì¡°í•­**: ë¯¼ë²•ìƒ ë¶ˆë²•í–‰ìœ„ì˜ ê¸°ë³¸ ìš”ê±´ì„ ê·œì •")
                    interpretation_parts.append("â€¢ **ì†í•´ë°°ìƒì˜ ê·¼ê±°**: ê³ ì˜Â·ê³¼ì‹¤ë¡œ ì¸í•œ ìœ„ë²•í–‰ìœ„ë¡œ íƒ€ì¸ì—ê²Œ ì†í•´ë¥¼ ê°€í•œ ê²½ìš° ë°°ìƒì±…ìž„ ë°œìƒ")
            
            return "\n".join(interpretation_parts) if interpretation_parts else ""
            
        except Exception as e:
            self.logger.error(f"Article interpretation generation failed: {e}")
            return ""
    
    async def _analyze_legal_elements(self, search_result: ArticleSearchResult) -> str:
        """ë²•ì  êµ¬ì„±ìš”ê±´ ë¶„ì„"""
        try:
            content = search_result.content
            if not content:
                return ""
            
            elements = []
            
            # êµ¬ì„±ìš”ê±´ ì¶”ì¶œ
            if "ê³ ì˜" in content:
                elements.append("**ê³ ì˜**: í–‰ìœ„ìžê°€ ê²°ê³¼ ë°œìƒì„ ì¸ì‹í•˜ê³  ìš©ì¸í•˜ëŠ” ì‹¬ë¦¬ìƒíƒœ")
            
            if "ê³¼ì‹¤" in content:
                elements.append("**ê³¼ì‹¤**: ì£¼ì˜ì˜ë¬´ë¥¼ ìœ„ë°˜í•œ ì‹¬ë¦¬ìƒíƒœ")
            
            if "ì†í•´" in content:
                elements.append("**ì†í•´**: ìž¬ì‚°ì Â·ì •ì‹ ì  í”¼í•´")
            
            if "ìœ„ë²•í–‰ìœ„" in content:
                elements.append("**ìœ„ë²•í–‰ìœ„**: ë²•ì§ˆì„œì— ìœ„ë°˜ë˜ëŠ” í–‰ìœ„")
            
            if "ì¸ê³¼ê´€ê³„" in content:
                elements.append("**ì¸ê³¼ê´€ê³„**: í–‰ìœ„ì™€ ê²°ê³¼ ì‚¬ì´ì˜ ì›ì¸Â·ê²°ê³¼ ê´€ê³„")
            
            return "\n".join(elements) if elements else ""
            
        except Exception as e:
            self.logger.error(f"Legal elements analysis failed: {e}")
            return ""
    
    async def _get_related_precedents(self, search_result: ArticleSearchResult) -> str:
        """ê´€ë ¨ íŒë¡€ ì •ë³´ ìƒì„±"""
        try:
            law_name = search_result.law_name
            article_number = search_result.article_number
            
            # íŒë¡€ ì •ë³´ í…œí”Œë¦¿ (ì‹¤ì œë¡œëŠ” íŒë¡€ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì—°ë™ í•„ìš”)
            precedents = []
            
            if law_name == "ë¯¼ë²•" and article_number == "750":
                precedents.extend([
                    "**ëŒ€ë²•ì› 2019ë‹¤12345 íŒê²°**: ë¶ˆë²•í–‰ìœ„ ì„±ë¦½ìš”ê±´ ì¤‘ ì¸ê³¼ê´€ê³„ ìž…ì¦ì±…ìž„",
                    "**ëŒ€ë²•ì› 2020ë‹¤67890 íŒê²°**: ê³¼ì‹¤ì˜ íŒë‹¨ ê¸°ì¤€ê³¼ ì£¼ì˜ì˜ë¬´ ë²”ìœ„",
                    "**ëŒ€ë²•ì› 2021ë‹¤11111 íŒê²°**: ì •ì‹ ì  í”¼í•´ì— ëŒ€í•œ ìœ„ìžë£Œ ì‚°ì • ê¸°ì¤€"
                ])
            
            return "\n".join(precedents) if precedents else ""
            
        except Exception as e:
            self.logger.error(f"Related precedents generation failed: {e}")
            return ""
    
    def _calculate_confidence(self, search_result: ArticleSearchResult, strategy: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            base_confidence = search_result.similarity
            
            # ê²€ìƒ‰ ë°©ë²•ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            method_weights = {
                'exact_match': 1.0,
                'fuzzy_match': 0.9,
                'semantic_search': 0.8,
                'hybrid_search': 0.85
            }
            
            weight = method_weights.get(strategy, 0.8)
            adjusted_confidence = base_confidence * weight
            
            # ë©”íƒ€ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ë°˜ì˜
            if search_result.metadata:
                quality_score = search_result.metadata.get('parsing_quality_score', 0.0)
                if quality_score > 0:
                    adjusted_confidence = min(1.0, adjusted_confidence + (quality_score * 0.1))
            
            return min(1.0, max(0.0, adjusted_confidence))
            
        except Exception as e:
            self.logger.error(f"Confidence calculation failed: {e}")
            return search_result.similarity
    
    def _convert_to_dict(self, search_result: ArticleSearchResult) -> Dict[str, Any]:
        """ArticleSearchResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'content': search_result.content,
            'law_name': search_result.law_name,
            'article_number': search_result.article_number,
            'article_title': search_result.article_title,
            'similarity': search_result.similarity,
            'source': search_result.source,
            'type': search_result.type,
            'metadata': search_result.metadata
        }
    
    async def search_multiple_articles(self, queries: List[str], strategy: str = 'hybrid') -> List[IntegratedSearchResult]:
        """ì—¬ëŸ¬ ì¡°ë¬¸ ë™ì‹œ ê²€ìƒ‰"""
        try:
            results = []
            
            for query in queries:
                result = await self.search_law_article(query, strategy)
                results.append(result)
            
            return results
            
        except Exception as e:
            self.logger.error(f"Multiple articles search failed: {e}")
            return []
    
    async def get_search_statistics(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        try:
            stats = {}
            
            # ì „ì²´ ë²•ë ¹ í†µê³„
            law_stats = await self.context_search_engine.get_law_statistics()
            stats.update(law_stats)
            
            # ë²¡í„° ìŠ¤í† ì–´ í†µê³„
            vector_stats = self.vector_store.get_stats()
            stats['vector_store'] = vector_stats
            
            return stats
            
        except Exception as e:
            self.logger.error(f"Search statistics failed: {e}")
            return {}
