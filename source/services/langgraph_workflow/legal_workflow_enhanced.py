# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ LangGraph Legal Workflow
ë‹µë³€ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í–¥ìƒëœ ì›Œí¬í”Œë¡œìš° êµ¬í˜„
"""

import logging
import time
from typing import Dict, List

from langchain_community.llms import Ollama
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import END, StateGraph

from ...utils.langgraph_config import LangGraphConfig
from .keyword_mapper import LegalKeywordMapper
from .legal_data_connector import LegalDataConnector
from .performance_optimizer import PerformanceOptimizer
from .prompt_templates import LegalPromptTemplates
from .state_definitions import LegalWorkflowState

logger = logging.getLogger(__name__)

# Mock QuestionType for enhanced workflow
class QuestionType:
    GENERAL_QUESTION = "general_question"
    LAW_INQUIRY = "law_inquiry"
    PRECEDENT_SEARCH = "precedent_search"
    LEGAL_ADVICE = "legal_advice"
    PROCEDURE_GUIDE = "procedure_guide"
    TERM_EXPLANATION = "term_explanation"
    CONTRACT_REVIEW = "contract_review"
    FAMILY_LAW = "family_law"
    CRIMINAL_LAW = "criminal_law"
    CIVIL_LAW = "civil_law"
    LABOR_LAW = "labor_law"
    PROPERTY_LAW = "property_law"
    INTELLECTUAL_PROPERTY = "intellectual_property"
    TAX_LAW = "tax_law"
    CIVIL_PROCEDURE = "civil_procedure"


class EnhancedLegalQuestionWorkflow:
    """ê°œì„ ëœ ë²•ë¥  ì§ˆë¬¸ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""

    def __init__(self, config: LangGraphConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.prompt_templates = LegalPromptTemplates()
        self.keyword_mapper = LegalKeywordMapper()
        self.data_connector = LegalDataConnector()
        self.performance_optimizer = PerformanceOptimizer()

        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.vector_store = self._initialize_vector_store()

        # LLM ì´ˆê¸°í™”
        self.llm = self._initialize_llm()

        # ì‹¤ì œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.current_law_search_engine = None
        self.unified_search_engine = None
        self.unified_rag_service = None
        self.conversation_store = None
        self.user_profile_manager = None
        self._initialize_external_services()

        # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì¶•
        self.graph = self._build_graph()
        logger.info("EnhancedLegalQuestionWorkflow initialized.")

    def _initialize_external_services(self):
        """ì™¸ë¶€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # CurrentLawSearchEngine ì´ˆê¸°í™”
            from ..current_law_search_engine import CurrentLawSearchEngine
            self.current_law_search_engine = CurrentLawSearchEngine(
                db_path="data/lawfirm.db",
                vector_store=self.vector_store
            )
            logger.info("âœ… CurrentLawSearchEngine ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"CurrentLawSearchEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.current_law_search_engine = None

        try:
            # UnifiedSearchEngine ì´ˆê¸°í™”
            from ..unified_search_engine import UnifiedSearchEngine
            self.unified_search_engine = UnifiedSearchEngine(
                vector_store=self.vector_store,
                current_law_search_engine=self.current_law_search_engine,
                enable_caching=True
            )
            logger.info("âœ… UnifiedSearchEngine ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"UnifiedSearchEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.unified_search_engine = None

        try:
            # UnifiedRAGService ì´ˆê¸°í™”
            logger.info("UnifiedRAGService ì´ˆê¸°í™” ì‹œë„ ì¤‘...")

            # ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            # ê²½ë¡œ ìˆ˜ì •: modelsëŠ” servicesì˜ í˜•ì œ ë””ë ‰í† ë¦¬
            import sys
            from pathlib import Path
            models_path = Path(__file__).parent.parent.parent / "models"
            if str(models_path) not in sys.path:
                sys.path.insert(0, str(models_path))

            from model_manager import LegalModelManager
            logger.info("LegalModelManager import ì„±ê³µ")

            model_manager = LegalModelManager()
            logger.info("LegalModelManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")

            # UnifiedRAGService import
            from ..unified_rag_service import UnifiedRAGService
            logger.info("UnifiedRAGService import ì„±ê³µ")

            # UnifiedRAGService ì´ˆê¸°í™” (search_engineì´ Noneì´ì–´ë„ ê°€ëŠ¥í•˜ë„ë¡ ê°œì„ )
            if self.unified_search_engine is None:
                logger.warning("unified_search_engineì´ Noneì…ë‹ˆë‹¤. UnifiedRAGServiceëŠ” ì œí•œì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

            self.unified_rag_service = UnifiedRAGService(
                model_manager=model_manager,
                search_engine=self.unified_search_engine,
                enable_caching=True
            )
            logger.info("âœ… UnifiedRAGService ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError as e:
            logger.error(f"UnifiedRAGService import ì‹¤íŒ¨ (ImportError): {e}")
            logger.debug(f"ImportError ìƒì„¸: {type(e).__name__}", exc_info=True)
            self.unified_rag_service = None
        except Exception as e:
            logger.error(f"UnifiedRAGService ì´ˆê¸°í™” ì‹¤íŒ¨: {type(e).__name__}: {e}")
            logger.debug(f"Exception ìƒì„¸: {e.__class__.__name__}", exc_info=True)
            self.unified_rag_service = None

        try:
            # ConversationStore ì´ˆê¸°í™”
            from ...data.conversation_store import ConversationStore
            self.conversation_store = ConversationStore(db_path="data/conversations.db")
            logger.info("âœ… ConversationStore ì´ˆê¸°í™” ì™„ë£Œ")

            # UserProfileManager ì´ˆê¸°í™”
            from ..user_profile_manager import UserProfileManager
            self.user_profile_manager = UserProfileManager(
                conversation_store=self.conversation_store
            )
            logger.info("âœ… UserProfileManager ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ConversationStore/UserProfileManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.conversation_store = None
            self.user_profile_manager = None

    def _initialize_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            from ...data.vector_store import LegalVectorStore

            vector_store = LegalVectorStore(
                model_name="jhgan/ko-sroberta-multitask",
                dimension=768,
                index_type="flat",
                enable_quantization=True,
                enable_lazy_loading=True,
                memory_threshold_mb=1500  # ë©”ëª¨ë¦¬ ì„ê³„ê°’ì„ 1500MBë¡œ ë‚®ì¶¤
            )

            # ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
            index_paths = [
                "data/embeddings/ml_enhanced_ko_sroberta/ml_enhanced_faiss_index",
                "data/embeddings/ml_enhanced_ko_sroberta_precedents/ml_enhanced_faiss_index",
                "data/embeddings/legal_vector_index"
            ]

            index_loaded = False
            for index_path in index_paths:
                try:
                    if vector_store.load_index(index_path):
                        print(f"Vector store loaded from: {index_path}")
                        index_loaded = True
                        break
                except Exception as e:
                    print(f"Failed to load vector store from {index_path}: {e}")
                    continue

            if not index_loaded:
                print("No vector store loaded, will use database search only")

            return vector_store

        except Exception as e:
            print(f"Failed to initialize vector store: {e}")
            return None

    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™” (Google Gemini ìš°ì„ , Ollama ë°±ì—…)"""
        if self.config.llm_provider == "google":
            try:
                # Google API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (api_key íŒŒë¼ë¯¸í„°ëŠ” ADCë§Œ ì§€ì›)
                import os
                if self.config.google_api_key:
                    os.environ['GOOGLE_API_KEY'] = self.config.google_api_key
                    logger.info(f"GOOGLE_API_KEY set in environment variables")
                else:
                    logger.warning("GOOGLE_API_KEY is not set in config. Falling back to Ollama.")

                gemini_llm = ChatGoogleGenerativeAI(
                    model=self.config.google_model,
                    temperature=0.3,
                    max_output_tokens=500,  # ë‹µë³€ ê¸¸ì´ ì¦ê°€
                    timeout=30,  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                )
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ ë¡œë“œ í™•ì¸ (ì œê±°)
                # test_response = gemini_llm.invoke("ì•ˆë…•í•˜ì„¸ìš”")
                logger.info(f"Initialized Google Gemini LLM: {self.config.google_model}")
                # logger.info(f"Test response: {test_response.content[:50]}...")
                return gemini_llm
            except Exception as e:
                logger.warning(f"Failed to initialize Google Gemini LLM: {e}. Falling back to Ollama.")

        if self.config.llm_provider == "ollama":
            try:
                ollama_llm = Ollama(
                    model=self.config.ollama_model,
                    base_url=self.config.ollama_base_url,
                    temperature=0.3,
                    num_predict=500,  # ë‹µë³€ ê¸¸ì´ ì¦ê°€
                    timeout=30  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                )
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ ë¡œë“œ í™•ì¸ (ì œê±°)
                # test_response = ollama_llm.invoke("ì•ˆë…•í•˜ì„¸ìš”")
                logger.info(f"Initialized Ollama LLM: {self.config.ollama_model}")
                # logger.info(f"Test response: {test_response[:50]}...")
                return ollama_llm
            except Exception as e:
                logger.warning(f"Failed to initialize Ollama LLM: {e}. Using Mock LLM.")

        # ğŸ†• ê°œì„ ëœ Mock LLM - ê²€ìƒ‰ ê²°ê³¼ í™œìš©
        class ImprovedMockLLM:
            def invoke(self, prompt):
                """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•œ ë²•ë¥  ë‹µë³€ ìƒì„±"""
                # í”„ë¡¬í”„íŠ¸ì—ì„œ ì»¨í…ìŠ¤íŠ¸(ê²€ìƒ‰ ê²°ê³¼) ì¶”ì¶œ
                context = ""
                question = ""

                # í”„ë¡¬í”„íŠ¸ íŒŒì‹± - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
                if "## ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ" in prompt:
                    parts = prompt.split("## ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ")
                    if len(parts) > 1:
                        context = parts[1].strip()
                elif "ê´€ë ¨ ë¬¸ì„œ:" in prompt:
                    parts = prompt.split("ê´€ë ¨ ë¬¸ì„œ:")
                    if len(parts) > 1:
                        context = parts[1].strip()
                elif "ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ" in prompt:
                    parts = prompt.split("ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ")
                    if len(parts) > 1:
                        context = parts[1].strip()
                elif "context:" in prompt.lower():
                    parts = prompt.split("context:")
                    if len(parts) > 1:
                        context = parts[1].strip()

                if "## ì‚¬ìš©ì ì§ˆë¬¸" in prompt:
                    parts = prompt.split("## ì‚¬ìš©ì ì§ˆë¬¸")
                    if len(parts) > 1:
                        question = parts[1].split("##")[0].strip()
                elif "ì§ˆë¬¸:" in prompt:
                    question_part = prompt.split("ì§ˆë¬¸:")[-1]
                    if "##" in question_part:
                        question = question_part.split("##")[0].strip()
                    else:
                        question = question_part.strip()
                elif "question:" in prompt.lower():
                    question_part = prompt.split("question:")[-1]
                    if "context:" in question_part:
                        question = question_part.split("context:")[0].strip()
                    else:
                        question = question_part.strip()

                # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€
                if context and context != "" and len(context) > 100:
                    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ ë‹µë³€ ìƒì„±
                    return self._generate_response_from_context(question, context)

                # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹µë³€
                return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë²•ë¥  ì¡°ë¬¸ì´ë‚˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

            def _generate_response_from_context(self, question, context):
                """ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ë‹µë³€ ìƒì„± - ì§ˆë¬¸ì— ë§ì¶° í•µì‹¬ ë‚´ìš© ë™ì  ì¶”ì¶œ"""
                # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
                lines = context.split('\n')

                # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
                contents = []
                for line in lines:
                    line = line.strip()
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë‚˜ JSON í˜•íƒœ íŒŒì‹±
                    if line and len(line) > 20:
                        # {'score': ..., 'text': '...'} í˜•íƒœ ì²˜ë¦¬
                        if "'text':" in line or '"text":' in line:
                            try:
                                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                if "'text':" in line:
                                    text_part = line.split("'text':")[-1].strip().replace("'", "")
                                else:
                                    text_part = line.split('"text":')[-1].strip().replace('"', "")
                                if text_part and len(text_part) > 20:
                                    contents.append(text_part)
                            except (ValueError, IndexError):
                                pass
                        elif not line.startswith("{'score':"):
                            contents.append(line)

                # ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
                question_keywords = self._extract_keywords(question)

                # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‚´ìš© ì¶”ì¶œ
                relevant_contents = self._extract_relevant_content(contents, question_keywords, question)

                # ê´€ë ¨ì„± ë†’ì€ ë‚´ìš© ì„ íƒ (ì§ˆë¬¸ ê¸¸ì´ì™€ ë¹ˆë„ ê¸°ë°˜)
                main_content = self._select_best_content(relevant_contents, question)

                # ë‹µë³€ ìƒì„±
                if main_content:
                    # ì§ˆë¬¸ ìœ í˜• íŒŒì•…
                    question_type = self._identify_question_type(question)

                    # ì§ˆë¬¸ ìœ í˜•ë³„ ì ì ˆí•œ ì„œë¡  ì‘ì„±
                    intro = self._generate_intro(question, question_type)

                    # í•µì‹¬ ë‚´ìš©ì„ ì§ˆë¬¸ì— ë§ê²Œ êµ¬ì¡°í™”
                    structured_content = self._structure_content(main_content, question, question_type)

                    response_text = f"""{intro}

{structured_content}

êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

                    return response_text
                else:
                    # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹µë³€
                    return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë²•ë¥  ì¡°ë¬¸ì´ë‚˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

            def _extract_keywords(self, question):
                """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
                # ë²•ë¥  ê´€ë ¨ í‚¤ì›Œë“œ
                legal_keywords = [
                    "ë²•", "ì¡°ë¬¸", "ì¡°í•­", "ë²•ë¥ ", "ë²•ë ¹", "ê·œì •", "íŒë¡€", "íŒê²°",
                    "ì´í˜¼", "í˜‘ì˜ì´í˜¼", "ì¬ì‚°ë¶„í• ", "ì–‘ìœ¡ê¶Œ", "ì–‘ìœ¡ë¹„",
                    "ìƒì†", "ìœ ì–¸", "ìƒì†ë¶„", "ìƒì†ì„¸", "ìƒì†ì¸",
                    "ê·¼ë¡œ", "ê·¼ë¬´", "ì„ê¸ˆ", "í‡´ì§ê¸ˆ", "ìˆ˜ë‹¹", "ì•¼ê°„", "íœ´ê°€",
                    "ê³„ì•½", "ë§¤ë§¤", "ì„ëŒ€", "ë³´ì¦", "ëŒ€ë¦¬",
                    "ì†í•´ë°°ìƒ", "ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„", "ì±„ê¶Œ", "ì±„ë¬´",
                    "ì†Œì†¡", "ì†Œì œê¸°", "ê´€í• ", "ì¦ê±°", "ì§‘í–‰",
                    "ì„¸ê¸ˆ", "ì„¸ë²•", "ì†Œë“ì„¸", "ë¶€ê°€ê°€ì¹˜ì„¸"
                ]

                # ì§ˆë¬¸ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ í‚¤ì›Œë“œ ë§¤ì¹­
                question_lower = question.lower()
                matched_keywords = [kw for kw in legal_keywords if kw in question_lower]

                # ì§ˆë¬¸ ë‹¨ì–´ ì¤‘ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
                import re
                words = re.findall(r'\b\w{2,}\b', question)
                matched_keywords.extend([w for w in words if len(w) >= 2 and w not in matched_keywords])

                return matched_keywords

            def _extract_relevant_content(self, contents, keywords, question):
                """ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„± ë†’ì€ ë‚´ìš© ì¶”ì¶œ"""
                if not contents:
                    return []

                # ê° ì»¨í…ìŠ¤íŠ¸ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                scored_contents = []
                for content in contents:
                    score = 0
                    content_lower = content.lower()
                    question_lower = question.lower()

                    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
                    for keyword in keywords:
                        if keyword in content_lower:
                            score += 2

                    # ì§ˆë¬¸ì˜ í•µì‹¬ ë‹¨ì–´ê°€ í¬í•¨ëœ ê²½ìš° ì¶”ê°€ ì ìˆ˜
                    for word in question_lower.split():
                        if len(word) >= 2 and word in content_lower:
                            score += 1

                    # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë„ ê³ ë ¤ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ë©´ ê°ì )
                    if 50 <= len(content) <= 1000:
                        score += 1

                    scored_contents.append((score, content))

                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
                scored_contents.sort(reverse=True, key=lambda x: x[0])

                return scored_contents

            def _select_best_content(self, scored_contents, question):
                """ê°€ì¥ ì í•©í•œ ë‚´ìš© ì„ íƒ"""
                if not scored_contents:
                    return ""

                # ìƒìœ„ 3ê°œ ì„ íƒí•˜ê³  í’ˆì§ˆì´ ì¢‹ì€ ê²ƒë§Œ í¬í•¨
                selected_contents = []
                for score, content in scored_contents[:5]:
                    if score >= 2:  # ìµœì†Œ ì ìˆ˜ ì´ìƒì¸ ê²½ìš°ë§Œ ì„ íƒ
                        selected_contents.append(content)

                if not selected_contents:
                    # ì ìˆ˜ê°€ ë‚®ì•„ë„ ìµœê³  ì ìˆ˜ ë‚´ìš©ì€ í¬í•¨
                    if scored_contents:
                        selected_contents.append(scored_contents[0][1])

                # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì¡°ì ˆ
                unique_contents = []
                seen = set()
                total_length = 0
                max_length = 800  # ìµœëŒ€ 800ì

                for content in selected_contents:
                    content_hash = hash(content[:100])  # ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ í•´ì‹œ
                    if content_hash not in seen:
                        if total_length + len(content) <= max_length:
                            unique_contents.append(content)
                            seen.add(content_hash)
                            total_length += len(content)
                        else:
                            # ê³µê°„ì´ ë¶€ì¡±í•˜ë©´ ìë¦„
                            remaining = max_length - total_length
                            if remaining > 100:
                                unique_contents.append(content[:remaining])
                            break

                return "\n\n".join(unique_contents)

            def _identify_question_type(self, question):
                """ì§ˆë¬¸ ìœ í˜• íŒŒì•…"""
                question_lower = question.lower()

                if any(kw in question_lower for kw in ["ì´í˜¼", "í˜‘ì˜ì´í˜¼", "ì¬ì‚°ë¶„í• ", "ì–‘ìœ¡ê¶Œ"]):
                    return "ê°€ì¡±ë²•"
                elif any(kw in question_lower for kw in ["ìƒì†", "ìœ ì–¸", "ìƒì†ë¶„", "ìƒì†ì„¸"]):
                    return "ìƒì†ë²•"
                elif any(kw in question_lower for kw in ["ê·¼ë¡œ", "ê·¼ë¬´", "ì„ê¸ˆ", "í‡´ì§ê¸ˆ", "ìˆ˜ë‹¹", "ì•¼ê°„", "íœ´ê°€"]):
                    return "ë…¸ë™ë²•"
                elif any(kw in question_lower for kw in ["ê³„ì•½", "ë§¤ë§¤", "ì„ëŒ€", "ë³´ì¦", "ëŒ€ë¦¬"]):
                    return "ê³„ì•½ë²•"
                elif any(kw in question_lower for kw in ["ì†í•´ë°°ìƒ", "ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„", "ì±„ê¶Œ", "ì±„ë¬´"]):
                    return "ë¯¼ì‚¬ë²•"
                elif any(kw in question_lower for kw in ["ì†Œì†¡", "ì†Œì œê¸°", "ê´€í• ", "ì¦ê±°", "ì§‘í–‰"]):
                    return "ë¯¼ì‚¬ì†Œì†¡ë²•"
                elif any(kw in question_lower for kw in ["ì ˆë„", "ë²”ì£„", "í˜•ì‚¬", "ì‚¬ê¸°", "í­í–‰", "ê°•ë„"]):
                    return "í˜•ì‚¬ë²•"
                elif any(kw in question_lower for kw in ["ì„¸ê¸ˆ", "ì„¸ë²•", "ì†Œë“ì„¸", "ë¶€ê°€ê°€ì¹˜ì„¸"]):
                    return "ì„¸ë²•"
                else:
                    return "ì¼ë°˜"

            def _generate_intro(self, question, question_type):
                """ì§ˆë¬¸ ìœ í˜•ì— ë§ëŠ” ì„œë¡  ìƒì„±"""
                if question_type == "ì¼ë°˜":
                    return "ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤."
                elif question_type == "ê°€ì¡±ë²•":
                    return "ê°€ì¡±ë²• ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”. ê´€ë ¨ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ìƒì†ë²•":
                    return "ìƒì† ê´€ë ¨ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ë…¸ë™ë²•":
                    return "ë…¸ë™ë²• ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ê³„ì•½ë²•":
                    return "ê³„ì•½ ê´€ë ¨ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ë¯¼ì‚¬ë²•":
                    return "ë¯¼ì‚¬ë²• ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ë¯¼ì‚¬ì†Œì†¡ë²•":
                    return "ë¯¼ì‚¬ì†Œì†¡ ê´€ë ¨ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "í˜•ì‚¬ë²•":
                    return "í˜•ì‚¬ë²• ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤."
                elif question_type == "ì„¸ë²•":
                    return "ì„¸ë²• ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤."
                else:
                    return "ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤."

            def _structure_content(self, content, question, question_type):
                """ë‚´ìš©ì„ ì§ˆë¬¸ì— ë§ê²Œ êµ¬ì¡°í™”"""
                # ì´ë¯¸ êµ¬ì¡°í™”ëœ ë‚´ìš©ì¸ì§€ í™•ì¸
                if "##" in content or "1." in content or "\n\n" in content:
                    return content

                # ë‚´ìš©ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
                sentences = [s.strip() for s in content.split('.') if s.strip()]

                # í•µì‹¬ ë¬¸ì¥ ìš°ì„  ì¶”ì¶œ
                relevant_sentences = []
                question_words = set(question.split())

                for sentence in sentences:
                    if len(sentence) > 30:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ì€ ì œì™¸
                        sentence_words = set(sentence.lower().split())
                        # ì§ˆë¬¸ê³¼ì˜ ê³µí†µ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ìš°ì„  í¬í•¨
                        if question_words & sentence_words:
                            relevant_sentences.insert(0, sentence)
                        else:
                            relevant_sentences.append(sentence)

                # ìƒìœ„ 5ê°œë§Œ ì„ íƒ
                result = ". ".join(relevant_sentences[:5])
                if result and not result.endswith('.'):
                    result += "."

                return result

            async def ainvoke(self, prompt):
                return self.invoke(prompt)

        logger.warning("No valid LLM provider configured or failed to initialize. Using Improved Mock LLM.")
        return ImprovedMockLLM()

    def _build_graph(self) -> StateGraph:
        """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì¶•"""
        workflow = StateGraph(LegalWorkflowState)

        # ê¸°ì¡´ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("classify_query", self.classify_query)
        workflow.add_node("retrieve_documents", self.retrieve_documents)
        workflow.add_node("generate_answer_enhanced", self.generate_answer_enhanced)
        workflow.add_node("format_response", self.format_response)

        # Phase 1: ì…ë ¥ ê²€ì¦ ë° íŠ¹ìˆ˜ ì¿¼ë¦¬ ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("validate_input", self.validate_input)
        workflow.add_node("detect_special_queries", self.detect_special_queries)
        workflow.add_node("handle_law_article", self.handle_law_article_query)
        workflow.add_node("handle_contract", self.handle_contract_query)

        # Phase 2: í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ì„ ë° ë²•ë¥  ì œí•œ ê²€ì¦ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_query_hybrid", self.analyze_query_hybrid)
        workflow.add_node("validate_legal_restrictions", self.validate_legal_restrictions)
        workflow.add_node("generate_restricted_response", self.generate_restricted_response)

        # Phase 4: ë‹µë³€ ìƒì„± í´ë°± ì²´ì¸ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("try_specific_law_search", self.try_specific_law_search)
        workflow.add_node("try_unified_search", self.try_unified_search)
        workflow.add_node("try_rag_service", self.try_rag_service)
        workflow.add_node("generate_template_response", self.generate_template_response)

        # Phase 3: Phase ì‹œìŠ¤í…œ í†µí•© ë…¸ë“œ ì¶”ê°€
        workflow.add_node("enrich_conversation_context", self.enrich_conversation_context)
        workflow.add_node("personalize_response", self.personalize_response)
        workflow.add_node("manage_memory_quality", self.manage_memory_quality)

        # Phase 5: í›„ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("enhance_completion", self.enhance_completion)
        workflow.add_node("add_disclaimer", self.add_disclaimer)

        # ì—£ì§€ ì„¤ì • (Phase 1: ìƒˆë¡œìš´ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸)
        workflow.set_entry_point("validate_input")
        workflow.add_edge("validate_input", "detect_special_queries")

        # íŠ¹ìˆ˜ ì¿¼ë¦¬ ë¼ìš°íŒ… (ì¡°ê±´ë¶€)
        workflow.add_conditional_edges(
            "detect_special_queries",
            self.should_route_special,
            {
                "law_article": "handle_law_article",
                "contract": "handle_contract",
                "regular": "classify_query"
            }
        )

        # íŠ¹ìˆ˜ ì¿¼ë¦¬ í•¸ë“¤ëŸ¬ì—ì„œ ì¢…ë£Œ
        workflow.add_edge("handle_law_article", END)
        workflow.add_edge("handle_contract", END)

        # Phase 2: classify_query ë‹¤ìŒì— í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ë…¸ë“œ ì¶”ê°€
        workflow.add_edge("classify_query", "analyze_query_hybrid")
        workflow.add_edge("analyze_query_hybrid", "validate_legal_restrictions")

        # ë²•ë¥  ì œí•œ ê²€ì¦ í›„ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "validate_legal_restrictions",
            self.should_continue_after_restriction,
            {
                "restricted": "generate_restricted_response",
                "continue": "retrieve_documents"
            }
        )
        workflow.add_edge("generate_restricted_response", END)

        # Phase 3: retrieve_documents ë‹¤ìŒì— Phase ë…¸ë“œë“¤ ë³‘ë ¬ ì‹¤í–‰
        workflow.add_edge("retrieve_documents", "enrich_conversation_context")
        workflow.add_edge("retrieve_documents", "personalize_response")
        workflow.add_edge("retrieve_documents", "manage_memory_quality")

        # ëª¨ë“  Phaseê°€ ì™„ë£Œë˜ë©´ ë‹µë³€ ìƒì„±ìœ¼ë¡œ
        workflow.add_edge("enrich_conversation_context", "generate_answer_enhanced")
        workflow.add_edge("personalize_response", "generate_answer_enhanced")
        workflow.add_edge("manage_memory_quality", "generate_answer_enhanced")

        # Phase 4: í´ë°± ì²´ì¸ ì„¤ì •
        workflow.add_conditional_edges(
            "generate_answer_enhanced",
            self.route_generation_fallback,
            {
                "success": "format_response",
                "fallback": "try_specific_law_search"
            }
        )

        workflow.add_conditional_edges(
            "try_specific_law_search",
            self.route_generation_fallback,
            {
                "success": "format_response",
                "fallback": "try_unified_search"
            }
        )

        workflow.add_conditional_edges(
            "try_unified_search",
            self.route_generation_fallback,
            {
                "success": "format_response",
                "fallback": "try_rag_service"
            }
        )

        workflow.add_conditional_edges(
            "try_rag_service",
            self.route_generation_fallback,
            {
                "success": "format_response",
                "fallback": "generate_template_response"
            }
        )

        workflow.add_edge("generate_template_response", "format_response")

        # Phase 5: format_response ë‹¤ìŒì— í›„ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€
        workflow.add_edge("format_response", "enhance_completion")
        workflow.add_edge("enhance_completion", "add_disclaimer")
        workflow.add_edge("add_disclaimer", END)

        return workflow

    def classify_query(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì§ˆë¬¸ ë¶„ë¥˜ (ê°œì„ ëœ ë²„ì „)"""
        try:
            # ë¡œê¹… ëŒ€ì‹  print ì‚¬ìš© (ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ ì•ˆì „)
            print(f"ğŸ” classify_query ì‹œì‘: query='{state.get('query', 'NOT_FOUND')}'")
            start_time = time.time()

            # ìƒíƒœ ë””ë²„ê¹…
            print(f"classify_query - Received state keys: {list(state.keys())}")
            print(f"classify_query - state['query']: '{state.get('query', 'NOT_FOUND')}'")
            print(f"classify_query - state['user_query']: '{state.get('user_query', 'NOT_FOUND')}'")

            # ìƒíƒœ ì´ˆê¸°í™” (í•„ìš”í•œ í‚¤ë“¤ì´ ì—†ìœ¼ë©´ ì¶”ê°€)
            if "query" not in state:
                state["query"] = ""
            if "errors" not in state:
                state["errors"] = []
            if "query_type" not in state:
                state["query_type"] = QuestionType.GENERAL_QUESTION
            if "confidence" not in state:
                state["confidence"] = 0.0
            if "sources" not in state:
                state["sources"] = []
            if "response" not in state:
                state["response"] = ""
            if "processing_time" not in state:
                state["processing_time"] = 0.0
            if "processing_steps" not in state:
                state["processing_steps"] = []

            # ì›ë³¸ ì¿¼ë¦¬ ë³´ì¡´ (user_queryê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
            original_query = state.get("user_query") or state.get("query", "")
            query = original_query.lower()

            print(f"classify_query - Using query: '{original_query}'")

            # ì›ë³¸ ì¿¼ë¦¬ë¥¼ ìƒíƒœì— ì €ì¥ (ë‹¤ë¥¸ ë…¸ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)
            state["query"] = original_query
            state["original_query"] = original_query

            # ê°œì„ ëœ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
            if any(k in query for k in ["ê³„ì•½", "ê³„ì•½ì„œ", "ë§¤ë§¤", "ì„ëŒ€", "ë„ê¸‰"]):
                state["query_type"] = QuestionType.CONTRACT_REVIEW
            elif any(k in query for k in ["ì´í˜¼", "ê°€ì¡±", "ìƒì†", "ì–‘ìœ¡", "ì…ì–‘"]):
                state["query_type"] = QuestionType.FAMILY_LAW
            elif any(k in query for k in ["ì ˆë„", "ë²”ì£„", "í˜•ì‚¬", "ì‚¬ê¸°", "í­í–‰", "ê°•ë„", "ì‚´ì¸"]):
                state["query_type"] = QuestionType.CRIMINAL_LAW
            elif any(k in query for k in ["ì†í•´ë°°ìƒ", "ë¯¼ì‚¬", "ë¶ˆë²•í–‰ìœ„", "ì±„ê¶Œ", "ì†Œìœ ê¶Œ"]):
                state["query_type"] = QuestionType.CIVIL_LAW
            elif any(k in query for k in ["í•´ê³ ", "ë…¸ë™", "ì„ê¸ˆ", "ê·¼ë¡œì‹œê°„", "íœ´ê°€", "ì‚°ì—…ì¬í•´"]):
                state["query_type"] = QuestionType.LABOR_LAW
            elif any(k in query for k in ["ë¶€ë™ì‚°", "ë§¤ë§¤", "ë“±ê¸°", "ê³µì‹œ", "í† ì§€"]):
                state["query_type"] = QuestionType.PROPERTY_LAW
            elif any(k in query for k in ["íŠ¹í—ˆ", "ì§€ì ì¬ì‚°ê¶Œ", "ì €ì‘ê¶Œ", "ìƒí‘œ", "ë””ìì¸"]):
                state["query_type"] = QuestionType.INTELLECTUAL_PROPERTY
            elif any(k in query for k in ["ì„¸ê¸ˆ", "ì†Œë“ì„¸", "ë¶€ê°€ê°€ì¹˜ì„¸", "ë²•ì¸ì„¸", "ìƒì†ì„¸", "ê°€ì‚°ì„¸"]):
                state["query_type"] = QuestionType.TAX_LAW
            elif any(k in query for k in ["ì†Œì†¡", "ê´€í• ", "ì¦ê±°", "íŒê²°", "ì§‘í–‰", "ë¯¼ì‚¬ì†Œì†¡"]):
                state["query_type"] = QuestionType.CIVIL_PROCEDURE
            else:
                state["query_type"] = QuestionType.GENERAL_QUESTION

            state["confidence"] = 0.8  # ë¶„ë¥˜ ì‹ ë¢°ë„ í–¥ìƒ
            state["processing_steps"].append(f"ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ (ê°œì„ ): {state['query_type']}")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"Query classified as {state['query_type']} with confidence {state['confidence']}")

        except Exception as e:
            error_msg = f"ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            state["errors"].append(error_msg)
            state["processing_steps"].append(error_msg)
            print(f"âŒ {error_msg}")

            # ê¸°ë³¸ê°’ ì„¤ì •
            state["query_type"] = QuestionType.GENERAL_QUESTION
            state["confidence"] = 0.3  # ê¸°ë³¸ ì‹ ë¢°ë„ë¥¼ ë‚®ì¶¤

        return state

    def retrieve_documents(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ë¬¸ì„œ ê²€ìƒ‰ (ìºì‹± ì ìš©)"""
        try:
            start_time = time.time()

            # ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì „í•œ ë°©ì‹)
            if "processing_steps" not in state:
                state["processing_steps"] = []
            if "retrieved_docs" not in state:
                state["retrieved_docs"] = []
            if "errors" not in state:
                state["errors"] = []
            if "query" not in state:
                state["query"] = ""
            if "query_type" not in state:
                state["query_type"] = QuestionType.GENERAL_QUESTION
            if "confidence" not in state:
                state["confidence"] = 0.3  # ê¸°ë³¸ ì‹ ë¢°ë„ë¥¼ ë‚®ì¶¤

            # âœ… ê°œì„ ëœ ì¿¼ë¦¬ ì¶”ì¶œ ë¡œì§ (ìˆœì„œ ë³€ê²½)
            query = state.get("user_query") or state.get("query") or state.get("original_query") or ""

            if not query:
                print("âŒ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                state["retrieved_docs"] = []
                state["processing_steps"].append("ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆì–´ ê²€ìƒ‰ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤")
                return state

            print(f"ğŸ” retrieve_documents ì‹œì‘: query='{query}'")

            query_type = state["query_type"]

            # ìƒíƒœ ë””ë²„ê¹…
            print(f"retrieve_documents - Received state keys: {list(state.keys())}")
            print(f"retrieve_documents - state['query']: '{state.get('query', 'NOT_FOUND')}'")
            print(f"retrieve_documents - state['user_query']: '{state.get('user_query', 'NOT_FOUND')}'")
            print(f"retrieve_documents - state['original_query']: '{state.get('original_query', 'NOT_FOUND')}'")

            # ì¿¼ë¦¬ ë””ë²„ê¹…
            print(f"Document retrieval - Query: '{query}', Type: {query_type}")

            # ìºì‹œì—ì„œ ë¬¸ì„œ í™•ì¸ (ë” ì ê·¹ì ì¸ ìºì‹±)
            cached_documents = self.performance_optimizer.cache.get_cached_documents(query, query_type)

            if cached_documents:
                state["retrieved_docs"] = cached_documents
                state["processing_steps"].append(f"{len(cached_documents)}ê°œ ìºì‹œëœ ë¬¸ì„œ ì‚¬ìš©")
                print(f"Using cached documents for query: {query[:50]}...")
            else:
                # ë²¡í„° ê²€ìƒ‰ ìš°ì„  ì‹œë„ (ì„±ëŠ¥ ìµœì í™”: top_kë¥¼ 5ì—ì„œ 3ìœ¼ë¡œ ê°ì†Œ)
                documents = []

                # ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰ ì‹œë„
                try:
                    if hasattr(self, 'vector_store') and self.vector_store and hasattr(self.vector_store, 'search'):
                        vector_results = self.vector_store.search(query, top_k=3)  # 5â†’3ìœ¼ë¡œ ìµœì í™”
                        if vector_results:
                            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            for i, result in enumerate(vector_results):
                                doc = {
                                    "id": f"vector_{i}",
                                    "content": result.get("content", str(result)),
                                    "source": "Vector Store",
                                    "relevance_score": result.get("similarity", result.get("score", 0.8)),
                                    "category": query_type
                                }
                                documents.append(doc)
                            print(f"Vector search found {len(documents)} documents")

                            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
                            self.performance_optimizer.cache.cache_documents(query, query_type, documents)
                except Exception as e:
                    print(f"âš ï¸ Vector search failed: {e}")

                # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ë©´ DB ê²€ìƒ‰ ìƒëµ (ì„±ëŠ¥ ìµœì í™”)
                if len(documents) >= 3:
                    print(f"âœ… ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¶©ë¶„ ({len(documents)}ê°œ). DB ê²€ìƒ‰ ìƒëµ")
                else:
                    # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ìˆ˜í–‰ (ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ë§Œ)
                    try:
                        print(f"ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: query='{query}', query_type='{query_type}'")
                        db_documents = self.data_connector.search_documents(query, query_type, limit=3)  # 5â†’3ìœ¼ë¡œ ìµœì í™”
                        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(db_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")

                        # ì¤‘ë³µ ì œê±°
                        existing_contents = {doc["content"][:100] for doc in documents}
                        for doc in db_documents:
                            if doc.get("content", "")[:100] not in existing_contents:
                                documents.append(doc)
                        print(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ìœ¼ë¡œ {len([doc for doc in db_documents if doc.get('content', '')[:100] not in existing_contents])}ê°œ ë¬¸ì„œ ì¶”ê°€")
                    except Exception as e:
                        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        import traceback
                        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

                # ì—¬ì „íˆ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ì¶”ê°€
                if len(documents) < 3:
                    try:
                        category_docs = self.data_connector.get_document_by_category(query_type, limit=3)
                        existing_contents = {doc["content"][:100] for doc in documents}
                        for doc in category_docs:
                            if doc.get("content", "")[:100] not in existing_contents:
                                documents.append(doc)
                        print(f"Category search added {len(category_docs)} documents")
                    except Exception as e:
                        print(f"Category search failed: {e}")

                state["retrieved_docs"] = documents
                state["processing_steps"].append(f"{len(documents)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ (ë²¡í„°+DB)")

                # ë¬¸ì„œ ìºì‹±
                self.performance_optimizer.cache.cache_documents(query, query_type, documents)

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"Retrieved {len(state['retrieved_docs'])} documents for query type {query_type}")

        except Exception as e:
            error_msg = f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            state["errors"].append(error_msg)
            state["processing_steps"].append(error_msg)
            print(f"âŒ {error_msg}")

            # í´ë°±: ê¸°ë³¸ ë¬¸ì„œ ì„¤ì •
            state["retrieved_docs"] = [
                {"content": f"'{state['query']}'ì— ëŒ€í•œ ê¸°ë³¸ ë²•ë¥  ì •ë³´ì…ë‹ˆë‹¤.", "source": "Default DB"}
            ]

        return state

    def generate_answer_enhanced(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ê°œì„ ëœ ë‹µë³€ ìƒì„±"""
        # user_queryë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ query ì‚¬ìš©
        query_value = state.get('user_query') or state.get('query', 'NOT_FOUND')
        print(f"ğŸ” generate_answer_enhanced ì‹œì‘: query='{query_value}'")

        # ğŸ†• ìƒì„¸ ìƒíƒœ ë””ë²„ê¹…
        print(f"ğŸ“‹ state í‚¤ ëª©ë¡: {list(state.keys())}")
        print(f"ğŸ“Š retrieved_docs ìœ ë¬´: {'retrieved_docs' in state}")
        print(f"ğŸ“Š retrieved_docs íƒ€ì…: {type(state.get('retrieved_docs', 'NOT_FOUND'))}")
        print(f"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(state.get('retrieved_docs', []))}")

        # ğŸ†• retrieved_docs ë‚´ìš© í™•ì¸
        if 'retrieved_docs' in state:
            docs = state['retrieved_docs']
            if isinstance(docs, list):
                print(f"ğŸ“Š retrieved_docs ë¦¬ìŠ¤íŠ¸ ê¸¸ì´: {len(docs)}")
                if docs:
                    print(f"ğŸ“Š ì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ: {type(docs[0])} - {list(docs[0].keys()) if isinstance(docs[0], dict) else str(docs[0])[:100]}")
            else:
                print(f"ğŸ“Š retrieved_docs íƒ€ì…: {type(docs)}")

        try:
            start_time = time.time()

            # ğŸ†• ì „ì²´ state ë³´ì¡´ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
            # TypedDictì´ë¯€ë¡œ ì „ì²´ ë”•ì…”ë„ˆë¦¬ë¡œ ì²˜ë¦¬
            updated_state = dict(state)  # ì „ì²´ state ë³µì‚¬

            # í•„ìš”í•œ í•„ë“œë§Œ ì´ˆê¸°í™” (ê¸°ì¡´ ê°’ ìœ ì§€)
            if "query_type" not in updated_state:
                updated_state["query_type"] = QuestionType.GENERAL_QUESTION
            if "query" not in updated_state:
                updated_state["query"] = ""
            if "response" not in updated_state:
                updated_state["response"] = ""
            if "confidence" not in updated_state:
                updated_state["confidence"] = 0.0
            if "sources" not in updated_state:
                updated_state["sources"] = []
            if "processing_steps" not in updated_state:
                updated_state["processing_steps"] = []
            if "errors" not in updated_state:
                updated_state["errors"] = []

            # ğŸ†• retrieved_docsëŠ” ì´ë¯¸ stateì— ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            retrieved_docs = updated_state.get("retrieved_docs", [])

            print(f"ğŸ” generate_answer_enhancedì—ì„œ retrieved_docs í™•ì¸: {len(retrieved_docs)}ê°œ")
            if not retrieved_docs:
                query = updated_state.get("user_query") or updated_state.get("query") or "ì§ˆë¬¸"
                print("âš ï¸ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")
                updated_state["generated_response"] = (
                    f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. "
                    f"ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.\n\n"
                    f"ì´ ì§ˆë¬¸ì€ {updated_state['query_type']} ì˜ì—­ì— í•´ë‹¹í•©ë‹ˆë‹¤. "
                    f"êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ëŒ€í•œ ì •í™•í•œ ë²•ë¥  ì¡°ì–¸ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                )
                updated_state["confidence"] = 0.3
                updated_state["processing_steps"] = updated_state.get("processing_steps", [])
                updated_state["processing_steps"].append("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ ë‹µë³€ ì œê³µ")
                return updated_state

            # ğŸ” ë””ë²„ê¹…: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œì²˜ í™•ì¸
            print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´:")
            for i, doc in enumerate(retrieved_docs[:5], 1):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                source = doc.get("source", "Unknown")
                title = doc.get("title", doc.get("content", "")[:50])
                category = doc.get("category", "Unknown")
                relevance_score = doc.get("relevance_score", 0.0)
                print(f"  [{i}] Source: {source}, Category: {category}, Relevance: {relevance_score:.2f}")
                print(f"      Title: {title[:80]}...")

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± - ë©”íƒ€ë°ì´í„° ì œì™¸í•˜ê³  ì‹¤ì œ ë‚´ìš©ë§Œ ì¶”ì¶œ
            import re
            context_parts = []
            for doc in retrieved_docs:
                if not doc:
                    continue

                # content í•„ë“œì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                content = doc.get("content", "")

                # contentê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° 'text' í•„ë“œì—ì„œ ì¶”ì¶œ
                if isinstance(content, dict):
                    content_text = content.get("text", "")
                # contentê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                elif isinstance(content, str):
                    # {'score': ..., 'text': '...'} í˜•íƒœì˜ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                    if "'text':" in content or '"text":' in content:
                        # í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•œ ì •ê·œì‹
                        text_pattern = r"(?:'text':|[\"']text[\"']:\s*)[\"']([^\"']+)[\"']"
                        matches = re.findall(text_pattern, content)
                        if matches:
                            content_text = matches[0]
                        else:
                            # ê°„ë‹¨í•œ íŒŒì‹± ì‹œë„
                            if "'text':" in content:
                                parts = content.split("'text':")
                                if len(parts) > 1:
                                    text_part = parts[1].strip()
                                    # ë”°ì˜´í‘œ ì œê±°
                                    content_text = text_part.strip("'\"")
                                else:
                                    content_text = content
                            else:
                                content_text = content
                    else:
                        content_text = content
                # ê·¸ ì™¸ì˜ ê²½ìš° ë¬¸ìì—´ ë³€í™˜
                else:
                    content_text = str(content)

                # ë©”íƒ€ë°ì´í„° í‚¤ì›Œë“œ ì œê±°
                if "metadata:" in content_text or "law_id:" in content_text:
                    lines = content_text.split('\n')
                    content_text = '\n'.join([line for line in lines if "metadata:" not in line and "law_id:" not in line])

                # ìµœì¢… ê²€ì¦ ë° ì¶”ê°€
                if content_text and len(content_text) > 20 and not content_text.startswith("{"):
                    context_parts.append(content_text)

            context = "\n\n".join(context_parts)

            # ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
            original_query = updated_state.get("user_query") or updated_state.get("original_query") or updated_state.get("query")

            # ğŸ” ë””ë²„ê¹…: ì…ë ¥ê°’ í™•ì¸
            print(f"ğŸ” í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë””ë²„ê¹…:")
            print(f"  - original_query: '{original_query}'")
            print(f"  - context ê¸¸ì´: {len(context)}")
            print(f"  - query_type: {updated_state['query_type']}")

            # ì§ˆë¬¸ ìœ í˜•ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
            required_keywords = self.keyword_mapper.get_keywords_for_question(
                original_query, updated_state["query_type"]
            )
            print(f"  - required_keywords: {required_keywords[:5]}")

            # ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ
            template = self.prompt_templates.get_template_for_query_type(updated_state["query_type"])

            # ğŸ” ë””ë²„ê¹…: í…œí”Œë¦¿ í™•ì¸
            print(f"  - template íƒ€ì…: {type(template)}")
            print(f"  - template ê¸¸ì´: {len(template) if isinstance(template, str) else 'N/A'}")
            print(f"  - template ì‹œì‘: {str(template)[:100]}...")

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            try:
                # í…œí”Œë¦¿ì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                if not isinstance(template, str):
                    print(f"âš ï¸ templateì´ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤. ë³€í™˜í•©ë‹ˆë‹¤.")
                    template = str(template)

                # í”Œë ˆì´ìŠ¤í™€ë” í™•ì¸
                if "{question}" not in template or "{context}" not in template:
                    print(f"âš ï¸ templateì— í•„ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
                    # ê¸°ë³¸ í…œí”Œë¦¿ìœ¼ë¡œ ëŒ€ì²´
                    template = f"""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë²•ë¥  ìƒë‹´ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê³  ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{{question}}

## ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ
{{context}}

## ë‹µë³€ ì›ì¹™
1. ì¼ìƒì ì¸ ë²•ë¥  ìƒë‹´ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”
2. "~ì…ë‹ˆë‹¤", "ê·€í•˜" ê°™ì€ ê³¼ë„í•˜ê²Œ ê²©ì‹ì ì¸ í‘œí˜„ ëŒ€ì‹ , "~ì˜ˆìš”", "ì§ˆë¬¸í•˜ì‹ " ë“± ìì—°ìŠ¤ëŸ¬ìš´ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
3. ì§ˆë¬¸ì„ ë‹¤ì‹œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”
4. ì§ˆë¬¸ì˜ ë²”ìœ„ì— ë§ëŠ” ì ì ˆí•œ ì–‘ì˜ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
5. ë¶ˆí•„ìš”í•œ í˜•ì‹(ì œëª©, ë²ˆí˜¸ ë§¤ê¸°ê¸°)ì€ ìµœì†Œí™”í•˜ì„¸ìš”
6. í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì£¼ìš” ì£¼ì˜ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”
7. ë²•ì  ê·¼ê±°ë¥¼ ëª…ì‹œí•˜ê³  ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•˜ì„¸ìš”

ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì „ë¬¸ ë²•ë¥  ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

                prompt = template.format(
                    question=original_query,
                    context=context,
                    required_keywords=", ".join(required_keywords[:10]) if "required_keywords" in template else ""
                )
                print(f"  âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ: {len(prompt)} ë¬¸ì")
                print(f"  - í”„ë¡¬í”„íŠ¸ ìƒ˜í”Œ: {prompt[:300]}...")

            except KeyError as e:
                print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ - í”Œë ˆì´ìŠ¤í™€ë” ì˜¤ë¥˜: {e}")
                # í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ìˆ˜ë™ìœ¼ë¡œ êµì²´
                prompt = template.replace("{question}", original_query).replace("{context}", context)
                if "{required_keywords}" in prompt:
                    prompt = prompt.replace("{required_keywords}", ", ".join(required_keywords[:10]))
                print(f"  ğŸ”§ ìˆ˜ë™ êµì²´ ì„±ê³µ")
            except Exception as e:
                print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸
                prompt = f"""ì§ˆë¬¸: {original_query}

ê´€ë ¨ ë¬¸ì„œ:
{context}

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ë²•ë¥  ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

            # LLM í˜¸ì¶œ
            print(f"LLM í˜¸ì¶œ ì‹œì‘ - í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}")
            response = self._call_llm_with_retry(prompt)
            print(f"LLM ì‘ë‹µ ë°›ìŒ - ì‘ë‹µ ê¸¸ì´: {len(response) if response else 0}")
            print(f"LLM ì‘ë‹µ ë‚´ìš©: {response[:100] if response else 'None'}...")

            # ë‹µë³€ í›„ì²˜ë¦¬ (êµ¬ì¡°í™” ê°•í™”)
            enhanced_response = self._enhance_response_structure(response, required_keywords)
            print(f"êµ¬ì¡°í™”ëœ ì‘ë‹µ ê¸¸ì´: {len(enhanced_response) if enhanced_response else 0}")

            # ëª¨ë“  ì‘ë‹µ í•„ë“œì— ë™ì¼í•œ ê°’ ì„¤ì •
            updated_state["answer"] = enhanced_response
            updated_state["generated_response"] = enhanced_response
            updated_state["response"] = enhanced_response
            updated_state["processing_steps"] = updated_state.get("processing_steps", [])
            updated_state["processing_steps"].append("ê°œì„ ëœ ë‹µë³€ ìƒì„± ì™„ë£Œ")

            # ì‹ ë¢°ë„ ê³„ì‚° (ê°œì„ ëœ ë¡œì§)
            confidence = self._calculate_dynamic_confidence(
                enhanced_response,
                retrieved_docs,
                original_query,
                updated_state["query_type"]
            )
            updated_state["confidence"] = confidence
            updated_state["processing_steps"].append(f"ì‹ ë¢°ë„ ê³„ì‚° ì™„ë£Œ: {confidence:.2f}")

            # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            print(f"ì‘ë‹µ í•„ë“œ ì„¤ì • ì™„ë£Œ:")
            print(f"  - answer ê¸¸ì´: {len(updated_state['answer'])}")
            print(f"  - generated_response ê¸¸ì´: {len(updated_state['generated_response'])}")
            print(f"  - response ê¸¸ì´: {len(updated_state['response'])}")
            print(f"  - confidence: {confidence:.2f}")

            # ì„±ê³µ í”Œë˜ê·¸ ì„¤ì •
            updated_state["generation_success"] = True
            updated_state["generation_method"] = "enhanced_llm"

            processing_time = time.time() - start_time
            updated_state["processing_time"] = updated_state.get("processing_time", 0.0) + processing_time

            print(f"Enhanced answer generated in {processing_time:.2f}s")

        except Exception as e:
            error_msg = f"ê°œì„ ëœ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            # ìƒíƒœ ì´ˆê¸°í™” í™•ì¸
            if "errors" not in updated_state:
                updated_state["errors"] = []
            if "processing_steps" not in updated_state:
                updated_state["processing_steps"] = []

            updated_state["errors"].append(error_msg)
            updated_state["processing_steps"].append(error_msg)
            print(f"âŒ {error_msg}")

            # ì‹¤íŒ¨ í”Œë˜ê·¸ ì„¤ì • (í´ë°± ì²´ì¸ìœ¼ë¡œ)
            updated_state["generation_success"] = False

        return updated_state

    def _calculate_dynamic_confidence(self, response: str, retrieved_docs: List[Dict],
                                    query: str, query_type) -> float:
        """ë™ì  ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            base_confidence = 0.5  # âœ… ê¸°ë³¸ ì‹ ë¢°ë„ë¥¼ 0.5ë¡œ ì¦ê°€ (ê¸°ì¡´ 0.2)

            # 1. ì‘ë‹µ ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜
            response_length = len(response)
            if response_length > 500:
                length_score = 0.3
            elif response_length > 200:
                length_score = 0.2
            elif response_length > 100:
                length_score = 0.1
            else:
                length_score = 0.0

            # 2. ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ ê¸°ë°˜ ì ìˆ˜
            doc_count = len(retrieved_docs)
            if doc_count >= 3:
                doc_score = 0.2
            elif doc_count >= 2:
                doc_score = 0.15
            elif doc_count >= 1:
                doc_score = 0.1
            else:
                doc_score = 0.0

            # 3. ì§ˆë¬¸ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
            type_weights = {
                "LEGAL_ADVICE": 0.8,
                "PROCEDURE_GUIDE": 0.7,
                "TERM_EXPLANATION": 0.6,
                "CONTRACT_REVIEW": 0.9,
                "GENERAL_QUESTION": 0.5
            }
            type_score = type_weights.get(str(query_type), 0.5) * 0.2

            # 4. ì‘ë‹µ í’ˆì§ˆ ê¸°ë°˜ ì ìˆ˜ (ë²•ë¥  í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€)
            legal_keywords = ["ë²•ë¥ ", "ì¡°ë¬¸", "íŒë¡€", "ë²•ë ¹", "ê·œì •", "ì†Œì†¡", "ê³„ì•½", "ê¶Œë¦¬", "ì˜ë¬´",
                           "ë¯¼ë²•", "í˜•ë²•", "ìƒë²•", "í—Œë²•", "í–‰ì •", "í˜•ì‚¬", "ë¯¼ì‚¬", "ì´í˜¼", "ìƒì†"]
            keyword_count = sum(1 for keyword in legal_keywords if keyword in response)
            quality_score = min(keyword_count * 0.05, 0.2)

            # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            final_confidence = base_confidence + length_score + doc_score + type_score + quality_score

            # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì œí•œ
            return max(0.0, min(1.0, final_confidence))

        except Exception as e:
            print(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.3  # ê¸°ë³¸ê°’

    def _call_llm_with_retry(self, prompt: str, max_retries: int = 3) -> str:
        """LLM í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        print(f"LLM í˜¸ì¶œ ì‹œì‘ - í”„ë¡¬í”„íŠ¸: {prompt[:100]}...")

        for attempt in range(max_retries):
            try:
                print(f"LLM í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")

                if hasattr(self.llm, 'invoke'):
                    response = self.llm.invoke(prompt)
                    print(f"LLM ì›ë³¸ ì‘ë‹µ íƒ€ì…: {type(response)}")

                    if hasattr(response, 'content'):
                        result = response.content
                        print(f"LLM ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ ì„±ê³µ: {result[:100]}...")
                        result = self._clean_llm_response(result)  # âœ… ì‘ë‹µ ì •ë¦¬
                        return result
                    else:
                        result = str(response)
                        print(f"LLM ì‘ë‹µ ë¬¸ìì—´ ë³€í™˜: {result[:100]}...")
                        result = self._clean_llm_response(result)  # âœ… ì‘ë‹µ ì •ë¦¬
                        return result
                else:
                    result = self.llm.invoke(prompt)
                    print(f"LLM ì§ì ‘ í˜¸ì¶œ ê²°ê³¼: {result[:100]}...")
                    result = self._clean_llm_response(result)  # âœ… ì‘ë‹µ ì •ë¦¬
                    return result

            except Exception as e:
                print(f"LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    print(f"LLM í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {e}")
                    raise e
                time.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°

        print("LLM í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return "LLM í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    def _clean_llm_response(self, result: str) -> str:
        """âœ… LLM ì‘ë‹µì—ì„œ í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ ì œê±°"""
        if not result:
            return result

        # í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
        if "## ì‚¬ìš©ì ì§ˆë¬¸" in result and "## ë‹µë³€ ì‘ì„± ì§€ì¹¨" in result:
            # ì§€ì¹¨ ë¶€ë¶„ ì œê±°
            if "## ë‹µë³€ ì‘ì„±" in result:
                parts = result.split("## ë‹µë³€ ì‘ì„±")
                if len(parts) > 1:
                    result = parts[-1].strip()

            # ì¶”ê°€ë¡œ ë‹µë³€ ë¶€ë¶„ë§Œ ë‚¨ê¸°ê¸°
            if "## ë‹µë³€" in result:
                parts = result.split("## ë‹µë³€")
                if len(parts) > 1:
                    result = parts[-1].strip()

        # ë¶ˆí•„ìš”í•œ "ë‹µë³€ ì‘ì„±" ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±°
        if "ë‹µë³€ ì‘ì„± ì§€ì¹¨" in result:
            result = result.replace("ë‹µë³€ ì‘ì„± ì§€ì¹¨", "").strip()

        return result

    def _enhance_response_structure(self, response: str, required_keywords: List[str]) -> str:
        """ë‹µë³€ êµ¬ì¡°í™” ê°•í™”"""
        # í‚¤ì›Œë“œ í¬í•¨ í™•ì¸ ë° ê°•í™”
        missing_keywords = self.keyword_mapper.get_missing_keywords(response, required_keywords[:5])

        if missing_keywords:
            # ëˆ„ë½ëœ í‚¤ì›Œë“œ ì¶”ê°€
            response += f"\n\n## ì¶”ê°€ ê³ ë ¤ì‚¬í•­\n"
            for keyword in missing_keywords[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶”ê°€
                response += f"- {keyword} ê´€ë ¨ ì‚¬í•­ë„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n"

        # êµ¬ì¡°í™” ê°•í™”
        if "##" not in response:
            # ì œëª©ì´ ì—†ìœ¼ë©´ ì¶”ê°€
            response = f"## ë‹µë³€\n{response}"

        if not any(marker in response for marker in ["1.", "2.", "3.", "â€¢", "-"]):
            # ëª©ë¡ì´ ì—†ìœ¼ë©´ ì¶”ê°€
            response += "\n\n## ì£¼ìš” í¬ì¸íŠ¸\n- ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."

        return response

    def _generate_fallback_answer(self, state: LegalWorkflowState) -> str:
        """í´ë°± ë‹µë³€ ìƒì„±"""
        query = state["query"]
        query_type = state["query_type"]
        context = "\n".join([doc["content"] for doc in state["retrieved_docs"]])

        return f"""## ë‹µë³€

ì§ˆë¬¸: {query}

ì´ ì§ˆë¬¸ì€ {query_type} ì˜ì—­ì— í•´ë‹¹í•©ë‹ˆë‹¤.

## ê´€ë ¨ ë²•ë¥  ì •ë³´
{context}

## ì£¼ìš” í¬ì¸íŠ¸
1. ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
2. ì •í™•í•œ ë²•ë¥ ì  ì¡°ì–¸ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
3. ê´€ë ¨ ë²•ì¡°ë¬¸ê³¼ íŒë¡€ë¥¼ ì¶”ê°€ë¡œ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

## ì£¼ì˜ì‚¬í•­
- ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ì •ë³´ ì œê³µ ëª©ì ì´ë©°, êµ¬ì²´ì ì¸ ë²•ë¥ ì  ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤.
- ì‹¤ì œ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

    def format_response(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì‘ë‹µ í¬ë§·íŒ… (ê°œì„ ëœ ë²„ì „)"""
        try:
            start_time = time.time()

            # ìƒíƒœ ë””ë²„ê¹…
            print(f"format_response - Received state keys: {list(state.keys())}")
            print(f"format_response - state['answer']: '{state.get('answer', 'NOT_FOUND')}'")
            print(f"format_response - state['response']: '{state.get('response', 'NOT_FOUND')}'")
            print(f"format_response - state['generated_response']: '{state.get('generated_response', 'NOT_FOUND')}'")

            # ìƒíƒœ ì´ˆê¸°í™”
            if "answer" not in state:
                state["answer"] = state.get("response", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            if "confidence" not in state:
                state["confidence"] = 0.0
            if "retrieved_docs" not in state:
                state["retrieved_docs"] = []
            if "query" not in state:
                state["query"] = ""
            if "query_type" not in state:
                state["query_type"] = QuestionType.GENERAL_QUESTION
            if "response" not in state:
                state["response"] = ""
            if "processing_steps" not in state:
                state["processing_steps"] = []
            if "errors" not in state:
                state["errors"] = []

            # ìµœì¢… ë‹µë³€ ë° ë©”íƒ€ë°ì´í„° ì •ë¦¬
            # generated_responseê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if state.get("generated_response"):
                final_answer = state["generated_response"]
                print(f"format_response - Using generated_response: '{final_answer[:100]}...'")
            else:
                final_answer = state.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                print(f"format_response - Using answer: '{final_answer[:100]}...'")

            final_confidence = state.get("confidence", 0.0)
            final_sources = [doc.get("source", "Unknown") for doc in state.get("retrieved_docs", [])]

            # ğŸ” ì°¸ì¡° ì¶œì²˜ ì¶”ì¶œ ë° ë‹µë³€ì— ì¶”ê°€
            referenced_sources = []
            for doc in state.get("retrieved_docs", [])[:3]:  # ìƒìœ„ 3ê°œë§Œ
                source = doc.get("source", "Unknown")
                category = doc.get("category", "")
                if source and source not in [s["name"] for s in referenced_sources]:
                    referenced_sources.append({
                        "name": source,
                        "category": category,
                        "relevance": doc.get("relevance_score", 0.0)
                    })

            # ğŸ“š ë‹µë³€ì— ì°¸ì¡° ì¶œì²˜ ì¶”ê°€
            if referenced_sources:
                final_answer += "\n\n## ì°¸ì¡° ì¶œì²˜\n"
                for source_info in referenced_sources:
                    category_str = f" ({source_info['category']})" if source_info.get("category") else ""
                    final_answer += f"- {source_info['name']}{category_str}\n"
                print(f"ğŸ“š ì°¸ì¡° ì¶œì²˜ ì¶”ê°€ë¨: {len(referenced_sources)}ê°œ")

            # í‚¤ì›Œë“œ í¬í•¨ë„ ê³„ì‚° (ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©)
            original_query = state.get("original_query", state["query"])
            required_keywords = self.keyword_mapper.get_keywords_for_question(
                original_query, state["query_type"]
            )
            keyword_coverage = self.keyword_mapper.calculate_keyword_coverage(
                final_answer, required_keywords
            )

            # ì‹ ë¢°ë„ ì¡°ì • (í‚¤ì›Œë“œ í¬í•¨ë„ ë°˜ì˜)
            adjusted_confidence = min(0.9, final_confidence + (keyword_coverage * 0.2))

            # ëª¨ë“  ì‘ë‹µ í•„ë“œì— ìµœì¢… ë‹µë³€ ì„¤ì •
            state["answer"] = final_answer
            state["generated_response"] = final_answer  # generated_response í•„ë“œë„ ì„¤ì •
            state["response"] = final_answer  # response í•„ë“œë„ ì„¤ì •
            state["confidence"] = adjusted_confidence
            state["sources"] = list(set(final_sources))  # ì¤‘ë³µ ì œê±°
            state["legal_references"] = referenced_sources  # ğŸ†• ì°¸ì¡° ì¶œì²˜ ì €ì¥
            state["processing_steps"].append("ì‘ë‹µ í¬ë§·íŒ… ì™„ë£Œ (ê°œì„ )")

            # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            print(f"format_response - ìµœì¢… ì‘ë‹µ í•„ë“œ ì„¤ì •:")
            print(f"  - answer ê¸¸ì´: {len(state['answer'])}")
            print(f"  - generated_response ê¸¸ì´: {len(state['generated_response'])}")
            print(f"  - response ê¸¸ì´: {len(state['response'])}")

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            state["metadata"] = {
                "keyword_coverage": keyword_coverage,
                "required_keywords_count": len(required_keywords),
                "matched_keywords_count": len(required_keywords) - len(
                    self.keyword_mapper.get_missing_keywords(final_answer, required_keywords)
                ),
                "response_length": len(final_answer),
                "query_type": state["query_type"],
                "referenced_sources": [s["name"] for s in referenced_sources],  # ğŸ†• ì°¸ì¡° ì¶œì²˜ ëª©ë¡
                "reference_count": len(referenced_sources)  # ğŸ†• ì°¸ì¡° ì¶œì²˜ ê°œìˆ˜
            }

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print("Enhanced response formatting completed")

        except Exception as e:
            error_msg = f"ì‘ë‹µ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            # ìƒíƒœ ì´ˆê¸°í™” í™•ì¸
            if "errors" not in state:
                state["errors"] = []
            if "processing_steps" not in state:
                state["processing_steps"] = []

            state["errors"].append(error_msg)
            state["processing_steps"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    # ========== Phase 1: ì…ë ¥ ê²€ì¦ ë° íŠ¹ìˆ˜ ì¿¼ë¦¬ ì²˜ë¦¬ ë…¸ë“œ ==========

    def validate_input(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì…ë ¥ ê²€ì¦ (enhanced_chat_service._validate_and_preprocess_input ë¡œì§)"""
        print(f"ğŸ” validate_input ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "errors" not in state:
                state["errors"] = []
            if "validation_results" not in state:
                state["validation_results"] = {}
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")

            # ê²€ì¦ ë¡œì§
            if not message or not message.strip():
                error = "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                state["errors"].append(error)
                state["validation_results"] = {"valid": False, "error": error}
            elif len(message) > 10000:
                error = "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 10,000ì)"
                state["errors"].append(error)
                state["validation_results"] = {"valid": False, "error": error}
            else:
                state["validation_results"] = {
                    "valid": True,
                    "message": message.strip(),
                    "length": len(message)
                }

            state["processing_steps"].append("ì…ë ¥ ê²€ì¦ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ì…ë ¥ ê²€ì¦ ì™„ë£Œ: {state['validation_results'].get('valid', False)}")

        except Exception as e:
            error_msg = f"ì…ë ¥ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def detect_special_queries(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """íŠ¹ìˆ˜ ì¿¼ë¦¬ ê°ì§€"""
        print(f"ğŸ” detect_special_queries ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "is_law_article_query" not in state:
                state["is_law_article_query"] = False
            if "is_contract_query" not in state:
                state["is_contract_query"] = False
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")

            # ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ê°ì§€
            import re
            law_patterns = [
                r'(\w+ë²•)\s*ì œ\s*(\d+)ì¡°',
                r'ì œ\s*(\d+)ì¡°',
                r'(\w+ë²•)ì œ(\d+)ì¡°'
            ]

            is_law_article = False
            for pattern in law_patterns:
                if re.search(pattern, message):
                    is_law_article = True
                    break

            state["is_law_article_query"] = is_law_article

            # ê³„ì•½ì„œ ì¿¼ë¦¬ ê°ì§€
            contract_keywords = ["ê³„ì•½ì„œ", "ê³„ì•½", "ì‘ì„±", "ì²´ê²°", "ê³„ì•½ì´"]
            is_contract = any(keyword in message for keyword in contract_keywords)
            state["is_contract_query"] = is_contract

            state["processing_steps"].append(f"íŠ¹ìˆ˜ ì¿¼ë¦¬ ê°ì§€ ì™„ë£Œ (ë²•ë¥ ì¡°ë¬¸: {is_law_article}, ê³„ì•½ì„œ: {is_contract})")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… íŠ¹ìˆ˜ ì¿¼ë¦¬ ê°ì§€ ì™„ë£Œ: law_article={is_law_article}, contract={is_contract}")

        except Exception as e:
            error_msg = f"íŠ¹ìˆ˜ ì¿¼ë¦¬ ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def should_route_special(self, state: LegalWorkflowState) -> str:
        """íŠ¹ìˆ˜ ì¿¼ë¦¬ ë¼ìš°íŒ… ê²°ì •"""
        try:
            if state.get("is_law_article_query"):
                return "law_article"
            elif state.get("is_contract_query"):
                return "contract"
            return "regular"
        except Exception as e:
            print(f"ë¼ìš°íŒ… ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return "regular"

    def handle_law_article_query(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬"""
        print(f"ğŸ” handle_law_article_query ì‹œì‘")
        start_time = time.time()

        try:
            # í˜„ì¬ëŠ” ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ ë¡œì§ ì—°ê²° (í–¥í›„ CurrentLawSearchEngine í†µí•©)
            message = state.get("user_query", "")

            # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
            response_text = f"ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ ê¸°ëŠ¥ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ì§ˆë¬¸: {message}"

            state["answer"] = response_text
            state["generated_response"] = response_text
            state["response"] = response_text
            state["generation_method"] = "law_article_query"
            state["generation_success"] = True

            if "processing_steps" not in state:
                state["processing_steps"] = []
            state["processing_steps"].append("ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ë²•ë¥  ì¡°ë¬¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def handle_contract_query(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ê³„ì•½ì„œ ì¿¼ë¦¬ ì²˜ë¦¬"""
        print(f"ğŸ” handle_contract_query ì‹œì‘")
        start_time = time.time()

        try:
            message = state.get("user_query", "")

            # ê¸°ë³¸ ì‘ë‹µ ìƒì„± (í–¥í›„ ContractQueryHandler í†µí•©)
            response_text = f"ê³„ì•½ì„œ ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì§ˆë¬¸: {message}"

            state["answer"] = response_text
            state["generated_response"] = response_text
            state["response"] = response_text
            state["generation_method"] = "contract_query"
            state["generation_success"] = True

            if "processing_steps" not in state:
                state["processing_steps"] = []
            state["processing_steps"].append("ê³„ì•½ì„œ ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ê³„ì•½ì„œ ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ê³„ì•½ì„œ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    # ========== Phase 2: í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ì„ ë° ë²•ë¥  ì œí•œ ê²€ì¦ ë…¸ë“œ ==========

    def analyze_query_hybrid(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ë¶„ì„ (enhanced_chat_service._analyze_query ë¡œì§)"""
        print(f"ğŸ” analyze_query_hybrid ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "query_analysis" not in state:
                state["query_analysis"] = {}
            if "hybrid_classification" not in state:
                state["hybrid_classification"] = {}
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")

            # í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ê¸° ì‚¬ìš©
            try:
                from ..integrated_hybrid_classifier import (
                    IntegratedHybridQuestionClassifier,
                )

                classifier = IntegratedHybridQuestionClassifier(confidence_threshold=0.7)
                classification_result = classifier.classify(message)

                # ë„ë©”ì¸ ë¶„ì„ (í–¥í›„ êµ¬í˜„)
                domain_analysis = {}

                # ê²°ê³¼ë¥¼ stateì— ì €ì¥
                state["query_analysis"] = {
                    "query_type": classification_result.question_type_value,
                    "confidence": classification_result.confidence,
                    "domain": domain_analysis.get("domain", "general"),
                    "keywords": classification_result.features.get("keywords", []) if classification_result.features else [],
                    "classification_method": classification_result.method,
                    "hybrid_analysis": True
                }
                state["hybrid_classification"] = {
                    "result": classification_result,
                    "domain_analysis": domain_analysis
                }

            except Exception as e:
                # í´ë°±: ê¸°ë³¸ ë¶„ë¥˜
                state["query_analysis"] = {
                    "query_type": "general",
                    "confidence": 0.5,
                    "hybrid_analysis": False,
                    "error": str(e)
                }

            state["processing_steps"].append("í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def validate_legal_restrictions(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ë²•ë¥  ì œí•œ ê²€ì¦ (enhanced_chat_service._validate_legal_restrictions ë¡œì§)"""
        print(f"ğŸ” validate_legal_restrictions ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "legal_restriction_result" not in state:
                state["legal_restriction_result"] = {}
            if "is_restricted" not in state:
                state["is_restricted"] = False
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")
            query_analysis = state.get("query_analysis", {})

            # ë²•ë¥  ì œí•œ ì‹œìŠ¤í…œ í˜¸ì¶œ (í˜„ì¬ëŠ” ë¹„í™œì„±í™” ìƒíƒœì´ë¯€ë¡œ ê¸°ë³¸ê°’)
            restriction_result = {
                "restricted": False,
                "reason": None,
                "safe_response": None,
                "confidence": 1.0
            }

            state["legal_restriction_result"] = restriction_result
            state["is_restricted"] = restriction_result["restricted"]
            state["processing_steps"].append("ë²•ë¥  ì œí•œ ê²€ì¦ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ë²•ë¥  ì œí•œ ê²€ì¦ ì™„ë£Œ: restricted={restriction_result['restricted']}")

        except Exception as e:
            error_msg = f"ë²•ë¥  ì œí•œ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def should_continue_after_restriction(self, state: LegalWorkflowState) -> str:
        """ì œí•œ ê²€ì¦ í›„ ë¼ìš°íŒ…"""
        try:
            if state.get("is_restricted"):
                return "restricted"
            return "continue"
        except Exception as e:
            print(f"ë¼ìš°íŒ… ê²°ì • ì¤‘ ì˜¤ë¥˜: {e}")
            return "continue"

    def generate_restricted_response(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì œí•œëœ ì‘ë‹µ ìƒì„±"""
        print(f"ğŸ” generate_restricted_response ì‹œì‘")
        start_time = time.time()

        try:
            restriction_result = state.get("legal_restriction_result", {})

            # ì œí•œëœ ì‘ë‹µ ìƒì„±
            response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì€ ë²•ë¥  ì œí•œìœ¼ë¡œ ì¸í•´ ë‹µë³€ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            if restriction_result.get("safe_response"):
                response_text = restriction_result["safe_response"]

            state["answer"] = response_text
            state["generated_response"] = response_text
            state["response"] = response_text
            state["generation_method"] = "restricted_response"
            state["generation_success"] = True

            if "processing_steps" not in state:
                state["processing_steps"] = []
            state["processing_steps"].append("ì œí•œëœ ì‘ë‹µ ìƒì„± ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ì œí•œëœ ì‘ë‹µ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ì œí•œëœ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    # ========== Phase 4: ë‹µë³€ ìƒì„± í´ë°± ì²´ì¸ ë…¸ë“œ ==========

    def route_generation_fallback(self, state: LegalWorkflowState) -> str:
        """ë‹µë³€ ìƒì„± í´ë°± ë¼ìš°íŒ…"""
        try:
            if state.get("generation_success"):
                return "success"
            return "fallback"
        except Exception as e:
            print(f"í´ë°± ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
            return "fallback"

    def try_specific_law_search(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """íŠ¹ì • ë²•ë¥  ì¡°ë¬¸ ê²€ìƒ‰ (enhanced_chat_service._generate_enhanced_response 2ìˆœìœ„ ë¡œì§)"""
        print(f"ğŸ” try_specific_law_search ì‹œì‘")
        start_time = time.time()

        try:
            query_analysis = state.get("query_analysis", {})
            message = state.get("user_query", "")

            # CurrentLawSearchEngine ì‚¬ìš©
            if self.current_law_search_engine:
                try:
                    results = self.current_law_search_engine.search_current_laws(
                        query=message,
                        search_type='hybrid',
                        top_k=5
                    )

                    if results:
                        # ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
                        first_result = results[0]
                        response_text = f"ê´€ë ¨ ë²•ë ¹: {first_result.law_name_korean}\n\n{first_result.detailed_info}"

                        state["answer"] = response_text
                        state["generated_response"] = response_text
                        state["response"] = response_text
                        state["generation_method"] = "current_law_search"
                        state["generation_success"] = True
                        state["processing_steps"] = state.get("processing_steps", [])
                        state["processing_steps"].append(f"íŠ¹ì • ë²•ë¥  ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
                        return state
                except Exception as e:
                    print(f"CurrentLawSearchEngine ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

            # ì‹¤íŒ¨ ì‹œ
            state["generation_success"] = False
            state["processing_steps"] = state.get("processing_steps", [])
            state["processing_steps"].append("íŠ¹ì • ë²•ë¥  ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸êµ¬í˜„")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

        except Exception as e:
            error_msg = f"íŠ¹ì • ë²•ë¥  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            state["generation_success"] = False
            print(f"âŒ {error_msg}")

        return state

    def try_unified_search(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í†µí•© ê²€ìƒ‰ ì—”ì§„ (enhanced_chat_service._generate_enhanced_response 3ìˆœìœ„ ë¡œì§)"""
        print(f"ğŸ” try_unified_search ì‹œì‘")
        start_time = time.time()

        try:
            message = state.get("user_query", "")

            # UnifiedSearchEngine ì‚¬ìš© (ë¹„ë™ê¸°ëŠ” ë™ê¸°ë¡œ ë³€í™˜)
            if self.unified_search_engine:
                try:
                    import asyncio
                    # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œ
                    if hasattr(self.unified_search_engine, 'search'):
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        search_result = loop.run_until_complete(
                            self.unified_search_engine.search(
                                query=message,
                                top_k=5,
                                search_types=['vector', 'exact'],
                                use_cache=True
                            )
                        )
                        loop.close()

                        if search_result.results:
                            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹µë³€ìœ¼ë¡œ ë³€í™˜
                            sources_text = "\n\n".join([
                                f"- {r.get('title', r.get('content', ''))[:200]}"
                                for r in search_result.results[:3]
                            ])

                            response_text = f"ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n{sources_text}"

                            state["answer"] = response_text
                            state["generated_response"] = response_text
                            state["response"] = response_text
                            state["generation_method"] = "unified_search"
                            state["generation_success"] = True
                            state["processing_steps"] = state.get("processing_steps", [])
                            state["processing_steps"].append(f"í†µí•© ê²€ìƒ‰ ì„±ê³µ: {len(search_result.results)}ê°œ ê²°ê³¼")
                            return state
                except Exception as e:
                    print(f"UnifiedSearchEngine ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

            # ì‹¤íŒ¨ ì‹œ
            state["generation_success"] = False
            state["processing_steps"] = state.get("processing_steps", [])
            state["processing_steps"].append("í†µí•© ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸êµ¬í˜„")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

        except Exception as e:
            error_msg = f"í†µí•© ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            state["generation_success"] = False
            print(f"âŒ {error_msg}")

        return state

    def try_rag_service(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """RAG ì„œë¹„ìŠ¤ (enhanced_chat_service._generate_enhanced_response 4ìˆœìœ„ ë¡œì§)"""
        print(f"ğŸ” try_rag_service ì‹œì‘")
        start_time = time.time()

        try:
            message = state.get("user_query", "")
            query_analysis = state.get("query_analysis", {})

            # UnifiedRAGService ì‚¬ìš© (ë¹„ë™ê¸°ëŠ” ë™ê¸°ë¡œ ë³€í™˜)
            if self.unified_rag_service:
                try:
                    import asyncio
                    # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œ
                    if hasattr(self.unified_rag_service, 'generate_response'):
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        rag_response = loop.run_until_complete(
                            self.unified_rag_service.generate_response(
                                query=message,
                                max_length=500,
                                top_k=10,
                                use_cache=True
                            )
                        )
                        loop.close()

                        if rag_response and hasattr(rag_response, 'response'):
                            response_text = rag_response.response

                            state["answer"] = response_text
                            state["generated_response"] = response_text
                            state["response"] = response_text
                            state["generation_method"] = "unified_rag"
                            state["generation_success"] = True
                            state["confidence"] = rag_response.confidence if hasattr(rag_response, 'confidence') else 0.7
                            state["processing_steps"] = state.get("processing_steps", [])
                            state["processing_steps"].append("RAG ì„œë¹„ìŠ¤ ì„±ê³µ")
                            return state
                except Exception as e:
                    print(f"UnifiedRAGService ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

            # ì‹¤íŒ¨ ì‹œ
            state["generation_success"] = False
            state["processing_steps"] = state.get("processing_steps", [])
            state["processing_steps"].append("RAG ì„œë¹„ìŠ¤ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸êµ¬í˜„")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

        except Exception as e:
            error_msg = f"RAG ì„œë¹„ìŠ¤ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            state["generation_success"] = False
            print(f"âŒ {error_msg}")

        return state

    def generate_template_response(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ (enhanced_chat_service._generate_improved_template_response ë¡œì§)"""
        print(f"ğŸ” generate_template_response ì‹œì‘")
        start_time = time.time()

        try:
            message = state.get("user_query", "")
            query_type = state.get("query_type", "GENERAL_QUESTION")

            # í…œí”Œë¦¿ ê¸°ë°˜ ê¸°ë³¸ ë‹µë³€ ìƒì„±
            templates = {
                "FAMILY_LAW": "ê°€ì¡±ë²• ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”. ìƒì„¸í•œ ì‚¬ì•ˆì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "CRIMINAL_LAW": "í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”. êµ¬ì²´ì ì¸ ìƒí™©ì„ ì„¤ëª…í•´ì£¼ì‹œë©´ ê´€ë ¨ ì¡°ë¬¸ì„ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "CIVIL_LAW": "ë¯¼ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”. ìì„¸í•œ ë‚´ìš©ì„ ì•Œë ¤ì£¼ì‹œë©´ ë²•ë¥  ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "LABOR_LAW": "ë…¸ë™ë²• ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”. êµ¬ì²´ì ì¸ ì‚¬ì•ˆì„ ì•Œë ¤ì£¼ì‹œë©´ ê´€ë ¨ ë²•ë ¹ì„ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
            }

            response_text = templates.get(query_type,
                f"ì£„ì†¡í•©ë‹ˆë‹¤. '{message}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. "
                "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë¬¸ì˜í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")

            state["answer"] = response_text
            state["generated_response"] = response_text
            state["response"] = response_text
            state["generation_method"] = "template"
            state["generation_success"] = True
            state["confidence"] = 0.5
            state["processing_steps"] = state.get("processing_steps", [])
            state["processing_steps"].append("í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            error_msg = f"í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            state["generation_success"] = False
            print(f"âŒ {error_msg}")

        return state

    # ========== Phase 3: Phase ì‹œìŠ¤í…œ í†µí•© ë…¸ë“œ ==========

    def enrich_conversation_context(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™” (enhanced_chat_service._process_phase1_context ë¡œì§)"""
        print(f"ğŸ” enrich_conversation_context ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "phase1_context" not in state:
                state["phase1_context"] = {}
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")
            session_id = state.get("session_id", "")
            user_id = state.get("user_id", "")

            # Phase 1 ì •ë³´ ì„¤ì •
            phase1_info = {
                "session_context": None,
                "multi_turn_context": None,
                "compressed_context": None,
                "enabled": False  # í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœ
            }

            # ì‹¤ì œ Phase 1 ë¡œì§ (í–¥í›„ í™œì„±í™” ì‹œ êµ¬í˜„)
            # integrated_session_manager, multi_turn_handler, context_compressor í˜¸ì¶œ

            state["phase1_context"] = phase1_info
            state["processing_steps"].append("Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™” ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… Phase 1: ëŒ€í™” ë§¥ë½ ê°•í™” ì™„ë£Œ")

        except Exception as e:
            error_msg = f"Phase 1 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def personalize_response(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """Phase 2: ê°œì¸í™” (enhanced_chat_service._process_phase2_personalization ë¡œì§)"""
        print(f"ğŸ” personalize_response ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "phase2_personalization" not in state:
                state["phase2_personalization"] = {}
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")
            user_id = state.get("user_id", "")
            # session_idì™€ phase1_infoëŠ” í–¥í›„ í™•ì¥ ì‹œ ì‚¬ìš© ì˜ˆì •
            _session_id = state.get("session_id", "")
            _phase1_info = state.get("phase1_context", {})

            # Phase 2 ì •ë³´ ì„¤ì •
            phase2_info = {
                "user_profile": None,
                "emotion_intent": None,
                "conversation_flow": None,
                "enabled": True  # UserProfileManager ì‚¬ìš© ì‹œ í™œì„±í™”
            }

            # UserProfileManagerë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ Phase 2 ë¡œì§ êµ¬í˜„
            if self.user_profile_manager and user_id:
                try:
                    # 1. ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ ë˜ëŠ” ìƒì„±
                    profile = self.user_profile_manager.get_profile(user_id)
                    if not profile:
                        # í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
                        self.user_profile_manager.create_profile(user_id, {})
                        profile = self.user_profile_manager.get_profile(user_id)

                    if profile:
                        # 2. ê°œì¸í™”ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                        personalized_context = self.user_profile_manager.get_personalized_context(
                            user_id, message
                        )

                        # 3. ê´€ì‹¬ ë¶„ì•¼ ì—…ë°ì´íŠ¸
                        self.user_profile_manager.update_interest_areas(user_id, message)

                        # 4. ìƒíƒœì— ê°œì¸í™” ì •ë³´ ì„¤ì •
                        phase2_info["user_profile"] = personalized_context

                        # 5. ì „ì—­ ìƒíƒœì—ë„ ê°œì¸í™” ì •ë³´ ë°˜ì˜
                        if "user_expertise_level" not in state:
                            state["user_expertise_level"] = profile.get("expertise_level", "beginner")
                        else:
                            state["user_expertise_level"] = profile.get("expertise_level", state["user_expertise_level"])

                        if "preferred_response_style" not in state:
                            state["preferred_response_style"] = personalized_context.get("response_style", "medium")
                        else:
                            state["preferred_response_style"] = personalized_context.get("response_style", state["preferred_response_style"])

                        state["expertise_context"] = personalized_context.get("expertise_context", {})
                        state["interest_areas"] = personalized_context.get("interest_areas", [])
                        state["personalization_score"] = personalized_context.get("personalization_score", 0.0)

                        logger.info(f"âœ… Phase 2: ê°œì¸í™” ì™„ë£Œ - ì „ë¬¸ì„±: {profile.get('expertise_level')}, ê´€ì‹¬ë¶„ì•¼: {len(personalized_context.get('interest_areas', []))}ê°œ")
                    else:
                        logger.warning("í”„ë¡œí•„ ìƒì„± ë˜ëŠ” ì¡°íšŒ ì‹¤íŒ¨")

                except Exception as e:
                    logger.error(f"UserProfileManager ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    # ì—ëŸ¬ê°€ ë‚˜ë„ ê³„ì† ì§„í–‰
                    phase2_info["enabled"] = False
            else:
                logger.info("UserProfileManagerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ - ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰")

            state["phase2_personalization"] = phase2_info
            state["processing_steps"].append("Phase 2: ê°œì¸í™” ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… Phase 2: ê°œì¸í™” ì™„ë£Œ")

        except Exception as e:
            error_msg = f"Phase 2 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            logger.error(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def manage_memory_quality(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (enhanced_chat_service._process_phase3_memory_quality ë¡œì§)"""
        print(f"ğŸ” manage_memory_quality ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "phase3_memory_quality" not in state:
                state["phase3_memory_quality"] = {}
            if "processing_steps" not in state:
                state["processing_steps"] = []

            message = state.get("user_query", "")
            user_id = state.get("user_id", "")
            # session_id, phase1_info, phase2_infoëŠ” í–¥í›„ í™•ì¥ ì‹œ ì‚¬ìš© ì˜ˆì •
            _session_id = state.get("session_id", "")
            _phase1_info = state.get("phase1_context", {})
            _phase2_info = state.get("phase2_personalization", {})

            # Phase 3 ì •ë³´ ì„¤ì •
            phase3_info = {
                "contextual_memory": None,
                "quality_metrics": None,
                "enabled": False  # í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœ
            }

            # ì‹¤ì œ Phase 3 ë¡œì§ (í–¥í›„ í™œì„±í™” ì‹œ êµ¬í˜„)
            # contextual_memory_manager, conversation_quality_monitor í˜¸ì¶œ

            state["phase3_memory_quality"] = phase3_info
            state["processing_steps"].append("Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… Phase 3: ì¥ê¸° ê¸°ì–µ ë° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"Phase 3 ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    # ========== Phase 5: í›„ì²˜ë¦¬ ë…¸ë“œ ==========

    def enhance_completion(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ë° ë³´ì™„ (enhanced_chat_service.process_message ë¡œì§)"""
        print(f"ğŸ” enhance_completion ì‹œì‘")
        start_time = time.time()

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            if "processing_steps" not in state:
                state["processing_steps"] = []
            if "completion_result" not in state:
                state["completion_result"] = {}

            response_text = state.get("response", "")
            # messageì™€ query_analysisëŠ” í–¥í›„ í™•ì¥ ì‹œ ì‚¬ìš© ì˜ˆì •
            _message = state.get("user_query", "")
            _query_analysis = state.get("query_analysis", {})

            # í–¥í›„ enhanced_completion_system í†µí•©
            # í˜„ì¬ëŠ” ê¸°ë³¸ ê²€ì¦ë§Œ ìˆ˜í–‰
            was_truncated = False
            if response_text and len(response_text) < 50:
                # ë„ˆë¬´ ì§§ì€ ë‹µë³€ì€ ë³´ì™„ í•„ìš”
                was_truncated = True
                state["completion_result"] = {
                    "improved": True,
                    "method": "length_validation",
                    "confidence": 0.7
                }

            if was_truncated:
                # ë‹µë³€ì„ ì¡°ê¸ˆ ë” í’ë¶€í•˜ê²Œ ë§Œë“¤ì–´ì¤Œ
                enhanced_response = response_text + "\n\nì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                state["response"] = enhanced_response
                state["answer"] = enhanced_response
                state["generated_response"] = enhanced_response

            state["processing_steps"].append("ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

            print(f"âœ… ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ë‹µë³€ ì™„ì„±ë„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return state

    def add_disclaimer(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ë©´ì±… ì¡°í•­ ì¶”ê°€ (UserPreferenceManager í†µí•©)"""
        print(f"ğŸ” add_disclaimer ì‹œì‘")
        start_time = time.time()

        try:
            # UserPreferenceManager import
            from ...user_preference_manager import (
                DisclaimerPosition,
                DisclaimerStyle,
                preference_manager,
            )

            # ìƒíƒœ ì´ˆê¸°í™”
            if "processing_steps" not in state:
                state["processing_steps"] = []
            if "disclaimer_added" not in state:
                state["disclaimer_added"] = False

            response_text = state.get("response", "")

            # ì‚¬ìš©ì ì„¤ì • ê°€ì ¸ì˜¤ê¸° (stateì—ì„œ ë˜ëŠ” ê¸°ë³¸ê°’)
            user_preferences = state.get("user_preferences", {})
            show_disclaimer = user_preferences.get("show_disclaimer", True)

            # ì‚¬ìš©ì ì„¤ì •ì— ë”°ë¼ ë©´ì±… ì¡°í•­ ì¶”ê°€
            if response_text and show_disclaimer:
                # ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
                disclaimer_style_str = user_preferences.get("disclaimer_style", "natural")
                try:
                    disclaimer_style = DisclaimerStyle(disclaimer_style_str)
                except ValueError:
                    disclaimer_style = DisclaimerStyle.NATURAL

                # ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
                disclaimer_position_str = user_preferences.get("disclaimer_position", "end")
                try:
                    disclaimer_position = DisclaimerPosition(disclaimer_position_str)
                except ValueError:
                    disclaimer_position = DisclaimerPosition.END

                # preference_managerì— í˜„ì¬ ì„¤ì • ë°˜ì˜
                if hasattr(preference_manager, 'preferences'):
                    preference_manager.preferences.disclaimer_style = disclaimer_style
                    preference_manager.preferences.disclaimer_position = disclaimer_position
                    preference_manager.preferences.show_disclaimer = show_disclaimer

                # UserPreferenceManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ë©´ì±… ì¡°í•­ ì¶”ê°€
                question_text = state.get("user_query", "")
                enhanced_response = preference_manager.add_disclaimer_to_response(
                    response_text,
                    question_text
                )

                # ë©´ì±… ì¡°í•­ì´ ì¶”ê°€ëœ ê²½ìš°ì—ë§Œ ìƒíƒœ ì—…ë°ì´íŠ¸
                if enhanced_response != response_text:
                    state["response"] = enhanced_response
                    state["answer"] = enhanced_response
                    state["generated_response"] = enhanced_response
                    state["disclaimer_added"] = True
                    print(f"âœ… ë©´ì±… ì¡°í•­ ì¶”ê°€ ì™„ë£Œ (ìŠ¤íƒ€ì¼: {disclaimer_style.value}, ìœ„ì¹˜: {disclaimer_position.value})")
                else:
                    print(f"â„¹ï¸ ë©´ì±… ì¡°í•­ ì¶”ê°€ ì•ˆí•¨ (ì„¤ì •ì— ë”°ë¼ ê±´ë„ˆëœ€)")

            state["processing_steps"].append("ë©´ì±… ì¡°í•­ ì¶”ê°€ ì™„ë£Œ")

            processing_time = time.time() - start_time
            state["processing_time"] = state.get("processing_time", 0.0) + processing_time

        except ImportError as e:
            # UserPreferenceManagerë¥¼ importí•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¡œì§ ì‚¬ìš©
            print(f"âš ï¸ UserPreferenceManagerë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¡œì§ ì‚¬ìš©: {e}")
            response_text = state.get("response", "")

            if response_text and not response_text.endswith(".") and not response_text.endswith("!"):
                disclaimer = "\n\nâ€» ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, êµ¬ì²´ì ì¸ ë²•ë¥  ìë¬¸ì€ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
                state["response"] = response_text + disclaimer
                state["answer"] = state["response"]
                state["generated_response"] = state["response"]
                state["disclaimer_added"] = True
                print(f"âœ… ê¸°ë³¸ ë©´ì±… ì¡°í•­ ì¶”ê°€ ì™„ë£Œ")

        except Exception as e:
            error_msg = f"ë©´ì±… ì¡°í•­ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            if "errors" not in state:
                state["errors"] = []
            state["errors"].append(error_msg)
            print(f"âŒ {error_msg}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        return state
