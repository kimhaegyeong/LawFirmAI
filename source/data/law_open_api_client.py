#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"""
êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° OPEN API í´ë¼ì´ì–¸íŠ¸

êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì˜ OPEN APIë¥¼ í†µí•´ ë²•ë ¹ìš©ì–´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.
- ë²•ë ¹ìš©ì–´ ëª©ë¡ ì¡°íšŒ
- ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ
- ìš”ì²­ ì œí•œ ê´€ë¦¬
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
"""

import os
import time
import requests
import logging
import json
from typing import Dict, Any, Optional, List
from datetime import datetime
from pathlib import Path
import sys

logger = logging.getLogger(__name__)


class LawOpenAPIClient:
    """êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° OPEN API ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, oc_parameter: str = None):
        """
        API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            oc_parameter: OC íŒŒë¼ë¯¸í„° (ì´ë©”ì¼ ID). Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        """
        self.oc_parameter = oc_parameter or os.getenv("LAW_OPEN_API_OC")
        if not self.oc_parameter:
            raise ValueError("LAW_OPEN_API_OC í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.base_url = "http://www.law.go.kr/DRF/lawSearch.do"
        self.detail_url = "http://www.law.go.kr/DRF/lawService.do"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'LawFirmAI/1.0'
        })
        
        # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ê´€ë¦¬
        self.last_request_time = 0
        self.min_request_interval = 1.0  # ìµœì†Œ ìš”ì²­ ê°„ê²© (ì´ˆ) - ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
        
        # ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì (ì§€ì—° ë¡œë”©)
        self._checkpoint_manager = None
        
        logger.info(f"LawOpenAPIClient ì´ˆê¸°í™” ì™„ë£Œ - OC: {self.oc_parameter}")
    
    @property
    def checkpoint_manager(self):
        """ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì ì§€ì—° ë¡œë”©"""
        if self._checkpoint_manager is None:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
            project_root = Path(__file__).parent.parent.parent
            sys.path.append(str(project_root))
            
            from scripts.data_collection.law_open_api.utils.checkpoint_manager import CheckpointManager
            self._checkpoint_manager = CheckpointManager()
        
        return self._checkpoint_manager
    
    def _wait_for_request_interval(self):
        """ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ëŒ€ê¸°"""
        current_time = time.time()
        time_since_last_request = current_time - self.last_request_time
        
        if time_since_last_request < self.min_request_interval:
            sleep_time = self.min_request_interval - time_since_last_request
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _make_request(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        API ìš”ì²­ ì‹¤í–‰
        
        Args:
            params: ìš”ì²­ íŒŒë¼ë¯¸í„°
            
        Returns:
            API ì‘ë‹µ ë°ì´í„°
            
        Raises:
            requests.HTTPError: HTTP ì—ëŸ¬ ë°œìƒ ì‹œ
            requests.RequestException: ìš”ì²­ ì—ëŸ¬ ë°œìƒ ì‹œ
        """
        self._wait_for_request_interval()
        
        # OC íŒŒë¼ë¯¸í„° ì¶”ê°€
        params['OC'] = self.oc_parameter
        
        try:
            response = self.session.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            
            # JSON ì‘ë‹µ íŒŒì‹±
            data = response.json()
            
            logger.debug(f"API ìš”ì²­ ì„±ê³µ: {params.get('target', 'unknown')}")
            return data
            
        except requests.exceptions.HTTPError as e:
            logger.error(f"HTTP ì—ëŸ¬ ë°œìƒ: {e}, ì‘ë‹µ: {response.text if 'response' in locals() else 'N/A'}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"ìš”ì²­ ì—ëŸ¬ ë°œìƒ: {e}")
            raise
        except ValueError as e:
            logger.error(f"JSON íŒŒì‹± ì—ëŸ¬: {e}")
            raise
    
    def get_legal_term_list(self, query: str = "", page: int = 1, 
                           per_page: int = 100, sort: str = "rasc") -> Dict[str, Any]:
        """
        ë²•ë ¹ìš©ì–´ ëª©ë¡ ì¡°íšŒ
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
            per_page: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜
            sort: ì •ë ¬ì˜µì…˜ (rasc: ë“±ë¡ì¼ì ì˜¤ë¦„ì°¨ìˆœ, rdes: ë“±ë¡ì¼ì ë‚´ë¦¼ì°¨ìˆœ, 
                           lasc: ë²•ë ¹ìš©ì–´ëª… ì˜¤ë¦„ì°¨ìˆœ, ldes: ë²•ë ¹ìš©ì–´ëª… ë‚´ë¦¼ì°¨ìˆœ)
            
        Returns:
            ë²•ë ¹ìš©ì–´ ëª©ë¡ ë°ì´í„°
        """
        params = {
            'OC': self.oc_parameter,
            'target': 'lstrm',
            'type': 'JSON',
            'query': query,
            'page': page,
            'display': per_page,
            'sort': sort
        }
        
        logger.info(f"ë²•ë ¹ìš©ì–´ ëª©ë¡ ì¡°íšŒ - ì¿¼ë¦¬: '{query}', í˜ì´ì§€: {page}, í¬ê¸°: {per_page}, ì •ë ¬: {sort}")
        
        return self._make_request(params)
    
    def get_legal_terms_page(self, page: int, sort: str = "rasc", per_page: int = 100) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • í˜ì´ì§€ì˜ ë²•ë ¹ìš©ì–´ ëª©ë¡ ì¡°íšŒ
        
        Args:
            page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
            sort: ì •ë ¬ì˜µì…˜ (ê¸°ë³¸ê°’: rasc - ë“±ë¡ì¼ì ì˜¤ë¦„ì°¨ìˆœ)
            per_page: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (ê¸°ë³¸ê°’: 100)
            
        Returns:
            í•´ë‹¹ í˜ì´ì§€ì˜ ë²•ë ¹ìš©ì–´ ëª©ë¡
        """
        try:
            result = self.get_legal_term_list(query="", page=page, per_page=per_page, sort=sort)
            
            if result.get('LsTrmSearch') and result['LsTrmSearch'].get('lstrm'):
                lstrm = result['LsTrmSearch']['lstrm']
                # lstrmì´ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë°°ì—´ë¡œ ë³€í™˜
                if isinstance(lstrm, dict):
                    terms = [lstrm]
                else:
                    terms = lstrm
                logger.info(f"í˜ì´ì§€ {page} ì¡°íšŒ ì™„ë£Œ: {len(terms)}ê°œ í•­ëª©")
                return terms
            else:
                logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
                
        except Exception as e:
            logger.error(f"í˜ì´ì§€ {page} ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
    
    def get_legal_terms_count(self) -> int:
        """
        ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜ ì¡°íšŒ
        
        Returns:
            ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜
        """
        try:
            result = self.get_legal_term_list(query="", page=1, per_page=1, sort="rasc")
            
            if result.get('LsTrmSearch') and 'totalCnt' in result['LsTrmSearch']:
                total_count = int(result['LsTrmSearch']['totalCnt'])
                logger.info(f"ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜: {total_count:,}ê°œ")
                return total_count
            else:
                logger.warning("ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return 0
                
        except Exception as e:
            logger.error(f"ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
    
    def get_legal_term_detail(self, term_name: str) -> Dict[str, Any]:
        """
        ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ
        
        Args:
            term_name: ë²•ë ¹ìš©ì–´ëª…
            
        Returns:
            ë²•ë ¹ìš©ì–´ ìƒì„¸ ë°ì´í„°
        """
        # ìƒì„¸ ì¡°íšŒëŠ” ë³„ë„ URL ì‚¬ìš©
        detail_url = "http://www.law.go.kr/DRF/lawService.do"
        
        params = {
            'OC': self.oc_parameter,
            'target': 'lstrm',
            'type': 'JSON',
            'query': term_name
        }
        
        logger.debug(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ - ìš©ì–´ëª…: {term_name}")
        
        # ìƒì„¸ ì¡°íšŒëŠ” ë³„ë„ URLì´ë¯€ë¡œ ì§ì ‘ ìš”ì²­
        self._wait_for_request_interval()
        
        try:
            response = self.session.get(detail_url, params=params, timeout=30)
            response.raise_for_status()
            
            # ì‘ë‹µ ë‚´ìš© í™•ì¸
            response_text = response.text.strip()
            if not response_text:
                logger.warning(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ ì‘ë‹µì´ ë¹„ì–´ìˆìŒ: {term_name}")
                return {"error": "empty_response", "term_name": term_name}
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                data = response.json()
                logger.debug(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ ì„±ê³µ: {term_name}")
                return data
            except ValueError as e:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì‘ë‹µ ë‚´ìš©: {response_text[:200]}...")
                return {
                    "error": "json_parse_error", 
                    "term_name": term_name,
                    "response_text": response_text[:500]  # ì²˜ìŒ 500ìë§Œ ì €ì¥
                }
            
        except requests.exceptions.HTTPError as e:
            logger.error(f"HTTP ì—ëŸ¬ ë°œìƒ: {e}, ì‘ë‹µ: {response.text if 'response' in locals() else 'N/A'}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"ìš”ì²­ ì—ëŸ¬ ë°œìƒ: {e}")
            raise
    
    def get_legal_terms_with_details(self, query: str = "", max_pages: int = None, 
                                   sort: str = "rasc", batch_size: int = 1000, 
                                   save_batches: bool = True, resume_from_checkpoint: bool = False,
                                   resume_from_page: int = 1) -> List[Dict[str, Any]]:
        """
        ë²•ë ¹ìš©ì–´ ëª©ë¡ê³¼ ìƒì„¸ ì •ë³´ë¥¼ í•¨ê»˜ ì¡°íšŒ (ë°°ì¹˜ ì €ì¥ ì§€ì›)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (Noneì´ë©´ ëª¨ë“  í˜ì´ì§€)
            sort: ì •ë ¬ì˜µì…˜ (ê¸°ë³¸ê°’: rasc - ë“±ë¡ì¼ì ì˜¤ë¦„ì°¨ìˆœ)
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1000ê°œ)
            save_batches: ë°°ì¹˜ë³„ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            resume_from_checkpoint: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ ì—¬ë¶€
            resume_from_page: ì¬ì‹œì‘í•  í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            ìƒì„¸ ì •ë³´ê°€ í¬í•¨ëœ ë²•ë ¹ìš©ì–´ ëª©ë¡
        """
        # ë¨¼ì € ëª©ë¡ ì¡°íšŒ (ë°°ì¹˜ ì €ì¥)
        terms_list = self.get_all_legal_terms(query, max_pages, sort, True, batch_size, save_batches)
        
        logger.info(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹œì‘ - ì´ {len(terms_list)}ê°œ ìš©ì–´")
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘í•˜ëŠ” ê²½ìš°
        start_index = 0
        if resume_from_checkpoint:
            # ìƒì„¸ ë°°ì¹˜ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
            from scripts.data_collection.law_open_api.utils.checkpoint_manager import CheckpointManager
            checkpoint_manager = CheckpointManager()
            detailed_cp = checkpoint_manager.load_latest_detailed_batch_checkpoint("legal_terms")
            
            if detailed_cp:
                start_index = detailed_cp.get("end_index", 0)
                print(f"ğŸ”„ ìƒì„¸ ë°°ì¹˜ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: ì¸ë±ìŠ¤ {start_index}ë¶€í„°")
                logger.info(f"ìƒì„¸ ë°°ì¹˜ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: ì¸ë±ìŠ¤ {start_index}ë¶€í„°")
        
        detailed_terms = []
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if save_batches:
            batch_dir = Path("data/raw/law_open_api/legal_terms/detailed_batches")
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        error_count = 0
        
        for i, term in enumerate(terms_list, 1):
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘í•˜ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
            if i <= start_index:
                continue
                
            try:
                term_name = term.get('ë²•ë ¹ìš©ì–´ëª…', '')
                if term_name:
                    # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                    detail = self.get_legal_term_detail(term_name)
                    
                    # ëª©ë¡ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                    combined_term = {
                        **term,  # ëª©ë¡ ì •ë³´
                        'detailed_info': detail  # ìƒì„¸ ì •ë³´
                    }
                    detailed_terms.append(combined_term)
                    current_batch.append(combined_term)
                    
                    logger.info(f"ìƒì„¸ ì •ë³´ ì¡°íšŒ ì™„ë£Œ ({i}/{len(terms_list)}): {term_name}")
                else:
                    logger.warning(f"ìš©ì–´ëª…ì´ ì—†ì–´ ìƒì„¸ ì¡°íšŒ ê±´ë„ˆëœ€: {term}")
                    detailed_terms.append(term)
                    current_batch.append(term)
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                if save_batches and len(current_batch) >= batch_size:
                    batch_count += 1
                    batch_file = batch_dir / f"detailed_batch_{timestamp}_{batch_count:03d}.json"
                    
                    batch_data = {
                        "batch_number": batch_count,
                        "batch_size": len(current_batch),
                        "start_index": i - len(current_batch) + 1,
                        "end_index": i,
                        "timestamp": datetime.now().isoformat(),
                        "terms": current_batch
                    }
                    
                    with open(batch_file, 'w', encoding='utf-8') as f:
                        json.dump(batch_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"  ğŸ’¾ ìƒì„¸ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                    logger.info(f"ìƒì„¸ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                    
                    # ìƒì„¸ ë°°ì¹˜ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    if resume_from_checkpoint:
                        from scripts.data_collection.law_open_api.utils.checkpoint_manager import CheckpointManager
                        checkpoint_manager = CheckpointManager()
                        checkpoint_manager.save_detailed_batch_checkpoint(
                            "legal_terms", batch_count, batch_size, 
                            i - len(current_batch) + 1, i, current_batch, error_count
                        )
                    
                    current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if i % 100 == 0 or i == len(terms_list):
                    progress = (i / len(terms_list)) * 100
                    print(f"  ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì§„í–‰: {i}/{len(terms_list)} ({progress:.1f}%)")
                    
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                time.sleep(1.0)
                    
            except Exception as e:
                error_count += 1
                logger.error(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {term.get('ë²•ë ¹ìš©ì–´ëª…', 'Unknown')} - {e}")
                # ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨í•´ë„ ëª©ë¡ ì •ë³´ëŠ” í¬í•¨
                detailed_terms.append(term)
                current_batch.append(term)
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"detailed_batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "start_index": len(terms_list) - len(current_batch) + 1,
                "end_index": len(terms_list),
                "timestamp": datetime.now().isoformat(),
                "terms": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ ìƒì„¸ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
            logger.info(f"ë§ˆì§€ë§‰ ìƒì„¸ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
            
            # ë§ˆì§€ë§‰ ìƒì„¸ ë°°ì¹˜ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if resume_from_checkpoint:
                from scripts.data_collection.law_open_api.utils.checkpoint_manager import CheckpointManager
                checkpoint_manager = CheckpointManager()
                checkpoint_manager.save_detailed_batch_checkpoint(
                    "legal_terms", batch_count, batch_size, 
                    len(terms_list) - len(current_batch) + 1, len(terms_list), current_batch, error_count
                )
        
        # ìƒì„¸ ë°°ì¹˜ ìš”ì•½ ì •ë³´ ì €ì¥
        if save_batches and batch_count > 0:
            summary_file = batch_dir / f"detailed_batch_summary_{timestamp}.json"
            summary_data = {
                "total_batches": batch_count,
                "total_terms": len(detailed_terms),
                "batch_size": batch_size,
                "timestamp": timestamp,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "query": query,
                "sort": sort,
                "max_pages": max_pages
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ“Š ìƒì„¸ ë°°ì¹˜ ìš”ì•½ ì €ì¥: {batch_count}ê°œ ë°°ì¹˜, {len(detailed_terms):,}ê°œ í•­ëª© -> {summary_file.name}")
        
        logger.info(f"ë²•ë ¹ìš©ì–´ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì™„ë£Œ - ì´ {len(detailed_terms)}ê°œ ìš©ì–´")
        return detailed_terms
    
    def get_all_legal_terms(self, query: str = "", max_pages: int = None, 
                           sort: str = "rasc", resume_from_checkpoint: bool = True,
                           batch_size: int = 1000, save_batches: bool = True) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  ë²•ë ¹ìš©ì–´ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬, ì²´í¬í¬ì¸íŠ¸ ì§€ì›, ë°°ì¹˜ ì €ì¥)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (Noneì´ë©´ ëª¨ë“  í˜ì´ì§€)
            sort: ì •ë ¬ì˜µì…˜ (ê¸°ë³¸ê°’: rasc - ë“±ë¡ì¼ì ì˜¤ë¦„ì°¨ìˆœ)
            resume_from_checkpoint: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ ì—¬ë¶€
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1000ê°œ)
            save_batches: ë°°ì¹˜ë³„ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            ëª¨ë“  ë²•ë ¹ìš©ì–´ ëª©ë¡
        """
        all_terms = []
        page = 1
        total_pages = 0
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if save_batches:
            batch_dir = Path("data/raw/law_open_api/legal_terms/batches")
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ ì—¬ë¶€ í™•ì¸
        if resume_from_checkpoint:
            checkpoint = self.checkpoint_manager.load_page_checkpoint("legal_terms")
            if checkpoint:
                page = checkpoint.get("current_page", 1)
                total_pages = checkpoint.get("total_pages", 0)
                collected_count = checkpoint.get("collected_count", 0)
                batch_count = checkpoint.get("batch_count", 0)
                print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: í˜ì´ì§€ {page}ë¶€í„° (ì´ë¯¸ ìˆ˜ì§‘: {collected_count:,}ê°œ, ë°°ì¹˜: {batch_count}ê°œ)")
                logger.info(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘: í˜ì´ì§€ {page}, ìˆ˜ì§‘ëœ í•­ëª©: {collected_count}, ë°°ì¹˜: {batch_count}")
        
        logger.info(f"ì „ì²´ ë²•ë ¹ìš©ì–´ ì¡°íšŒ ì‹œì‘ - ì¿¼ë¦¬: '{query}', ìµœëŒ€í˜ì´ì§€: {max_pages or 'ë¬´ì œí•œ'}, ì •ë ¬: {sort}, ë°°ì¹˜í¬ê¸°: {batch_size}")
        
        # ì²« í˜ì´ì§€ë¡œ ì „ì²´ ê°œìˆ˜ í™•ì¸ (ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ì„ ë•Œë§Œ)
        if page == 1:
            first_response = self.get_legal_term_list(query, 1, 100, sort)
            if first_response and 'LsTrmSearch' in first_response:
                total_count = int(first_response['LsTrmSearch'].get('totalCnt', 0))
                total_pages = (total_count + 99) // 100  # í˜ì´ì§€ë‹¹ 100ê°œ
                print(f"  ì „ì²´ ë²•ë ¹ìš©ì–´ ìˆ˜: {total_count:,}ê°œ (ì´ {total_pages}í˜ì´ì§€)")
        
        while True:
            if max_pages and page > max_pages:
                break
            
            try:
                if page == 1 and not resume_from_checkpoint:
                    response = first_response
                else:
                    response = self.get_legal_term_list(query, page, 100, sort)
                
                # ì‘ë‹µ ë°ì´í„° í™•ì¸
                if not response or 'LsTrmSearch' not in response:
                    logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ë°ì´í„° ì—†ìŒ")
                    break
                
                search_result = response['LsTrmSearch']
                if 'lstrm' not in search_result:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë¹ˆ ê²°ê³¼ - ìˆ˜ì§‘ ì™„ë£Œ")
                    break
                
                # lstrmì´ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                terms = search_result['lstrm']
                if isinstance(terms, dict):
                    terms = [terms]
                
                all_terms.extend(terms)
                current_batch.extend(terms)
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                if save_batches and len(current_batch) >= batch_size:
                    batch_count += 1
                    batch_file = batch_dir / f"batch_{timestamp}_{batch_count:03d}.json"
                    
                    batch_data = {
                        "batch_number": batch_count,
                        "batch_size": len(current_batch),
                        "start_page": page - len(current_batch) // 100 + 1,
                        "end_page": page,
                        "timestamp": datetime.now().isoformat(),
                        "terms": current_batch
                    }
                    
                    with open(batch_file, 'w', encoding='utf-8') as f:
                        json.dump(batch_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"  ğŸ’¾ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                    logger.info(f"ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                    
                    current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                
                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ 10í˜ì´ì§€ë§ˆë‹¤)
                if page % 10 == 0:
                    last_term_id = terms[-1].get('ë²•ë ¹ìš©ì–´ID', '') if terms else ''
                    checkpoint_data = {
                        "data_type": "legal_terms",
                        "current_page": page,
                        "total_pages": total_pages,
                        "collected_count": len(all_terms),
                        "batch_count": batch_count,
                        "last_term_id": last_term_id,
                        "timestamp": datetime.now().isoformat(),
                        "status": "in_progress"
                    }
                    self.checkpoint_manager.save_page_checkpoint(
                        "legal_terms", page, total_pages, len(all_terms), last_term_id
                    )
                    print(f"  ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: í˜ì´ì§€ {page}")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if page % 10 == 0 or (total_pages > 0 and page >= total_pages):
                    progress = (page / total_pages * 100) if total_pages > 0 else 0
                    print(f"  í˜ì´ì§€ {page} ìˆ˜ì§‘ ì™„ë£Œ - ëˆ„ì : {len(all_terms):,}ê°œ ({progress:.1f}%)")
                
                logger.info(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì™„ë£Œ - {len(terms)}ê°œ ìš©ì–´, ëˆ„ì : {len(all_terms)}ê°œ")
                
                page += 1
                
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸° (1ì´ˆ)
                time.sleep(1.0)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                break
        
        logger.info(f"ì „ì²´ ë²•ë ¹ìš©ì–´ ì¡°íšŒ ì™„ë£Œ - ì´ {len(all_terms)}ê°œ ìš©ì–´")
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "start_page": page - len(current_batch) // 100,
                "end_page": page - 1,
                "timestamp": datetime.now().isoformat(),
                "terms": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
            logger.info(f"ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
        
        # ë°°ì¹˜ ìš”ì•½ ì •ë³´ ì €ì¥
        if save_batches and batch_count > 0:
            summary_file = batch_dir / f"batch_summary_{timestamp}.json"
            summary_data = {
                "total_batches": batch_count,
                "total_terms": len(all_terms),
                "batch_size": batch_size,
                "timestamp": timestamp,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "query": query,
                "sort": sort,
                "max_pages": max_pages
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ“Š ë°°ì¹˜ ìš”ì•½ ì €ì¥: {batch_count}ê°œ ë°°ì¹˜, {len(all_terms):,}ê°œ í•­ëª© -> {summary_file.name}")
        
        # ìˆ˜ì§‘ ì™„ë£Œ ì‹œ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ
        if len(all_terms) > 0:
            self.checkpoint_manager.clear_page_checkpoint("legal_terms")
            print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ - ì²´í¬í¬ì¸íŠ¸ ì‚­ì œë¨")
        
        return all_terms
    
    def search_constitutional_decisions(self, 
                                      query: str = "",
                                      search: int = 1,
                                      display: int = 20,
                                      page: int = 1,
                                      sort: str = "dasc",
                                      date: Optional[str] = None,
                                      edYd: Optional[str] = None,
                                      nb: Optional[int] = None) -> Dict[str, Any]:
        """
        í—Œì¬ê²°ì •ë¡€ ëª©ë¡ ì¡°íšŒ
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            search: ê²€ìƒ‰ë²”ìœ„ (1: í—Œì¬ê²°ì •ë¡€ëª…, 2: ë³¸ë¬¸ê²€ìƒ‰)
            display: ê²€ìƒ‰ëœ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸: 20, ìµœëŒ€: 100)
            page: ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ (ê¸°ë³¸: 1)
            sort: ì •ë ¬ì˜µì…˜ (dasc: ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ, ddes: ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ, 
                           lasc: ì‚¬ê±´ëª… ì˜¤ë¦„ì°¨ìˆœ, ldes: ì‚¬ê±´ëª… ë‚´ë¦¼ì°¨ìˆœ,
                           nasc: ì‚¬ê±´ë²ˆí˜¸ ì˜¤ë¦„ì°¨ìˆœ, ndes: ì‚¬ê±´ë²ˆí˜¸ ë‚´ë¦¼ì°¨ìˆœ,
                           efasc: ì¢…êµ­ì¼ì ì˜¤ë¦„ì°¨ìˆœ, efdes: ì¢…êµ­ì¼ì ë‚´ë¦¼ì°¨ìˆœ)
            date: ì¢…êµ­ì¼ì (YYYYMMDD í˜•ì‹)
            edYd: ì¢…êµ­ì¼ì ê¸°ê°„ ê²€ìƒ‰
            nb: ì‚¬ê±´ë²ˆí˜¸
            
        Returns:
            í—Œì¬ê²°ì •ë¡€ ëª©ë¡ ë°ì´í„°
        """
        params = {
            'OC': self.oc_parameter,
            'target': 'detc',
            'type': 'JSON',
            'query': query,
            'search': search,
            'display': display,
            'page': page,
            'sort': sort
        }
        
        if date:
            params['date'] = date
        if edYd:
            params['edYd'] = edYd
        if nb:
            params['nb'] = nb
            
        logger.info(f"í—Œì¬ê²°ì •ë¡€ ëª©ë¡ ì¡°íšŒ - ì¿¼ë¦¬: '{query}', í˜ì´ì§€: {page}, í¬ê¸°: {display}, ì •ë ¬: {sort}")
        
        return self._make_request(params)
    
    def get_constitutional_decision_detail(self, 
                                        decision_id: str,
                                        decision_name: Optional[str] = None) -> Dict[str, Any]:
        """
        í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ
        
        Args:
            decision_id: í—Œì¬ê²°ì •ë¡€ ì¼ë ¨ë²ˆí˜¸
            decision_name: í—Œì¬ê²°ì •ë¡€ëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ë°ì´í„°
        """
        # ìƒì„¸ ì¡°íšŒëŠ” ë³„ë„ URL ì‚¬ìš©
        detail_url = "http://www.law.go.kr/DRF/lawService.do"
        
        params = {
            'OC': self.oc_parameter,
            'target': 'detc',
            'type': 'JSON',
            'ID': decision_id
        }
        
        if decision_name:
            params['LM'] = decision_name
            
        logger.debug(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ - ID: {decision_id}, ì´ë¦„: {decision_name}")
        
        # ìƒì„¸ ì¡°íšŒëŠ” ë³„ë„ URLì´ë¯€ë¡œ ì§ì ‘ ìš”ì²­
        self._wait_for_request_interval()
        
        try:
            response = self.session.get(detail_url, params=params, timeout=30)
            response.raise_for_status()
            
            # ì‘ë‹µ ë‚´ìš© í™•ì¸
            response_text = response.text.strip()
            if not response_text:
                logger.warning(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ ì‘ë‹µì´ ë¹„ì–´ìˆìŒ: {decision_id}")
                return {"error": "empty_response", "decision_id": decision_id}
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                data = response.json()
                logger.debug(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ ì„±ê³µ: {decision_id}")
                return data
            except ValueError as e:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì‘ë‹µ ë‚´ìš©: {response_text[:200]}...")
                return {
                    "error": "json_parse_error", 
                    "decision_id": decision_id,
                    "response_text": response_text[:500]  # ì²˜ìŒ 500ìë§Œ ì €ì¥
                }
            
        except requests.exceptions.HTTPError as e:
            logger.error(f"HTTP ì—ëŸ¬ ë°œìƒ: {e}, ì‘ë‹µ: {response.text if 'response' in locals() else 'N/A'}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"ìš”ì²­ ì—ëŸ¬ ë°œìƒ: {e}")
            raise
    
    def get_all_constitutional_decisions(self, 
                                       query: str = "", 
                                       max_pages: int = None,
                                       sort: str = "dasc",
                                       include_details: bool = True,
                                       batch_size: int = 100,
                                       save_batches: bool = True) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  í—Œì¬ê²°ì •ë¡€ ì¡°íšŒ (ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ, ë°°ì¹˜ ì €ì¥ ì§€ì›)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (Noneì´ë©´ ëª¨ë“  í˜ì´ì§€)
            sort: ì •ë ¬ì˜µì…˜ (ê¸°ë³¸ê°’: dasc - ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ)
            include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
            batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 100ê°œ)
            save_batches: ë°°ì¹˜ë³„ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            í—Œì¬ê²°ì •ë¡€ ëª©ë¡ (ìƒì„¸ ì •ë³´ í¬í•¨)
        """
        all_decisions = []
        page = 1
        total_pages = 0
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if save_batches:
            batch_dir = Path("data/raw/constitutional_decisions/batches")
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        logger.info(f"ì „ì²´ í—Œì¬ê²°ì •ë¡€ ì¡°íšŒ ì‹œì‘ - ì¿¼ë¦¬: '{query}', ìµœëŒ€í˜ì´ì§€: {max_pages or 'ë¬´ì œí•œ'}, ì •ë ¬: {sort}, ë°°ì¹˜í¬ê¸°: {batch_size}")
        
        # ì²« í˜ì´ì§€ë¡œ ì „ì²´ ê°œìˆ˜ í™•ì¸
        if page == 1:
            first_response = self.search_constitutional_decisions(query, 1, 100, 1, sort)
            if first_response and 'DetcSearch' in first_response:
                total_count = int(first_response['DetcSearch'].get('totalCnt', 0))
                total_pages = (total_count + 99) // 100  # í˜ì´ì§€ë‹¹ 100ê°œ
                print(f"  ì „ì²´ í—Œì¬ê²°ì •ë¡€ ìˆ˜: {total_count:,}ê°œ (ì´ {total_pages}í˜ì´ì§€)")
        
        while True:
            if max_pages and page > max_pages:
                break
            
            try:
                if page == 1:
                    response = first_response
                else:
                    response = self.search_constitutional_decisions(query, 1, 100, page, sort)
                
                # ì‘ë‹µ ë°ì´í„° í™•ì¸
                if not response or 'DetcSearch' not in response:
                    logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ë°ì´í„° ì—†ìŒ")
                    break
                
                search_result = response['DetcSearch']
                if 'detc' not in search_result:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë¹ˆ ê²°ê³¼ - ìˆ˜ì§‘ ì™„ë£Œ")
                    break
                
                # detcê°€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                decisions = search_result['detc']
                if isinstance(decisions, dict):
                    decisions = [decisions]
                
                # ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ì²˜ë¦¬
                if include_details:
                    detailed_decisions = []
                    for decision in decisions:
                        decision_id = decision.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸')
                        if decision_id:
                            try:
                                # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                                detail = self.get_constitutional_decision_detail(decision_id)
                                
                                # ëª©ë¡ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                                combined_decision = {
                                    **decision,  # ëª©ë¡ ì •ë³´
                                    'detailed_info': detail  # ìƒì„¸ ì •ë³´
                                }
                                detailed_decisions.append(combined_decision)
                                
                                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                                time.sleep(1.0)
                                
                            except Exception as e:
                                logger.error(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {decision_id} - {e}")
                                detailed_decisions.append(decision)
                        else:
                            detailed_decisions.append(decision)
                    
                    all_decisions.extend(detailed_decisions)
                    current_batch.extend(detailed_decisions)
                else:
                    all_decisions.extend(decisions)
                    current_batch.extend(decisions)
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                if save_batches and len(current_batch) >= batch_size:
                    batch_count += 1
                    batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
                    
                    batch_data = {
                        "batch_number": batch_count,
                        "batch_size": len(current_batch),
                        "start_page": page - len(current_batch) // 100 + 1,
                        "end_page": page,
                        "timestamp": datetime.now().isoformat(),
                        "decisions": current_batch
                    }
                    
                    with open(batch_file, 'w', encoding='utf-8') as f:
                        json.dump(batch_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"  ğŸ’¾ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                    logger.info(f"í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                    
                    current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if page % 10 == 0 or (total_pages > 0 and page >= total_pages):
                    progress = (page / total_pages * 100) if total_pages > 0 else 0
                    print(f"  í˜ì´ì§€ {page} ìˆ˜ì§‘ ì™„ë£Œ - ëˆ„ì : {len(all_decisions):,}ê°œ ({progress:.1f}%)")
                
                logger.info(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì™„ë£Œ - {len(decisions)}ê°œ ê²°ì •ë¡€, ëˆ„ì : {len(all_decisions)}ê°œ")
                
                page += 1
                
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸° (1ì´ˆ)
                time.sleep(1.0)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                break
        
        logger.info(f"ì „ì²´ í—Œì¬ê²°ì •ë¡€ ì¡°íšŒ ì™„ë£Œ - ì´ {len(all_decisions)}ê°œ ê²°ì •ë¡€")
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "start_page": page - len(current_batch) // 100,
                "end_page": page - 1,
                "timestamp": datetime.now().isoformat(),
                "decisions": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
            logger.info(f"ë§ˆì§€ë§‰ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
        
        # ë°°ì¹˜ ìš”ì•½ ì •ë³´ ì €ì¥
        if save_batches and batch_count > 0:
            summary_file = batch_dir / f"constitutional_batch_summary_{timestamp}.json"
            summary_data = {
                "total_batches": batch_count,
                "total_decisions": len(all_decisions),
                "batch_size": batch_size,
                "timestamp": timestamp,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "query": query,
                "sort": sort,
                "max_pages": max_pages,
                "include_details": include_details
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ“Š í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ ìš”ì•½ ì €ì¥: {batch_count}ê°œ ë°°ì¹˜, {len(all_decisions):,}ê°œ í•­ëª© -> {summary_file.name}")
        
        return all_decisions
    
    def search_current_laws(self, 
                           query: str = "",
                           search: int = 1,
                           display: int = 20,
                           page: int = 1,
                           sort: str = "ldes",
                           nw: int = 3,
                           knd: str = "A0002",
                           efYd: str = None,
                           date: str = None,
                           ancYd: str = None,
                           ancNo: str = None,
                           rrClsCd: str = None,
                           nb: int = None,
                           org: str = None,
                           gana: str = None) -> Dict[str, Any]:
        """
        í˜„í–‰ë²•ë ¹ ëª©ë¡ ì¡°íšŒ
        
        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            search: ê²€ìƒ‰ ë²”ìœ„ (1: ë²•ë ¹ëª…, 2: ë³¸ë¬¸ê²€ìƒ‰)
            display: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ 20, ìµœëŒ€ 100)
            page: ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ (ê¸°ë³¸ 1)
            sort: ì •ë ¬ ì˜µì…˜ (ê¸°ë³¸ ldes: ë²•ë ¹ë‚´ë¦¼ì°¨ìˆœ)
            nw: ê²€ìƒ‰ ë²”ìœ„ (3: í˜„í–‰)
            knd: ë²•ë ¹ì¢…ë¥˜ (A0002: ë²•ë¥ )
            efYd: ì‹œí–‰ì¼ì ë²”ìœ„ ê²€ìƒ‰
            date: ê³µí¬ì¼ì ê²€ìƒ‰
            ancYd: ê³µí¬ì¼ì ë²”ìœ„ ê²€ìƒ‰
            ancNo: ê³µí¬ë²ˆí˜¸ ë²”ìœ„ ê²€ìƒ‰
            rrClsCd: ë²•ë ¹ ì œê°œì • ì¢…ë¥˜
            nb: ë²•ë ¹ì˜ ê³µí¬ë²ˆí˜¸ ê²€ìƒ‰
            org: ì†Œê´€ë¶€ì²˜ë³„ ê²€ìƒ‰
            gana: ì‚¬ì „ì‹ ê²€ìƒ‰
            
        Returns:
            í˜„í–‰ë²•ë ¹ ëª©ë¡ ë°ì´í„°
        """
        params = {
            'target': 'eflaw',
            'type': 'JSON',
            'query': query,
            'search': search,
            'display': min(display, 100),  # ìµœëŒ€ 100ê°œë¡œ ì œí•œ
            'page': page,
            'sort': sort,
            'nw': nw,
            'knd': knd
        }
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ê°€
        if efYd:
            params['efYd'] = efYd
        if date:
            params['date'] = date
        if ancYd:
            params['ancYd'] = ancYd
        if ancNo:
            params['ancNo'] = ancNo
        if rrClsCd:
            params['rrClsCd'] = rrClsCd
        if nb:
            params['nb'] = nb
        if org:
            params['org'] = org
        if gana:
            params['gana'] = gana
        
        logger.info(f"í˜„í–‰ë²•ë ¹ ëª©ë¡ ì¡°íšŒ ìš”ì²­ - í˜ì´ì§€: {page}, ê²€ìƒ‰ì–´: '{query}', ì •ë ¬: {sort}")
        
        try:
            response = self._make_request(params)
            logger.info(f"í˜„í–‰ë²•ë ¹ ëª©ë¡ ì¡°íšŒ ì„±ê³µ - í˜ì´ì§€: {page}")
            return response
        except Exception as e:
            logger.error(f"í˜„í–‰ë²•ë ¹ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ - í˜ì´ì§€: {page}, ì—ëŸ¬: {e}")
            raise
    
    def get_current_law_detail(self, 
                              law_id: str = None,
                              mst: str = None,
                              efYd: int = None,
                              jo: str = None,
                              chrClsCd: str = None) -> Dict[str, Any]:
        """
        í˜„í–‰ë²•ë ¹ ë³¸ë¬¸ ì¡°íšŒ
        
        Args:
            law_id: ë²•ë ¹ ID (ID ë˜ëŠ” MST ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì…ë ¥)
            mst: ë²•ë ¹ ë§ˆìŠ¤í„° ë²ˆí˜¸ - ë²•ë ¹í…Œì´ë¸”ì˜ lsi_seq ê°’ì„ ì˜ë¯¸í•¨
            efYd: ë²•ë ¹ì˜ ì‹œí–‰ì¼ì (ID ì…ë ¥ì‹œì—ëŠ” ë¬´ì‹œí•˜ëŠ” ê°’ìœ¼ë¡œ ì…ë ¥í•˜ì§€ ì•ŠìŒ)
            jo: ì¡°ë²ˆí˜¸ (ìƒëµì‹œ ëª¨ë“  ì¡° í‘œì‹œ, 6ìë¦¬ìˆ«ì: ì¡°ë²ˆí˜¸(4ìë¦¬)+ì¡°ê°€ì§€ë²ˆí˜¸(2ìë¦¬))
            chrClsCd: ì›ë¬¸/í•œê¸€ ì—¬ë¶€ (ìƒëµì‹œ ê¸°ë³¸ê°’: í•œê¸€, 010202: í•œê¸€, 010201: ì›ë¬¸)
            
        Returns:
            í˜„í–‰ë²•ë ¹ ë³¸ë¬¸ ë°ì´í„°
        """
        if not law_id and not mst:
            raise ValueError("law_id ë˜ëŠ” mst ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        params = {
            'target': 'eflaw',
            'type': 'JSON'
        }
        
        if law_id:
            params['ID'] = law_id
        else:
            params['MST'] = mst
            if efYd:
                params['efYd'] = efYd
        
        if jo:
            params['JO'] = jo
        if chrClsCd:
            params['chrClsCd'] = chrClsCd
        
        logger.info(f"í˜„í–‰ë²•ë ¹ ë³¸ë¬¸ ì¡°íšŒ ìš”ì²­ - ID: {law_id}, MST: {mst}")
        
        try:
            # ë³¸ë¬¸ ì¡°íšŒëŠ” ë³„ë„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            self._wait_for_request_interval()
            params['OC'] = self.oc_parameter
            
            response = self.session.get(self.detail_url, params=params, timeout=30)
            response.raise_for_status()
            
            # JSON ì‘ë‹µ íŒŒì‹±
            data = response.json()
            logger.info(f"í˜„í–‰ë²•ë ¹ ë³¸ë¬¸ ì¡°íšŒ ì„±ê³µ - ID: {law_id}, MST: {mst}")
            return data
        except Exception as e:
            logger.error(f"í˜„í–‰ë²•ë ¹ ë³¸ë¬¸ ì¡°íšŒ ì‹¤íŒ¨ - ID: {law_id}, MST: {mst}, ì—ëŸ¬: {e}")
            raise
    
    def get_all_current_laws(self, 
                           query: str = "",
                           max_pages: int = None,
                           start_page: int = 1,
                           sort: str = "ldes",
                           batch_size: int = 10,
                           save_batches: bool = True,
                           include_details: bool = True,
                           resume_from_checkpoint: bool = False) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  í˜„í–‰ë²•ë ¹ ì¡°íšŒ (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            sort: ì •ë ¬ ì˜µì…˜
            batch_size: ë°°ì¹˜ í¬ê¸°
            save_batches: ë°°ì¹˜ ì €ì¥ ì—¬ë¶€
            include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
            resume_from_checkpoint: ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì¬ì‹œì‘ ì—¬ë¶€
            
        Returns:
            ëª¨ë“  í˜„í–‰ë²•ë ¹ ëª©ë¡
        """
        logger.info(f"ì „ì²´ í˜„í–‰ë²•ë ¹ ì¡°íšŒ ì‹œì‘ - ê²€ìƒ‰ì–´: '{query}', ë°°ì¹˜í¬ê¸°: {batch_size}, ìƒì„¸ì •ë³´: {include_details}")
        
        all_laws = []
        page = start_page
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if save_batches:
            batch_dir = Path("data/raw/law_open_api/current_laws/batches")
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ê¸°ì¡´ ë°°ì¹˜ íŒŒì¼ë“¤ì—ì„œ ë§ˆì§€ë§‰ ë°°ì¹˜ ë²ˆí˜¸ ì°¾ê¸°
            existing_batches = list(batch_dir.glob("current_law_batch_*_*.json"))
            if existing_batches:
                # íŒŒì¼ëª…ì—ì„œ ë°°ì¹˜ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: current_law_batch_20251023_220223_001.json)
                batch_numbers = []
                for batch_file in existing_batches:
                    try:
                        # íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
                        parts = batch_file.stem.split('_')
                        if len(parts) >= 4 and parts[-1].isdigit():
                            batch_num = int(parts[-1])
                            # ë¹„ì •ìƒì ìœ¼ë¡œ í° ë°°ì¹˜ ë²ˆí˜¸ëŠ” ë¬´ì‹œ (220811 ê°™ì€)
                            if batch_num < 10000:  # í•©ë¦¬ì ì¸ ë²”ìœ„ ë‚´ì—ì„œë§Œ
                                batch_numbers.append(batch_num)
                    except:
                        continue
                
                if batch_numbers:
                    batch_count = max(batch_numbers)
                    logger.info(f"ê¸°ì¡´ ë°°ì¹˜ íŒŒì¼ ë°œê²¬ - ë§ˆì§€ë§‰ ë°°ì¹˜ ë²ˆí˜¸: {batch_count}")
        
        # ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì¬ì‹œì‘
        if resume_from_checkpoint:
            checkpoint_info = self.checkpoint_manager.get_resume_info("current_laws")
            if checkpoint_info["has_page_checkpoint"]:
                page = checkpoint_info["resume_from_page"]
                logger.info(f"ì²´í¬í¬ì¸íŠ¸ë¶€í„° ì¬ì‹œì‘ - í˜ì´ì§€: {page}")
        
        while True:
            if max_pages and page > start_page + max_pages - 1:
                logger.info(f"ìµœëŒ€ í˜ì´ì§€ ìˆ˜({max_pages}) ë„ë‹¬ - ìˆ˜ì§‘ ì¤‘ë‹¨ (ì‹œì‘: {start_page}, í˜„ì¬: {page})")
                break
            
            try:
                # API ìš”ì²­
                response = self.search_current_laws(
                    query=query,
                    display=100,  # í•œ ë²ˆì— ìµœëŒ€ 100ê°œì”© ì¡°íšŒ
                    page=page,
                    sort=sort,
                    nw=3,  # í˜„í–‰ë²•ë ¹ë§Œ
                    knd="A0002"  # ë²•ë¥ ë§Œ
                )
                
                if not response or 'LawSearch' not in response:
                    logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                    break
                
                search_result = response['LawSearch']
                if 'law' not in search_result:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë¹ˆ ê²°ê³¼ - ìˆ˜ì§‘ ì™„ë£Œ")
                    break
                
                # lawê°€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                page_laws = search_result['law']
                if isinstance(page_laws, dict):
                    page_laws = [page_laws]
                
                for law in page_laws:
                    if include_details:
                        try:
                            # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                            law_id = law.get('ë²•ë ¹ID')
                            if law_id:
                                detail = self.get_current_law_detail(law_id=law_id)
                                
                                # ëª©ë¡ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                                combined_law = {
                                    **law,  # ëª©ë¡ ì •ë³´
                                    'detailed_info': detail,  # ìƒì„¸ ì •ë³´ (API ë¬¸ì„œì˜ ëª¨ë“  í•„ë“œ í¬í•¨)
                                    'document_type': 'current_law',
                                    'collected_at': datetime.now().isoformat()
                                }
                                all_laws.append(combined_law)
                                current_batch.append(combined_law)
                                
                                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                                time.sleep(1.0)
                                
                        except Exception as e:
                            logger.error(f"í˜„í–‰ë²•ë ¹ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {law_id} - {e}")
                            law['document_type'] = 'current_law'
                            law['collected_at'] = datetime.now().isoformat()
                            all_laws.append(law)
                            current_batch.append(law)
                    else:
                        law['document_type'] = 'current_law'
                        law['collected_at'] = datetime.now().isoformat()
                        all_laws.append(law)
                        current_batch.append(law)
                    
                    # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                    if save_batches and len(current_batch) >= batch_size:
                        batch_count += 1
                        batch_file = batch_dir / f"current_law_batch_{timestamp}_{batch_count:03d}.json"
                        
                        # ì‹¤ì œ í˜ì´ì§€ ë²”ìœ„ ê³„ì‚°
                        laws_per_page = 100  # display=100ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ
                        start_page_for_batch = page - (len(current_batch) - 1) // laws_per_page
                        
                        batch_data = {
                            "batch_number": batch_count,
                            "batch_size": len(current_batch),
                            "start_page": start_page_for_batch,
                            "end_page": page,
                            "timestamp": datetime.now().isoformat(),
                            "laws": current_batch
                        }
                        
                        with open(batch_file, 'w', encoding='utf-8') as f:
                            json.dump(batch_data, f, ensure_ascii=False, indent=2)
                        
                        print(f"  ğŸ’¾ í˜„í–‰ë²•ë ¹ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                        logger.info(f"í˜„í–‰ë²•ë ¹ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                        
                        current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                        
                        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                        if resume_from_checkpoint:
                            self.checkpoint_manager.save_checkpoint("current_laws", page + 1, batch_count)
                
                logger.info(f"í˜ì´ì§€ {page} ì™„ë£Œ: {len(page_laws)}ê°œ ë²•ë ¹ ìˆ˜ì§‘")
                logger.info(f"ëˆ„ì  ìˆ˜ì§‘: {len(all_laws)}ê°œ ë²•ë ¹")
                
                page += 1
                
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                time.sleep(1.0)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                break
        
        logger.info(f"ì „ì²´ í˜„í–‰ë²•ë ¹ ì¡°íšŒ ì™„ë£Œ - ì´ {len(all_laws)}ê°œ ë²•ë ¹")
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"current_law_batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "start_page": page - len(current_batch) // 100,
                "end_page": page - 1,
                "timestamp": datetime.now().isoformat(),
                "laws": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ í˜„í–‰ë²•ë ¹ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
            logger.info(f"ë§ˆì§€ë§‰ í˜„í–‰ë²•ë ¹ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
        
        # ë°°ì¹˜ ìš”ì•½ ì •ë³´ ì €ì¥
        if save_batches and batch_count > 0:
            summary_file = batch_dir / f"current_law_batch_summary_{timestamp}.json"
            summary_data = {
                "total_batches": batch_count,
                "total_laws": len(all_laws),
                "batch_size": batch_size,
                "timestamp": timestamp,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "query": query,
                "sort": sort,
                "max_pages": max_pages,
                "include_details": include_details
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ“Š í˜„í–‰ë²•ë ¹ ë°°ì¹˜ ìš”ì•½ ì €ì¥: {batch_count}ê°œ ë°°ì¹˜, {len(all_laws):,}ê°œ í•­ëª© -> {summary_file.name}")
        
        return all_laws

    def test_connection(self) -> bool:
        """
        API ì—°ê²° í…ŒìŠ¤íŠ¸
        
        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘")
            response = self.get_legal_term_list("", 1, 1)
            
            if response and 'LsTrmSearch' in response:
                logger.info("API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                logger.error("API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                return False
                
        except Exception as e:
            logger.error(f"API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False


class LawOpenAPIConfig:
    """Law Open API ì„¤ì • í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_url = "http://www.law.go.kr/DRF/lawSearch.do"
        self.timeout = 30
        self.max_retries = 3
        self.retry_delay = 5
        self.min_request_interval = 0.1
        self.page_size = 100
        self.max_pages = None  # Noneì´ë©´ ëª¨ë“  í˜ì´ì§€ ìˆ˜ì§‘


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_client(oc_parameter: str = None) -> LawOpenAPIClient:
    """
    Law Open API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    
    Args:
        oc_parameter: OC íŒŒë¼ë¯¸í„°
        
    Returns:
        LawOpenAPIClient ì¸ìŠ¤í„´ìŠ¤
    """
    return LawOpenAPIClient(oc_parameter)


def test_api_connection(oc_parameter: str = None) -> bool:
    """
    API ì—°ê²° í…ŒìŠ¤íŠ¸
    
    Args:
        oc_parameter: OC íŒŒë¼ë¯¸í„°
        
    Returns:
        ì—°ê²° ì„±ê³µ ì—¬ë¶€
    """
    try:
        client = create_client(oc_parameter)
        return client.test_connection()
    except Exception as e:
        logger.error(f"API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    logging.basicConfig(level=logging.INFO)
    
    print("Law Open API í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    oc_param = os.getenv("LAW_OPEN_API_OC")
    if not oc_param:
        print("âŒ LAW_OPEN_API_OC í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("export LAW_OPEN_API_OC='your_email@example.com'")
        exit(1)
    
    print(f"âœ… OC íŒŒë¼ë¯¸í„°: {oc_param}")
    
    # í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸
    try:
        client = create_client()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if client.test_connection():
            print("âœ… API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
            # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
            print("\nìƒ˜í”Œ ë²•ë ¹ìš©ì–´ ì¡°íšŒ:")
            terms = client.get_legal_term_list("", 1, 5)
            
            if terms and 'data' in terms:
                for i, term in enumerate(terms['data'][:3], 1):
                    print(f"  {i}. {term.get('termName', 'N/A')}")
                print("âœ… ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
            else:
                print("âŒ ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
        else:
            print("âŒ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")




