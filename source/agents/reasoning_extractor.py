# -*- coding: utf-8 -*-
"""
ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ ë° ê²€ì¦ ëª¨ë“ˆ
LLM ì‘ë‹µì—ì„œ ì¶”ë¡  ê³¼ì •(Chain-of-Thought)ì„ ì¶”ì¶œí•˜ê³  ì‹¤ì œ ë‹µë³€ë§Œ ë¶„ë¦¬
"""

import logging
import re
from typing import Any, Dict, Optional

from source.agents.workflow_constants import AnswerExtractionPatterns


class ReasoningExtractor:
    """
    ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ ë° ê²€ì¦ í´ë˜ìŠ¤

    LLM ì‘ë‹µì—ì„œ ì¶”ë¡  ê³¼ì •ê³¼ ì‹¤ì œ ë‹µë³€ì„ ë¶„ë¦¬í•˜ê³ ,
    í’ˆì§ˆì„ ê²€ì¦í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        ReasoningExtractor ì´ˆê¸°í™”

        Args:
            logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        """
        self.logger = logger or logging.getLogger(__name__)
        self._compile_regex_patterns()

    def _compile_regex_patterns(self):
        """ì •ê·œì‹ íŒ¨í„´ì„ ì»´íŒŒì¼í•˜ì—¬ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)"""
        # ì¶”ë¡  ê³¼ì • ì„¹ì…˜ íŒ¨í„´ ì»´íŒŒì¼
        self._compiled_reasoning_patterns = [
            re.compile(pattern, re.IGNORECASE | re.MULTILINE)
            for pattern in AnswerExtractionPatterns.REASONING_SECTION_PATTERNS
        ]

        # ì¶œë ¥ ì„¹ì…˜ íŒ¨í„´ ì»´íŒŒì¼
        self._compiled_output_patterns = [
            re.compile(pattern, re.IGNORECASE | re.MULTILINE)
            for pattern in AnswerExtractionPatterns.OUTPUT_SECTION_PATTERNS
        ]

        # ë‹µë³€ ì„¹ì…˜ íŒ¨í„´ ì»´íŒŒì¼
        self._compiled_answer_patterns = [
            re.compile(pattern, re.IGNORECASE | re.MULTILINE)
            for pattern in AnswerExtractionPatterns.ANSWER_SECTION_PATTERNS
        ]

        # Step í—¤ë” íŒ¨í„´ ì»´íŒŒì¼ (Step 1, 2, 3)
        self._compiled_step_header_patterns = {
            "step1": [
                re.compile(r'###\s*Step\s*1[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*ë‹¨ê³„\s*1[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*Step\s*1\s*[:ï¼š]', re.IGNORECASE | re.MULTILINE),
            ],
            "step2": [
                re.compile(r'###\s*Step\s*2[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*ë‹¨ê³„\s*2[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*Step\s*2\s*[:ï¼š]', re.IGNORECASE | re.MULTILINE),
            ],
            "step3": [
                re.compile(r'###\s*Step\s*3[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*ë‹¨ê³„\s*3[:ï¼š]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'###\s*Step\s*3\s*[:ï¼š]', re.IGNORECASE | re.MULTILINE),
            ],
        }

        # ë‹¤ìŒ ë§ˆì»¤ íŒ¨í„´ ì»´íŒŒì¼
        self._compiled_next_marker_patterns = {
            "step1": [
                re.compile(r'\n\s*###\s*Step\s*2', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*###\s*ë‹¨ê³„\s*2', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*[^#]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ğŸ“¤', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ì¶œë ¥', re.IGNORECASE | re.MULTILINE),
            ],
            "step2": [
                re.compile(r'\n\s*###\s*Step\s*3', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*###\s*ë‹¨ê³„\s*3', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*[^#]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ğŸ“¤', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ì¶œë ¥', re.IGNORECASE | re.MULTILINE),
            ],
            "step3": [
                re.compile(r'\n\s*##\s*[^#]', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ğŸ“¤', re.IGNORECASE | re.MULTILINE),
                re.compile(r'\n\s*##\s*ì¶œë ¥', re.IGNORECASE | re.MULTILINE),
            ],
        }

        # ë¶€ë¶„ ì •ë¦¬ íŒ¨í„´ ì»´íŒŒì¼
        self._compiled_partial_cleaning_patterns = [
            re.compile(r'##\s*ğŸ§ \s*ì¶”ë¡ [^\n]*', re.IGNORECASE | re.MULTILINE),
            re.compile(r'###\s*Step\s*[123][^\n]*', re.IGNORECASE | re.MULTILINE),
            re.compile(r'###\s*ë‹¨ê³„\s*[123][^\n]*', re.IGNORECASE | re.MULTILINE),
        ]

        # ë‹¤ìŒ ì„¹ì…˜ íŒ¨í„´ ì»´íŒŒì¼ (ë©´ì±…ì¡°í•­, ì°¸ê³ ìë£Œ ë“±)
        self._compiled_next_section_patterns = [
            re.compile(r'###?\s*ğŸ“š', re.IGNORECASE),
            re.compile(r'###?\s*ì°¸ê³ ìë£Œ', re.IGNORECASE),
            re.compile(r'###?\s*ğŸ’¡', re.IGNORECASE),
            re.compile(r'###?\s*ì‹ ë¢°ë„', re.IGNORECASE),
            re.compile(r'---'),
            re.compile(r'ğŸ’¼\s*ë©´ì±…', re.IGNORECASE),
        ]

    def extract_reasoning(self, answer: str) -> Dict[str, Any]:
        """
        LLM ë‹µë³€ì—ì„œ ì¶”ë¡  ê³¼ì •(Chain-of-Thought) ì„¹ì…˜ì„ ì¶”ì¶œ

        Args:
            answer: LLM ì›ë³¸ ë‹µë³€ ë¬¸ìì—´

        Returns:
            Dict with keys:
                - "reasoning": ì¶”ë¡  ê³¼ì • ì „ì²´ ë‚´ìš©
                - "step1": Step 1 ë‚´ìš©
                - "step2": Step 2 ë‚´ìš©
                - "step3": Step 3 ë‚´ìš©
                - "has_reasoning": ì¶”ë¡  ê³¼ì • ì¡´ì¬ ì—¬ë¶€
                - "reasoning_section_count": ì¶”ë¡  ì„¹ì…˜ ê°œìˆ˜
        """
        if not answer or not isinstance(answer, str):
            return {
                "reasoning": "",
                "step1": "",
                "step2": "",
                "step3": "",
                "has_reasoning": False,
                "reasoning_section_count": 0
            }

        # ì„±ëŠ¥ ìµœì í™”: ëŒ€ìš©ëŸ‰ ì‘ë‹µì— ëŒ€í•œ ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
        answer_length = len(answer)
        MAX_REASONING_SEARCH_LENGTH = 10000  # 10KB ì´ìƒì¸ ê²½ìš° ì„±ëŠ¥ ìµœì í™” ì ìš©

        if answer_length > MAX_REASONING_SEARCH_LENGTH:
            # ëŒ€ìš©ëŸ‰ ì‘ë‹µì˜ ê²½ìš° ì²˜ìŒ 10KBë§Œ ê²€ìƒ‰ (ì¶”ë¡  ê³¼ì •ì€ ë³´í†µ ì•ë¶€ë¶„ì— ìˆìŒ)
            search_text = answer[:MAX_REASONING_SEARCH_LENGTH]
            self.logger.debug(f"Large response ({answer_length} chars), searching first {MAX_REASONING_SEARCH_LENGTH} chars only")
        else:
            search_text = answer

        result = {
            "reasoning": "",
            "step1": "",
            "step2": "",
            "step3": "",
            "has_reasoning": False,
            "reasoning_section_count": 0
        }

        # ì¶”ë¡  ê³¼ì • ì„¹ì…˜ ì°¾ê¸° (ì—¬ëŸ¬ ê³³ì— ë¶„ì‚°ëœ ê²½ìš°ë„ ì²˜ë¦¬)
        reasoning_sections = []  # ëª¨ë“  ì¶”ë¡  ì„¹ì…˜ì„ ì €ì¥

        # ëª¨ë“  ì¶”ë¡  ì„¹ì…˜ ì°¾ê¸° (search_text ì‚¬ìš©)
        reasoning_found = False
        for compiled_pattern in self._compiled_reasoning_patterns:
            # ëª¨ë“  ë§¤ì¹­ ì°¾ê¸° (ì²« ë²ˆì§¸ë§Œì´ ì•„ë‹ˆë¼)
            for match in compiled_pattern.finditer(search_text):
                reasoning_found = True
                reasoning_start_idx = match.start()
                # ë‹¤ìŒ ì„¹ì…˜ ì°¾ê¸° (ì¶œë ¥ ì„¹ì…˜ ë˜ëŠ” ë‹µë³€ ì„¹ì…˜) - search_text ê¸°ì¤€
                remaining_text = search_text[reasoning_start_idx:]
                next_section_patterns = (
                    self._compiled_output_patterns +
                    self._compiled_answer_patterns
                )

                reasoning_end_idx = None
                for compiled_next_pattern in next_section_patterns:
                    next_match = compiled_next_pattern.search(remaining_text)
                    if next_match:
                        reasoning_end_idx = reasoning_start_idx + next_match.start()
                        break

                if reasoning_end_idx is None:
                    # ë‹¤ìŒ ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì¶”ë¡  ì„¹ì…˜ ëê¹Œì§€ ì „ì²´ í¬í•¨
                    # search_text ê¸°ì¤€ì´ë¯€ë¡œ ì›ë³¸ answer ê¸¸ì´ë¡œ ì¡°ì •
                    if answer_length > MAX_REASONING_SEARCH_LENGTH and reasoning_start_idx < MAX_REASONING_SEARCH_LENGTH:
                        # ëŒ€ìš©ëŸ‰ ì‘ë‹µì—ì„œ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²½ìš° ì›ë³¸ ëê¹Œì§€
                        reasoning_end_idx = answer_length
                    else:
                        reasoning_end_idx = answer_length if reasoning_start_idx < answer_length else len(search_text)

                # ì¤‘ë³µ ì²´í¬ (ì´ë¯¸ í¬í•¨ëœ ì„¹ì…˜ì¸ì§€ í™•ì¸)
                is_duplicate = False
                for existing_start, existing_end in reasoning_sections:
                    if reasoning_start_idx >= existing_start and reasoning_start_idx < existing_end:
                        is_duplicate = True
                        break
                    if existing_start >= reasoning_start_idx and existing_start < reasoning_end_idx:
                        # ê¸°ì¡´ ì„¹ì…˜ì´ í˜„ì¬ ì„¹ì…˜ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í™•ì¥
                        reasoning_sections.remove((existing_start, existing_end))
                        break

                if not is_duplicate:
                    reasoning_sections.append((reasoning_start_idx, reasoning_end_idx))

        # ì—¬ëŸ¬ ì¶”ë¡  ì„¹ì…˜ì´ ìˆëŠ” ê²½ìš° ë³‘í•©
        if reasoning_sections:
            # ì‹œì‘ ìœ„ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬
            reasoning_sections.sort(key=lambda x: x[0])

            # ê²¹ì¹˜ëŠ” ì„¹ì…˜ ë³‘í•©
            merged_sections = []
            current_start, current_end = reasoning_sections[0]

            for start_idx, end_idx in reasoning_sections[1:]:
                if start_idx <= current_end:
                    # ê²¹ì¹˜ëŠ” ê²½ìš° ë³‘í•©
                    current_end = max(current_end, end_idx)
                else:
                    # ê²¹ì¹˜ì§€ ì•ŠëŠ” ê²½ìš° ì €ì¥í•˜ê³  ìƒˆë¡œ ì‹œì‘
                    merged_sections.append((current_start, current_end))
                    current_start, current_end = start_idx, end_idx

            merged_sections.append((current_start, current_end))

            # ë³‘í•©ëœ ì„¹ì…˜ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
            reasoning_text_parts = []
            for start_idx, end_idx in merged_sections:
                # ì›ë³¸ answerì—ì„œ ì¶”ì¶œ (ì¸ë±ìŠ¤ëŠ” search_text ê¸°ì¤€ì´ì§€ë§Œ answerì—ì„œ ê°€ì ¸ì˜´)
                if start_idx < answer_length:
                    end_idx = min(end_idx, answer_length)
                    section_text = answer[start_idx:end_idx].strip()
                    if section_text:
                        reasoning_text_parts.append(section_text)

            reasoning_text = "\n\n".join(reasoning_text_parts)
            result["reasoning"] = reasoning_text
            result["has_reasoning"] = True
            result["reasoning_section_count"] = len(merged_sections)  # ì„¹ì…˜ ê°œìˆ˜ ì €ì¥

            # Step 1, 2, 3 ì¶”ì¶œ (Step í—¤ë”ë¥¼ ì§ì ‘ ì°¾ì•„ì„œ ê·¸ ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ)
            # ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ Step ì¶”ì¶œ í›„ ë³‘í•©
            step_keys = ["step1", "step2", "step3"]

            # ì„±ëŠ¥ ìµœì í™”: reasoning_textê°€ ë„ˆë¬´ ê¸´ ê²½ìš° ì¡°ê¸° ì¢…ë£Œ
            MAX_STEP_SEARCH_LENGTH = 5000  # Step ì¶”ì¶œë„ 5KB ì œí•œ
            step_search_text = reasoning_text[:MAX_STEP_SEARCH_LENGTH] if len(reasoning_text) > MAX_STEP_SEARCH_LENGTH else reasoning_text

            # ê° Stepì— ëŒ€í•´ ëª¨ë“  ì„¹ì…˜ì—ì„œ ì¶”ì¶œí•˜ì—¬ ë³‘í•©
            for step_key in step_keys:
                step_contents = []  # ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ ì¶”ì¶œí•œ Step ë‚´ìš© ì €ì¥

                # ë³‘í•©ëœ ì¶”ë¡  í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ Step ì°¾ê¸° (step_search_text ì‚¬ìš©)
                compiled_headers = self._compiled_step_header_patterns[step_key]
                for compiled_header in compiled_headers:
                    # ëª¨ë“  Step í—¤ë” ì°¾ê¸° (ì—¬ëŸ¬ ì„¹ì…˜ì— ìˆì„ ìˆ˜ ìˆìŒ)
                    full_header_pattern = compiled_header.pattern + r'[^\n]*\n'
                    full_header_compiled = re.compile(full_header_pattern, re.IGNORECASE | re.MULTILINE)

                    # ëª¨ë“  ë§¤ì¹­ ì°¾ê¸° (step_search_text ì‚¬ìš©)
                    for match in full_header_compiled.finditer(step_search_text):
                        step_start = match.end()

                        # ë‹¤ìŒ ë§ˆì»¤ ì°¾ê¸° (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©) - step_search_text ê¸°ì¤€
                        remaining_text = step_search_text[step_start:]
                        compiled_markers = self._compiled_next_marker_patterns[step_key]
                        step_end = None

                        for compiled_marker in compiled_markers:
                            next_match = compiled_marker.search(remaining_text)
                            if next_match:
                                step_end = step_start + next_match.start()
                                break

                        if step_end is None:
                            # ë‹¤ìŒ ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ëê¹Œì§€ (reasoning_text ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •)
                            step_end = min(step_start + len(remaining_text), len(reasoning_text))

                        # Step ë‚´ìš© ì¶”ì¶œ (í—¤ë” ì¤„ ì œì™¸, ë¹ˆ ì¤„ ì œê±°) - reasoning_textì—ì„œ
                        step_content = reasoning_text[step_start:step_end].strip() if step_start < len(reasoning_text) else ""
                        if step_content:
                            step_contents.append(step_content)

                    # ì²« ë²ˆì§¸ í—¤ë” íŒ¨í„´ì—ì„œ ì°¾ìœ¼ë©´ ë‹¤ìŒ íŒ¨í„´ìœ¼ë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
                    if step_contents:
                        break

                # ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ ì¶”ì¶œí•œ Step ë‚´ìš© ë³‘í•© (ì¤‘ë³µ ì œê±° ë° ì •ë ¬)
                if step_contents:
                    # ì¤‘ë³µ ì œê±° (ë™ì¼í•œ ë‚´ìš©ì€ í•œ ë²ˆë§Œ)
                    unique_contents = []
                    seen_contents = set()
                    for content in step_contents:
                        # ì •ê·œí™”í•˜ì—¬ ë¹„êµ (ê³µë°±, ì¤„ë°”ê¿ˆ ì •ë¦¬)
                        normalized = re.sub(r'\s+', ' ', content.strip())
                        if normalized and normalized not in seen_contents:
                            seen_contents.add(normalized)
                            unique_contents.append(content)

                    # ë³‘í•© (ë¹ˆ ì¤„ë¡œ êµ¬ë¶„)
                    if unique_contents:
                        merged_step_content = "\n\n".join(unique_contents)
                        result[step_key] = merged_step_content
                elif step_key == "step3":
                    # Step 3ì˜ ê²½ìš° ë‚´ìš©ì´ ë¹„ì–´ìˆì„ ìˆ˜ë„ ìˆì§€ë§Œ í—¤ë”ëŠ” ì¡´ì¬í•˜ë¯€ë¡œ ì €ì¥
                    result[step_key] = ""

        return result

    def extract_actual_answer(self, llm_response: str) -> str:
        """
        LLM ì‘ë‹µì—ì„œ ì‹¤ì œ ë‹µë³€ë§Œ ì¶”ì¶œ (ì¶”ë¡  ê³¼ì • ì œì™¸)

        ìš°ì„ ìˆœìœ„:
        1. "## ğŸ“¤ ì¶œë ¥" ì„¹ì…˜
        2. "## ë‹µë³€" ì„¹ì…˜ (ì¶”ë¡  ê³¼ì • ì œì™¸)
        3. ì „ì²´ ë‚´ìš©ì—ì„œ ì¶”ë¡  ê³¼ì • ì œê±° í›„ ë‚¨ì€ ë¶€ë¶„

        Args:
            llm_response: LLM ì›ë³¸ ì‘ë‹µ ë¬¸ìì—´

        Returns:
            ì‹¤ì œ ë‹µë³€ë§Œ í¬í•¨í•œ ë¬¸ìì—´
        """
        if not llm_response or not isinstance(llm_response, str):
            return ""

        # 1ë‹¨ê³„: ì¶œë ¥ ì„¹ì…˜ ì°¾ê¸° (ìµœìš°ì„ , ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
        for compiled_pattern in self._compiled_output_patterns:
            match = compiled_pattern.search(llm_response)
            if match:
                # ì¶œë ¥ ì„¹ì…˜ ì´í›„ì˜ ëª¨ë“  ë‚´ìš©
                output_start = match.end()
                remaining = llm_response[output_start:].strip()

                # ë‹¤ìŒ ì„¹ì…˜(ë©´ì±…ì¡°í•­, ì°¸ê³ ìë£Œ ë“±) ì „ê¹Œì§€ ì¶”ì¶œ (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
                next_section_idx = len(remaining)
                for compiled_next_pattern in self._compiled_next_section_patterns:
                    next_match = compiled_next_pattern.search(remaining)
                    if next_match:
                        next_section_idx = min(next_section_idx, next_match.start())

                answer = remaining[:next_section_idx].strip()
                if answer:
                    return answer

        # 2ë‹¨ê³„: ë‹µë³€ ì„¹ì…˜ ì°¾ê¸° (ì¶”ë¡  ê³¼ì • ì œì™¸)
        reasoning_info = self.extract_reasoning(llm_response)
        if reasoning_info["has_reasoning"]:
            # ì¶”ë¡  ê³¼ì • ì œê±°
            reasoning_start = llm_response.find(reasoning_info["reasoning"])
            if reasoning_start != -1:
                # ì¶”ë¡  ê³¼ì • ì´í›„ ë¶€ë¶„ ì¶”ì¶œ
                after_reasoning_start = reasoning_start + len(reasoning_info["reasoning"])
                after_reasoning = llm_response[after_reasoning_start:].strip()

                # ë‹µë³€ ì„¹ì…˜ì´ ì¶”ë¡  ê³¼ì • ì´í›„ì— ìˆëŠ”ì§€ í™•ì¸ (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
                for compiled_pattern in self._compiled_answer_patterns:
                    match = compiled_pattern.search(after_reasoning)
                    if match:
                        answer_start = match.end()
                        answer = after_reasoning[answer_start:].strip()
                        # ë‹¤ìŒ ì„¹ì…˜ ì „ê¹Œì§€ (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
                        next_section_idx = len(answer)
                        for compiled_next_pattern in self._compiled_next_section_patterns:
                            next_match = compiled_next_pattern.search(answer)
                            if next_match:
                                next_section_idx = min(next_section_idx, next_match.start())

                        answer = answer[:next_section_idx].strip()
                        if answer:
                            return answer

        # 3ë‹¨ê³„: ì „ì²´ ë‚´ìš©ì—ì„œ ì¶”ë¡  ê³¼ì • ì œê±° (ëª¨ë“  ì„¹ì…˜ ì™„ì „ ì œê±°)
        if reasoning_info["has_reasoning"]:
            reasoning_text = reasoning_info["reasoning"]
            reasoning_section_count = reasoning_info.get("reasoning_section_count", 1)

            # ì—¬ëŸ¬ ì„¹ì…˜ì´ ìˆëŠ” ê²½ìš° ê° ì„¹ì…˜ì„ ê°œë³„ì ìœ¼ë¡œ ì œê±°
            if reasoning_section_count > 1:
                # ì›ë³¸ì—ì„œ ëª¨ë“  ì¶”ë¡  ì„¹ì…˜ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ ì €ì¥
                reasoning_section_indices = []
                for compiled_pattern in self._compiled_reasoning_patterns:
                    # ëª¨ë“  ì¶”ë¡  ì„¹ì…˜ ì°¾ê¸°
                    for match in compiled_pattern.finditer(llm_response):
                        reasoning_start = match.start()
                        # ë‹¤ìŒ ì„¹ì…˜ ì°¾ê¸° (ì¶œë ¥ ì„¹ì…˜ ë˜ëŠ” ë‹µë³€ ì„¹ì…˜)
                        remaining_text = llm_response[reasoning_start:]
                        next_section_patterns = (
                            self._compiled_output_patterns +
                            self._compiled_answer_patterns
                        )
                        reasoning_end = None
                        for compiled_next_pattern in next_section_patterns:
                            next_match = compiled_next_pattern.search(remaining_text)
                            if next_match:
                                reasoning_end = reasoning_start + next_match.start()
                                break

                        if reasoning_end is None:
                            reasoning_end = len(llm_response)

                        # ì¤‘ë³µ ì²´í¬
                        is_duplicate = False
                        for existing_start, existing_end in reasoning_section_indices:
                            if reasoning_start >= existing_start and reasoning_start < existing_end:
                                is_duplicate = True
                                break
                            if existing_start >= reasoning_start and existing_start < reasoning_end:
                                # ê¸°ì¡´ ì„¹ì…˜ì´ í˜„ì¬ ì„¹ì…˜ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ êµì²´
                                reasoning_section_indices.remove((existing_start, existing_end))
                                break

                        if not is_duplicate and reasoning_end > reasoning_start:
                            reasoning_section_indices.append((reasoning_start, reasoning_end))

                # ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì œê±° (ë’¤ì—ì„œë¶€í„° ì œê±°í•˜ë©´ ì¸ë±ìŠ¤ ë³€í™” ì—†ìŒ)
                reasoning_section_indices.sort(key=lambda x: x[0], reverse=True)

                # ê° ì„¹ì…˜ì„ ì—­ìˆœìœ¼ë¡œ ì œê±°
                cleaned_response = llm_response
                for reasoning_start, reasoning_end in reasoning_section_indices:
                    cleaned_response = (
                        cleaned_response[:reasoning_start] +
                        cleaned_response[reasoning_end:]
                    )

                cleaned_response = cleaned_response.strip()
            else:
                # ë‹¨ì¼ ì„¹ì…˜ì¸ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                cleaned_response = llm_response.replace(reasoning_text, "").strip()

            # ë‹µë³€ ì„¹ì…˜ ì°¾ê¸° (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
            for compiled_pattern in self._compiled_answer_patterns:
                match = compiled_pattern.search(cleaned_response)
                if match:
                    answer_start = match.end()
                    answer = cleaned_response[answer_start:].strip()
                    # ë‹¤ìŒ ì„¹ì…˜ ì „ê¹Œì§€ (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
                    next_section_idx = len(answer)
                    for compiled_next_pattern in self._compiled_next_section_patterns:
                        next_match = compiled_next_pattern.search(answer)
                        if next_match:
                            next_section_idx = min(next_section_idx, next_match.start())

                    answer = answer[:next_section_idx].strip()
                    if answer:
                        return answer

            # ë‹µë³€ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì¶”ë¡  ê³¼ì • ì œê±° í›„ ë‚¨ì€ ë‚´ìš© ë°˜í™˜
            if cleaned_response:
                return cleaned_response

        # 4ë‹¨ê³„: ì¶”ë¡  ê³¼ì •ì´ ì—†ê±°ë‚˜ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¶€ë¶„ ë¶„ë¦¬ ì‹œë„ (ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš©)
        # ì¶”ë¡  ê³¼ì • ì„¹ì…˜ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ë¶€ë¶„ì ìœ¼ë¡œ ì œê±° ì‹œë„
        cleaned_response = llm_response
        for compiled_pattern in self._compiled_partial_cleaning_patterns:
            cleaned_response = compiled_pattern.sub('', cleaned_response)

        # ë¹ˆ ì¤„ ì •ë¦¬
        cleaned_response = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_response)

        # ë³€ê²½ì´ ìˆì—ˆìœ¼ë©´ ë°˜í™˜
        if cleaned_response.strip() != llm_response.strip():
            return cleaned_response.strip()

        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        return llm_response

    def extract_by_output_section(self, llm_response: str) -> str:
        """
        ì¶œë ¥ ì„¹ì…˜ì—ì„œ ì‹¤ì œ ë‹µë³€ ì¶”ì¶œ (ì¬ì‹œë„ ë¡œì§ìš© helper)

        Args:
            llm_response: LLM ì›ë³¸ ì‘ë‹µ

        Returns:
            ì¶”ì¶œëœ ë‹µë³€ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        if not llm_response or not isinstance(llm_response, str):
            return ""

        for compiled_pattern in self._compiled_output_patterns:
            match = compiled_pattern.search(llm_response)
            if match:
                output_start = match.end()
                remaining = llm_response[output_start:].strip()

                next_section_idx = len(remaining)
                for compiled_next_pattern in self._compiled_next_section_patterns:
                    next_match = compiled_next_pattern.search(remaining)
                    if next_match:
                        next_section_idx = min(next_section_idx, next_match.start())

                answer = remaining[:next_section_idx].strip()
                if answer:
                    return answer

        return ""

    def extract_by_removing_reasoning(self, llm_response: str, reasoning_info: Dict[str, Any]) -> str:
        """
        ì¶”ë¡  ê³¼ì • ì œê±° í›„ ì‹¤ì œ ë‹µë³€ ì¶”ì¶œ (ì¬ì‹œë„ ë¡œì§ìš© helper)

        Args:
            llm_response: LLM ì›ë³¸ ì‘ë‹µ
            reasoning_info: ì¶”ì¶œëœ ì¶”ë¡  ê³¼ì • ì •ë³´

        Returns:
            ì¶”ì¶œëœ ë‹µë³€ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        if not reasoning_info.get("has_reasoning"):
            return ""

        reasoning_text = reasoning_info.get("reasoning", "")
        if not reasoning_text:
            return ""

        reasoning_section_count = reasoning_info.get("reasoning_section_count", 1)

        # ì—¬ëŸ¬ ì„¹ì…˜ì´ ìˆëŠ” ê²½ìš° ê° ì„¹ì…˜ì„ ê°œë³„ì ìœ¼ë¡œ ì œê±°
        if reasoning_section_count > 1:
            reasoning_section_indices = []
            for compiled_pattern in self._compiled_reasoning_patterns:
                for match in compiled_pattern.finditer(llm_response):
                    reasoning_start = match.start()
                    remaining_text = llm_response[reasoning_start:]
                    next_section_patterns = (
                        self._compiled_output_patterns +
                        self._compiled_answer_patterns
                    )
                    reasoning_end = None
                    for compiled_next_pattern in next_section_patterns:
                        next_match = compiled_next_pattern.search(remaining_text)
                        if next_match:
                            reasoning_end = reasoning_start + next_match.start()
                            break

                    if reasoning_end is None:
                        reasoning_end = len(llm_response)

                    is_duplicate = False
                    for existing_start, existing_end in reasoning_section_indices:
                        if reasoning_start >= existing_start and reasoning_start < existing_end:
                            is_duplicate = True
                            break
                        if existing_start >= reasoning_start and existing_start < reasoning_end:
                            reasoning_section_indices.remove((existing_start, existing_end))
                            break

                    if not is_duplicate and reasoning_end > reasoning_start:
                        reasoning_section_indices.append((reasoning_start, reasoning_end))

            reasoning_section_indices.sort(key=lambda x: x[0], reverse=True)

            cleaned_response = llm_response
            for reasoning_start, reasoning_end in reasoning_section_indices:
                cleaned_response = (
                    cleaned_response[:reasoning_start] +
                    cleaned_response[reasoning_end:]
                )

            cleaned_response = cleaned_response.strip()
        else:
            cleaned_response = llm_response.replace(reasoning_text, "").strip()

        # ë‹µë³€ ì„¹ì…˜ ì°¾ê¸°
        for compiled_pattern in self._compiled_answer_patterns:
            match = compiled_pattern.search(cleaned_response)
            if match:
                answer_start = match.end()
                answer = cleaned_response[answer_start:].strip()

                next_section_idx = len(answer)
                for compiled_next_pattern in self._compiled_next_section_patterns:
                    next_match = compiled_next_pattern.search(answer)
                    if next_match:
                        next_section_idx = min(next_section_idx, next_match.start())

                answer = answer[:next_section_idx].strip()
                if answer:
                    return answer

        # ë‹µë³€ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì¶”ë¡  ê³¼ì • ì œê±° í›„ ë‚¨ì€ ë‚´ìš© ë°˜í™˜
        if cleaned_response:
            return cleaned_response

        return ""

    def extract_by_partial_cleaning(self, llm_response: str) -> str:
        """
        ë¶€ë¶„ ì •ë¦¬ ë°©ë²•ìœ¼ë¡œ ì¶”ì¶œ (ì¬ì‹œë„ ë¡œì§ìš© helper)

        Args:
            llm_response: LLM ì›ë³¸ ì‘ë‹µ

        Returns:
            ì¶”ì¶œëœ ë‹µë³€ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        cleaned_response = llm_response
        for compiled_pattern in self._compiled_partial_cleaning_patterns:
            cleaned_response = compiled_pattern.sub('', cleaned_response)

        cleaned_response = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_response)

        if cleaned_response.strip() != llm_response.strip():
            return cleaned_response.strip()

        return ""

    def clean_reasoning_keywords(self, answer: str) -> str:
        """
        ì‹¤ì œ ë‹µë³€ì—ì„œ ì¶”ë¡  ê³¼ì • í‚¤ì›Œë“œ ì”ì—¬ í™•ì¸ ë° ì •ë¦¬

        Args:
            answer: ì¶”ì¶œëœ ì‹¤ì œ ë‹µë³€

        Returns:
            ì¶”ë¡  ê³¼ì • í‚¤ì›Œë“œê°€ ì •ë¦¬ëœ ë‹µë³€
        """
        if not answer or not isinstance(answer, str):
            return answer

        # ì¶”ë¡  ê³¼ì • ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´
        reasoning_keywords = [
            r'##\s*ğŸ§ \s*ì¶”ë¡ ',
            r'###\s*Step\s*[123]',
            r'###\s*ë‹¨ê³„\s*[123]',
            r'Chain-of-Thought',
            r'CoT',
            r'ì¶”ë¡ ê³¼ì •ì‘ì„±',
        ]

        cleaned_answer = answer
        found_keywords = []

        # í‚¤ì›Œë“œ ê²€ì‚¬ ë° ì œê±°
        for keyword_pattern in reasoning_keywords:
            compiled_pattern = re.compile(keyword_pattern, re.IGNORECASE | re.MULTILINE)
            matches = list(compiled_pattern.finditer(cleaned_answer))
            if matches:
                found_keywords.append(keyword_pattern)
                # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¤„ ì „ì²´ ì œê±°
                for match in reversed(matches):  # ì—­ìˆœìœ¼ë¡œ ì œê±°í•˜ì—¬ ì¸ë±ìŠ¤ ë³€í™” ë°©ì§€
                    start_pos = match.start()
                    # ì¤„ ì‹œì‘ ì°¾ê¸°
                    line_start = cleaned_answer.rfind('\n', 0, start_pos) + 1
                    # ì¤„ ë ì°¾ê¸°
                    line_end = cleaned_answer.find('\n', match.end())
                    if line_end == -1:
                        line_end = len(cleaned_answer)

                    # í•´ë‹¹ ì¤„ ì œê±°
                    cleaned_answer = cleaned_answer[:line_start] + cleaned_answer[line_end + 1:]
                    cleaned_answer = cleaned_answer.lstrip()  # ì‹œì‘ ë¶€ë¶„ ë¹ˆ ì¤„ ì œê±°

        # ë¹ˆ ì¤„ ì •ë¦¬ (ì—°ì†ëœ ë¹ˆ ì¤„ì„ í•˜ë‚˜ë¡œ)
        cleaned_answer = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_answer)

        # í‚¤ì›Œë“œ ë°œê²¬ ì‹œ ë¡œê¹…
        if found_keywords:
            self.logger.warning(
                f"Found and removed reasoning keywords from answer: {found_keywords}"
            )

        return cleaned_answer.strip()

    def verify_extraction_quality(
        self,
        original_answer: str,
        actual_answer: str,
        reasoning_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ í›„ í’ˆì§ˆ ê²€ì¦

        Args:
            original_answer: ì›ë³¸ ë‹µë³€
            actual_answer: ì¶”ë¡  ê³¼ì • ì œê±°ëœ ì‹¤ì œ ë‹µë³€
            reasoning_info: ì¶”ì¶œëœ ì¶”ë¡  ê³¼ì • ì •ë³´

        Returns:
            Dict: í’ˆì§ˆ ë©”íŠ¸ë¦­
                - "is_valid": ìœ íš¨ ì—¬ë¶€
                - "warnings": ê²½ê³  ëª©ë¡
                - "errors": ì—ëŸ¬ ëª©ë¡
                - "score": í’ˆì§ˆ ì ìˆ˜ (0.0-1.0)
        """
        quality = {
            "is_valid": True,
            "warnings": [],
            "errors": [],
            "score": 1.0,
        }

        if not original_answer or not actual_answer:
            quality["is_valid"] = False
            quality["errors"].append("ì›ë³¸ ë‹µë³€ ë˜ëŠ” ì‹¤ì œ ë‹µë³€ì´ ë¹„ì–´ìˆìŒ")
            quality["score"] = 0.0
            return quality

        # 1. ê¸¸ì´ ê²€ì¦
        if len(actual_answer) == 0:
            quality["is_valid"] = False
            quality["errors"].append("ì‹¤ì œ ë‹µë³€ì´ ë¹„ì–´ìˆìŒ")
            quality["score"] = 0.0
            return quality

        # 2. ì¶”ë¡  ê³¼ì •ì´ ì‹¤ì œ ë‹µë³€ì— í¬í•¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        if reasoning_info.get("has_reasoning"):
            reasoning_text = reasoning_info.get("reasoning", "")
            if reasoning_text and reasoning_text in actual_answer:
                quality["is_valid"] = False
                quality["errors"].append("ì¶”ë¡  ê³¼ì •ì´ ì‹¤ì œ ë‹µë³€ì— í¬í•¨ë˜ì–´ ìˆìŒ")
                quality["score"] = 0.0
            elif any(keyword in actual_answer for keyword in ["ğŸ§ ", "ì¶”ë¡ ê³¼ì •", "Step 1", "Step 2", "Step 3"]):
                quality["warnings"].append("ì¶”ë¡  ê³¼ì • í‚¤ì›Œë“œê°€ ì‹¤ì œ ë‹µë³€ì— ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŒ")
                quality["score"] = 0.8

        # 3. ë‹µë³€ ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬¸ì œ)
        extraction_ratio = len(actual_answer) / len(original_answer) if original_answer else 0.0
        if extraction_ratio < 0.1:
            quality["warnings"].append(f"ì‹¤ì œ ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŒ (ë¹„ìœ¨: {extraction_ratio:.1%})")
            quality["score"] = min(quality["score"], 0.7)
        elif extraction_ratio > 0.95:
            quality["warnings"].append("ì¶”ë¡  ê³¼ì •ì´ ê±°ì˜ ì œê±°ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ")
            quality["score"] = min(quality["score"], 0.9)

        # 4. í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ ê²€ì¦ (ë²•ë¥  ê´€ë ¨ í‚¤ì›Œë“œê°€ ì‹¤ì œ ë‹µë³€ì— ìˆëŠ”ì§€)
        legal_keywords = ["ë²•", "ì¡°ë¬¸", "íŒë¡€", "ë²•ë¥ ", "ë¯¼ë²•", "í˜•ë²•", "ìƒë²•"]
        original_keywords = [kw for kw in legal_keywords if kw in original_answer]
        actual_keywords = [kw for kw in legal_keywords if kw in actual_answer]

        if original_keywords and len(actual_keywords) < len(original_keywords) * 0.5:
            quality["warnings"].append("ë²•ë¥  í‚¤ì›Œë“œê°€ ë§ì´ ì œê±°ë˜ì—ˆì„ ìˆ˜ ìˆìŒ")
            quality["score"] = min(quality["score"], 0.8)

        # 5. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        if quality["errors"]:
            quality["score"] = 0.0
        elif quality["warnings"]:
            quality["score"] = quality["score"] * 0.9

        return quality
