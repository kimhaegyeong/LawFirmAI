# -*- coding: utf-8 -*-
"""
ë‹µë³€ í¬ë§·íŒ… ëª¨ë“ˆ
LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ë‹µë³€ í¬ë§·íŒ… ë° ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ë¡œì§ì„ ë…ë¦½ ëª¨ë“ˆë¡œ ë¶„ë¦¬
"""

import logging
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

from source.agents.state_definitions import LegalWorkflowState
from source.agents.workflow_utils import WorkflowUtils
from source.agents.quality_validators import AnswerValidator

# Constants for processing steps
MAX_PROCESSING_STEPS = 50

# ë‹µë³€ ê¸¸ì´ ëª©í‘œ (ì§ˆì˜ ìœ í˜•ë³„)
ANSWER_LENGTH_TARGETS = {
    "simple_question": (500, 1000),      # ê°„ë‹¨í•œ ì§ˆì˜: 500-1000ì
    "term_explanation": (800, 1500),     # ìš©ì–´ ì„¤ëª…: 800-1500ì
    "legal_analysis": (1500, 2500),      # ë²•ë¥  ë¶„ì„: 1500-2500ì
    "complex_question": (2000, 3500),    # ë³µì¡í•œ ì§ˆì˜: 2000-3500ì
    "default": (800, 2000)               # ê¸°ë³¸ê°’: 800-2000ì
}


def prune_processing_steps(steps: List[Dict[str, Any]], max_items: int = MAX_PROCESSING_STEPS) -> List[Dict[str, Any]]:
    """ì²˜ë¦¬ ë‹¨ê³„ ëª©ë¡ ì¶•ì†Œ"""
    if not isinstance(steps, list):
        return []
    if len(steps) <= max_items:
        return steps
    # ìµœê·¼ í•­ëª©ë“¤ë§Œ ìœ ì§€
    return steps[-max_items:]


class AnswerFormatterHandler:
    """
    ë‹µë³€ í¬ë§·íŒ… í´ë˜ìŠ¤

    LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ë‹µë³€ í¬ë§·íŒ… ë° ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        keyword_mapper: Any = None,
        answer_structure_enhancer: Any = None,
        answer_formatter: Any = None,
        confidence_calculator: Any = None,
        reasoning_extractor: Any = None,
        answer_generator: Any = None,
        logger: Optional[logging.Logger] = None
    ):
        """
        AnswerFormatter ì´ˆê¸°í™”

        Args:
            keyword_mapper: LegalKeywordMapper ì¸ìŠ¤í„´ìŠ¤
            answer_structure_enhancer: AnswerStructureEnhancer ì¸ìŠ¤í„´ìŠ¤
            answer_formatter: AnswerFormatter ì¸ìŠ¤í„´ìŠ¤ (ì‹œê°ì  í¬ë§·íŒ…ìš©)
            confidence_calculator: ConfidenceCalculator ì¸ìŠ¤í„´ìŠ¤
            reasoning_extractor: ReasoningExtractor ì¸ìŠ¤í„´ìŠ¤
            answer_generator: AnswerGenerator ì¸ìŠ¤í„´ìŠ¤ (íŒŒì´í”„ë¼ì¸ ì¶”ì ìš©)
            logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        """
        self.keyword_mapper = keyword_mapper
        self.answer_structure_enhancer = answer_structure_enhancer
        self.answer_formatter = answer_formatter
        self.confidence_calculator = confidence_calculator
        self.reasoning_extractor = reasoning_extractor
        self.answer_generator = answer_generator
        self.logger = logger or logging.getLogger(__name__)

    def format_answer(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í†µí•©ëœ ë‹µë³€ í¬ë§·íŒ…: êµ¬ì¡°í™” + ì‹œê°ì  í¬ë§·íŒ…"""
        try:
            start_time = time.time()

            answer = WorkflowUtils.get_state_value(state, "answer", "")
            query = WorkflowUtils.get_state_value(state, "query", "")
            query_type = WorkflowUtils.get_state_value(state, "query_type", "general_question")
            confidence = WorkflowUtils.get_state_value(state, "confidence", 0.0)

            # 1ë‹¨ê³„: ë‹µë³€ êµ¬ì¡°í™” ë° ë²•ì  ê·¼ê±° ê°•í™”
            structured_answer = answer
            if self.answer_structure_enhancer:
                try:
                    retrieved_docs = state.get("retrieved_docs", [])
                    legal_references = state.get("legal_references", [])
                    legal_citations = state.get("legal_citations", [])

                    enhanced_result = self.answer_structure_enhancer.enhance_answer_structure(
                        answer=answer,
                        question_type=query_type,
                        question=query,
                        domain="general",
                        retrieved_docs=retrieved_docs if retrieved_docs else None,
                        legal_references=legal_references if legal_references else None,
                        legal_citations=legal_citations if legal_citations else None
                    )

                    if enhanced_result and "structured_answer" in enhanced_result:
                        structured_answer = WorkflowUtils.normalize_answer(enhanced_result["structured_answer"])

                        quality_metrics = enhanced_result.get("quality_metrics", {})
                        if quality_metrics:
                            WorkflowUtils.set_state_value(state, "quality_metrics", quality_metrics)
                            confidence = quality_metrics.get("overall_score", confidence)
                            WorkflowUtils.set_state_value(state, "structure_confidence", confidence)

                        if "legal_citations" in enhanced_result:
                            WorkflowUtils.set_state_value(state, "legal_citations", enhanced_result["legal_citations"])

                        self.logger.info("Answer structure enhanced successfully")
                except Exception as e:
                    self.logger.warning(f"AnswerStructureEnhancer failed: {e}")
                    structured_answer = WorkflowUtils.normalize_answer(answer)

            # 2ë‹¨ê³„: ì‹œê°ì  í¬ë§·íŒ… (ì´ëª¨ì§€ + ì„¹ì…˜ êµ¬ì¡°)
            if self.answer_formatter:
                try:
                    from source.services.question_classifier import (
                        QuestionType as QType,
                    )
                    question_type_mapping = {
                        "precedent_search": QType.PRECEDENT_SEARCH,
                        "law_inquiry": QType.LAW_INQUIRY,
                        "legal_advice": QType.LEGAL_ADVICE,
                        "procedure_guide": QType.PROCEDURE_GUIDE,
                        "term_explanation": QType.TERM_EXPLANATION,
                        "general_question": QType.GENERAL_QUESTION,
                    }
                    q_type = question_type_mapping.get(query_type, QType.GENERAL_QUESTION)

                    from source.services.confidence_calculator import (
                        ConfidenceInfo,
                    )
                    final_confidence = state.get("structure_confidence") or confidence
                    confidence_info = ConfidenceInfo(
                        confidence=final_confidence,
                        level=self.map_confidence_level(final_confidence),
                        factors={"answer_quality": final_confidence},
                        explanation=f"ì‹ ë¢°ë„: {final_confidence:.1%}"
                    )

                    sources = {
                        "law_results": [
                            d for d in state.get("retrieved_docs", [])
                            if isinstance(d, dict) and (
                                "law" in str(d.get("type", "")).lower() or
                                "law" in str(d.get("source", "")).lower()
                            )
                        ],
                        "precedent_results": [
                            d for d in state.get("retrieved_docs", [])
                            if isinstance(d, dict) and (
                                "precedent" in str(d.get("type", "")).lower() or
                                "precedent" in str(d.get("source", "")).lower()
                            )
                        ]
                    }

                    formatted_result = self.answer_formatter.format_answer(
                        raw_answer=structured_answer,
                        question_type=q_type,
                        sources=sources,
                        confidence=confidence_info
                    )

                    if formatted_result and formatted_result.formatted_content:
                        final_answer = WorkflowUtils.normalize_answer(formatted_result.formatted_content)
                        state["answer"] = final_answer
                        state["format_metadata"] = formatted_result.metadata
                        self.logger.info("Visual formatting applied successfully")
                    else:
                        state["answer"] = structured_answer

                except Exception as e:
                    self.logger.warning(f"AnswerFormatter failed: {e}")
                    state["answer"] = structured_answer
            else:
                state["answer"] = structured_answer

            WorkflowUtils.update_processing_time(state, start_time)
            WorkflowUtils.add_step(state, "í¬ë§·íŒ…", "ë‹µë³€ êµ¬ì¡°í™” ë° í¬ë§·íŒ… ì™„ë£Œ")

        except Exception as e:
            WorkflowUtils.handle_error(state, str(e), "ë‹µë³€ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            answer = WorkflowUtils.get_state_value(state, "answer", "")
            normalized_answer = WorkflowUtils.normalize_answer(answer)
            state["answer"] = normalized_answer

        return state

    def format_answer_part(self, state: LegalWorkflowState) -> str:
        """
        Part 1: ë‹µë³€ í¬ë§·íŒ… ë¡œì§ë§Œ ì²˜ë¦¬

        Args:
            state: LegalWorkflowState ê°ì²´

        Returns:
            str: í¬ë§·íŒ…ëœ ë‹µë³€
        """
        format_start_time = time.time()

        answer = WorkflowUtils.get_state_value(state, "answer", "")
        query = WorkflowUtils.get_state_value(state, "query", "")
        query_type = WorkflowUtils.get_state_value(state, "query_type", "general_question")
        confidence = WorkflowUtils.get_state_value(state, "confidence", 0.0)

        # ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ (LLM ì‘ë‹µì—ì„œ ì¶”ë¡  ê³¼ì •ê³¼ ì‹¤ì œ ë‹µë³€ ë¶„ë¦¬)
        extraction_start_time = time.time()
        reasoning_info = self.reasoning_extractor.extract_reasoning(answer) if self.reasoning_extractor else {}
        actual_answer = None
        extraction_method = "none"

        # ì¶”ì¶œ ë°©ë²• ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì¬ì‹œë„
        if self.reasoning_extractor:
            extraction_methods = [
                ("output_section", lambda: self.reasoning_extractor.extract_by_output_section(answer)),
                ("reasoning_removed", lambda: self.reasoning_extractor.extract_by_removing_reasoning(answer, reasoning_info)),
                ("partial_cleaning", lambda: self.reasoning_extractor.extract_by_partial_cleaning(answer)),
            ]

            for method_name, extract_func in extraction_methods:
                try:
                    extracted = extract_func()
                    if extracted and extracted.strip() and extracted != answer:
                        actual_answer = extracted
                        extraction_method = method_name
                        break
                except Exception as e:
                    self.logger.debug(f"Extraction method {method_name} failed: {e}")
                    continue

        if not actual_answer or not actual_answer.strip():
            actual_answer = answer
            extraction_method = "fallback"

        extraction_time = time.time() - extraction_start_time

        # Stepë³„ ì¶”ì¶œ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        step_extraction_status = {
            "step1": {"extracted": bool(reasoning_info.get("step1")), "length": len(reasoning_info.get("step1", ""))},
            "step2": {"extracted": bool(reasoning_info.get("step2")), "length": len(reasoning_info.get("step2", ""))},
            "step3": {"extracted": bool(reasoning_info.get("step3")), "length": len(reasoning_info.get("step3", ""))},
        }

        # ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ í›„ í’ˆì§ˆ ê²€ì¦
        quality_metrics = {}
        if self.reasoning_extractor:
            quality_metrics = self.reasoning_extractor.verify_extraction_quality(
                original_answer=answer,
                actual_answer=actual_answer,
                reasoning_info=reasoning_info
            )

        # ì¶”ë¡  ê³¼ì •ì„ ë©”íƒ€ë°ì´í„°ì— ì €ì¥
        if reasoning_info.get("has_reasoning") or extraction_method != "none":
            if "metadata" not in state:
                state["metadata"] = {}
            if "debug" not in state["metadata"]:
                state["metadata"]["debug"] = {}

            REASONING_MAX_LENGTH = 5000
            STEP_MAX_LENGTH = 2000

            full_reasoning = reasoning_info.get("reasoning", "")
            reasoning_stored = full_reasoning
            if len(full_reasoning) > REASONING_MAX_LENGTH:
                summary_length = REASONING_MAX_LENGTH // 2
                reasoning_stored = (
                    full_reasoning[:summary_length] +
                    "\n\n... (ì¤‘ê°„ ìƒëµ) ...\n\n" +
                    full_reasoning[-summary_length:]
                )

            step1 = reasoning_info.get("step1", "")[:STEP_MAX_LENGTH] + ("... (ìƒëµ)" if len(reasoning_info.get("step1", "")) > STEP_MAX_LENGTH else "")
            step2 = reasoning_info.get("step2", "")[:STEP_MAX_LENGTH] + ("... (ìƒëµ)" if len(reasoning_info.get("step2", "")) > STEP_MAX_LENGTH else "")
            step3 = reasoning_info.get("step3", "")[:STEP_MAX_LENGTH] + ("... (ìƒëµ)" if len(reasoning_info.get("step3", "")) > STEP_MAX_LENGTH else "")

            state["metadata"]["debug"]["reasoning"] = {
                "extraction_success": reasoning_info.get("has_reasoning", False),
                "extraction_method": extraction_method,
                "extraction_time_ms": round(extraction_time * 1000, 2),
                "full_reasoning": reasoning_stored,
                "step1": step1,
                "step2": step2,
                "step3": step3,
                "step_extraction_status": step_extraction_status,
                "reasoning_section_count": reasoning_info.get("reasoning_section_count", 1),
                "quality_metrics": quality_metrics,
                "extracted_at": datetime.now().isoformat(),
                "original_answer_length": len(answer),
                "actual_answer_length": len(actual_answer),
                "reasoning_length": len(full_reasoning),
                "extraction_ratio": round(len(actual_answer) / len(answer), 3) if answer else 0.0,
                "memory_optimized": len(full_reasoning) > REASONING_MAX_LENGTH,
            }

        # ì‹¤ì œ ë‹µë³€ì—ì„œ ì¶”ë¡  ê³¼ì • í‚¤ì›Œë“œ ì •ë¦¬
        if self.reasoning_extractor:
            cleaned_actual_answer = self.reasoning_extractor.clean_reasoning_keywords(actual_answer if actual_answer else answer)
        else:
            cleaned_actual_answer = actual_answer if actual_answer else answer

        # 1ë‹¨ê³„: ë‹µë³€ êµ¬ì¡°í™” ë° ë²•ì  ê·¼ê±° ê°•í™”
        structured_answer = cleaned_actual_answer
        if self.answer_structure_enhancer:
            try:
                retrieved_docs = state.get("retrieved_docs", [])
                legal_references = state.get("legal_references", [])
                legal_citations = state.get("legal_citations", [])

                enhanced_result = self.answer_structure_enhancer.enhance_answer_structure(
                    answer=structured_answer,
                    question_type=query_type,
                    question=query,
                    domain="general",
                    retrieved_docs=retrieved_docs if retrieved_docs else None,
                    legal_references=legal_references if legal_references else None,
                    legal_citations=legal_citations if legal_citations else None
                )

                if enhanced_result and "structured_answer" in enhanced_result:
                    enhanced_answer = WorkflowUtils.normalize_answer(enhanced_result["structured_answer"])

                    # Enhancer ê²°ê³¼ì—ì„œ ì¶”ë¡  ê³¼ì •ì´ ì¬í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if self.reasoning_extractor:
                        enhanced_reasoning_info = self.reasoning_extractor.extract_reasoning(enhanced_answer)
                        if enhanced_reasoning_info.get("has_reasoning"):
                            self.logger.warning("AnswerStructureEnhancer re-included reasoning process. Re-extracting...")
                            enhanced_actual_answer = self.reasoning_extractor.extract_actual_answer(enhanced_answer)

                            if enhanced_actual_answer and enhanced_actual_answer.strip():
                                structured_answer = enhanced_actual_answer
                                enhanced_quality_metrics = self.reasoning_extractor.verify_extraction_quality(
                                    original_answer=enhanced_answer,
                                    actual_answer=enhanced_actual_answer,
                                    reasoning_info=enhanced_reasoning_info
                                )
                                if "metadata" in state and "debug" in state["metadata"] and "reasoning" in state["metadata"]["debug"]:
                                    existing_quality = state["metadata"]["debug"]["reasoning"].get("quality_metrics", {})
                                    if enhanced_quality_metrics.get("score", 1.0) < existing_quality.get("score", 1.0):
                                        self.logger.warning(
                                            f"Enhanced answer quality degraded "
                                            f"(before: {existing_quality.get('score', 1.0):.2f}, "
                                            f"after: {enhanced_quality_metrics.get('score', 1.0):.2f})"
                                        )
                                    state["metadata"]["debug"]["reasoning"]["enhanced_quality_metrics"] = enhanced_quality_metrics
                            else:
                                self.logger.warning("Failed to re-extract reasoning from enhancer output. Using original.")
                        else:
                            structured_answer = enhanced_answer
                            if self.reasoning_extractor:
                                enhanced_quality_metrics = self.reasoning_extractor.verify_extraction_quality(
                                    original_answer=structured_answer,
                                    actual_answer=structured_answer,
                                    reasoning_info=enhanced_reasoning_info
                                )
                                if "metadata" in state and "debug" in state["metadata"] and "reasoning" in state["metadata"]["debug"]:
                                    state["metadata"]["debug"]["reasoning"]["enhanced_quality_metrics"] = enhanced_quality_metrics
                    else:
                        structured_answer = enhanced_answer

                    quality_metrics_enhanced = enhanced_result.get("quality_metrics", {})
                    if quality_metrics_enhanced:
                        WorkflowUtils.set_state_value(state, "quality_metrics", quality_metrics_enhanced)
                        confidence = quality_metrics_enhanced.get("overall_score", confidence)
                        WorkflowUtils.set_state_value(state, "structure_confidence", confidence)

                    if "legal_citations" in enhanced_result:
                        WorkflowUtils.set_state_value(state, "legal_citations", enhanced_result["legal_citations"])

                    self.logger.info("Answer structure enhanced successfully")
            except Exception as e:
                self.logger.warning(f"AnswerStructureEnhancer failed: {e}")
                structured_answer = WorkflowUtils.normalize_answer(structured_answer)

        # 2ë‹¨ê³„: ì‹œê°ì  í¬ë§·íŒ… (ì´ëª¨ì§€ + ì„¹ì…˜ êµ¬ì¡°)
        formatted_answer = structured_answer
        if self.answer_formatter:
            try:
                from source.services.question_classifier import (
                    QuestionType as QType,
                )
                question_type_mapping = {
                    "precedent_search": QType.PRECEDENT_SEARCH,
                    "law_inquiry": QType.LAW_INQUIRY,
                    "legal_advice": QType.LEGAL_ADVICE,
                    "procedure_guide": QType.PROCEDURE_GUIDE,
                    "term_explanation": QType.TERM_EXPLANATION,
                    "general_question": QType.GENERAL_QUESTION,
                }
                q_type = question_type_mapping.get(query_type, QType.GENERAL_QUESTION)

                from source.services.confidence_calculator import (
                    ConfidenceInfo,
                )
                final_confidence = state.get("structure_confidence") or confidence
                confidence_info = ConfidenceInfo(
                    confidence=final_confidence,
                    level=self.map_confidence_level(final_confidence),
                    factors={"answer_quality": final_confidence},
                    explanation=f"ì‹ ë¢°ë„: {final_confidence:.1%}"
                )

                sources = {
                    "law_results": [
                        d for d in state.get("retrieved_docs", [])
                        if isinstance(d, dict) and (
                            "law" in str(d.get("type", "")).lower() or
                            "law" in str(d.get("source", "")).lower()
                        )
                    ],
                    "precedent_results": [
                        d for d in state.get("retrieved_docs", [])
                        if isinstance(d, dict) and (
                            "precedent" in str(d.get("type", "")).lower() or
                            "precedent" in str(d.get("source", "")).lower()
                        )
                    ]
                }

                formatted_result = self.answer_formatter.format_answer(
                    raw_answer=structured_answer,
                    question_type=q_type,
                    sources=sources,
                    confidence=confidence_info
                )

                if formatted_result and formatted_result.formatted_content:
                    formatted_answer = WorkflowUtils.normalize_answer(formatted_result.formatted_content)
                    state["format_metadata"] = formatted_result.metadata
                    self.logger.info("Visual formatting applied successfully")
                else:
                    formatted_answer = structured_answer
            except Exception as e:
                self.logger.warning(f"AnswerFormatter failed: {e}")
                formatted_answer = structured_answer

        # ë‹µë³€ ë°˜í™˜ ì „ ìµœì¢… ì •ë¦¬: ì¤‘ë³µ í—¤ë” ì œê±° ë° ì‹ ë¢°ë„ ê°’ í†µì¼ (ì¦‰ì‹œ ì ìš©)
        import re
        if formatted_answer and isinstance(formatted_answer, str):
            lines = formatted_answer.split('\n')
            cleaned_lines = []
            seen_answer_header = False

            for line in lines:
                # "## ë‹µë³€" í—¤ë”ëŠ” í•œ ë²ˆë§Œ ìœ ì§€
                if re.match(r'^##\s*ë‹µë³€\s*$', line, re.IGNORECASE):
                    if not seen_answer_header:
                        cleaned_lines.append(line)
                        seen_answer_header = True
                    continue
                # "###" ë¡œ ì‹œì‘í•˜ê³  "ë‹µë³€"ì´ í¬í•¨ëœ ì¤„ ì œê±° (ì´ëª¨ì§€ í¬í•¨)
                elif re.match(r'^###\s*.*ë‹µë³€', line, re.IGNORECASE):
                    continue
                else:
                    cleaned_lines.append(line)

            formatted_answer = '\n'.join(cleaned_lines)

            # ì‹ ë¢°ë„ ê°’ í†µì¼ (í˜„ì¬ stateì˜ confidence ê°’ìœ¼ë¡œ êµì²´) - format_answer_part ë‹¨ê³„ì—ì„œë„ ì ìš©
            current_confidence = state.get("confidence", 0.0)
            if current_confidence > 0:
                confidence_str = f"{current_confidence:.1%}"
                # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
                if current_confidence >= 0.8:
                    level = "high"
                    emoji = "ğŸŸ¢"
                elif current_confidence >= 0.6:
                    level = "medium"
                    emoji = "ğŸŸ¡"
                else:
                    level = "low"
                    emoji = "ğŸŸ "

                # ë°˜ë³µ ì ìš©í•˜ì—¬ ëª¨ë“  ì‹ ë¢°ë„ íŒ¨í„´ êµì²´
                for _ in range(5):  # ë” ë§ì´ ë°˜ë³µ
                    formatted_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', formatted_answer, flags=re.IGNORECASE)
                    formatted_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', formatted_answer, flags=re.IGNORECASE)
                    formatted_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', formatted_answer, flags=re.IGNORECASE)
                    formatted_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', formatted_answer, flags=re.IGNORECASE)
                    formatted_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%', f'ì‹ ë¢°ë„: {confidence_str}', formatted_answer, flags=re.IGNORECASE)
                    formatted_answer = re.sub(r'ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', formatted_answer, flags=re.IGNORECASE)

                # "ì‹ ë¢°ë„ì •ë³´" ì„¹ì…˜ë„ êµì²´ (format_answer_part ë‹¨ê³„ì—ì„œ)
                new_confidence_section = f'### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\n{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})\n\n**ìƒì„¸ì ìˆ˜:**\n- ë‹µë³€ í’ˆì§ˆ: {confidence_str}\n\n**ì„¤ëª…:** ì‹ ë¢°ë„: {confidence_str}'

                # ì„¹ì…˜ì„ ì§ì ‘ ì°¾ì•„ êµì²´
                lines = formatted_answer.split('\n')
                new_lines = []
                in_confidence_section = False

                for line in lines:
                    if re.match(r'^###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´', line, re.IGNORECASE):
                        in_confidence_section = True
                        new_lines.append(new_confidence_section)
                        continue

                    if in_confidence_section:
                        if line.strip() == '---' or line.strip().startswith('ğŸ’¼') or re.match(r'^###\s+', line):
                            in_confidence_section = False
                            new_lines.append(line)
                        continue

                    new_lines.append(line)

                formatted_answer = '\n'.join(new_lines)

        WorkflowUtils.update_processing_time(state, format_start_time)
        WorkflowUtils.add_step(state, "í¬ë§·íŒ…", "ë‹µë³€ êµ¬ì¡°í™” ë° í¬ë§·íŒ… ì™„ë£Œ")

        return formatted_answer

    def prepare_final_response(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ìµœì¢… ì‘ë‹µ ìƒíƒœ ì¤€ë¹„"""
        try:
            start_time = time.time()

            # íŒŒì´í”„ë¼ì¸ í’ˆì§ˆ ì¶”ì 
            if self.answer_generator:
                self.answer_generator.track_search_to_answer_pipeline(state)

            # Final pruning
            if len(state.get("processing_steps", [])) > MAX_PROCESSING_STEPS:
                state["processing_steps"] = prune_processing_steps(
                    state["processing_steps"],
                    max_items=MAX_PROCESSING_STEPS
                )

            errors = WorkflowUtils.get_state_value(state, "errors", [])
            if len(errors) > 10:
                WorkflowUtils.set_state_value(state, "errors", errors[-10:])

            # ì‹ ë¢°ë„ ê³„ì‚°
            answer_value = WorkflowUtils.normalize_answer(state.get("answer", ""))

            sources_list = []
            for doc in state.get("retrieved_docs", []):
                if isinstance(doc, dict):
                    sources_list.append(doc)

            query_type = WorkflowUtils.get_state_value(state, "query_type", "general")

            # ConfidenceCalculatorë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ë¢°ë„ ê³„ì‚°
            calculated_confidence = None
            if self.confidence_calculator and answer_value:
                try:
                    confidence_info = self.confidence_calculator.calculate_confidence(
                        answer=answer_value,
                        sources=sources_list,
                        question_type=query_type
                    )
                    calculated_confidence = confidence_info.confidence
                    self.logger.info(f"ConfidenceCalculator: confidence={calculated_confidence:.3f}, factors={confidence_info.factors}")
                except Exception as e:
                    self.logger.warning(f"ConfidenceCalculator failed: {e}")

            existing_confidence = state.get("structure_confidence") or state.get("confidence", 0.0)

            if calculated_confidence is not None:
                final_confidence = calculated_confidence
            else:
                final_confidence = existing_confidence

            # ê¸°ë³¸ ì‹ ë¢°ë„ ë³´ì¥
            min_confidence = 0.25 if (answer_value and sources_list) else (0.15 if answer_value else 0.05)
            final_confidence = max(final_confidence, min_confidence)

            # í‚¤ì›Œë“œ í¬í•¨ë„ ê¸°ë°˜ ë³´ì •
            keyword_coverage = self.calculate_keyword_coverage(state, answer_value)
            keyword_boost = keyword_coverage * 0.3
            adjusted_confidence = min(0.95, final_confidence + keyword_boost)

            # ì†ŒìŠ¤ ê°œìˆ˜ ê¸°ë°˜ ì¶”ê°€ ë³´ì •
            if sources_list:
                source_count = len(sources_list)
                if source_count >= 5:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.05)
                elif source_count >= 3:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.03)
                elif source_count >= 1:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.01)

            # ë‹µë³€ ê¸¸ì´ ê¸°ë°˜ ì¶”ê°€ ë³´ì •
            if answer_value:
                answer_length = len(answer_value)
                if answer_length >= 500:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.05)
                elif answer_length >= 200:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.03)
                elif answer_length >= 100:
                    adjusted_confidence = min(0.95, adjusted_confidence + 0.01)

            state["confidence"] = adjusted_confidence

            # Phase 3: ìµœì¢… answerë¥¼ ë¬¸ìì—´ë¡œ ìˆ˜ë ´ - íƒ€ì… í™•ì¸ í›„ í•„ìš”ì‹œë§Œ ì •ê·œí™”
            current_answer = state.get("answer", "")
            if not isinstance(current_answer, str):
                # ì´ë¯¸ í¬ë§·íŒ…ëœ answerëŠ” ì •ê·œí™” ë¶ˆí•„ìš”, íƒ€ì… ê²€ì¦ë§Œ ìˆ˜í–‰
                try:
                    state["answer"] = WorkflowUtils.normalize_answer(current_answer)
                except Exception:
                    state["answer"] = str(current_answer) if current_answer else ""

            # sources ì¶”ì¶œ (ê°œì„ : ë©”íƒ€ë°ì´í„°ì—ì„œë„ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ)
            final_sources_list = []
            seen_sources = set()

            for doc in state.get("retrieved_docs", []):
                if not isinstance(doc, dict):
                    continue

                # ë‹¤ì–‘í•œ í•„ë“œì—ì„œ ì†ŒìŠ¤ ì¶”ì¶œ ì‹œë„
                source = None

                # 1. ì§ì ‘ source í•„ë“œ í™•ì¸ (ë‹¨, "semantic", "keyword" ê°™ì€ ê²€ìƒ‰ íƒ€ì…ì€ ì œì™¸)
                # ìš°ì„ ìˆœìœ„: statute_name > law_name > source_name > source
                source_raw = (
                    doc.get("statute_name") or
                    doc.get("law_name") or
                    doc.get("source_name") or
                    doc.get("source")
                )

                # ê²€ìƒ‰ íƒ€ì…ì´ ì•„ë‹Œ ì‹¤ì œ ì†ŒìŠ¤ëª…ë§Œ ì¶”ì¶œ
                if source_raw and isinstance(source_raw, str):
                    source_lower = source_raw.lower().strip()
                    # ê²€ìƒ‰ íƒ€ì… í•„í„°ë§ (ë” í¬ê´„ì )
                    invalid_sources = ["semantic", "keyword", "unknown", "fts", "vector", "search", "text2sql", ""]
                    if source_lower not in invalid_sources and len(source_lower) > 2:
                        source = source_raw.strip()
                    else:
                        source = None
                else:
                    source = None

                # law_name, statute_nameë„ ë³„ë„ë¡œ í™•ì¸ (ìœ„ì—ì„œ í™•ì¸í–ˆì§€ë§Œ ì¬í™•ì¸)
                if not source:
                    law_name = doc.get("law_name") or doc.get("statute_name")
                    if law_name and isinstance(law_name, str) and law_name.strip() and len(law_name.strip()) > 2:
                        source = law_name.strip()

                # 2. metadataì—ì„œ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
                if not source:
                    metadata = doc.get("metadata", {})
                    if isinstance(metadata, dict):
                        source = (
                            metadata.get("statute_name") or
                            metadata.get("statute_abbrv") or
                            metadata.get("law_name") or
                            metadata.get("court") or
                            metadata.get("org") or
                            metadata.get("title")
                        )

                # 3. contentë‚˜ textì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ ì‹œë„ (ì •ê·œì‹ íŒ¨í„´)
                if not source:
                    content = doc.get("content", "") or doc.get("text", "")
                    if isinstance(content, str) and content:
                        import re
                        # ë²•ë ¹ëª… íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: "ë¯¼ë²• ì œ550ì¡°", "í˜•ë²• ì œ257ì¡°" ë“±)
                        law_pattern = re.search(r'([ê°€-í£]+ë²•)\s*(?:ì œ\d+ì¡°)?', content[:200])
                        if law_pattern:
                            source = law_pattern.group(1)

                # ì†ŒìŠ¤ ë¬¸ìì—´ ë³€í™˜ ë° ì¤‘ë³µ ì œê±°
                if source:
                    if isinstance(source, str):
                        source_str = source.strip()
                    else:
                        try:
                            source_str = str(source).strip()
                        except Exception:
                            source_str = None

                    if source_str and source_str not in seen_sources and source_str != "Unknown":
                        final_sources_list.append(source_str)
                        seen_sources.add(source_str)

            state["sources"] = final_sources_list[:10]  # ìµœëŒ€ 10ê°œë§Œ

            # ë²•ì  ì°¸ì¡° ì •ë³´ ì¶”ê°€
            if "legal_references" not in state:
                state["legal_references"] = []

            # ë©”íƒ€ë°ì´í„° ì„¤ì •
            self.set_metadata(state, answer_value, keyword_coverage)

            # ì„ì‹œ ë¼ìš°íŒ… í”Œë˜ê·¸/í”¼ë“œë°± ì œê±°
            try:
                metadata = state.get("metadata", {})
                if isinstance(metadata, dict):
                    for k in ("force_rag_fallback", "router_feedback"):
                        metadata.pop(k, None)
                    state["metadata"] = metadata
            except Exception:
                pass

            # sources í‘œì¤€í™” ë° ì¤‘ë³µ ì œê±° (ê°œì„ : í¬ë§·íŒ… í–¥ìƒ)
            try:
                src = state.get("sources", [])
                norm = []
                seen = set()
                if isinstance(src, list):
                    for s in src:
                        if isinstance(s, dict):
                            # dict í˜•ì‹ì˜ ì†ŒìŠ¤ëŠ” ë” ìì„¸í•œ ì •ë³´ ì¶”ì¶œ
                            source_name = s.get("statute_name") or s.get("law_name") or s.get("title") or s.get("source_name")
                            article = s.get("article_number") or s.get("article")
                            if source_name:
                                formatted_source = f"{source_name}"
                                if article:
                                    formatted_source += f" {article}"
                            else:
                                formatted_source = str(s.get("sql") or s.get("url") or s.get("type", "Unknown"))

                            key = formatted_source.lower()
                            if key in seen:
                                continue
                            seen.add(key)
                            norm.append(formatted_source)
                        elif isinstance(s, str):
                            if s in seen:
                                continue
                            seen.add(s.lower())
                            norm.append(s)

                # ìµœëŒ€ 10ê°œë¡œ ì œí•œí•˜ê³  ì •ë ¬ (ê¸´ ì´ë¦„ ìš°ì„ )
                state["sources"] = sorted(norm[:10], key=len, reverse=True)
            except Exception as e:
                self.logger.warning(f"Error formatting sources: {e}")
                pass

            WorkflowUtils.update_processing_time(state, start_time)
            WorkflowUtils.add_step(state, "ìµœì¢… ì¤€ë¹„", "ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ")

            # Final pruning after adding last step
            if len(state.get("processing_steps", [])) > MAX_PROCESSING_STEPS:
                state["processing_steps"] = prune_processing_steps(
                    state["processing_steps"],
                    max_items=MAX_PROCESSING_STEPS
                )

            self.logger.info(f"Final response prepared with confidence: {adjusted_confidence:.3f}")

        except Exception as e:
            WorkflowUtils.handle_error(state, str(e), "ìµœì¢… ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

        return state

    def _extract_metadata_sections(self, answer_text: str) -> Dict[str, str]:
        """ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ ì •ë³´ ì„¹ì…˜ ì¶”ì¶œ"""
        import re

        metadata = {
            "confidence_info": "",
            "reference_materials": "",
            "disclaimer": ""
        }

        if not answer_text or not isinstance(answer_text, str):
            return metadata

        # ì‹ ë¢°ë„ ì •ë³´ ì„¹ì…˜ ì¶”ì¶œ
        confidence_match = re.search(
            r'###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´.*?(?=\n###|\n---|\Z)',
            answer_text,
            flags=re.DOTALL | re.IGNORECASE
        )
        if confidence_match:
            metadata["confidence_info"] = confidence_match.group(0).strip()

        # ì°¸ê³  ìë£Œ ì„¹ì…˜ ì¶”ì¶œ
        reference_match = re.search(
            r'###\s*ğŸ“š\s*ì°¸ê³ \s*ìë£Œ.*?(?=\n###|\n---|\Z)',
            answer_text,
            flags=re.DOTALL | re.IGNORECASE
        )
        if reference_match:
            metadata["reference_materials"] = reference_match.group(0).strip()

        # ë©´ì±… ì¡°í•­ ì„¹ì…˜ ì¶”ì¶œ (--- ì´í›„ ë¶€ë¶„)
        disclaimer_match = re.search(
            r'---\s*\n\s*ğŸ’¼\s*\*\*ë©´ì±…\s*ì¡°í•­\*\*.*?(?=\n###|\Z)',
            answer_text,
            flags=re.DOTALL | re.IGNORECASE
        )
        if disclaimer_match:
            metadata["disclaimer"] = disclaimer_match.group(0).strip()

        return metadata

    def _remove_metadata_sections(self, answer_text: str) -> str:
        """ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ ì •ë³´ ì„¹ì…˜ ì œê±° (ì¤„ ë‹¨ìœ„ ì§ì ‘ ì²˜ë¦¬)"""
        import re

        if not answer_text or not isinstance(answer_text, str):
            return answer_text

        lines = answer_text.split('\n')
        cleaned_lines = []
        in_confidence_section = False
        in_reference_section = False
        in_disclaimer_section = False

        for line in lines:
            # ì‹ ë¢°ë„ ì •ë³´ ì„¹ì…˜ ì‹œì‘
            if re.match(r'^###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´', line, re.IGNORECASE):
                in_confidence_section = True
                continue

            # ì°¸ê³  ìë£Œ ì„¹ì…˜ ì‹œì‘
            if re.match(r'^###\s*ğŸ“š\s*ì°¸ê³ \s*ìë£Œ', line, re.IGNORECASE):
                in_reference_section = True
                continue

            # ë©´ì±… ì¡°í•­ ì„¹ì…˜ ì‹œì‘ (--- ë˜ëŠ” ğŸ’¼)
            if line.strip() == '---' or re.match(r'^\s*ğŸ’¼\s*\*\*ë©´ì±…\s*ì¡°í•­\*\*', line, re.IGNORECASE):
                in_disclaimer_section = True
                continue

            # ì„¹ì…˜ ì¢…ë£Œ í™•ì¸
            if in_confidence_section:
                # ë‹¤ìŒ ### ì„¹ì…˜ì´ë‚˜ --- ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                if re.match(r'^###\s+', line) or line.strip() == '---':
                    in_confidence_section = False
                    # ì´ ì¤„ì€ ê±´ë„ˆë›°ê¸°
                    continue
                # ì„¹ì…˜ ë‚´ë¶€ëŠ” ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                continue

            if in_reference_section:
                # ë‹¤ìŒ ### ì„¹ì…˜ì´ë‚˜ --- ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                if re.match(r'^###\s+', line) or line.strip() == '---':
                    in_reference_section = False
                    # ì´ ì¤„ì€ ê±´ë„ˆë›°ê¸°
                    continue
                # ì„¹ì…˜ ë‚´ë¶€ëŠ” ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                continue

            if in_disclaimer_section:
                # ë©´ì±… ì¡°í•­ ì„¹ì…˜ì€ ëê¹Œì§€ ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                continue

            # ë‚¨ì•„ìˆëŠ” ë©”íƒ€ ì •ë³´ íŒ¨í„´ ì œê±° (ìƒì„¸ ì ìˆ˜, ì„¤ëª… ë“±)
            if re.match(r'^\*\*ìƒì„¸\s*ì ìˆ˜:\*\*', line, re.IGNORECASE):
                continue
            if re.match(r'^\*\*ì„¤ëª…:\*\*', line, re.IGNORECASE):
                continue
            if re.match(r'^-\s*ë‹µë³€\s*í’ˆì§ˆ:', line, re.IGNORECASE):
                continue
            if re.match(r'^-\s*ì‹ ë¢°ë„:', line, re.IGNORECASE):
                continue

            # ë©”íƒ€ ì •ë³´ ì„¹ì…˜ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
            cleaned_lines.append(line)

        cleaned_text = '\n'.join(cleaned_lines)

        # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
        cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

        # ë‚¨ì•„ìˆëŠ” ë©”íƒ€ ì •ë³´ íŒ¨í„´ ì¶”ê°€ ì œê±°
        # "**ìƒì„¸ ì ìˆ˜:**" ì„¹ì…˜ ì œê±°
        cleaned_text = re.sub(r'\*\*ìƒì„¸\s*ì ìˆ˜:\*\*.*?\n', '', cleaned_text, flags=re.DOTALL | re.IGNORECASE)
        # "- ë‹µë³€ í’ˆì§ˆ:" íŒ¨í„´ ì œê±°
        cleaned_text = re.sub(r'-\s*ë‹µë³€\s*í’ˆì§ˆ:\s*[\d.]+%?\s*\n?', '', cleaned_text, flags=re.IGNORECASE | re.MULTILINE)
        # "**ì„¤ëª…:**" íŒ¨í„´ ì œê±°
        cleaned_text = re.sub(r'\*\*ì„¤ëª…:\*\*\s*ì‹ ë¢°ë„:.*?\n?', '', cleaned_text, flags=re.IGNORECASE | re.MULTILINE)
        # "- ì‹ ë¢°ë„:" íŒ¨í„´ ì œê±°
        cleaned_text = re.sub(r'-\s*ì‹ ë¢°ë„:\s*[\d.]+%?\s*\n?', '', cleaned_text, flags=re.IGNORECASE | re.MULTILINE)

        # ì—°ì†ëœ ë¹ˆ ì¤„ ì¬ì •ë¦¬
        cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

        return cleaned_text.strip()

    def _remove_answer_header(self, answer_text: str) -> str:
        """ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ '## ë‹µë³€' í—¤ë” ì œê±°"""
        import re

        if not answer_text or not isinstance(answer_text, str):
            return answer_text

        # '## ë‹µë³€' í—¤ë” ì œê±° (ë‹¨ë… ë¼ì¸ìœ¼ë¡œ ìˆëŠ” ê²½ìš°)
        answer_text = re.sub(r'^##\s*ë‹µë³€\s*\n+', '', answer_text, flags=re.MULTILINE | re.IGNORECASE)

        # ì•ë¶€ë¶„ì˜ ë¹ˆ ì¤„ ì œê±°
        answer_text = answer_text.lstrip('\n')

        return answer_text

    def _remove_intermediate_text(self, answer_text: str) -> str:
        """
        ì¤‘ê°„ ìƒì„± í…ìŠ¤íŠ¸ ì œê±° (STEP 0, ì›ë³¸ ë‹µë³€, ì§ˆë¬¸ ì •ë³´ ë“±)

        Args:
            answer_text: ì›ë³¸ ë‹µë³€ í…ìŠ¤íŠ¸

        Returns:
            ì¤‘ê°„ í…ìŠ¤íŠ¸ê°€ ì œê±°ëœ ë‹µë³€
        """
        import re

        if not answer_text or not isinstance(answer_text, str):
            return answer_text

        lines = answer_text.split('\n')
        cleaned_lines = []
        skip_section = False

        # ì œê±°í•  íŒ¨í„´ ëª©ë¡
        skip_patterns = [
            r'^##\s*STEP\s*0',
            r'^##\s*ì›ë³¸\s*í’ˆì§ˆ\s*í‰ê°€',
            r'^##\s*ì§ˆë¬¸\s*ì •ë³´',
            r'^##\s*ì›ë³¸\s*ë‹µë³€',
            r'^\*\*ì§ˆë¬¸\*\*:',
            r'^\*\*ì§ˆë¬¸\s*ìœ í˜•\*\*:',
            r'^í‰ê°€\s*ê²°ê³¼',
            r'ì›ë³¸\s*ì—\s*ê°œì„ ì´\s*í•„ìš”í•˜ë©´',
            r'^\*\*í‰ê°€\s*ê²°\s*ê³¼\s*ì—\s*ë”°ë¥¸\s*ì‘ì—…',
        ]

        for i, line in enumerate(lines):
            # ì„¹ì…˜ ì‹œì‘ íŒ¨í„´ í™•ì¸
            is_section_start = False
            for pattern in skip_patterns:
                if re.match(pattern, line, re.IGNORECASE):
                    skip_section = True
                    is_section_start = True
                    self.logger.debug(f"[INTERMEDIATE TEXT REMOVAL] Found skip pattern: {line[:50]}")
                    break

            if is_section_start:
                continue

            # ì„¹ì…˜ ì¢…ë£Œ í™•ì¸ (ë‹¤ìŒ ## í—¤ë” ë˜ëŠ” ì‹¤ì œ ë‹µë³€ ì‹œì‘)
            if skip_section:
                # ë‹¤ìŒ ## í—¤ë”ê°€ ë‚˜ì˜¤ê±°ë‚˜, ì‹¤ì œ ë‹µë³€ ì‹œì‘ íŒ¨í„´ í™•ì¸
                if re.match(r'^##\s+[ê°€-í£]', line):  # ì‹¤ì œ ë‹µë³€ ì„¹ì…˜ ì‹œì‘
                    skip_section = False
                    # ì´ ì¤„ì€ í¬í•¨ (í•˜ì§€ë§Œ íŒ¨í„´ì— ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš°ë§Œ)
                    if not any(re.match(p, line, re.IGNORECASE) for p in skip_patterns):
                        cleaned_lines.append(line)
                    continue

                # ì²´í¬ë¦¬ìŠ¤íŠ¸ íŒ¨í„´ ì œê±° (â€¢ [ ] í˜•íƒœ)
                if re.match(r'^\s*[â€¢\-\*]\s*\[.*?\].*?', line):
                    continue

                # "ì•ˆë…•í•˜ì„¸ìš”" ê°™ì€ ì¸ì‚¬ë§ ë’¤ì— ì˜¤ëŠ” ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë„ ì œê±°
                if re.match(r'^ì•ˆë…•í•˜ì„¸ìš”.*?ê¶ê¸ˆí•˜ì‹œêµ°ìš”', line, re.IGNORECASE):
                    continue

                # ì„¹ì…˜ ë‚´ë¶€ì˜ ë‹¤ë¥¸ ì¤„ë“¤ì€ ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                continue
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ê°€ (ì²´í¬ë¦¬ìŠ¤íŠ¸ íŒ¨í„´ í•„í„°ë§)
                if re.match(r'^\s*[â€¢\-\*]\s*\[.*?\].*?', line):
                    continue

                # ì²´í¬ë°•ìŠ¤ íŒ¨í„´ ì œê±° (â€¢ [ ] ë²•ì  ì •ë³´ê°€ ì¶©ë¶„í•˜ê³ ...)
                if re.search(r'\[.*?\].*?(ì¶©ë¶„|ëª…í™•|ì¼ê´€|í¬í•¨)', line):
                    continue

                cleaned_lines.append(line)

        cleaned_text = '\n'.join(cleaned_lines)

        # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
        cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)

        # ì•ë’¤ ê³µë°± ì œê±°
        cleaned_text = cleaned_text.strip()

        self.logger.debug(f"[INTERMEDIATE TEXT REMOVAL] Removed sections, original: {len(answer_text)}, cleaned: {len(cleaned_text)}")

        return cleaned_text

    def _adjust_answer_length(
        self,
        answer: str,
        query_type: str,
        query_complexity: str
    ) -> str:
        """
        ë‹µë³€ ê¸¸ì´ë¥¼ ì§ˆì˜ ìœ í˜•ì— ë§ê²Œ ì¡°ì ˆ

        Args:
            answer: ì›ë³¸ ë‹µë³€
            query_type: ì§ˆì˜ ìœ í˜•
            query_complexity: ì§ˆì˜ ë³µì¡ë„

        Returns:
            ì¡°ì ˆëœ ë‹µë³€
        """
        import re

        if not answer:
            return answer

        current_length = len(answer)

        # ëª©í‘œ ê¸¸ì´ ê²°ì •
        if query_complexity == "simple":
            min_len, max_len = ANSWER_LENGTH_TARGETS.get("simple_question", (500, 1000))
        elif query_complexity == "complex":
            min_len, max_len = ANSWER_LENGTH_TARGETS.get("complex_question", (2000, 3500))
        else:
            targets = ANSWER_LENGTH_TARGETS.get(query_type, ANSWER_LENGTH_TARGETS["default"])
            min_len, max_len = targets

        # ê¸¸ì´ê°€ ì ì ˆí•œ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if min_len <= current_length <= max_len:
            self.logger.debug(f"[ANSWER LENGTH] Length OK: {current_length} (target: {min_len}-{max_len})")
            return answer

        # ë„ˆë¬´ ê¸´ ê²½ìš°: í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
        if current_length > max_len:
            self.logger.info(f"[ANSWER LENGTH] Too long: {current_length}, adjusting to max {max_len}")
            # ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬
            sections = re.split(r'\n\n+', answer)

            # ê° ì„¹ì…˜ì˜ ì¤‘ìš”ë„ í‰ê°€ (ë²•ë ¹ ì¸ìš©, íŒë¡€ ë“± í¬í•¨ ì—¬ë¶€)
            important_sections = []
            other_sections = []

            for section in sections:
                if (re.search(r'\[ë²•ë ¹:', section) or
                    re.search(r'ëŒ€ë²•ì›', section) or
                    re.search(r'ì œ\s*\d+\s*ì¡°', section)):
                    important_sections.append(section)
                else:
                    other_sections.append(section)

            # ì¤‘ìš” ì„¹ì…˜ ìš°ì„  í¬í•¨
            result = []
            current_len = 0

            for section in important_sections:
                if current_len + len(section) <= max_len:
                    result.append(section)
                    current_len += len(section)
                else:
                    # ì„¹ì…˜ ì¼ë¶€ë§Œ í¬í•¨
                    remaining = max_len - current_len - 10  # ì—¬ìœ  ê³µê°„
                    if remaining > 100:  # ìµœì†Œ 100ì ì´ìƒì€ í¬í•¨
                        result.append(section[:remaining] + "...")
                    break

            # ì—¬ìœ ê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì„¹ì…˜ë„ í¬í•¨
            for section in other_sections:
                if current_len + len(section) <= max_len:
                    result.append(section)
                    current_len += len(section)
                else:
                    break

            adjusted_answer = '\n\n'.join(result)
            self.logger.info(f"[ANSWER LENGTH] Adjusted: {len(answer)} -> {len(adjusted_answer)}")
            return adjusted_answer

        # ë„ˆë¬´ ì§§ì€ ê²½ìš°: ì´ë¯¸ ìµœì†Œ ê¸¸ì´ë¡œ ìƒì„±ëœ ê²ƒì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
        # (ì¶”ê°€ ìƒì„±ì€ LLM í˜¸ì¶œì´ í•„ìš”í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í•˜ì§€ ì•ŠìŒ)
        self.logger.debug(f"[ANSWER LENGTH] Too short: {current_length} (target: {min_len}-{max_len}), keeping as is")
        return answer

    def _calculate_consistent_confidence(
        self,
        base_confidence: float,
        query_type: str,
        query_complexity: str,
        grounding_score: Optional[float] = None,
        source_coverage: Optional[float] = None
    ) -> float:
        """
        ì¼ê´€ëœ ì‹ ë¢°ë„ ê³„ì‚°

        Args:
            base_confidence: ê¸°ë³¸ ì‹ ë¢°ë„
            query_type: ì§ˆì˜ ìœ í˜•
            query_complexity: ì§ˆì˜ ë³µì¡ë„
            grounding_score: ê²€ì¦ ì ìˆ˜ (ì„ íƒì )
            source_coverage: ì†ŒìŠ¤ ì»¤ë²„ë¦¬ì§€ (ì„ íƒì )

        Returns:
            ì¡°ì •ëœ ì‹ ë¢°ë„
        """
        # 1. ê¸°ë³¸ ì‹ ë¢°ë„ ì¡°ì •
        confidence = base_confidence

        # 2. ì§ˆì˜ ë³µì¡ë„ì— ë”°ë¥¸ ì¡°ì •
        complexity_adjustments = {
            "simple": 0.05,      # ê°„ë‹¨í•œ ì§ˆì˜: +5%
            "moderate": 0.0,      # ë³´í†µ: ë³€í™” ì—†ìŒ
            "complex": -0.05      # ë³µì¡í•œ ì§ˆì˜: -5%
        }
        confidence += complexity_adjustments.get(query_complexity or "moderate", 0.0)

        # 3. ê²€ì¦ ì ìˆ˜ì— ë”°ë¥¸ ì¡°ì • (ìˆëŠ” ê²½ìš°)
        if grounding_score is not None and grounding_score < 0.8:
            confidence -= (0.8 - grounding_score) * 0.3  # ìµœëŒ€ 30% ê°ì†Œ

        # 4. ì†ŒìŠ¤ ì»¤ë²„ë¦¬ì§€ì— ë”°ë¥¸ ì¡°ì • (ìˆëŠ” ê²½ìš°)
        if source_coverage is not None and source_coverage < 0.5:
            confidence -= (0.5 - source_coverage) * 0.2  # ìµœëŒ€ 20% ê°ì†Œ

        # 5. ë²”ìœ„ ì œí•œ (0.0 ~ 1.0)
        confidence = max(0.0, min(1.0, confidence))

        # 6. ì§ˆì˜ ìœ í˜•ë³„ ìµœì†Œ ì‹ ë¢°ë„ ì„¤ì •
        min_confidence_by_type = {
            "simple_question": 0.75,
            "term_explanation": 0.80,
            "legal_analysis": 0.75,
            "complex_question": 0.70,
            "general_question": 0.70
        }
        min_confidence = min_confidence_by_type.get(query_type, 0.70)

        # ìµœì†Œ ì‹ ë¢°ë„ë³´ë‹¤ ë‚®ìœ¼ë©´ ê²½ê³  (í•˜ì§€ë§Œ ê°•ì œë¡œ ì˜¬ë¦¬ì§€ëŠ” ì•ŠìŒ)
        if confidence < min_confidence:
            self.logger.warning(
                f"ì‹ ë¢°ë„ê°€ ìµœì†Œ ê¸°ì¤€({min_confidence:.2%})ë³´ë‹¤ ë‚®ìŒ: {confidence:.2%}"
            )

        return confidence

    def prepare_final_response_part(
        self,
        state: LegalWorkflowState,
        query_complexity: Optional[str],
        needs_search: bool
    ) -> None:
        """
        Part 2: ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ë¡œì§ë§Œ ì²˜ë¦¬

        Args:
            state: LegalWorkflowState ê°ì²´
            query_complexity: ë³´ì¡´í•  query_complexity ê°’
            needs_search: ë³´ì¡´í•  needs_search ê°’
        """
        final_start_time = time.time()

        # query_complexity ë³´ì¡´ ë° ì €ì¥
        if query_complexity:
            self.preserve_and_store_values(state, query_complexity, needs_search)

        # íŒŒì´í”„ë¼ì¸ í’ˆì§ˆ ì¶”ì 
        if self.answer_generator:
            self.answer_generator.track_search_to_answer_pipeline(state)

        # Final pruning
        if len(state.get("processing_steps", [])) > MAX_PROCESSING_STEPS:
            state["processing_steps"] = prune_processing_steps(
                state["processing_steps"],
                max_items=MAX_PROCESSING_STEPS
            )

        errors = WorkflowUtils.get_state_value(state, "errors", [])
        if len(errors) > 10:
            WorkflowUtils.set_state_value(state, "errors", errors[-10:])

        # ì‹ ë¢°ë„ ê³„ì‚°
        answer_value = WorkflowUtils.normalize_answer(state.get("answer", ""))

        sources_list = []
        for doc in state.get("retrieved_docs", []):
            if isinstance(doc, dict):
                sources_list.append(doc)

        query_type = WorkflowUtils.get_state_value(state, "query_type", "general")

        # ConfidenceCalculatorë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ë¢°ë„ ê³„ì‚°
        calculated_confidence = None
        if self.confidence_calculator and answer_value:
            try:
                confidence_info = self.confidence_calculator.calculate_confidence(
                    answer=answer_value,
                    sources=sources_list,
                    question_type=query_type
                )
                calculated_confidence = confidence_info.confidence
                self.logger.info(f"ConfidenceCalculator: confidence={calculated_confidence:.3f}, factors={confidence_info.factors}")
            except Exception as e:
                self.logger.warning(f"ConfidenceCalculator failed: {e}")

        existing_confidence = state.get("structure_confidence") or state.get("confidence", 0.0)

        if calculated_confidence is not None:
            final_confidence = calculated_confidence
        else:
            final_confidence = existing_confidence

        # ê¸°ë³¸ ì‹ ë¢°ë„ ë³´ì¥
        min_confidence = 0.25 if (answer_value and sources_list) else (0.15 if answer_value else 0.05)
        final_confidence = max(final_confidence, min_confidence)

        # í‚¤ì›Œë“œ í¬í•¨ë„ ê¸°ë°˜ ë³´ì •
        keyword_coverage = self.calculate_keyword_coverage(state, answer_value)
        keyword_boost = keyword_coverage * 0.3
        adjusted_confidence = min(0.95, final_confidence + keyword_boost)

        # ì†ŒìŠ¤ ê°œìˆ˜ ê¸°ë°˜ ì¶”ê°€ ë³´ì •
        if sources_list:
            source_count = len(sources_list)
            if source_count >= 5:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.05)
            elif source_count >= 3:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.03)
            elif source_count >= 1:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.01)

        # ë‹µë³€ ê¸¸ì´ ê¸°ë°˜ ì¶”ê°€ ë³´ì •
        if answer_value:
            answer_length = len(answer_value)
            if answer_length >= 500:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.05)
            elif answer_length >= 200:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.03)
            elif answer_length >= 100:
                adjusted_confidence = min(0.95, adjusted_confidence + 0.01)

        # ì¼ê´€ëœ ì‹ ë¢°ë„ ê³„ì‚° ì ìš© (ê²€ì¦ ì ìˆ˜ ë°˜ì˜)
        # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ê²€ì¦ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸° (ìˆëŠ” ê²½ìš°)
        grounding_score = state.get("grounding_score")
        source_coverage = state.get("source_coverage")

        # ì¼ê´€ëœ ì‹ ë¢°ë„ë¡œ ìµœì¢… ì¡°ì •
        final_adjusted_confidence = self._calculate_consistent_confidence(
            base_confidence=adjusted_confidence,
            query_type=query_type,
            query_complexity=query_complexity or "moderate",
            grounding_score=grounding_score,
            source_coverage=source_coverage
        )

        state["confidence"] = final_adjusted_confidence

        # ì‹ ë¢°ë„ ê°’ ì„¤ì • ì§í›„ ë‹µë³€ í…ìŠ¤íŠ¸ì˜ ì‹ ë¢°ë„ ê°’ êµì²´ (ì¤‘ìš”: prepare_final_response_partì—ì„œ)
        import re
        current_answer = state.get("answer", "")
        if current_answer and isinstance(current_answer, str) and final_adjusted_confidence > 0:
            confidence_str = f"{final_adjusted_confidence:.1%}"
            # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
            if final_adjusted_confidence >= 0.8:
                level = "high"
                emoji = "ğŸŸ¢"
            elif final_adjusted_confidence >= 0.6:
                level = "medium"
                emoji = "ğŸŸ¡"
            else:
                level = "low"
                emoji = "ğŸŸ "

            # ë°˜ë³µ ì ìš©í•˜ì—¬ ëª¨ë“  ì‹ ë¢°ë„ íŒ¨í„´ êµì²´
            for _ in range(5):
                current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%', f'ì‹ ë¢°ë„: {confidence_str}', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', current_answer, flags=re.IGNORECASE)
                # ë ˆë²¨ë„ í•¨ê»˜ êµì²´
                current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(medium\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(high\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                current_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)

            # "ì‹ ë¢°ë„ì •ë³´" ì„¹ì…˜ ì§ì ‘ êµì²´
            new_confidence_section = f'### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\n{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})\n\n**ìƒì„¸ì ìˆ˜:**\n- ë‹µë³€ í’ˆì§ˆ: {confidence_str}\n\n**ì„¤ëª…:** ì‹ ë¢°ë„: {confidence_str}'

            lines = current_answer.split('\n')
            new_lines = []
            in_confidence_section = False

            for line in lines:
                if re.match(r'^###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´', line, re.IGNORECASE):
                    in_confidence_section = True
                    new_lines.append(new_confidence_section)
                    continue

                if in_confidence_section:
                    if line.strip() == '---' or line.strip().startswith('ğŸ’¼') or re.match(r'^###\s+', line):
                        in_confidence_section = False
                        new_lines.append(line)
                    continue

                new_lines.append(line)

            state["answer"] = '\n'.join(new_lines)

        # ìµœì¢… answerë¥¼ ë¬¸ìì—´ë¡œ ìˆ˜ë ´
        try:
            state["answer"] = WorkflowUtils.normalize_answer(state.get("answer", ""))
        except Exception:
            state["answer"] = str(state.get("answer", ""))

        # normalize_answer í˜¸ì¶œ ì´í›„ ì‹ ë¢°ë„ ê°’ ë‹¤ì‹œ êµì²´ (ì •ê·œí™”ë¡œ ì¸í•œ ì†ì‹¤ ë°©ì§€)
        if final_adjusted_confidence > 0 and state.get("answer"):
            current_answer = state.get("answer", "")
            if isinstance(current_answer, str):
                confidence_str = f"{final_adjusted_confidence:.1%}"
                if final_adjusted_confidence >= 0.8:
                    level = "high"
                    emoji = "ğŸŸ¢"
                elif final_adjusted_confidence >= 0.6:
                    level = "medium"
                    emoji = "ğŸŸ¡"
                else:
                    level = "low"
                    emoji = "ğŸŸ "

                # ë°˜ë³µ ì ìš©í•˜ì—¬ ëª¨ë“  ì‹ ë¢°ë„ íŒ¨í„´ êµì²´
                for _ in range(5):
                    current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%', f'ì‹ ë¢°ë„: {confidence_str}', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', current_answer, flags=re.IGNORECASE)
                    # ë ˆë²¨ë„ í•¨ê»˜ êµì²´
                    current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(medium\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(high\)', f'**ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)
                    current_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})', current_answer, flags=re.IGNORECASE)

                # "ì‹ ë¢°ë„ì •ë³´" ì„¹ì…˜ ì§ì ‘ êµì²´ (ë‹¤ì‹œ)
                new_confidence_section = f'### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\n{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})\n\n**ìƒì„¸ì ìˆ˜:**\n- ë‹µë³€ í’ˆì§ˆ: {confidence_str}\n\n**ì„¤ëª…:** ì‹ ë¢°ë„: {confidence_str}'

                lines = current_answer.split('\n')
                new_lines = []
                in_confidence_section = False

                for line in lines:
                    if re.match(r'^###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´', line, re.IGNORECASE):
                        in_confidence_section = True
                        new_lines.append(new_confidence_section)
                        continue

                    if in_confidence_section:
                        if line.strip() == '---' or line.strip().startswith('ğŸ’¼') or re.match(r'^###\s+', line):
                            in_confidence_section = False
                            new_lines.append(line)
                        continue

                    new_lines.append(line)

                state["answer"] = '\n'.join(new_lines)

        # sources ì¶”ì¶œ
        final_sources_list = []
        for doc in state.get("retrieved_docs", []):
            source = doc.get("source", "Unknown") if isinstance(doc, dict) else str(doc) if doc else "Unknown"
            if isinstance(source, str):
                final_sources_list.append(source)
            elif source is not None:
                try:
                    final_sources_list.append(str(source))
                except Exception:
                    final_sources_list.append("Unknown")
        state["sources"] = list(set(final_sources_list))

        # ë²•ì  ì°¸ì¡° ì •ë³´ ì¶”ê°€
        if "legal_references" not in state:
            state["legal_references"] = []

        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        self.set_metadata(state, answer_value, keyword_coverage)

        # ì„ì‹œ ë¼ìš°íŒ… í”Œë˜ê·¸/í”¼ë“œë°± ì œê±°
        try:
            metadata = state.get("metadata", {})
            if isinstance(metadata, dict):
                for k in ("force_rag_fallback", "router_feedback"):
                    metadata.pop(k, None)
                state["metadata"] = metadata
        except Exception:
            pass

        # sources í‘œì¤€í™” ë° ì¤‘ë³µ ì œê±°
        try:
            src = state.get("sources", [])
            norm = []
            seen = set()
            if isinstance(src, list):
                for s in src:
                    if isinstance(s, dict):
                        key = (s.get("type"), s.get("sql") or s.get("title") or s.get("url"))
                        if key in seen:
                            continue
                        seen.add(key)
                        norm.append(s)
                    elif isinstance(s, str):
                        if s in seen:
                            continue
                        seen.add(s)
                        norm.append(s)
            state["sources"] = norm[:10]
        except Exception:
            pass

        WorkflowUtils.update_processing_time(state, final_start_time)
        WorkflowUtils.add_step(state, "ìµœì¢… ì¤€ë¹„", "ìµœì¢… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ")

        # Final pruning after adding last step
        if len(state.get("processing_steps", [])) > MAX_PROCESSING_STEPS:
            state["processing_steps"] = prune_processing_steps(
                state["processing_steps"],
                max_items=MAX_PROCESSING_STEPS
            )

    def format_and_prepare_final(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í†µí•©ëœ ë‹µë³€ í¬ë§·íŒ… ë° ìµœì¢… ì¤€ë¹„ (format_answer + prepare_final_response)"""
        try:
            overall_start_time = time.time()

            # ë³´ì¡´í•  ê°’ ì¶”ì¶œ
            preserved_values = self.extract_preserved_values(state)
            query_complexity = preserved_values["query_complexity"]
            needs_search = preserved_values["needs_search"]

            # Part 1: í¬ë§·íŒ…
            formatted_answer = self.format_answer_part(state)
            # Phase 1/Phase 3: _set_answer_safelyëŠ” legal_workflow_enhancedì— ìˆìœ¼ë¯€ë¡œ,
            # ì—¬ê¸°ì„œëŠ” ì •ê·œí™”ë§Œ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì—…ë°ì´íŠ¸ (format_answer_partì—ì„œ ì´ë¯¸ ì •ê·œí™”ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
            if not isinstance(formatted_answer, str):
                formatted_answer = WorkflowUtils.normalize_answer(formatted_answer)
            state["answer"] = formatted_answer

            # Part 2: ìµœì¢… ì¤€ë¹„
            self.prepare_final_response_part(state, query_complexity, needs_search)

            # Part 3: ìµœì¢… í›„ì²˜ë¦¬ (ê°œì„ : ì¤‘ë³µ í—¤ë”, ë¹ˆ ì„¹ì…˜, ë¶ˆí•„ìš”í•œ í˜•ì‹ ì œê±°)
            final_answer = state.get("answer", "")
            if final_answer:
                import re

                # ì¤‘ë³µ í—¤ë” ì œê±° (ê°œì„ ëœ ë²„ì „)
                lines = final_answer.split('\n')
                result_lines = []
                seen_headers = set()
                skip_next_empty = False

                for i, line in enumerate(lines):
                    header_match = re.match(r'^(#{1,3})\s+(.+)', line)
                    if header_match:
                        level = len(header_match.group(1))
                        header_text = header_match.group(2).strip()

                        # ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
                        clean_header = re.sub(r'[ğŸ“–âš–ï¸ğŸ’¼ğŸ’¡ğŸ“šğŸ“‹â­ğŸ“ŒğŸ”ğŸ’¬ğŸ¯ğŸ“ŠğŸ“ğŸ“„â°ğŸ”—âš ï¸â—âœ…ğŸš¨ğŸ‰ğŸ’¯ğŸ””]+\s*', '', header_text).strip()

                        # "ë‹µë³€", "ë‹µ" ê°™ì€ ë‹¨ì–´ë§Œ í¬í•¨ëœ í—¤ë”ëŠ” ë” ì¼ë°˜ì ìœ¼ë¡œ ì²˜ë¦¬
                        normalized_header = re.sub(r'\s+', ' ', clean_header.lower())

                        # ì¤‘ë³µ í™•ì¸ (ê°™ì€ ë ˆë²¨, ê°™ì€ ì œëª©)
                        header_key = f"{level}:{normalized_header}"

                        # íŠ¹ì • ì¤‘ë³µ íŒ¨í„´ ì œê±°
                        if normalized_header in ["ë‹µë³€", "answer", "ë‹µ"]:
                            # ì´ë¯¸ "ë‹µë³€" í—¤ë”ê°€ ìˆìœ¼ë©´ ì¤‘ë³µ ì œê±°
                            if "ë‹µë³€" in seen_headers or "answer" in seen_headers:
                                skip_next_empty = True
                                continue

                        if header_key in seen_headers:
                            skip_next_empty = True
                            continue

                        seen_headers.add(normalized_header)
                        seen_headers.add(header_key)
                        skip_next_empty = False
                    elif skip_next_empty and line.strip() == "":
                        # ì¤‘ë³µ í—¤ë” ë‹¤ìŒì˜ ë¹ˆ ì¤„ë„ ì œê±°
                        continue
                    else:
                        skip_next_empty = False

                    result_lines.append(line)

                final_answer = '\n'.join(result_lines)

                # ì¤‘ë³µ í—¤ë” ì œê±° (ë” ê°•ë ¥í•œ ë°©ì‹ - ì¤„ ë‹¨ìœ„ ì§ì ‘ ì²˜ë¦¬)
                lines = final_answer.split('\n')
                cleaned_lines = []
                seen_answer_header = False
                i = 0

                while i < len(lines):
                    line = lines[i]
                    # "## ë‹µë³€" í—¤ë”ëŠ” í•œ ë²ˆë§Œ ìœ ì§€
                    if re.match(r'^##\s*ë‹µë³€\s*$', line, re.IGNORECASE):
                        if not seen_answer_header:
                            cleaned_lines.append(line)
                            seen_answer_header = True
                        # ë‹¤ìŒ ì¤„ì´ "###"ë¡œ ì‹œì‘í•˜ë©´ ê±´ë„ˆë›°ê¸°
                        if i + 1 < len(lines) and re.match(r'^###\s*.*ë‹µë³€', lines[i + 1], re.IGNORECASE):
                            i += 2  # "## ë‹µë³€"ê³¼ "### ë‹µë³€" ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                            continue
                        else:
                            i += 1
                            continue
                    # "###" ë¡œ ì‹œì‘í•˜ê³  "ë‹µë³€"ì´ í¬í•¨ëœ ì¤„ ì œê±°
                    elif re.match(r'^###\s*.*ë‹µë³€', line, re.IGNORECASE):
                        i += 1
                        continue  # ì´ ì¤„ì€ ê±´ë„ˆë›°ê¸°
                    else:
                        cleaned_lines.append(line)
                        i += 1

                final_answer = '\n'.join(cleaned_lines)

                # ì¶”ê°€ íŒ¨í„´ ì œê±° (ì •ê·œì‹ìœ¼ë¡œ ë‚¨ì€ ê²ƒë“¤ ì²˜ë¦¬)
                # "## ë‹µë³€" ë°”ë¡œ ë‹¤ìŒì— ì˜¤ëŠ” "###" í—¤ë” ì œê±°
                final_answer = re.sub(
                    r'(##\s*ë‹µë³€\s*\n+)(###\s*.*ë‹µë³€\s*\n+)',
                    r'\1',
                    final_answer,
                    flags=re.MULTILINE | re.IGNORECASE
                )

                # ì—°ì†ëœ "## ë‹µë³€" íŒ¨í„´ ì œê±°
                final_answer = re.sub(
                    r'##\s*ë‹µë³€\s*\n+\s*##\s*ë‹µë³€',
                    '## ë‹µë³€',
                    final_answer,
                    flags=re.IGNORECASE | re.MULTILINE
                )

                # ë¹ˆ ì„¹ì…˜ ì •ë¦¬ (í—¤ë”ë§Œ ìˆê³  ë‚´ìš© ì—†ëŠ” ì„¹ì…˜)
                final_answer = re.sub(r'###\s+[^\n]+\s*\n\s*\n(?=###|$)', '', final_answer, flags=re.MULTILINE)

                # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬ (3ê°œ ì´ìƒ -> 2ê°œ)
                final_answer = re.sub(r'\n{3,}', '\n\n', final_answer)

                # ê³µë°± ì—†ëŠ” í…ìŠ¤íŠ¸ ìˆ˜ì • (ì˜ˆ: "ë¯¼ì‚¬ë²•ìƒê³„ì•½í•´ì§€ì˜ìš”ê±´" -> "ë¯¼ì‚¬ë²•ìƒ ê³„ì•½ í•´ì§€ì˜ ìš”ê±´")
                # í•œê¸€ + ì˜ë¬¸/ìˆ«ì ì‚¬ì´ì— ê³µë°± ì¶”ê°€
                final_answer = re.sub(r'([ê°€-í£])([A-Za-z0-9])', r'\1 \2', final_answer)
                final_answer = re.sub(r'([A-Za-z0-9])([ê°€-í£])', r'\1 \2', final_answer)
                # íŠ¹ì • íŒ¨í„´ ìˆ˜ì • (ë²•ë ¹ëª… + ì¡°í•­)
                final_answer = re.sub(r'([ê°€-í£]+ë²•)([ê°€-í£])', r'\1 \2', final_answer)
                # "ì˜", "ë°", "ì™€", "ê³¼" ì•ë’¤ ê³µë°± ë³´ì¥
                final_answer = re.sub(r'([ê°€-í£])(ì˜|ë°|ì™€|ê³¼|ì—ì„œ|ìœ¼ë¡œ|ì—ê²Œ)([ê°€-í£])', r'\1 \2 \3', final_answer)

                # ë‹µë³€ ë‚´ë¶€ì˜ í•˜ë“œì½”ë”©ëœ ì‹ ë¢°ë„ ê°’ êµì²´ (stateì˜ confidenceë¡œ í†µì¼)
                current_confidence = state.get("confidence", 0.0)
                if current_confidence > 0:
                    # ë‹µë³€ ë‚´ë¶€ì˜ ëª¨ë“  ì‹ ë¢°ë„ íŒ¨í„´ ì°¾ê¸° ë° êµì²´ (ê°œì„ : ë” í¬ê´„ì ì¸ íŒ¨í„´)
                    confidence_str = f"{current_confidence:.1%}"

                    # ë‹¤ì–‘í•œ ì‹ ë¢°ë„ íŒ¨í„´ êµì²´ (ë” í¬ê´„ì ì´ê³  ê°•ë ¥í•œ íŒ¨í„´, ëª¨ë“  ê²½ìš°ë¥¼ ì°¾ê¸° ìœ„í•´ ë°˜ë³µ ì ìš©)
                    # ì´ëª¨ì§€ í¬í•¨ íŒ¨í„´ (ìš°ì„  ì²˜ë¦¬, ë” í¬ê´„ì ì¸ íŒ¨í„´)
                    final_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'ğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(medium\)', f'ğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'ğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'ğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)

                    # ë³¼ë“œ íŒ¨í„´ (ë” í¬ê´„ì )
                    final_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(low\)', f'**ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*\s*\(medium\)', f'**ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)

                    # ì¼ë°˜ íŒ¨í„´ (ë” í¬ê´„ì )
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%\s*\(low\)', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%\s*\(medium\)', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%\s*\(high\)', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    # ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´ (ëª¨ë“  ìˆ«ì íŒ¨í„´ ë§¤ì¹­, ì—¬ëŸ¬ ë²ˆ ì ìš©)
                    for _ in range(3):  # ì—¬ëŸ¬ ë²ˆ ì ìš©í•˜ì—¬ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ êµì²´
                        final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'ğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)

                    # % ì—†ëŠ” íŒ¨í„´
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+\s*\(low\)', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+\s*\(medium\)', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+(?:\s|$|\))', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)

                    # ë‹µë³€ í’ˆì§ˆ íŒ¨í„´
                    final_answer = re.sub(r'ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', final_answer, flags=re.IGNORECASE)
                    final_answer = re.sub(r'ë‹µë³€\s*í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', final_answer, flags=re.IGNORECASE)

                    # ìƒì„¸ì ìˆ˜ íŒ¨í„´ë„ êµì²´
                    final_answer = re.sub(r'ìƒì„¸ì ìˆ˜:.*?ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ìƒì„¸ì ìˆ˜:\n- ë‹µë³€ í’ˆì§ˆ: {confidence_str}', final_answer, flags=re.IGNORECASE | re.DOTALL)

                    # "ì‹ ë¢°ë„ì •ë³´" ì„¹ì…˜ ì „ì²´ êµì²´ ì‹œë„
                    final_answer = re.sub(
                        r'###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´.*?(?=\n###|\n---|\Z)',
                        f'### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\nğŸŸ¡ **ì‹ ë¢°ë„: {confidence_str}** (medium)\n\n**ì„¤ëª…:** ì‹ ë¢°ë„: {confidence_str}',
                        final_answer,
                        flags=re.DOTALL | re.IGNORECASE
                    )

                # "ì°¸ê³ ìë£Œ" ì„¹ì…˜ì´ "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¡œ í‘œì‹œëœ ê²½ìš° ì†ŒìŠ¤ ì •ë³´ë¡œ êµì²´
                sources_list = state.get("sources", [])
                if sources_list and len(sources_list) > 0:
                    # ì‹¤ì œ ì†ŒìŠ¤ ì´ë¦„ë§Œ ì¶”ì¶œ (ê²€ìƒ‰ íƒ€ì… ì œì™¸)
                    valid_sources = [s for s in sources_list if isinstance(s, str) and
                                   s.lower() not in ["semantic", "keyword", "unknown", "fts", "vector", ""]]

                    if valid_sources:
                        sources_text = "\n".join([f"- {source}" for source in valid_sources[:5]])
                        # "ì°¸ê³ ìë£Œ" ì„¹ì…˜ êµì²´
                        final_answer = re.sub(
                            r'###\s*ğŸ“š\s*ì°¸ê³ ìë£Œ.*?ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\.',
                            f'### ğŸ“š ì°¸ê³ ìë£Œ\n\n{sources_text}',
                            final_answer,
                            flags=re.DOTALL | re.IGNORECASE
                        )
                        # "ì°¸ê³ ìë£Œ" ì„¹ì…˜ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                        final_answer = re.sub(
                            r'###\s*ğŸ“š\s*ì°¸ê³ ìë£Œ\s*\n+\s*ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\.',
                            f'### ğŸ“š ì°¸ê³ ìë£Œ\n\n{sources_text}',
                            final_answer,
                            flags=re.IGNORECASE
                        )
                    else:
                        # ìœ íš¨í•œ ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ "ì°¸ê³ ìë£Œ" ì„¹ì…˜ ì œê±°
                        final_answer = re.sub(
                            r'###\s*ğŸ“š\s*ì°¸ê³ ìë£Œ.*?(?=\n###|\n---|\Z)',
                            '',
                            final_answer,
                            flags=re.DOTALL | re.IGNORECASE
                        )
                else:
                    # ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ "ì°¸ê³ ìë£Œ" ì„¹ì…˜ ì œê±°
                    final_answer = re.sub(
                        r'###\s*ğŸ“š\s*ì°¸ê³ ìë£Œ.*?(?=\n###|\n---|\Z)',
                        '',
                        final_answer,
                        flags=re.DOTALL | re.IGNORECASE
                    )

                # ìµœì¢… í›„ì²˜ë¦¬: ì¤‘ë³µ í—¤ë”ê°€ ì—¬ì „íˆ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì œê±° (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
                # "###" ë¡œ ì‹œì‘í•˜ê³  "ë‹µë³€"ì´ í¬í•¨ëœ ì¤„ì´ ìˆëŠ”ì§€ í™•ì¸
                if '###' in final_answer and 'ë‹µë³€' in final_answer:
                    lines_final = final_answer.split('\n')
                    final_cleaned = []
                    for line in lines_final:
                        # "###" ë¡œ ì‹œì‘í•˜ê³  "ë‹µë³€"ì´ í¬í•¨ëœ ì¤„ì€ ì œê±°
                        if re.match(r'^###\s*.*ë‹µë³€', line, re.IGNORECASE):
                            continue
                        final_cleaned.append(line)
                    final_answer = '\n'.join(final_cleaned)

                # ì‹ ë¢°ë„ ê°’ ìµœì¢… êµì²´ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜ - ë” ê°•ë ¥í•œ íŒ¨í„´ ë§¤ì¹­)
                current_confidence = state.get("confidence", 0.0)
                if current_confidence > 0:
                    confidence_str = f"{current_confidence:.1%}"
                    # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
                    if current_confidence >= 0.8:
                        level = "high"
                        emoji = "ğŸŸ¢"
                    elif current_confidence >= 0.6:
                        level = "medium"
                        emoji = "ğŸŸ¡"
                    else:
                        level = "low"
                        emoji = "ğŸŸ "

                    # ëª¨ë“  ì‹ ë¢°ë„ íŒ¨í„´ ìµœì¢… êµì²´ (ë°˜ë³µ ì ìš©, ë” í¬ê´„ì ì¸ íŒ¨í„´)
                    for _ in range(10):  # ì¶©ë¶„íˆ ë°˜ë³µ ì ìš©
                        # ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´ ìš°ì„ 
                        final_answer = re.sub(r'\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'**ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ğŸŸ¡\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ğŸŸ \s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ğŸŸ¢\s*\*\*ì‹ ë¢°ë„:\s*[\d.]+%\*\*', f'{emoji} **ì‹ ë¢°ë„: {confidence_str}**', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ì‹ ë¢°ë„:\s*[\d.]+%', f'ì‹ ë¢°ë„: {confidence_str}', final_answer, flags=re.IGNORECASE)
                        final_answer = re.sub(r'ë‹µë³€í’ˆì§ˆ:\s*[\d.]+%', f'ë‹µë³€ í’ˆì§ˆ: {confidence_str}', final_answer, flags=re.IGNORECASE)

                    # "ì‹ ë¢°ë„ì •ë³´" ì„¹ì…˜ ì „ì²´ë¥¼ ì°¾ì•„ì„œ êµì²´ (ë” ê°•ë ¥í•œ ë°©ë²• - ì§ì ‘ ì„¹ì…˜ ì°¾ê¸°)
                    # ì„¹ì…˜ ì „ì²´ë¥¼ ìƒˆë¡œìš´ ë‚´ìš©ìœ¼ë¡œ êµì²´
                    new_confidence_section = f'### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\n{emoji} **ì‹ ë¢°ë„: {confidence_str}** ({level})\n\n**ìƒì„¸ì ìˆ˜:**\n- ë‹µë³€ í’ˆì§ˆ: {confidence_str}\n\n**ì„¤ëª…:** ì‹ ë¢°ë„: {confidence_str}'

                    # ë” ì§ì ‘ì ì¸ ë°©ë²•: "### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´"ë¡œ ì‹œì‘í•˜ëŠ” ì„¹ì…˜ì„ ì§ì ‘ ì°¾ì•„ êµì²´
                    lines = final_answer.split('\n')
                    new_lines = []
                    in_confidence_section = False

                    for i, line in enumerate(lines):
                        # "### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´" ë˜ëŠ” "###ğŸ’¡ì‹ ë¢°ë„ì •ë³´"ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ ì°¾ê¸°
                        if re.match(r'^###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´', line, re.IGNORECASE):
                            in_confidence_section = True
                            new_lines.append(new_confidence_section)
                            continue

                        # ì‹ ë¢°ë„ ì„¹ì…˜ ë‚´ë¶€ì´ë©´ ê±´ë„ˆë›°ê¸° (ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ê¹Œì§€)
                        if in_confidence_section:
                            # "---" ë˜ëŠ” "ğŸ’¼" ë˜ëŠ” ë‹¤ìŒ "###" ì„¹ì…˜ ì‹œì‘ê¹Œì§€ ê±´ë„ˆë›°ê¸°
                            if line.strip() == '---' or line.strip().startswith('ğŸ’¼') or re.match(r'^###\s+', line):
                                in_confidence_section = False
                                # ì„¹ì…˜ ì¢…ë£Œ í›„ ì´ ì¤„ì€ í¬í•¨
                                new_lines.append(line)
                            # ê·¸ ì™¸ëŠ” ëª¨ë‘ ê±´ë„ˆë›°ê¸°
                            continue

                        new_lines.append(line)

                    final_answer = '\n'.join(new_lines)

                    # ì¶”ê°€ë¡œ ì •ê·œì‹ìœ¼ë¡œë„ ì‹œë„ (fallback)
                    if '### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´' in final_answer or '###ğŸ’¡ì‹ ë¢°ë„ì •ë³´' in final_answer:
                        # ì •ê·œì‹ìœ¼ë¡œ í•œ ë²ˆ ë” êµì²´ ì‹œë„
                        patterns = [
                            r'###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´.*?(?=\n---|\nğŸ’¼|\Z)',
                            r'###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´.*?(?=\n###|\Z)',
                            r'###\s*ğŸ’¡\s*ì‹ ë¢°ë„ì •ë³´[^\n]*\n.*?(?=\n---|\nğŸ’¼|\Z)',
                        ]

                        for pattern in patterns:
                            if re.search(pattern, final_answer, flags=re.DOTALL | re.IGNORECASE):
                                final_answer = re.sub(
                                    pattern,
                                    new_confidence_section,
                                    final_answer,
                                    flags=re.DOTALL | re.IGNORECASE
                                )
                                break

                # ë©”íƒ€ ì •ë³´ ì„¹ì…˜ ì¶”ì¶œ ë° ë¶„ë¦¬ (ì‹ ë¢°ë„ ì„¹ì…˜ êµì²´ í›„)
                metadata_sections = self._extract_metadata_sections(final_answer)

                # answerì—ì„œ ë©”íƒ€ ì •ë³´ ì„¹ì…˜ ì œê±°
                clean_answer = self._remove_metadata_sections(final_answer)

                # ì¤‘ê°„ ìƒì„± í…ìŠ¤íŠ¸ ì œê±° (STEP 0, ì›ë³¸ ë‹µë³€, ì§ˆë¬¸ ì •ë³´ ë“±)
                clean_answer = self._remove_intermediate_text(clean_answer)

                # '## ë‹µë³€' í—¤ë” ì œê±°
                clean_answer = self._remove_answer_header(clean_answer)

                # ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ (ì§ˆì˜ ìœ í˜•ì— ë§ê²Œ)
                query_type = WorkflowUtils.get_state_value(state, "query_type", "general_question")
                query_complexity = WorkflowUtils.get_state_value(state, "complexity_level", "moderate")
                clean_answer = self._adjust_answer_length(clean_answer, query_type, query_complexity)

                # ë””ë²„ê¹… ë¡œê·¸
                self.logger.info(f"[ANSWER CLEANUP] Original length: {len(final_answer)}, Clean length: {len(clean_answer)}")
                self.logger.info(f"[ANSWER CLEANUP] Has confidence_info: {bool(metadata_sections.get('confidence_info'))}")
                self.logger.info(f"[ANSWER CLEANUP] Has reference_materials: {bool(metadata_sections.get('reference_materials'))}")
                self.logger.info(f"[ANSWER CLEANUP] Has disclaimer: {bool(metadata_sections.get('disclaimer'))}")

                # stateì— ì •ë¦¬ëœ answer ì €ì¥
                state["answer"] = clean_answer.strip()

                # ë©”íƒ€ ì •ë³´ë¥¼ ë³„ë„ í•„ë“œë¡œ ì €ì¥
                state["confidence_info"] = metadata_sections.get("confidence_info", "")
                state["reference_materials"] = metadata_sections.get("reference_materials", "")
                state["disclaimer"] = metadata_sections.get("disclaimer", "")

                # ìµœì¢… ë‹µë³€ ê²€ì¦ (ê°œì„ : í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ë¡œì§ ì¶”ê°€)
                # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ê²€ì¦ ì¶”ê°€ (Hallucination ë°©ì§€)
                retrieved_docs = state.get("retrieved_docs", [])
                query = WorkflowUtils.get_state_value(state, "query", "")

                # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ê²€ì¦ ìˆ˜í–‰
                source_verification_result = AnswerValidator.validate_answer_source_verification(
                    answer=clean_answer,
                    retrieved_docs=retrieved_docs,
                    query=query
                )

                # ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ ì‹ ë¢°ë„ ì¡°ì •
                if source_verification_result.get("needs_review", False):
                    self.logger.warning(
                        f"ë‹µë³€ ê²€ì¦ ê²°ê³¼: grounding_score={source_verification_result.get('grounding_score', 0):.2f}, "
                        f"unverified_count={source_verification_result.get('unverified_count', 0)}"
                    )

                    # ì‹ ë¢°ë„ ì¡°ì • ì ìš©
                    current_confidence = state.get("confidence", 0.8)
                    penalty = source_verification_result.get("confidence_penalty", 0.0)
                    adjusted_confidence = max(0.0, current_confidence - penalty)
                    state["confidence"] = adjusted_confidence

                    # ê²€ì¦ë˜ì§€ ì•Šì€ ì„¹ì…˜ì„ ë¡œê·¸ì— ê¸°ë¡
                    unverified = source_verification_result.get("unverified_sentences", [])
                    if unverified:
                        self.logger.warning(
                            f"ê²€ì¦ë˜ì§€ ì•Šì€ ë¬¸ì¥ {len(unverified)}ê°œ ë°œê²¬. "
                            f"ìƒ˜í”Œ: {unverified[0].get('sentence', '')[:50]}..."
                        )
                else:
                    self.logger.info(
                        f"ë‹µë³€ ê²€ì¦ í†µê³¼: grounding_score={source_verification_result.get('grounding_score', 0):.2f}"
                    )

                # ê²€ì¦ ê²°ê³¼ë¥¼ stateì— ì €ì¥ (ì‹ ë¢°ë„ ê³„ì‚°ì— ì‚¬ìš©)
                state["grounding_score"] = source_verification_result.get("grounding_score", 0.0)
                state["source_coverage"] = source_verification_result.get("source_coverage", 0.0)

                # ê¸°ì¡´ ë‹µë³€ ê²€ì¦ ìˆ˜í–‰
                validation_result = self._validate_final_answer(clean_answer, retrieved_docs, query)
                if validation_result.get("has_issues"):
                    self.logger.warning(f"Answer validation issues: {validation_result.get('issues', [])}")
                    # ê²€ì¦ ì‹¤íŒ¨í•´ë„ ë‹µë³€ì€ ìœ ì§€ (ë¡œê·¸ë§Œ ê¸°ë¡)

            elapsed = time.time() - overall_start_time
            confidence = state.get("confidence", 0.0)
            self.logger.info(
                f"format_and_prepare_final completed in {elapsed:.2f}s, "
                f"confidence: {confidence:.3f}"
            )

        except Exception as e:
            WorkflowUtils.handle_error(state, str(e), "ë‹µë³€ í¬ë§·íŒ… ë° ìµœì¢… ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            answer = WorkflowUtils.get_state_value(state, "answer", "")

            # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì¶”ë¡  ê³¼ì • ë¶„ë¦¬ ì‹œë„
            if self.reasoning_extractor:
                try:
                    reasoning_info = self.reasoning_extractor.extract_reasoning(answer)
                    if reasoning_info.get("has_reasoning"):
                        actual_answer = self.reasoning_extractor.extract_actual_answer(answer)
                        if actual_answer and actual_answer.strip():
                            state["answer"] = WorkflowUtils.normalize_answer(actual_answer)
                except Exception:
                    pass

            # Phase 5: ì—ëŸ¬ ì²˜ë¦¬ í†µì¼ - answer ë³µì› ë¡œì§ ê°œì„ 
            if not state.get("answer"):
                # answerê°€ ì—†ìœ¼ë©´ ì •ê·œí™”í•˜ì—¬ ì„¤ì •
                state["answer"] = WorkflowUtils.normalize_answer(answer) if answer else ""
            elif answer and state.get("answer") != answer:
                # answerê°€ ìˆì§€ë§Œ ì›ë³¸ê³¼ ë‹¤ë¥´ë©´ ì •ê·œí™”ë§Œ ìˆ˜í–‰
                current_answer = state.get("answer")
                if not isinstance(current_answer, str):
                    state["answer"] = WorkflowUtils.normalize_answer(current_answer)

        return state

    def _validate_final_answer(
        self,
        answer: str,
        retrieved_docs: Optional[List[Dict[str, Any]]] = None,
        query: Optional[str] = None
    ) -> Dict[str, Any]:
        """ìµœì¢… ë‹µë³€ ê²€ì¦ (ê°•í™”ëœ ë²„ì „)"""
        try:
            issues = []
            warnings = []
            quality_metrics = {}

            if not answer or len(answer.strip()) == 0:
                issues.append("ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return {"has_issues": True, "issues": issues, "warnings": warnings, "quality_metrics": quality_metrics}

            # ì¤‘ë³µ í—¤ë” í™•ì¸ (ê°œì„ )
            headers = re.findall(r'^#{1,3}\s+(.+)$', answer, re.MULTILINE)
            header_counts = {}
            duplicate_headers = []
            for header in headers:
                clean_header = re.sub(r'[ğŸ“–âš–ï¸ğŸ’¼ğŸ’¡ğŸ“šğŸ“‹â­ğŸ“ŒğŸ”ğŸ’¬ğŸ¯ğŸ“ŠğŸ“ğŸ“„â°ğŸ”—âš ï¸â—âœ…ğŸš¨ğŸ‰ğŸ’¯ğŸ””]+\s*', '', header).strip().lower()
                normalized = re.sub(r'\s+', ' ', clean_header)
                header_counts[normalized] = header_counts.get(normalized, 0) + 1
                if header_counts[normalized] > 1:
                    duplicate_headers.append(normalized)

            # ì¤‘ë³µ í—¤ë” ì œê±° ì‹œë„ (ìë™ ìˆ˜ì •)
            if duplicate_headers:
                warnings.append(f"ì¤‘ë³µ í—¤ë” ë°œê²¬: {', '.join(set(duplicate_headers))}")

            # ë¹ˆ ì„¹ì…˜ í™•ì¸ (ê°œì„ )
            sections = re.findall(r'^###\s+(.+)$\n(.*?)(?=^###|$)', answer, re.MULTILINE | re.DOTALL)
            empty_sections = []
            for section_title, section_content in sections:
                clean_content = section_content.strip()
                if not clean_content or clean_content == "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." or len(clean_content) < 10:
                    empty_sections.append(section_title.strip())

            if empty_sections:
                warnings.append(f"ë¹ˆ ì„¹ì…˜: {', '.join(empty_sections)}")

            # ë‹µë³€ ê¸¸ì´ í™•ì¸ (ê°œì„ )
            answer_length = len(answer)
            quality_metrics["answer_length"] = answer_length
            if answer_length < 50:
                issues.append("ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (50ì ë¯¸ë§Œ)")
            elif answer_length > 5000:
                warnings.append("ë‹µë³€ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (5000ì ì´ˆê³¼)")
            elif answer_length < 100:
                warnings.append("ë‹µë³€ì´ ë‹¤ì†Œ ì§§ìŠµë‹ˆë‹¤ (100ì ë¯¸ë§Œ)")

            # ë²•ì  ì¸ìš© í™•ì¸ (ê°œì„ )
            legal_citations = len(re.findall(r'\[ë²•ë ¹:|\[íŒë¡€:|ì œ\d+ì¡°', answer))
            quality_metrics["legal_citations"] = legal_citations
            if legal_citations == 0:
                warnings.append("ë²•ì  ì¸ìš©ì´ ì—†ìŠµë‹ˆë‹¤")

            # êµ¬ì¡° í’ˆì§ˆ ì ìˆ˜ (ê°œì„ )
            structure_score = 0.0
            if len(headers) > 0:
                structure_score += 0.3  # í—¤ë”ê°€ ìˆìœ¼ë©´ êµ¬ì¡°í™”ë¨
            if len(re.findall(r'\n\n', answer)) > 2:
                structure_score += 0.2  # ë‹¨ë½ êµ¬ë¶„ì´ ìˆìœ¼ë©´ ê°€ë…ì„± í–¥ìƒ
            if re.search(r'\d+\.|-\s+', answer):
                structure_score += 0.2  # ëª©ë¡ì´ ìˆìœ¼ë©´ êµ¬ì¡°í™”ë¨
            if len(answer) > 200:
                structure_score += 0.3  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆìŒ

            quality_metrics["structure_score"] = structure_score

            # ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (ê°œì„ )
            readability_score = structure_score * 100
            quality_metrics["readability_score"] = readability_score

            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = structure_score
            if legal_citations > 0:
                quality_score += 0.2  # ë²•ì  ì¸ìš© ë³´ë„ˆìŠ¤
            if answer_length >= 200 and answer_length <= 2000:
                quality_score += 0.1  # ì ì ˆí•œ ê¸¸ì´ ë³´ë„ˆìŠ¤

            quality_metrics["quality_score"] = min(1.0, quality_score)

            return {
                "has_issues": len(issues) > 0,
                "issues": issues,
                "warnings": warnings,
                "readability_score": readability_score,
                "header_count": len(headers),
                "quality_metrics": quality_metrics,
                "answer_length": len(answer)
            }

        except Exception as e:
            self.logger.error(f"Error validating final answer: {e}")
            return {"has_issues": False, "issues": [], "warnings": [f"ê²€ì¦ ì˜¤ë¥˜: {str(e)}"]}

    def extract_preserved_values(self, state: LegalWorkflowState) -> Dict[str, Any]:
        """
        stateì—ì„œ ë³´ì¡´í•´ì•¼ í•˜ëŠ” ê°’ë“¤ì„ í•œ ë²ˆì— ì¶”ì¶œ

        Args:
            state: LegalWorkflowState ê°ì²´

        Returns:
            Dict[str, Any]: {
                "query_complexity": str | None,
                "needs_search": bool
            }
        """
        preserved = {
            "query_complexity": None,
            "needs_search": True
        }

        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê²€ìƒ‰
        search_paths = [
            (None, "query_complexity", "needs_search"),  # ì§ì ‘ ì ‘ê·¼
            ("common", "query_complexity", "needs_search"),  # common ê·¸ë£¹
            ("metadata", "query_complexity", "needs_search"),  # metadata ê·¸ë£¹
            ("classification", "query_complexity", "needs_search")  # classification ê·¸ë£¹
        ]

        for path in search_paths:
            group_key, complexity_key, search_key = path

            if group_key is None:
                if isinstance(state, dict):
                    if complexity_key in state and not preserved["query_complexity"]:
                        preserved["query_complexity"] = state.get(complexity_key)
                    if search_key in state:
                        preserved["needs_search"] = state.get(search_key, True)
            else:
                if isinstance(state, dict) and group_key in state:
                    group = state[group_key]
                    if isinstance(group, dict):
                        if not preserved["query_complexity"] and complexity_key in group:
                            preserved["query_complexity"] = group.get(complexity_key)
                        if search_key in group:
                            preserved["needs_search"] = group.get(search_key, True)

            if preserved["query_complexity"] is not None:
                break

        return preserved

    def preserve_and_store_values(
        self,
        state: LegalWorkflowState,
        query_complexity: Optional[str],
        needs_search: bool
    ) -> None:
        """
        ì¶”ì¶œí•œ ê°’ì„ stateì˜ ëª¨ë“  í•„ìš”í•œ ìœ„ì¹˜ì— ì €ì¥

        Args:
            state: LegalWorkflowState ê°ì²´
            query_complexity: ë³´ì¡´í•  query_complexity ê°’
            needs_search: ë³´ì¡´í•  needs_search ê°’
        """
        if not query_complexity:
            return

        # ì €ì¥í•  ìœ„ì¹˜ë“¤
        storage_locations = [state]

        # ê·¸ë£¹ë³„ë¡œ ì €ì¥
        for group_key in ["common", "metadata", "classification"]:
            if group_key not in state:
                state[group_key] = {}
            storage_locations.append(state[group_key])

        for location in storage_locations:
            if isinstance(location, dict):
                location["query_complexity"] = query_complexity
                location["needs_search"] = needs_search

    def map_confidence_level(self, confidence: float):
        """ì‹ ë¢°ë„ ì ìˆ˜ì— ë”°ë¥¸ ë ˆë²¨ ë§¤í•‘"""
        from source.services.confidence_calculator import ConfidenceLevel

        if confidence >= 0.9:
            return ConfidenceLevel.VERY_HIGH
        elif confidence >= 0.7:
            return ConfidenceLevel.HIGH
        elif confidence >= 0.5:
            return ConfidenceLevel.MEDIUM
        elif confidence >= 0.3:
            return ConfidenceLevel.LOW
        else:
            return ConfidenceLevel.VERY_LOW

    def calculate_keyword_coverage(
        self,
        state: LegalWorkflowState,
        answer: Union[str, Dict[str, Any], None]
    ) -> float:
        """í‚¤ì›Œë“œ í¬í•¨ë„ ê³„ì‚°"""
        try:
            answer_str = WorkflowUtils.normalize_answer(answer)

            if not isinstance(answer_str, str):
                answer_str = str(answer_str) if answer_str else ""

            if not answer_str:
                return 0.0

            query = WorkflowUtils.get_state_value(state, "query", "")
            query_type = WorkflowUtils.get_state_value(state, "query_type", "")
            if not self.keyword_mapper:
                return 1.0

            required_keywords = self.keyword_mapper.get_keywords_for_question(query, query_type)

            if not required_keywords:
                return 1.0

            return self.keyword_mapper.calculate_keyword_coverage(answer_str, required_keywords)
        except Exception as e:
            self.logger.warning(f"Keyword coverage calculation failed: {e}")
            return 0.0

    def set_metadata(
        self,
        state: LegalWorkflowState,
        answer: Union[str, Dict[str, Any], None],
        keyword_coverage: float
    ) -> None:
        """ë©”íƒ€ë°ì´í„° ì„¤ì •"""
        try:
            answer_str = WorkflowUtils.normalize_answer(answer)

            if not isinstance(answer_str, str):
                answer_str = str(answer_str) if answer_str else ""

            if not answer_str:
                answer_str = ""

            query = WorkflowUtils.get_state_value(state, "query", "")
            query_type = WorkflowUtils.get_state_value(state, "query_type", "")
            required_keywords = []
            if self.keyword_mapper:
                try:
                    required_keywords = self.keyword_mapper.get_keywords_for_question(query, query_type)
                    if required_keywords is None:
                        required_keywords = []
                    elif not isinstance(required_keywords, (list, tuple)):
                        required_keywords = [str(required_keywords)]
                except Exception as e:
                    self.logger.warning(f"Keyword retrieval failed: {e}")

            missing_keywords = []
            if answer_str and required_keywords and self.keyword_mapper:
                try:
                    missing_keywords = self.keyword_mapper.get_missing_keywords(answer_str, list(required_keywords))
                except Exception as e:
                    self.logger.warning(f"Missing keyword calculation failed: {e}")

            metadata = WorkflowUtils.get_state_value(state, "metadata", {})
            if not isinstance(metadata, dict):
                metadata = {}
            metadata.update({
                "keyword_coverage": keyword_coverage,
                "required_keywords_count": len(required_keywords) if required_keywords else 0,
                "matched_keywords_count": len(required_keywords) - len(missing_keywords) if required_keywords else 0,
                "response_length": len(answer_str) if answer_str else 0,
                "query_type": query_type
            })
            WorkflowUtils.set_state_value(state, "metadata", metadata)
        except Exception as e:
            self.logger.warning(f"Metadata setting failed: {e}")
