#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Document Analyzer Component for LawFirmAI
PDF/DOCX parsing and contract analysis functionality
"""

import os
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
import re

try:
    import PyPDF2
except ImportError:
    PyPDF2 = None
    logging.warning("PyPDF2 not installed. PDF parsing will not be available.")

try:
    from docx import Document
except ImportError:
    Document = None
    logging.warning("python-docx not installed. DOCX parsing will not be available.")

logger = logging.getLogger(__name__)

class DocumentAnalyzer:
    """ë¬¸ì„œ ë¶„ì„ í´ëž˜ìŠ¤ - PDF/DOCX íŒŒì‹± ë° ê³„ì•½ì„œ ë¶„ì„"""
    
    def __init__(self, rag_service=None):
        """
        DocumentAnalyzer ì´ˆê¸°í™”
        
        Args:
            rag_service: RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì‚¬í•­)
        """
        self.rag_service = rag_service
        
        # ìœ„í—˜ í‚¤ì›Œë“œ ì •ì˜
        self.risk_keywords = {
            "high": [
                "ì†í•´ë°°ìƒ", "ìœ„ì•½ê¸ˆ", "í•´ì§€", "ë©´ì±…", "ì±…ìž„", "ë°°ìƒ", "ì†ì‹¤",
                "ìœ„í—˜", "ë¶€ë‹´", "ì±…ìž„ì œí•œ", "ë©´ì±…ì¡°í•­", "í•´ì§€ê¶Œ", "ìœ„ì•½ê¸ˆì•¡"
            ],
            "medium": [
                "ê³„ì•½", "ì¡°ê±´", "ê¸°ê°„", "ì—°ìž¥", "ê°±ì‹ ", "ë³€ê²½", "ìˆ˜ì •",
                "í†µì§€", "ê³ ì§€", "ì´í–‰", "ë¶ˆì´í–‰", "ì§€ì—°", "ì—°ì²´"
            ],
            "low": [
                "ë‹¹ì‚¬ìž", "ëª©ì ", "ê¸°ê°„", "ëŒ€ê°€", "ì§€ê¸‰", "ìˆ˜ë ¹", "ì¸ë„",
                "ì¸ìˆ˜", "ë³´ê´€", "ê´€ë¦¬", "ìš´ì˜", "ì‚¬ìš©", "ì´ìš©"
            ]
        }
        
        # ë²•ë¥  ìš©ì–´ íŒ¨í„´
        self.legal_patterns = {
            "contract_terms": [
                r"ì œ\d+ì¡°", r"ì œ\d+í•­", r"ì œ\d+í˜¸",  # ì¡°í•­ ë²ˆí˜¸
                r"ê³„ì•½ê¸°ê°„", r"ê³„ì•½ì¡°ê±´", r"ê³„ì•½ë‚´ìš©",  # ê³„ì•½ ê´€ë ¨
                r"ë‹¹ì‚¬ìž", r"ê°‘", r"ì„", r"ë³‘", r"ì •"  # ë‹¹ì‚¬ìž í‘œì‹œ
            ],
            "obligations": [
                r"ì˜ë¬´", r"ì±…ìž„", r"ì´í–‰", r"ì¤€ìˆ˜", r"ë³´ìž¥",
                r"ì¸ë„", r"ì¸ìˆ˜", r"ì§€ê¸‰", r"ìˆ˜ë ¹", r"ë³´ê´€"
            ],
            "penalties": [
                r"ìœ„ì•½ê¸ˆ", r"ì†í•´ë°°ìƒ", r"ë°°ìƒ", r"ì†ì‹¤", r"ë³´ìƒ",
                r"ê³¼íƒœë£Œ", r"ë²Œê¸ˆ", r"ì²˜ë²Œ", r"ì œìž¬"
            ]
        }
    
    def parse_pdf(self, file_path: str) -> str:
        """
        PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            file_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        if PyPDF2 is None:
            raise ImportError("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install PyPDF2ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                
                for page_num, page in enumerate(reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n--- íŽ˜ì´ì§€ {page_num + 1} ---\n"
                            text += page_text
                    except Exception as e:
                        logger.warning(f"íŽ˜ì´ì§€ {page_num + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                        continue
                
                return text.strip()
                
        except Exception as e:
            logger.error(f"PDF íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise ValueError(f"PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def parse_docx(self, file_path: str) -> str:
        """
        DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            file_path: DOCX íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        if Document is None:
            raise ImportError("python-docxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-docxë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        try:
            doc = Document(file_path)
            text_parts = []
            
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text_parts.append(paragraph.text.strip())
            
            # í‘œ ë‚´ìš©ë„ ì¶”ì¶œ
            for table in doc.tables:
                for row in table.rows:
                    row_text = []
                    for cell in row.cells:
                        if cell.text.strip():
                            row_text.append(cell.text.strip())
                    if row_text:
                        text_parts.append(" | ".join(row_text))
            
            return "\n".join(text_parts)
            
        except Exception as e:
            logger.error(f"DOCX íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise ValueError(f"DOCX íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def parse_document(self, file_path: str) -> str:
        """
        íŒŒì¼ í™•ìž¥ìžì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œ ì„ íƒ
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        if file_path.suffix.lower() == '.pdf':
            return self.parse_pdf(str(file_path))
        elif file_path.suffix.lower() == '.docx':
            return self.parse_docx(str(file_path))
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ìž…ë‹ˆë‹¤: {file_path.suffix}")
    
    def analyze_contract(self, text: str) -> Dict[str, Any]:
        """
        ê³„ì•½ì„œ í…ìŠ¤íŠ¸ ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            summary = self._generate_summary(text)
            
            # ì¡°í•­ ì¶”ì¶œ
            clauses = self._extract_clauses(text)
            
            # ìœ„í—˜ ìš”ì†Œ í‰ê°€
            risks = self._assess_risks(text, clauses)
            
            # ê°œì„  ì œì•ˆ ìƒì„±
            recommendations = self._generate_recommendations(risks, text)
            
            # ì „ì²´ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
            risk_score = self._calculate_risk_score(risks)
            
            return {
                "summary": summary,
                "clauses": clauses,
                "risks": risks,
                "recommendations": recommendations,
                "risk_score": risk_score,
                "analysis_metadata": {
                    "text_length": len(text),
                    "clause_count": len(clauses),
                    "risk_count": len(risks),
                    "high_risk_count": len([r for r in risks if r["risk_level"] == "high"])
                }
            }
            
        except Exception as e:
            logger.error(f"ê³„ì•½ì„œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            raise ValueError(f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _generate_summary(self, text: str) -> str:
        """ë¬¸ì„œ ìš”ì•½ ìƒì„±"""
        lines = text.split('\n')
        non_empty_lines = [line.strip() for line in lines if line.strip()]
        
        # ë¬¸ì„œ ê¸¸ì´ ì •ë³´
        char_count = len(text)
        word_count = len(text.split())
        line_count = len(non_empty_lines)
        
        # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(text)
        
        summary = f"""**ë¬¸ì„œ ê¸°ë³¸ ì •ë³´**
- ë¬¸ì„œ ê¸¸ì´: {char_count:,}ìž
- ë‹¨ì–´ ìˆ˜: {word_count:,}ê°œ
- ìœ íš¨ ë¼ì¸ ìˆ˜: {line_count:,}ê°œ

**ì£¼ìš” í‚¤ì›Œë“œ**
{', '.join(keywords[:10]) if keywords else 'í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}

**ë¶„ì„ ì™„ë£Œ**: {len(non_empty_lines)}ê°œ ì„¹ì…˜ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤."""
        
        return summary
    
    def _extract_clauses(self, text: str) -> List[Dict]:
        """ì¤‘ìš”í•œ ì¡°í•­ ì¶”ì¶œ"""
        clauses = []
        
        # ì¡°í•­ ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ì¡°í•­ ì°¾ê¸°
        clause_pattern = r'(ì œ\s*\d+\s*ì¡°[^\n]*)'
        matches = re.finditer(clause_pattern, text, re.IGNORECASE)
        
        for i, match in enumerate(matches, 1):
            clause_text = match.group(1).strip()
            if len(clause_text) > 10:  # ë„ˆë¬´ ì§§ì€ ì¡°í•­ ì œì™¸
                clauses.append({
                    "id": i,
                    "title": f"ì œ {i}ì¡°",
                    "content": clause_text[:200] + "..." if len(clause_text) > 200 else clause_text,
                    "type": "numbered_clause",
                    "importance": self._assess_clause_importance(clause_text)
                })
        
        # RAG ì„œë¹„ìŠ¤ê°€ ìžˆìœ¼ë©´ ì¶”ê°€ ë¶„ì„
        if self.rag_service and clauses:
            try:
                # ìƒìœ„ 3ê°œ ì¡°í•­ì— ëŒ€í•´ RAG ë¶„ì„
                for clause in clauses[:3]:
                    query = f"ë‹¤ìŒ ê³„ì•½ ì¡°í•­ì˜ ë²•ì  ì˜ë¯¸ì™€ ì£¼ì˜ì‚¬í•­ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”: {clause['content'][:100]}"
                    rag_result = self.rag_service.process_query(query, top_k=3)
                    
                    if rag_result and rag_result.get("sources"):
                        clause["rag_analysis"] = rag_result["sources"][0].get("content", "")[:200]
            except Exception as e:
                logger.warning(f"RAG ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return clauses
    
    def _assess_clause_importance(self, clause_text: str) -> str:
        """ì¡°í•­ ì¤‘ìš”ë„ í‰ê°€"""
        high_importance_keywords = ["ì†í•´ë°°ìƒ", "ìœ„ì•½ê¸ˆ", "í•´ì§€", "ë©´ì±…", "ì±…ìž„"]
        medium_importance_keywords = ["ê³„ì•½", "ì¡°ê±´", "ê¸°ê°„", "ì´í–‰", "í†µì§€"]
        
        clause_lower = clause_text.lower()
        
        if any(keyword in clause_lower for keyword in high_importance_keywords):
            return "high"
        elif any(keyword in clause_lower for keyword in medium_importance_keywords):
            return "medium"
        else:
            return "low"
    
    def _assess_risks(self, text: str, clauses: List[Dict]) -> List[Dict]:
        """ìœ„í—˜ ìš”ì†Œ í‰ê°€"""
        risks = []
        
        # í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ ìœ„í—˜ í‚¤ì›Œë“œ ê²€ìƒ‰
        text_lower = text.lower()
        
        for risk_level, keywords in self.risk_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    # í‚¤ì›Œë“œ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    context = self._extract_context(text, keyword, 100)
                    
                    risks.append({
                        "keyword": keyword,
                        "risk_level": risk_level,
                        "context": context,
                        "reason": self._get_risk_reason(keyword, risk_level),
                        "recommendation": self._get_risk_recommendation(keyword, risk_level)
                    })
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_risks = []
        seen_keywords = set()
        
        for risk in risks:
            if risk["keyword"] not in seen_keywords:
                unique_risks.append(risk)
                seen_keywords.add(risk["keyword"])
        
        # ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        risk_order = {"high": 3, "medium": 2, "low": 1}
        unique_risks.sort(key=lambda x: risk_order.get(x["risk_level"], 0), reverse=True)
        
        return unique_risks[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
    
    def _extract_context(self, text: str, keyword: str, context_length: int = 100) -> str:
        """í‚¤ì›Œë“œ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            index = text.lower().find(keyword.lower())
            if index == -1:
                return ""
            
            start = max(0, index - context_length)
            end = min(len(text), index + len(keyword) + context_length)
            
            context = text[start:end]
            return context.strip()
        except Exception:
            return ""
    
    def _get_risk_reason(self, keyword: str, risk_level: str) -> str:
        """ìœ„í—˜ ìš”ì†Œ ì´ìœ  ì„¤ëª…"""
        reasons = {
            "high": f"'{keyword}' í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìžˆì–´ ë†’ì€ ë²•ì  ìœ„í—˜ì´ ìžˆìŠµë‹ˆë‹¤.",
            "medium": f"'{keyword}' ê´€ë ¨ ì¡°í•­ì´ ìžˆì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            "low": f"'{keyword}' ê´€ë ¨ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤."
        }
        return reasons.get(risk_level, "ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _get_risk_recommendation(self, keyword: str, risk_level: str) -> str:
        """ìœ„í—˜ ìš”ì†Œë³„ ê°œì„  ì œì•ˆ"""
        recommendations = {
            "high": f"'{keyword}' ì¡°í•­ì— ëŒ€í•´ ë²•ë¬´íŒ€ ê²€í† ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤.",
            "medium": f"'{keyword}' ê´€ë ¨ ë‚´ìš©ì„ ëª…í™•ížˆ ì •ì˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.",
            "low": f"'{keyword}' ê´€ë ¨ ì¡°í•­ì„ í™•ì¸í•´ë³´ì„¸ìš”."
        }
        return recommendations.get(risk_level, "ì „ë¬¸ê°€ ê²€í† ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤.")
    
    def _generate_recommendations(self, risks: List[Dict], text: str) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        recommendations = []
        
        # ìœ„í—˜ë„ë³„ ê°œì„  ì œì•ˆ
        high_risks = [r for r in risks if r["risk_level"] == "high"]
        medium_risks = [r for r in risks if r["risk_level"] == "medium"]
        
        if high_risks:
            recommendations.append(f"âš ï¸ **ë†’ì€ ìœ„í—˜ë„ ì¡°í•­ {len(high_risks)}ê°œ ë°œê²¬**")
            recommendations.append("ë²•ë¬´íŒ€ì˜ ì „ë¬¸ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            for risk in high_risks[:3]:  # ìƒìœ„ 3ê°œë§Œ
                recommendations.append(f"- {risk['keyword']}: {risk['recommendation']}")
        
        if medium_risks:
            recommendations.append(f"âš¡ **ì¤‘ê°„ ìœ„í—˜ë„ ì¡°í•­ {len(medium_risks)}ê°œ ë°œê²¬**")
            recommendations.append("ì¡°í•­ ë‚´ìš©ì„ ëª…í™•ížˆ ì •ì˜í•˜ëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤.")
        
        # ì¼ë°˜ì ì¸ ê°œì„  ì œì•ˆ
        if not high_risks and not medium_risks:
            recommendations.append("âœ… íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¬¸ì„œ í’ˆì§ˆ ê°œì„  ì œì•ˆ
        recommendations.extend([
            "",
            "ðŸ“‹ **ì¼ë°˜ì ì¸ ê°œì„  ì œì•ˆ**",
            "â€¢ ê³„ì•½ ë‹¹ì‚¬ìž ì •ë³´ë¥¼ ëª…í™•ížˆ ê¸°ìž¬í•˜ì„¸ìš”",
            "â€¢ ê³„ì•½ ëª©ì ê³¼ ë²”ìœ„ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”",
            "â€¢ ì´í–‰ ê¸°ê°„ê³¼ ë°©ë²•ì„ ìƒì„¸ížˆ ê¸°ìˆ í•˜ì„¸ìš”",
            "â€¢ ë¶„ìŸ í•´ê²° ë°©ë²•ì„ ëª…ì‹œí•˜ì„¸ìš”"
        ])
        
        return recommendations
    
    def _calculate_risk_score(self, risks: List[Dict]) -> int:
        """ì „ì²´ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        if not risks:
            return 0
        
        # ìœ„í—˜ë„ë³„ ê°€ì¤‘ì¹˜
        weights = {"high": 3, "medium": 2, "low": 1}
        
        total_weight = sum(weights.get(risk["risk_level"], 1) for risk in risks)
        max_possible_weight = len(risks) * 3  # ëª¨ë“  ìœ„í—˜ì´ highì¼ ë•Œ
        
        if max_possible_weight == 0:
            return 0
        
        # 0-100 ì ìˆ˜ë¡œ ë³€í™˜
        score = int((total_weight / max_possible_weight) * 100)
        return min(100, score)
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš© ê°€ëŠ¥)
        words = re.findall(r'\b[ê°€-íž£]{2,}\b', text)
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:20] if freq > 1]
