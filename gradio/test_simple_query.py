# -*- coding: utf-8 -*-
"""
ê°„ë‹¨í•œ ì§ˆì˜-ë‹µë³€ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
LawFirmAI - ë²•ë¥  AI ì–´ì‹œìŠ¤í„´íŠ¸ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from source.data.database import DatabaseManager
from source.data.vector_store import LegalVectorStore
from prompt_manager import prompt_manager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimpleLawFirmAITest:
    """ê°„ë‹¨í•œ LawFirmAI í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.database_manager = None
        self.vector_store = None
        self.initialized = False
    
    def initialize(self) -> bool:
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            logger.info("Initializing test services...")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.database_manager = DatabaseManager()
            logger.info("Database manager initialized")
            
            # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
            self._initialize_vector_store()
            
            self.initialized = True
            logger.info("Test services initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize test services: {e}")
            return False
    
    def _initialize_vector_store(self):
        """ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        try:
            logger.info("Initializing vector store...")
            
            self.vector_store = LegalVectorStore(model_name="jhgan/ko-sroberta-multitask")
            
            # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì‹œë„
            project_root = Path(__file__).parent.parent
            vector_store_paths = [
                str(project_root / "data" / "embeddings" / "ml_enhanced_ko_sroberta"),
                str(project_root / "data" / "embeddings" / "ml_enhanced_bge_m3"),
                str(project_root / "data" / "embeddings" / "faiss_index")
            ]
            
            vector_store_loaded = False
            for path in vector_store_paths:
                if os.path.exists(path):
                    try:
                        if os.path.isdir(path):
                            files = os.listdir(path)
                            faiss_files = [f for f in files if f.endswith('.faiss')]
                            if faiss_files:
                                faiss_file_path = os.path.join(path, faiss_files[0])
                                success = self.vector_store.load_index(faiss_file_path)
                            else:
                                success = False
                        else:
                            success = self.vector_store.load_index(path)
                        
                        if success:
                            logger.info(f"Vector store loaded successfully from {path}")
                            vector_store_loaded = True
                            break
                    except Exception as e:
                        logger.warning(f"Error loading vector store from {path}: {e}")
            
            if not vector_store_loaded:
                logger.warning("No vector store could be loaded, using database search only")
                
        except Exception as e:
            logger.error(f"Failed to initialize vector store: {e}")
    
    def search_documents(self, query: str, top_k: int = 5):
        """ë¬¸ì„œ ê²€ìƒ‰"""
        results = []
        
        try:
            logger.info(f"Searching documents for query: '{query}'")
            
            # ë²¡í„° ì €ì¥ì†Œ ê²€ìƒ‰
            if self.vector_store:
                try:
                    logger.info("Attempting vector store search...")
                    similar_docs = self.vector_store.search(query, top_k)
                    logger.info(f"Vector search returned {len(similar_docs)} documents")
                    
                    for i, doc in enumerate(similar_docs):
                        doc_info = {
                            'content': doc.get('text', '') or doc.get('content', ''),
                            'metadata': doc.get('metadata', {}),
                            'similarity': doc.get('score', 0.0),
                            'source': doc.get('metadata', {}).get('law_name', 'unknown')
                        }
                        results.append(doc_info)
                        
                        logger.info(f"  Document {i+1}: {doc_info['source']} (similarity: {doc_info['similarity']:.3f})")
                        logger.info(f"      Content preview: {doc_info['content'][:100]}...")
                        
                except Exception as e:
                    logger.error(f"Vector search failed: {e}")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ (ë°±ì—…)
            if not results and self.database_manager:
                try:
                    logger.info("Attempting database search...")
                    assembly_results = self.database_manager.search_assembly_documents(query, top_k)
                    logger.info(f"Database search returned {len(assembly_results)} documents")
                    
                    for i, result in enumerate(assembly_results):
                        doc_info = {
                            'content': result.get('content', ''),
                            'metadata': {
                                'law_name': result.get('law_name', ''),
                                'article_number': result.get('article_number', ''),
                                'article_title': result.get('article_title', '')
                            },
                            'similarity': result.get('relevance_score', 0.8),
                            'source': result.get('law_name', 'assembly_database')
                        }
                        results.append(doc_info)
                        
                        logger.info(f"  DB Document {i+1}: {doc_info['source']} (similarity: {doc_info['similarity']:.3f})")
                        logger.info(f"      Content preview: {doc_info['content'][:100]}...")
                        
                except Exception as e:
                    logger.warning(f"Database search failed: {e}")
            
            # ìƒ˜í”Œ ë°ì´í„° ì œê³µ
            if not results:
                logger.warning("No documents found, providing sample data")
                results = self._get_sample_legal_documents(query)
            
            logger.info(f"Total search results: {len(results)}")
            return results
            
        except Exception as e:
            logger.error(f"Error in search_documents: {e}")
            return self._get_sample_legal_documents(query)
    
    def _get_sample_legal_documents(self, query: str):
        """ìƒ˜í”Œ ë²•ë¥  ë¬¸ì„œ ì œê³µ"""
        sample_docs = [
            {
                'content': 'ë‚œë¯¼ë²• ì œ1ì¡°(ëª©ì ) ì´ ë²•ì€ ã€Œë‚œë¯¼ì˜ ì§€ìœ„ì— ê´€í•œ 1951ë…„ í˜‘ì•½ã€(ì´í•˜ "ë‚œë¯¼í˜‘ì•½"ì´ë¼ í•œë‹¤) ë° ã€Œë‚œë¯¼ì˜ ì§€ìœ„ì— ê´€í•œ 1967ë…„ ì˜ì •ì„œã€(ì´í•˜ "ë‚œë¯¼ì˜ì •ì„œ"ë¼ í•œë‹¤) ë“±ì— ë”°ë¼ ë‚œë¯¼ì˜ ì§€ìœ„ì™€ ì²˜ìš° ë“±ì— ê´€í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.',
                'metadata': {
                    'law_name': 'ë‚œë¯¼ë²•',
                    'article_number': 'ì œ1ì¡°',
                    'article_title': 'ëª©ì '
                },
                'similarity': 0.9,
                'source': 'ë‚œë¯¼ë²•'
            },
            {
                'content': 'ë¯¼ë²• ì œ750ì¡°(ë¶ˆë²•í–‰ìœ„ì˜ ë‚´ìš©) íƒ€ì¸ì˜ ê³ ì˜ ë˜ëŠ” ê³¼ì‹¤ë¡œ ì¸í•œ ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•˜ì—¬ ì†í•´ë¥¼ ë°›ì€ ìëŠ” ê·¸ ì†í•´ë¥¼ ê°€í•œ ìì—ê²Œ ì†í•´ë°°ìƒì„ ì²­êµ¬í•  ìˆ˜ ìˆë‹¤.',
                'metadata': {
                    'law_name': 'ë¯¼ë²•',
                    'article_number': 'ì œ750ì¡°',
                    'article_title': 'ë¶ˆë²•í–‰ìœ„ì˜ ë‚´ìš©'
                },
                'similarity': 0.8,
                'source': 'ë¯¼ë²•'
            },
            {
                'content': 'ë¯¼ë²• ì œ543ì¡°(ê³„ì•½ì˜ ì„±ë¦½) ê³„ì•½ì€ ë‹¹ì‚¬ì ì¼ë°©ì´ ìƒëŒ€ë°©ì—ê²Œ ê³„ì•½ì„ ì²´ê²°í•  ì˜ì‚¬ë¥¼ í‘œì‹œí•˜ê³  ìƒëŒ€ë°©ì´ ì´ë¥¼ ìŠ¹ë‚™í•¨ìœ¼ë¡œì¨ ì„±ë¦½í•œë‹¤.',
                'metadata': {
                    'law_name': 'ë¯¼ë²•',
                    'article_number': 'ì œ543ì¡°',
                    'article_title': 'ê³„ì•½ì˜ ì„±ë¦½'
                },
                'similarity': 0.7,
                'source': 'ë¯¼ë²•'
            },
            {
                'content': 'ìƒë²• ì œ170ì¡°(ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½) ì£¼ì‹íšŒì‚¬ëŠ” ë°œê¸°ì¸ì´ ì •ê´€ì„ ì‘ì„±í•˜ê³  ì£¼ì‹ì˜ ì¸ìˆ˜ë¥¼ ì£¼ì¥í•˜ì—¬ ì„¤ë¦½í•œë‹¤.',
                'metadata': {
                    'law_name': 'ìƒë²•',
                    'article_number': 'ì œ170ì¡°',
                    'article_title': 'ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½'
                },
                'similarity': 0.6,
                'source': 'ìƒë²•'
            },
            {
                'content': 'í˜•ë²• ì œ329ì¡°(ì ˆë„) íƒ€ì¸ì˜ ì¬ë¬¼ì„ ì ˆì·¨í•œ ìëŠ” 6ë…„ ì´í•˜ì˜ ì§•ì—­ ë˜ëŠ” 1ì²œë§Œì› ì´í•˜ì˜ ë²Œê¸ˆì— ì²˜í•œë‹¤.',
                'metadata': {
                    'law_name': 'í˜•ë²•',
                    'article_number': 'ì œ329ì¡°',
                    'article_title': 'ì ˆë„'
                },
                'similarity': 0.5,
                'source': 'í˜•ë²•'
            }
        ]
        
        # ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œë§Œ í•„í„°ë§
        filtered_docs = []
        query_lower = query.lower()
        
        for doc in sample_docs:
            content_lower = doc['content'].lower()
            metadata_lower = str(doc['metadata']).lower()
            
            # ë” ì •êµí•œ í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = ['ë‚œë¯¼ë²•', 'ë¯¼ë²•', 'ìƒë²•', 'í˜•ë²•', 'ê³„ì•½', 'ë¶ˆë²•í–‰ìœ„', 'ì£¼ì‹íšŒì‚¬', 'ì ˆë„', 'ì„¤ë¦½', 'ì„±ë¦½']
            if any(keyword in content_lower or keyword in metadata_lower or keyword in query_lower
                   for keyword in keywords):
                filtered_docs.append(doc)
        
        return filtered_docs[:3]
    
    def generate_response(self, query: str, context_docs):
        """ì‘ë‹µ ìƒì„±"""
        try:
            logger.info(f"Generating response for query: '{query}'")
            
            if not context_docs:
                return self._generate_fallback_response(query, context_docs)
            
            # ìì—°ìŠ¤ëŸ¬ìš´ í”„ë¡¬í”„íŠ¸ë¡œ ì „í™˜
            natural_prompt_loaded = prompt_manager.switch_to_version("natural_legal_consultant_v1.0")
            if natural_prompt_loaded:
                logger.info("Switched to natural legal consultant prompt")
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "\n\n".join([
                f"[ë¬¸ì„œ: {doc['source']}]\n{doc['content'][:500]}..."
                for doc in context_docs[:3]
            ])
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
            response = f"""ì•ˆë…•í•˜ì„¸ìš”! ë§ì”€í•˜ì‹  '{query}'ì— ëŒ€í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ë§ì”€í•˜ì‹  ì§ˆë¬¸ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”.

ğŸ“‹ ê´€ë ¨ ë²•ë¥  ì¡°í•­"""
            
            # ì‹¤ì œ ì¡°ë¬¸ ë‚´ìš© í¬í•¨
            main_doc = context_docs[0] if context_docs else None
            if main_doc and main_doc.get('content'):
                metadata = main_doc.get('metadata', {})
                law_name = metadata.get('law_name', 'ê´€ë ¨ ë²•ë¥ ')
                article_number = metadata.get('article_number', '')
                article_title = metadata.get('article_title', '')
                actual_content = main_doc['content']
                
                response += f"\n\n**{law_name} {article_number}**"
                if article_title:
                    response += f" ({article_title})"
                response += f"\n{actual_content}"
            
            response += f"""

ğŸ’¡ ì‰½ê²Œ ì„¤ëª…í•˜ë©´
ì´ ì¡°í•­ì€ ë§ì”€í•˜ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë²•ë¥ ì˜ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤.

ğŸ” ì‹¤ì œ ì ìš© ì˜ˆì‹œ
ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ ìƒí™©ì—ì„œ ì´ ë²•ë¥ ì´ ì ìš©ë  ë•ŒëŠ” êµ¬ì²´ì ì¸ ì ˆì°¨ì™€ ìš”ê±´ì„ ë”°ë¥´ê²Œ ë©ë‹ˆë‹¤.

âš ï¸ ì£¼ì˜ì‚¬í•­
ì´ëŸ° ê²½ìš°ì—ëŠ” ê´€ë ¨ ë²•ë¥ ì˜ êµ¬ì²´ì ì¸ ìš”ê±´ê³¼ ì ˆì°¨ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì‹œëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

ğŸ“ ì¶”ê°€ ë„ì›€
ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!

ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•œ ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
            
            logger.info(f"Response generated successfully (length: {len(response)} characters)")
            return response
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return self._generate_fallback_response(query, context_docs)
    
    def _generate_fallback_response(self, query: str, context_docs):
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        return f"""**[ì§ˆë¬¸ ìš”ì•½]**
ê·€í•˜ì˜ ì§ˆë¬¸ì€ '{query}'ì— ê´€í•œ ê²ƒìœ¼ë¡œ ì´í•´ë©ë‹ˆë‹¤.

**[ìƒí™© ë¶„ì„]**
ë§ì”€í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ê´€ë ¨ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.

**[ì‹¤ë¬´ì  ì¡°ì–¸]**
ì´ëŸ¬í•œ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
1. ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•´ë³´ì„¸ìš”
2. ê´€ë ¨ ë²•ë¥  ë¶„ì•¼ë¥¼ ëª…ì‹œí•˜ì—¬ ì§ˆë¬¸í•´ë³´ì„¸ìš”
3. êµ¬ì²´ì ì¸ ìƒí™©ì´ë‚˜ ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ì—¬ ì§ˆë¬¸í•´ë³´ì„¸ìš”

**[ì£¼ì˜ì‚¬í•­]**
- ë²•ë¥ ì€ í•´ì„ì˜ ì—¬ì§€ê°€ ìˆìœ¼ë¯€ë¡œ ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ ì¶©ë¶„í•œ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤
- ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•´ì„œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤

**[ë©´ì±… ë¬¸êµ¬]**
ë³¸ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•˜ë©°, ê°œë³„ ì‚¬ì•ˆì— ëŒ€í•œ ë²•ë¥  ìë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ì§ì ‘ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""
    
    def test_query(self, query: str):
        """í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰"""
        if not self.initialized:
            logger.error("Service not initialized")
            return
        
        logger.info(f"\n{'='*60}")
        logger.info(f"TESTING QUERY: {query}")
        logger.info(f"{'='*60}")
        
        try:
            # ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_documents(query, top_k=5)
            
            # ì‘ë‹µ ìƒì„±
            response = self.generate_response(query, search_results)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\n{'='*60}")
            print(f"QUERY: {query}")
            print(f"{'='*60}")
            print(f"\nRESPONSE:")
            print(response)
            print(f"\n{'='*60}")
            print(f"SEARCH RESULTS SUMMARY:")
            print(f"Total documents found: {len(search_results)}")
            for i, doc in enumerate(search_results, 1):
                print(f"  {i}. {doc['source']} (similarity: {doc['similarity']:.3f})")
                print(f"     Content: {doc['content'][:100]}...")
            print(f"{'='*60}\n")
            
        except Exception as e:
            logger.error(f"Error in test_query: {e}")
            print(f"Error: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("Starting LawFirmAI Simple Test...")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ìˆ˜ì •
    os.chdir(Path(__file__).parent.parent)  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™
    
    # í…ŒìŠ¤íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    test_instance = SimpleLawFirmAITest()
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    if not test_instance.initialize():
        logger.error("Failed to initialize test services")
        return
    
    print("\n" + "="*60)
    print("LawFirmAI ê°„ë‹¨í•œ ì§ˆì˜-ë‹µë³€ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print("ë‹¤ì–‘í•œ ë²•ë¥  ì§ˆë¬¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤!")
    print("\ní…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤:")
    print("1. ë‚œë¯¼ë²• ì œ1ì¡°ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜")
    print("2. ë¯¼ë²• ì œ750ì¡° ë¶ˆë²•í–‰ìœ„ì— ëŒ€í•´ ì•Œë ¤ì¤˜")
    print("3. ê³„ì•½ì˜ ì„±ë¦½ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?")
    print("4. ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")
    print("5. ì ˆë„ì£„ì˜ êµ¬ì„±ìš”ê±´ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”")
    print("\n" + "="*60)
    
    # ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ë‚œë¯¼ë²• ì œ1ì¡°ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜",
        "ë¯¼ë²• ì œ750ì¡° ë¶ˆë²•í–‰ìœ„ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
        "ê³„ì•½ì˜ ì„±ë¦½ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì£¼ì‹íšŒì‚¬ì˜ ì„¤ë¦½ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ì ˆë„ì£„ì˜ êµ¬ì„±ìš”ê±´ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
    ]
    
    try:
        # ê° í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰
        for i, query in enumerate(test_queries, 1):
            print(f"\n{'='*20} í…ŒìŠ¤íŠ¸ {i}/5 {'='*20}")
            test_instance.test_query(query)
            
            # ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸°
            if i < len(test_queries):
                print("\në‹¤ìŒ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°...")
                import time
                time.sleep(2)
        
        print(f"\n{'='*60}")
        print("ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*60)
        
    except Exception as e:
        logger.error(f"Error in test execution: {e}")
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    logger.info("Test completed successfully")

if __name__ == "__main__":
    main()
