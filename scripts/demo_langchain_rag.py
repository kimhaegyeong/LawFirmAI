#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangChain RAG Demo Script
LangChain ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import logging
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'source'))

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

from services.langchain_rag_service import LangChainRAGService
from utils.langchain_config import LangChainConfig
from services.langfuse_client import LangfuseClient

# ë¡œê¹… ì„¤ì •
from utils.safe_logging import setup_script_logging
logger = setup_script_logging("demo_langchain_rag")


def setup_demo_environment():
    """ë°ëª¨ í™˜ê²½ ì„¤ì •"""
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë°ëª¨ìš©)
    os.environ.setdefault('LANGFUSE_ENABLED', 'false')
    os.environ.setdefault('LLM_PROVIDER', 'openai')
    os.environ.setdefault('LLM_MODEL', 'gpt-3.5-turbo')
    os.environ.setdefault('VECTOR_STORE_TYPE', 'faiss')
    os.environ.setdefault('EMBEDDING_MODEL', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    
    logger.info("ë°ëª¨ í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    logger.info("ì°¸ê³ : sqlite3ëŠ” Python ë‚´ì¥ ëª¨ë“ˆì´ë¯€ë¡œ ë³„ë„ ì„¤ì¹˜ ë¶ˆí•„ìš”")
    logger.info("ì§€ì› LLM: OpenAI, Anthropic, Google Gemini Pro, ë¡œì»¬ ëª¨ë¸")


def test_configuration():
    """ì„¤ì • í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
    
    try:
        config = LangChainConfig.from_env()
        logger.info(f"âœ… ì„¤ì • ë¡œë“œ ì„±ê³µ")
        logger.info(f"   - ë²¡í„° ì €ì¥ì†Œ: {config.vector_store_type.value}")
        logger.info(f"   - ì„ë² ë”© ëª¨ë¸: {config.embedding_model}")
        logger.info(f"   - LLM ì œê³µì: {config.llm_provider.value}")
        logger.info(f"   - LLM ëª¨ë¸: {config.llm_model}")
        logger.info(f"   - Langfuse í™œì„±í™”: {config.langfuse_enabled}")
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
        errors = config.validate()
        if errors:
            logger.warning(f"âš ï¸ ì„¤ì • ì˜¤ë¥˜: {errors}")
        else:
            logger.info("âœ… ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
            
        return config
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def test_langfuse_client(config: LangChainConfig):
    """Langfuse í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    logger.info("=== Langfuse í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        client = LangfuseClient(config)
        
        if client.is_enabled():
            logger.info("âœ… Langfuse í´ë¼ì´ì–¸íŠ¸ í™œì„±í™”")
            trace_id = client.get_current_trace_id()
            logger.info(f"   - í˜„ì¬ ì¶”ì  ID: {trace_id}")
        else:
            logger.info("â„¹ï¸ Langfuse í´ë¼ì´ì–¸íŠ¸ ë¹„í™œì„±í™” (ì •ìƒ)")
            
        return client
        
    except Exception as e:
        logger.error(f"âŒ Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def test_rag_service(config: LangChainConfig):
    """RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    logger.info("=== RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        service = LangChainRAGService(config)
        logger.info("âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ
        stats = service.get_service_statistics()
        logger.info("ğŸ“Š ì„œë¹„ìŠ¤ í†µê³„:")
        logger.info(f"   - LangChain ì‚¬ìš© ê°€ëŠ¥: {stats['langchain_available']}")
        logger.info(f"   - ì„ë² ë”© ëª¨ë¸: {stats['embeddings_model']}")
        logger.info(f"   - LLM ëª¨ë¸: {stats['llm_model']}")
        logger.info(f"   - Langfuse í™œì„±í™”: {stats['langfuse_enabled']}")
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
        errors = service.validate_configuration()
        if errors:
            logger.warning(f"âš ï¸ ì„œë¹„ìŠ¤ ì„¤ì • ì˜¤ë¥˜: {errors}")
        else:
            logger.info("âœ… ì„œë¹„ìŠ¤ ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
            
        return service
        
    except Exception as e:
        logger.error(f"âŒ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def test_query_processing(service: LangChainRAGService):
    """ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    test_queries = [
        {
            "query": "ê³„ì•½ì„œ ê²€í†  ìš”ì²­",
            "template_type": "contract_review",
            "description": "ê³„ì•½ì„œ ê²€í†  í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"
        },
        {
            "query": "ë¯¼ë²• ì œ1ì¡°ëŠ” ë¬´ì—‡ì„ ê·œì •í•˜ê³  ìˆë‚˜ìš”?",
            "template_type": "legal_qa",
            "description": "ë²•ë¥  Q&A í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"
        },
        {
            "query": "ìµœê·¼ íŒë¡€ ë¶„ì„ ìš”ì²­",
            "template_type": "legal_analysis",
            "description": "ë²•ë¥  ë¶„ì„ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"
        }
    ]
    
    session_id = "demo-session-1"
    
    for i, test_case in enumerate(test_queries, 1):
        logger.info(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {test_case['description']}")
        
        try:
            result = service.process_query(
                query=test_case["query"],
                session_id=session_id,
                template_type=test_case["template_type"]
            )
            
            logger.info(f"âœ… ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ")
            logger.info(f"   - ì‘ë‹µ ì‹œê°„: {result.response_time:.2f}ì´ˆ")
            logger.info(f"   - ì‹ ë¢°ë„: {result.confidence:.2f}")
            logger.info(f"   - í† í° ì‚¬ìš©ëŸ‰: {result.tokens_used}")
            logger.info(f"   - ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(result.retrieved_docs)}")
            logger.info(f"   - ì¶”ì  ID: {result.trace_id}")
            logger.info(f"   - ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {result.answer[:100]}...")
            
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        logger.info("")  # ë¹ˆ ì¤„


def test_session_management(service: LangChainRAGService):
    """ì„¸ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì„¸ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        session_id = "demo-session-2"
        
        # ì²« ë²ˆì§¸ ì¿¼ë¦¬
        result1 = service.process_query(
            query="ì²« ë²ˆì§¸ ì§ˆë¬¸",
            session_id=session_id
        )
        logger.info(f"âœ… ì²« ë²ˆì§¸ ì¿¼ë¦¬ ì²˜ë¦¬: {result1.response_time:.2f}ì´ˆ")
        
        # ë‘ ë²ˆì§¸ ì¿¼ë¦¬ (ê°™ì€ ì„¸ì…˜)
        result2 = service.process_query(
            query="ë‘ ë²ˆì§¸ ì§ˆë¬¸",
            session_id=session_id
        )
        logger.info(f"âœ… ë‘ ë²ˆì§¸ ì¿¼ë¦¬ ì²˜ë¦¬: {result2.response_time:.2f}ì´ˆ")
        
        # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
        session_context = service.context_manager.get_session_context(session_id)
        logger.info(f"ğŸ“‹ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(session_context)}ì")
        
        # ì„¸ì…˜ ì‚­ì œ
        success = service.clear_session(session_id)
        if success:
            logger.info("âœ… ì„¸ì…˜ ì‚­ì œ ì„±ê³µ")
        else:
            logger.warning("âš ï¸ ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"âŒ ì„¸ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def test_performance_monitoring(service: LangChainRAGService):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # ì„œë¹„ìŠ¤ í†µê³„
        stats = service.get_service_statistics()
        logger.info("ğŸ“Š ì„œë¹„ìŠ¤ í†µê³„:")
        logger.info(f"   - ì´ ì¿¼ë¦¬ ìˆ˜: {stats['rag_stats']['total_queries']}")
        logger.info(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['rag_stats']['avg_response_time']:.2f}ì´ˆ")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['rag_stats']['avg_confidence']:.2f}")
        
        # ì»¨í…ìŠ¤íŠ¸ í†µê³„
        context_stats = stats['context_stats']
        logger.info("ğŸ“‹ ì»¨í…ìŠ¤íŠ¸ í†µê³„:")
        logger.info(f"   - í™œì„± ì„¸ì…˜ ìˆ˜: {context_stats['active_sessions']}")
        logger.info(f"   - ì´ ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {context_stats['total_contexts']}")
        logger.info(f"   - ìºì‹œ ì ì¤‘ë¥ : {context_stats['cache_hit_ratio']:.2f}")
        
        # ìƒì„±ê¸° í†µê³„
        generator_stats = stats['generator_stats']
        logger.info("ğŸ¤– ìƒì„±ê¸° í†µê³„:")
        logger.info(f"   - ì´ í† í° ì‚¬ìš©ëŸ‰: {generator_stats['total_tokens']}")
        logger.info(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {generator_stats['avg_response_time']:.2f}ì´ˆ")
        logger.info(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿: {generator_stats['templates_available']}")
        
    except Exception as e:
        logger.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ LangChain RAG ì‹œìŠ¤í…œ ë°ëª¨ ì‹œì‘")
    logger.info("=" * 50)
    
    # 1. í™˜ê²½ ì„¤ì •
    setup_demo_environment()
    
    # 2. ì„¤ì • í…ŒìŠ¤íŠ¸
    config = test_configuration()
    if not config:
        logger.error("âŒ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 3. Langfuse í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
    client = test_langfuse_client(config)
    
    # 4. RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    service = test_rag_service(config)
    if not service:
        logger.error("âŒ RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 5. ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    test_query_processing(service)
    
    # 6. ì„¸ì…˜ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    test_session_management(service)
    
    # 7. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    test_performance_monitoring(service)
    
    logger.info("=" * 50)
    logger.info("âœ… LangChain RAG ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ")
    logger.info("")
    logger.info("ğŸ“š ì¶”ê°€ ì •ë³´:")
    logger.info("   - ì•„í‚¤í…ì²˜ ë¬¸ì„œ: docs/langchain_rag_architecture.md")
    logger.info("   - Langfuse ì„¤ì • ê°€ì´ë“œ: docs/langfuse_setup_guide.md")
    logger.info("   - í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ: docs/langchain_env_example.md")
    logger.info("")
    logger.info("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„:")
    logger.info("   1. .env íŒŒì¼ì— ì‹¤ì œ API í‚¤ ì„¤ì •")
    logger.info("   2. Langfuse ê³„ì • ìƒì„± ë° ì„¤ì •")
    logger.info("   3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•")
    logger.info("   4. í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬")


if __name__ == "__main__":
    main()
