#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸"""

import sys
import argparse
import logging
from pathlib import Path
from typing import Optional

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from lawfirm_langgraph.core.search.engines.semantic_search_engine_v2 import SemanticSearchEngineV2
from scripts.utils.embedding_version_manager import EmbeddingVersionManager
from scripts.utils.faiss_version_manager import FAISSVersionManager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def build_indexivfpq(
    db_path: str,
    vector_store_path: str,
    embedding_version_id: int,
    output_path: Optional[str] = None,
    m: int = 64,
    nbits: int = 8,
    nlist: Optional[int] = None
):
    """
    IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„±
    
    Args:
        db_path: ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
        vector_store_path: ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ
        embedding_version_id: ì„ë² ë”© ë²„ì „ ID
        output_path: ì¶œë ¥ ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        m: Product Quantizationì˜ ì„œë¸Œë²¡í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 64)
        nbits: ê° ì„œë¸Œë²¡í„°ì˜ ë¹„íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 8)
        nlist: í´ëŸ¬ìŠ¤í„° ìˆ˜ (ì„ íƒì‚¬í•­, ìë™ ê³„ì‚°)
    """
    try:
        import faiss
        import numpy as np
    except ImportError:
        logger.error("FAISS or NumPy not available")
        return False
    
    logger.info("="*80)
    logger.info("IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„±")
    logger.info("="*80)
    
    # SemanticSearchEngineV2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    engine = SemanticSearchEngineV2(
        db_path=db_path,
        use_external_index=False
    )
    
    # EmbeddingVersionManagerë¥¼ í†µí•´ ë²„ì „ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    evm = EmbeddingVersionManager(db_path)
    version_info = evm.get_version_statistics(embedding_version_id)
    
    if not version_info:
        logger.error(f"âŒ ë²„ì „ ID {embedding_version_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    logger.info(f"ğŸ“¦ Embedding version {embedding_version_id}ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë¡œë“œí•˜ì—¬ IndexIVFPQ ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘...")
    
    # ë²¡í„° ë¡œë“œ
    chunk_vectors = engine._load_chunk_vectors(embedding_version_id=embedding_version_id)
    if not chunk_vectors:
        logger.error("âŒ ì„ë² ë”© ë²¡í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    logger.info(f"âœ… {len(chunk_vectors)}ê°œì˜ ë²¡í„° ë¡œë“œ ì™„ë£Œ")
    
    # numpy ë°°ì—´ ìƒì„±
    chunk_ids_sorted = sorted(chunk_vectors.keys())
    vectors = np.array([
        chunk_vectors[chunk_id]
        for chunk_id in chunk_ids_sorted
    ]).astype('float32')
    
    dimension = vectors.shape[1]
    num_vectors = vectors.shape[0]
    
    logger.info(f"ë²¡í„° ì°¨ì›: {dimension}, ë²¡í„° ê°œìˆ˜: {num_vectors:,}")
    
    # nlist ìë™ ê³„ì‚° (ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
    if nlist is None:
        nlist = min(1000, max(100, num_vectors // 100))
        logger.info(f"nlist ìë™ ê³„ì‚°: {nlist}")
    
    # Product Quantization íŒŒë¼ë¯¸í„° ê²€ì¦
    if dimension % m != 0:
        logger.warning(f"âš ï¸  ë²¡í„° ì°¨ì›({dimension})ì´ m({m})ìœ¼ë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. mì„ ì¡°ì •í•©ë‹ˆë‹¤.")
        # mì„ dimensionì˜ ì•½ìˆ˜ë¡œ ì¡°ì •
        for candidate_m in [32, 48, 64, 96, 128]:
            if dimension % candidate_m == 0:
                m = candidate_m
                logger.info(f"mì„ {m}ìœ¼ë¡œ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.")
                break
        else:
            logger.error(f"âŒ ë²¡í„° ì°¨ì›({dimension})ì— ì í•©í•œ m ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
    
    logger.info(f"IndexIVFPQ íŒŒë¼ë¯¸í„°: nlist={nlist}, m={m}, nbits={nbits}")
    
    # IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„±
    logger.info("IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    quantizer = faiss.IndexFlatL2(dimension)
    index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)
    
    # í•™ìŠµ
    logger.info(f"IndexIVFPQ ì¸ë±ìŠ¤ í•™ìŠµ ì¤‘... (nlist={nlist})")
    index.train(vectors)
    
    # ë²¡í„° ì¶”ê°€
    logger.info(f"ë²¡í„° ì¶”ê°€ ì¤‘... ({num_vectors:,}ê°œ)")
    index.add(vectors)
    
    # nprobe ì„¤ì •
    optimal_nprobe = engine._calculate_optimal_nprobe(10, num_vectors)
    index.nprobe = optimal_nprobe
    logger.info(f"nprobe ì„¤ì •: {optimal_nprobe}")
    
    # ì¶œë ¥ ê²½ë¡œ ê²°ì •
    if output_path is None:
        version_name = version_info.get('version_name', f'v{embedding_version_id}')
        chunking_strategy = version_info.get('chunking_strategy', 'standard')
        output_dir = Path(vector_store_path) / f"{version_name}-{chunking_strategy}-ivfpq"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = str(output_dir / "index.faiss")
    else:
        output_path = str(Path(output_path))
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    # ì¸ë±ìŠ¤ ì €ì¥
    logger.info(f"IndexIVFPQ ì¸ë±ìŠ¤ ì €ì¥ ì¤‘: {output_path}")
    faiss.write_index(index, output_path)
    
    # chunk_ids.json ì €ì¥
    chunk_ids_path = Path(output_path).with_suffix('.chunk_ids.json')
    import json
    with open(chunk_ids_path, 'w', encoding='utf-8') as f:
        json.dump(chunk_ids_sorted, f, indent=2)
    logger.info(f"chunk_ids ì €ì¥: {chunk_ids_path}")
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    index_size_mb = Path(output_path).stat().st_size / (1024 * 1024)
    logger.info(f"âœ… IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")
    logger.info(f"   ì¸ë±ìŠ¤ íŒŒì¼: {output_path}")
    logger.info(f"   íŒŒì¼ í¬ê¸°: {index_size_mb:.2f} MB")
    logger.info(f"   ë²¡í„° ê°œìˆ˜: {num_vectors:,}")
    logger.info(f"   PQ íŒŒë¼ë¯¸í„°: m={m}, nbits={nbits}")
    logger.info(f"   nlist: {nlist}, nprobe: {optimal_nprobe}")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ (ì˜ˆìƒ)
    original_size_mb = (num_vectors * dimension * 4) / (1024 * 1024)  # float32
    compressed_size_mb = (num_vectors * m * nbits / 8) / (1024 * 1024)  # PQ ì••ì¶•
    compression_ratio = original_size_mb / compressed_size_mb if compressed_size_mb > 0 else 0
    logger.info(f"   ì˜ˆìƒ ë©”ëª¨ë¦¬ ì ˆì•½: {compression_ratio:.2f}x (ì›ë³¸: {original_size_mb:.2f} MB â†’ ì••ì¶•: {compressed_size_mb:.2f} MB)")
    
    return True


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="IndexIVFPQ ì¸ë±ìŠ¤ ìƒì„±")
    parser.add_argument("--db", default="data/lawfirm_v2.db", help="ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ")
    parser.add_argument("--vector-store", default="data/vector_store", help="ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ")
    parser.add_argument("--version-id", type=int, required=True, help="ì„ë² ë”© ë²„ì „ ID")
    parser.add_argument("--output", type=str, default=None, help="ì¶œë ¥ ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)")
    parser.add_argument("--m", type=int, default=64, help="Product Quantization ì„œë¸Œë²¡í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 64)")
    parser.add_argument("--nbits", type=int, default=8, help="ê° ì„œë¸Œë²¡í„°ì˜ ë¹„íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 8)")
    parser.add_argument("--nlist", type=int, default=None, help="í´ëŸ¬ìŠ¤í„° ìˆ˜ (ì„ íƒì‚¬í•­, ìë™ ê³„ì‚°)")
    
    args = parser.parse_args()
    
    success = build_indexivfpq(
        db_path=args.db,
        vector_store_path=args.vector_store,
        embedding_version_id=args.version_id,
        output_path=args.output,
        m=args.m,
        nbits=args.nbits,
        nlist=args.nlist
    )
    
    sys.exit(0 if success else 1)

