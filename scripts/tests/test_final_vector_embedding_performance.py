#!/usr/bin/env python3
"""
ë²¡í„° ì„ë² ë”© ìµœì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import sys
import os
from pathlib import Path
import time
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from source.data.vector_store import LegalVectorStore
from source.services.rag_service import MLEnhancedRAGService
from source.services.search_service import MLEnhancedSearchService
from source.data.database import DatabaseManager
from source.models.model_manager import LegalModelManager
from source.utils.config import Config

def test_vector_store():
    """ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
        vector_store = LegalVectorStore(
            model_name="jhgan/ko-sroberta-multitask",
            dimension=768,
            index_type="flat"
        )
        
        # ì¸ë±ìŠ¤ ë¡œë“œ (ì˜¬ë°”ë¥¸ ê²½ë¡œ ì‚¬ìš©)
        index_path = "data/embeddings/ml_enhanced_ko_sroberta/ml_enhanced_faiss_index"
        vector_store.load_index(index_path)
        
        # í†µê³„ í™•ì¸
        stats = vector_store.get_stats()
        print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ")
        print(f"   - ì´ ë¬¸ì„œ ìˆ˜: {stats.get('documents_count', 0):,}")
        print(f"   - ì¸ë±ìŠ¤ í¬ê¸°: {stats.get('index_size', 0):,}")
        print(f"   - ëª¨ë¸ëª…: {stats.get('model_name', 'Unknown')}")
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_queries = [
            "ê³„ì•½ì„œ í•´ì§€ ì¡°ê±´",
            "ì†í•´ë°°ìƒ ì±…ì„",
            "ë¶€ì¹™ ì‹œí–‰ì¼",
            "ë¯¼ë²• ì œ1ì¡°",
            "ìƒë²• íšŒì‚¬"
        ]
        
        print(f"\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ({len(test_queries)}ê°œ ì¿¼ë¦¬)...")
        total_search_time = 0
        
        for i, query in enumerate(test_queries, 1):
            start_time = time.time()
            results = vector_store.search(query, top_k=5)
            search_time = time.time() - start_time
            total_search_time += search_time
            
            print(f"   {i}. '{query}' â†’ {len(results)}ê°œ ê²°ê³¼ ({search_time:.3f}ì´ˆ)")
            
            if results:
                best_result = results[0]
                print(f"      ìµœê³  ì ìˆ˜: {best_result.get('score', 0):.3f}")
                print(f"      ë¬¸ì„œ ID: {best_result.get('metadata', {}).get('document_id', 'Unknown')}")
        
        avg_search_time = total_search_time / len(test_queries)
        print(f"\nğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥:")
        print(f"   - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.3f}ì´ˆ")
        print(f"   - ì´ ê²€ìƒ‰ ì‹œê°„: {total_search_time:.3f}ì´ˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_database_integration():
    """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ìˆ˜ì •
        db_path = os.path.abspath("data/lawfirm.db")
        database = DatabaseManager(db_path)
        
        # ML ê°•í™” ë°ì´í„° í™•ì¸
        ml_stats_query = """
            SELECT 
                COUNT(*) as total_articles,
                SUM(CASE WHEN ml_enhanced = 1 THEN 1 ELSE 0 END) as ml_enhanced_articles,
                AVG(parsing_quality_score) as avg_quality_score,
                SUM(CASE WHEN article_type = 'main' THEN 1 ELSE 0 END) as main_articles,
                SUM(CASE WHEN article_type = 'supplementary' THEN 1 ELSE 0 END) as supplementary_articles
            FROM assembly_articles
        """
        
        result = database.execute_query(ml_stats_query)
        stats = result[0] if result else {}
        
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì„±ê³µ")
        print(f"   - ì´ ì¡°ë¬¸ ìˆ˜: {stats.get('total_articles', 0):,}")
        print(f"   - ML ê°•í™” ì¡°ë¬¸: {stats.get('ml_enhanced_articles', 0):,}")
        print(f"   - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {stats.get('avg_quality_score', 0):.3f}")
        print(f"   - ë³¸ì¹™ ì¡°ë¬¸: {stats.get('main_articles', 0):,}")
        print(f"   - ë¶€ì¹™ ì¡°ë¬¸: {stats.get('supplementary_articles', 0):,}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_rag_service():
    """RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¤– RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ì„¤ì • ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        config = Config()
        db_path = os.path.abspath("data/lawfirm.db")
        database = DatabaseManager(db_path)
        
        vector_store = LegalVectorStore(
            model_name="jhgan/ko-sroberta-multitask",
            dimension=768,
            index_type="flat"
        )
        vector_store.load_index("data/embeddings/ml_enhanced_ko_sroberta/ml_enhanced_faiss_index")
        
        model_manager = LegalModelManager(config)
        rag_service = MLEnhancedRAGService(config, model_manager, vector_store, database)
        
        # RAG í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "ê³„ì•½ì„œ í•´ì§€ ì¡°ê±´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì†í•´ë°°ìƒ ì±…ì„ì˜ ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë¶€ì¹™ì˜ ì‹œí–‰ì¼ì€ ì–¸ì œì¸ê°€ìš”?"
        ]
        
        print(f"ğŸ” RAG í…ŒìŠ¤íŠ¸ ({len(test_queries)}ê°œ ì¿¼ë¦¬)...")
        total_rag_time = 0
        
        for i, query in enumerate(test_queries, 1):
            start_time = time.time()
            result = rag_service.process_query(query, top_k=3)
            rag_time = time.time() - start_time
            total_rag_time += rag_time
            
            print(f"   {i}. '{query}'")
            print(f"      ì‘ë‹µ ê¸¸ì´: {len(result.get('response', ''))}ì")
            print(f"      ì‹ ë¢°ë„: {result.get('confidence', 0):.3f}")
            print(f"      ì†ŒìŠ¤ ìˆ˜: {len(result.get('sources', []))}")
            print(f"      ì²˜ë¦¬ ì‹œê°„: {rag_time:.3f}ì´ˆ")
            print(f"      ML ê°•í™”: {result.get('ml_enhanced', False)}")
            
            if result.get('ml_stats'):
                ml_stats = result['ml_stats']
                print(f"      ML í†µê³„: í’ˆì§ˆ {ml_stats.get('avg_quality_score', 0):.3f}, ì‹ ë¢°ë„ {ml_stats.get('avg_ml_confidence', 0):.3f}")
        
        avg_rag_time = total_rag_time / len(test_queries)
        print(f"\nğŸ“Š RAG ì„±ëŠ¥:")
        print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_rag_time:.3f}ì´ˆ")
        print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {total_rag_time:.3f}ì´ˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_search_service():
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” ê²€ìƒ‰ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # ì„¤ì • ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        config = Config()
        db_path = os.path.abspath("data/lawfirm.db")
        database = DatabaseManager(db_path)
        
        vector_store = LegalVectorStore(
            model_name="jhgan/ko-sroberta-multitask",
            dimension=768,
            index_type="flat"
        )
        vector_store.load_index("data/embeddings/ml_enhanced_ko_sroberta/ml_enhanced_faiss_index")
        
        model_manager = LegalModelManager(config)
        search_service = MLEnhancedSearchService(config, database, vector_store, model_manager)
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        search_types = ["semantic", "keyword", "hybrid", "supplementary", "high_quality"]
        
        print(f"ğŸ” ê²€ìƒ‰ íƒ€ì…ë³„ í…ŒìŠ¤íŠ¸ ({len(search_types)}ê°œ íƒ€ì…)...")
        total_search_time = 0
        
        for search_type in search_types:
            start_time = time.time()
            results = search_service.search_documents(
                "ê³„ì•½ì„œ í•´ì§€ ì¡°ê±´", 
                search_type=search_type, 
                limit=5
            )
            search_time = time.time() - start_time
            total_search_time += search_time
            
            print(f"   {search_type}: {len(results)}ê°œ ê²°ê³¼ ({search_time:.3f}ì´ˆ)")
            
            if results:
                best_result = results[0]
                print(f"      ìµœê³  ì ìˆ˜: {best_result.get('similarity', best_result.get('hybrid_score', 0)):.3f}")
                print(f"      í’ˆì§ˆ ì ìˆ˜: {best_result.get('quality_score', 0):.3f}")
        
        avg_search_time = total_search_time / len(search_types)
        print(f"\nğŸ“Š ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì„±ëŠ¥:")
        print(f"   - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.3f}ì´ˆ")
        print(f"   - ì´ ê²€ìƒ‰ ì‹œê°„: {total_search_time:.3f}ì´ˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ë²¡í„° ì„ë² ë”© ìµœì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    test_results = []
    
    # 1. ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸
    test_results.append(("ë²¡í„° ìŠ¤í† ì–´", test_vector_store()))
    
    # 2. ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸
    test_results.append(("ë°ì´í„°ë² ì´ìŠ¤ í†µí•©", test_database_integration()))
    
    # 3. RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    test_results.append(("RAG ì„œë¹„ìŠ¤", test_rag_service()))
    
    # 4. ê²€ìƒ‰ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    test_results.append(("ê²€ìƒ‰ ì„œë¹„ìŠ¤", test_search_service()))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ë²¡í„° ì„ë² ë”© ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)