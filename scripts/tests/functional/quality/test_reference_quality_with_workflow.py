#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•œ ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„

ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ê³  retrieved_docsì˜ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import sys
import asyncio
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
_CURRENT_FILE = Path(__file__).resolve()
_PROJECT_ROOT = _CURRENT_FILE.parents[1]
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['USE_STREAMING_MODE'] = 'false'

# ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_workflow_and_analyze(query: str):
    """ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ë° ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„"""
    try:
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.core.workflow.workflow_service import LangGraphWorkflowService
        
        # ì„¤ì • ë¡œë“œ
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        service = LangGraphWorkflowService(config)
        
        # ì§ˆì˜ ì²˜ë¦¬
        logger.info(f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘: {query}")
        result = await service.process_query(
            query=query,
            session_id="quality_test",
            enable_checkpoint=False
        )
        
        # ì°¸ì¡° ìë£Œ ë¶„ì„
        retrieved_docs = result.get("retrieved_docs", [])
        sources = result.get("sources", [])
        sources_detail = result.get("sources_detail", [])
        
        print("\n" + "="*80)
        print("ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("="*80)
        print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        print(f"ë‹µë³€ ê¸¸ì´: {len(str(result.get('answer', '')))}ì\n")
        
        # retrieved_docs ë¶„ì„
        print("ğŸ“š Retrieved Docs ë¶„ì„")
        print("-" * 80)
        print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {len(retrieved_docs)}ê°œ")
        
        if retrieved_docs:
            # íƒ€ì…ë³„ ë¶„í¬
            type_counts = {}
            for doc in retrieved_docs:
                doc_type = doc.get("type") or doc.get("source_type") or doc.get("metadata", {}).get("source_type", "unknown")
                type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
            
            print(f"\níƒ€ì…ë³„ ë¶„í¬:")
            for doc_type, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"  {doc_type}: {count}ê°œ")
            
            # ìœ ì‚¬ë„ ë¶„ì„
            similarities = []
            for doc in retrieved_docs:
                if isinstance(doc, dict):
                    score = doc.get("score") or doc.get("similarity") or doc.get("relevance_score", 0.0)
                    similarities.append(score)
            
            if similarities:
                print(f"\nìœ ì‚¬ë„ í†µê³„:")
                print(f"  í‰ê· : {sum(similarities) / len(similarities):.4f}")
                print(f"  ìµœê³ : {max(similarities):.4f}")
                print(f"  ìµœì €: {min(similarities):.4f}")
                print(f"  ê³ í’ˆì§ˆ (â‰¥0.7): {sum(1 for s in similarities if s >= 0.7)}ê°œ")
                print(f"  ì¤‘í’ˆì§ˆ (0.5-0.7): {sum(1 for s in similarities if 0.5 <= s < 0.7)}ê°œ")
                print(f"  ì €í’ˆì§ˆ (<0.5): {sum(1 for s in similarities if s < 0.5)}ê°œ")
            
            # ì²­í‚¹ ì „ëµ ë¶„ì„
            strategy_counts = {}
            for doc in retrieved_docs:
                if isinstance(doc, dict):
                    strategy = doc.get("metadata", {}).get("chunking_strategy") or "unknown"
                    strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
            
            if strategy_counts:
                print(f"\nì²­í‚¹ ì „ëµ ë¶„í¬:")
                for strategy, count in sorted(strategy_counts.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {strategy}: {count}ê°œ")
            
            # ìƒìœ„ ê²°ê³¼ ìƒ˜í”Œ
            print(f"\nìƒìœ„ ê²°ê³¼ ìƒ˜í”Œ (ìƒìœ„ 5ê°œ):")
            for i, doc in enumerate(retrieved_docs[:5], 1):
                if isinstance(doc, dict):
                    doc_type = doc.get("type") or doc.get("source_type", "unknown")
                    score = (doc.get("score") or 
                            doc.get("similarity") or 
                            doc.get("relevance_score") or 
                            doc.get("hybrid_score") or 
                            doc.get("metadata", {}).get("score") or
                            doc.get("metadata", {}).get("similarity") or
                            0.0)
                    text_preview = (doc.get("text") or doc.get("content", ""))[:100]
                    print(f"\n  {i}. [{doc_type}] (ìœ ì‚¬ë„: {score:.4f})")
                    print(f"     {text_preview}...")
        else:
            print("  âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # sources ë¶„ì„
        print(f"\nğŸ“‹ Sources ë¶„ì„")
        print("-" * 80)
        print(f"ì´ ì†ŒìŠ¤ ìˆ˜: {len(sources)}ê°œ")
        if sources:
            for i, source in enumerate(sources[:5], 1):
                if isinstance(source, dict):
                    name = source.get("name") or source.get("title", "ì œëª© ì—†ìŒ")
                    print(f"  {i}. {name}")
        
        # sources_detail ë¶„ì„
        print(f"\nğŸ“„ Sources Detail ë¶„ì„")
        print("-" * 80)
        print(f"ì´ ìƒì„¸ ì†ŒìŠ¤ ìˆ˜: {len(sources_detail)}ê°œ")
        if sources_detail:
            for i, detail in enumerate(sources_detail[:5], 1):
                if isinstance(detail, dict):
                    name = detail.get("name") or detail.get("title", "ì œëª© ì—†ìŒ")
                    source_type = detail.get("type") or detail.get("source_type", "unknown")
                    print(f"  {i}. [{source_type}] {name}")
        
        # í’ˆì§ˆ í‰ê°€
        print(f"\nğŸ¯ í’ˆì§ˆ í‰ê°€")
        print("-" * 80)
        
        issues = []
        if not retrieved_docs:
            issues.append("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        elif len(retrieved_docs) < 3:
            issues.append(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(retrieved_docs)}ê°œ")
        
        if similarities:
            avg_sim = sum(similarities) / len(similarities)
            if avg_sim < 0.6:
                issues.append(f"í‰ê·  ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤: {avg_sim:.4f}")
            if sum(1 for s in similarities if s < 0.5) > len(similarities) * 0.3:
                issues.append("ì €í’ˆì§ˆ ê²°ê³¼ê°€ ë§ìŠµë‹ˆë‹¤.")
        
        if not sources:
            issues.append("Sourcesê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if issues:
            print("âš ï¸  ë°œê²¬ëœ ë¬¸ì œì :")
            for i, issue in enumerate(issues, 1):
                print(f"  {i}. {issue}")
        else:
            print("âœ… íŠ¹ë³„í•œ ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print("\n" + "="*80)
        
        return result
        
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì›Œí¬í”Œë¡œìš° ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„')
    parser.add_argument('--query', default='ì „ì„¸ê¸ˆ ë°˜í™˜ ë³´ì¦ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”', help='ê²€ìƒ‰ ì¿¼ë¦¬')
    
    args = parser.parse_args()
    
    result = asyncio.run(test_workflow_and_analyze(args.query))
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")


if __name__ == '__main__':
    main()

