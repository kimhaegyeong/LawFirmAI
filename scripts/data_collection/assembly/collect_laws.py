#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë²•ë¥  ìˆ˜ì§‘ (Playwright + ì ì§„ì  + ì••ì¶•)

ì‚¬ìš©ë²•:
  python collect_laws.py --sample 10     # ìƒ˜í”Œ 10ê°œ
  python collect_laws.py --sample 100    # ìƒ˜í”Œ 100ê°œ
  python collect_laws.py --sample 1000   # ìƒ˜í”Œ 1000ê°œ
  python collect_laws.py --full          # ì „ì²´ 7602ê°œ
  python collect_laws.py --resume        # ì¤‘ë‹¨ ì§€ì ì—ì„œ ì¬ê°œ

íŠ¹ì§•:
  - ìë™ ë°ì´í„° ì••ì¶• (95% ì´ìƒ ìš©ëŸ‰ ì ˆì•½)
  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ìˆ˜ì§‘
  - ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¬ê°œ ê¸°ëŠ¥
  - ì‹¤ì‹œê°„ ì••ì¶• í†µê³„ í‘œì‹œ
"""

import argparse
import sys
import signal
import logging
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.assembly_playwright_client import AssemblyPlaywrightClient
from scripts.assembly.assembly_collector import AssemblyCollector
from scripts.assembly.checkpoint_manager import CheckpointManager
from scripts.assembly.assembly_logger import setup_logging, log_progress, log_memory_usage, log_collection_stats, log_checkpoint_info
from scripts.assembly.law_data_compressor import compress_law_data, compress_and_save_page_data

# ë¡œê±° ì„¤ì •
logger = setup_logging("law_collection")

# Graceful shutdown ì²˜ë¦¬
interrupted = False

def signal_handler(sig, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (Ctrl+C ë“±)"""
    global interrupted
    logger.warning("\nâš ï¸ Interrupt signal received. Saving progress...")
    interrupted = True

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def collect_laws_incremental(
    target_count: int = None,
    page_size: int = 100,
    resume: bool = True,
    start_page: int = 1
):
    """
    ì ì§„ì  ë²•ë¥  ìˆ˜ì§‘
    
    Args:
        target_count: ëª©í‘œ ìˆ˜ì§‘ ê±´ìˆ˜ (None=ì „ì²´)
        page_size: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (100 ê¶Œì¥)
        resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ LAW COLLECTION STARTED")
    print(f"{'='*60}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €
    checkpoint_mgr = CheckpointManager("data/checkpoints/laws")
    print(f"ğŸ“ Checkpoint directory: data/checkpoints/laws")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    actual_start_page = start_page
    checkpoint = None
    
    if resume:
        print(f"ğŸ” Checking for existing checkpoint...")
        checkpoint = checkpoint_mgr.load_checkpoint()
        if checkpoint:
            print(f"ğŸ“‚ Resuming from checkpoint")
            print(f"   Data type: {checkpoint.get('data_type', 'unknown')}")
            print(f"   Category: {checkpoint.get('category', 'None')}")
            print(f"   Page: {checkpoint.get('current_page', 0)}/{checkpoint.get('total_pages', 0)}")
            print(f"   Collected: {checkpoint.get('collected_count', 0)} items")
            print(f"   Memory: {checkpoint.get('memory_usage_mb', 0):.1f}MB")
            actual_start_page = checkpoint['current_page'] + 1
        else:
            print(f"ğŸ“‚ No checkpoint found, starting from page {start_page}")
    else:
        print(f"ğŸ“‚ Resume disabled, starting from page {start_page}")
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    print(f"\nğŸ“¦ Initializing collector...")
    collector = AssemblyCollector(
        base_dir="data/raw/assembly",
        data_type="law",
        category=None,
        batch_size=50,
        memory_limit_mb=800
    )
    print(f"âœ… Collector initialized")
    
    # ì‹œì‘ ì‹œê°„ ì„¤ì •
    start_time = datetime.now().isoformat()
    collector.set_start_time(start_time)
    
    # ì „ì²´ í˜ì´ì§€ ê³„ì‚° (ì‹¤ì œë¡œëŠ” í˜ì´ì§€ë‹¹ 10ê°œì”© í‘œì‹œë¨)
    if target_count:
        total_pages = actual_start_page + (target_count + 10 - 1) // 10 - 1  # í˜ì´ì§€ë‹¹ 10ê°œ
    else:
        total_pages = 100  # ëŒ€ëµì ì¸ í˜ì´ì§€ ìˆ˜
    
    print(f"\nğŸ“Š Collection Parameters:")
    print(f"   Target: {target_count or 'ALL (7602)'} items")
    print(f"   Pages: {actual_start_page} to {total_pages}")
    print(f"   Page size: 10 (fixed)")
    print(f"   Batch size: {collector.batch_size}")
    print(f"   Memory limit: {collector.memory_limit_mb}MB")
    print(f"   Start time: {start_time}")
    
    collected_this_run = 0
    total_original_size = 0
    total_compressed_size = 0
    
    try:
        print(f"\nğŸŒ Starting Playwright browser...")
        # Playwright ì‹œì‘
        with AssemblyPlaywrightClient(
            rate_limit=3.0,
            headless=True,
            memory_limit_mb=800
        ) as client:
            print(f"âœ… Playwright browser started")
            
            for page in range(actual_start_page, total_pages + 1):
                if interrupted:
                    print(f"\nâš ï¸ INTERRUPTED by user signal")
                    break
                
                print(f"\n{'â”€'*50}")
                print(f"ğŸ“„ Processing Page {page}/{total_pages}")
                print(f"{'â”€'*50}")
                
                # ë©”ëª¨ë¦¬ ì²´í¬
                memory_mb = client.check_memory_usage()
                print(f"ğŸ“Š Memory usage: {memory_mb:.1f}MB")
                
                # ëª©ë¡ ì¡°íšŒ
                print(f"ğŸ” Fetching law list from page {page}...")
                laws = client.get_law_list_page(page_num=page, page_size=10)
                print(f"âœ… Found {len(laws)} laws on page")
                
                if not laws:
                    print(f"âš ï¸ No laws found on page {page}, skipping...")
                    continue
                
                # ê° ë²•ë¥  ìƒì„¸ ìˆ˜ì§‘
                print(f"ğŸ“‹ Processing {len(laws)} laws...")
                page_laws = []  # í˜„ì¬ í˜ì´ì§€ì˜ ë²•ë¥ ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                
                for idx, law_item in enumerate(laws, 1):
                    if interrupted:
                        print(f"\nâš ï¸ INTERRUPTED during law processing")
                        break
                    
                    try:
                        print(f"   [{idx:2d}/{len(laws)}] Processing: {law_item['law_name'][:50]}...")
                        
                        detail = client.get_law_detail(
                            law_item['cont_id'],
                            law_item['cont_sid']
                        )
                        
                        # ëª©ë¡ ì •ë³´ ë³‘í•©
                        detail.update({
                            'row_number': law_item['row_number'],
                            'category': law_item['category'],
                            'law_type': law_item['law_type'],
                            'promulgation_number': law_item['promulgation_number'],
                            'promulgation_date': law_item['promulgation_date'],
                            'enforcement_date': law_item['enforcement_date'],
                            'amendment_type': law_item['amendment_type']
                        })
                        
                        page_laws.append(detail)  # í˜ì´ì§€ë³„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        collector.save_item(detail)
                        collected_this_run += 1
                        
                        print(f"      âœ… Collected (Total: {collector.collected_count})")
                        
                        # ëª©í‘œ ë‹¬ì„± ì²´í¬
                        if target_count and collected_this_run >= target_count:
                            print(f"\nğŸ¯ TARGET REACHED: {collected_this_run}/{target_count}")
                            break
                        
                    except Exception as e:
                        print(f"      âŒ Failed: {str(e)[:100]}...")
                        collector.add_failed_item(law_item, str(e))
                        continue
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ë²•ë¥ ë“¤ì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ (ì••ì¶•ëœ ë²„ì „)
                if page_laws:
                    timestamp = datetime.now().strftime("%H%M%S")
                    page_filename = f"law_page_{page:03d}_{timestamp}.json"
                    page_filepath = collector.output_dir / page_filename
                    
                    page_data = {
                        "page_number": page,
                        "total_pages": total_pages,
                        "laws_count": len(page_laws),
                        "collected_at": datetime.now().isoformat(),
                        "laws": page_laws
                    }
                    
                    # ì••ì¶•ëœ ë°ì´í„°ë¡œ ì €ì¥
                    compressed_size = compress_and_save_page_data(page_data, str(page_filepath))
                    
                    # ì••ì¶• í†µê³„ ì—…ë°ì´íŠ¸
                    total_compressed_size += compressed_size
                    
                    # ì›ë³¸ í¬ê¸° ì¶”ì • (ì••ì¶• ì „ í¬ê¸°)
                    estimated_original_size = compressed_size * 20  # ëŒ€ëµì ì¸ ì••ì¶•ë¥  ê³ ë ¤
                    total_original_size += estimated_original_size
                    
                    compression_ratio = (1 - compressed_size / estimated_original_size) * 100 if estimated_original_size > 0 else 0
                    
                    print(f"ğŸ“„ Page {page} saved: {page_filename} ({len(page_laws)} laws, {compressed_size:,} bytes, {compression_ratio:.1f}% ì••ì¶•)")
                
                # ì§„í–‰ë¥  ë¡œê·¸
                print(f"\nğŸ“ˆ Progress Summary:")
                print(f"   Page: {page}/{total_pages} ({page/total_pages*100:.1f}%)")
                print(f"   Collected this run: {collected_this_run}")
                print(f"   Total collected: {collector.collected_count}")
                print(f"   Failed: {len(collector.failed_items)}")
                print(f"   Success rate: {collector.collected_count/(collector.collected_count + len(collector.failed_items))*100:.1f}%" if (collector.collected_count + len(collector.failed_items)) > 0 else "   Success rate: N/A")
                
                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                checkpoint_data = {
                    'data_type': 'law',
                    'category': None,
                    'current_page': page,
                    'total_pages': total_pages,
                    'collected_count': collector.collected_count,
                    'collected_this_run': collected_this_run,
                    'start_time': checkpoint['start_time'] if checkpoint else start_time,
                    'memory_usage_mb': memory_mb,
                    'target_count': target_count,
                    'page_size': page_size
                }
                
                checkpoint_mgr.save_checkpoint(checkpoint_data)
                print(f"ğŸ’¾ Checkpoint saved at page {page}")
                
                # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
                if target_count and collected_this_run >= target_count:
                    print(f"\nğŸ¯ Target achieved, stopping collection")
                    break
            
            # ìˆ˜ì§‘ ì™„ë£Œ
            print(f"\nğŸ Finalizing collection...")
            collector.finalize()
            
            if not interrupted:
                checkpoint_mgr.clear_checkpoint()
                print(f"\nâœ… COLLECTION COMPLETED SUCCESSFULLY!")
            else:
                print(f"\nâš ï¸ COLLECTION INTERRUPTED (progress saved)")
            
            # ìµœì¢… í†µê³„
            print(f"\nğŸ“Š Final Statistics:")
            print(f"   Total collected: {collector.collected_count} items")
            print(f"   Failed: {len(collector.failed_items)} items")
            print(f"   Requests made: {client.request_count}")
            print(f"   Rate limit: {client.get_stats()['rate_limit']}s")
            print(f"   Timeout: {client.get_stats()['timeout']}ms")
            
            # ì••ì¶• í†µê³„
            if total_compressed_size > 0:
                overall_compression_ratio = (1 - total_compressed_size / total_original_size) * 100 if total_original_size > 0 else 0
                print(f"\nğŸ—œï¸ Compression Statistics:")
                print(f"   Estimated original size: {total_original_size:,} bytes ({total_original_size/1024/1024:.1f} MB)")
                print(f"   Compressed size: {total_compressed_size:,} bytes ({total_compressed_size/1024/1024:.1f} MB)")
                print(f"   Compression ratio: {overall_compression_ratio:.1f}%")
                print(f"   Space saved: {(total_original_size - total_compressed_size)/1024/1024:.1f} MB")
            
    except Exception as e:
        print(f"\nâŒ CRITICAL ERROR: {e}")
        print(f"ğŸ”§ Finalizing collector...")
        collector.finalize()
        raise

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë²•ë¥  ìˆ˜ì§‘ (Playwright)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python collect_laws.py --sample 10                    # ìƒ˜í”Œ 10ê°œ ìˆ˜ì§‘
  python collect_laws.py --sample 100                   # ìƒ˜í”Œ 100ê°œ ìˆ˜ì§‘
  python collect_laws.py --sample 100 --start-page 5     # 5í˜ì´ì§€ë¶€í„° 100ê°œ ìˆ˜ì§‘
  python collect_laws.py --sample 50 --start-page 10     # 10í˜ì´ì§€ë¶€í„° 50ê°œ ìˆ˜ì§‘
  python collect_laws.py --full                          # ì „ì²´ 7602ê°œ ìˆ˜ì§‘
  python collect_laws.py --resume                        # ì¤‘ë‹¨ ì§€ì ì—ì„œ ì¬ê°œ
        """
    )
    
    parser.add_argument('--sample', type=int, metavar='N',
                        help='ìƒ˜í”Œ ìˆ˜ì§‘ ê°œìˆ˜ (10, 100, 1000 ë“±)')
    parser.add_argument('--full', action='store_true',
                        help='ì „ì²´ ìˆ˜ì§‘ (7602ê°œ)')
    parser.add_argument('--resume', action='store_true', default=True,
                        help='ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ (ê¸°ë³¸ê°’)')
    parser.add_argument('--no-resume', dest='resume', action='store_false',
                        help='ì²˜ìŒë¶€í„° ì‹œì‘')
    parser.add_argument('--page-size', type=int, default=100,
                        help='í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--start-page', type=int, default=1,
                        help='ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸: 1)')
    parser.add_argument('--log-level', type=str, default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help='ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸: INFO)')
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ë ˆë²¨ ì¬ì„¤ì •
    if args.log_level != 'INFO':
        logger.setLevel(getattr(logging, args.log_level))
    
    if args.sample:
        print(f"ğŸ“¦ Sample mode: {args.sample} items")
        collect_laws_incremental(
            target_count=args.sample,
            page_size=args.page_size,
            resume=args.resume,
            start_page=args.start_page
        )
    elif args.full:
        logger.info(f"ğŸ“¦ Full mode: 7602 items")
        collect_laws_incremental(
            target_count=None,
            page_size=args.page_size,
            resume=args.resume,
            start_page=args.start_page
        )
    else:
        parser.print_help()
        logger.error("\nâŒ Please specify --sample N or --full")
        sys.exit(1)

if __name__ == "__main__":
    main()
