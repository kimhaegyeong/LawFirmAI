#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ê¸°

êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° OPEN APIë¥¼ í†µí•´ í—Œì¬ê²°ì •ë¡€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
- ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìˆ˜ì§‘
- 100ê°œ ë‹¨ìœ„ ë°°ì¹˜ ì²˜ë¦¬
- ìƒì„¸ ì •ë³´ í¬í•¨ ìˆ˜ì§‘
- ì²´í¬í¬ì¸íŠ¸ ì§€ì›
- ë°°ì¹˜ ì €ì¥ ì‹œìŠ¤í…œ
"""

import os
import sys
import time
import json
import logging
from typing import Dict, Any, List, Optional, Set
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, field

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.law_open_api_client import LawOpenAPIClient

logger = logging.getLogger(__name__)


@dataclass
class CollectionConfig:
    """ìˆ˜ì§‘ ì„¤ì •"""
    base_output_dir: Path = field(default_factory=lambda: Path("data/raw/constitutional_decisions"))
    batch_size: int = 100
    max_pages: Optional[int] = None
    include_details: bool = True
    sort_order: str = "dasc"  # ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ
    save_batches: bool = True
    resume_from_checkpoint: bool = True


@dataclass
class CollectionStats:
    """ìˆ˜ì§‘ í†µê³„"""
    total_collected: int = 0
    total_pages: int = 0
    batch_count: int = 0
    api_requests_made: int = 0
    errors: List[str] = field(default_factory=list)
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    collected_decisions: Set[str] = field(default_factory=set)


class ConstitutionalDecisionCollector:
    """í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self, config: CollectionConfig = None):
        """
        í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        
        Args:
            config: ìˆ˜ì§‘ ì„¤ì •
        """
        self.config = config or CollectionConfig()
        self.client = LawOpenAPIClient()
        self.stats = CollectionStats()
        self.collected_decisions: Set[str] = set()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.config.base_output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ConstitutionalDecisionCollector ì´ˆê¸°í™” ì™„ë£Œ - ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.config.base_output_dir}")
    
    def collect_decisions_by_keyword(self, 
                                   keyword: str = "", 
                                   max_count: int = 1000,
                                   include_details: bool = True) -> List[Dict[str, Any]]:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_count: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜
            include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
            
        Returns:
            ìˆ˜ì§‘ëœ í—Œì¬ê²°ì •ë¡€ ëª©ë¡
        """
        logger.info(f"í‚¤ì›Œë“œ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹œì‘ - í‚¤ì›Œë“œ: '{keyword}', ìµœëŒ€ê°œìˆ˜: {max_count}")
        
        decisions = []
        page = 1
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if self.config.save_batches:
            batch_dir = self.config.base_output_dir / "batches"
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        while len(decisions) < max_count:
            try:
                # API ìš”ì²­
                response = self.client.search_constitutional_decisions(
                    query=keyword,
                    search=1,  # í—Œì¬ê²°ì •ë¡€ëª… ê²€ìƒ‰
                    display=min(100, max_count - len(decisions)),
                    page=page,
                    sort=self.config.sort_order
                )
                
                self.stats.api_requests_made += 1
                
                if not response or 'DetcSearch' not in response:
                    logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                    break
                
                search_result = response['DetcSearch']
                if 'detc' not in search_result:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë¹ˆ ê²°ê³¼ - ìˆ˜ì§‘ ì™„ë£Œ")
                    break
                
                # detcê°€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                page_decisions = search_result['detc']
                if isinstance(page_decisions, dict):
                    page_decisions = [page_decisions]
                
                new_decisions = 0
                for decision in page_decisions:
                    if len(decisions) >= max_count:
                        break
                    
                    decision_id = decision.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸')
                    if decision_id and decision_id not in self.collected_decisions:
                        if include_details:
                            try:
                                # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                                detail = self.client.get_constitutional_decision_detail(decision_id)
                                
                                # ëª©ë¡ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                                combined_decision = {
                                    **decision,  # ëª©ë¡ ì •ë³´
                                    'detailed_info': detail,  # ìƒì„¸ ì •ë³´
                                    'document_type': 'constitutional_decision',
                                    'collected_at': datetime.now().isoformat()
                                }
                                decisions.append(combined_decision)
                                current_batch.append(combined_decision)
                                
                                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                                time.sleep(1.0)
                                
                            except Exception as e:
                                logger.error(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {decision_id} - {e}")
                                decision['document_type'] = 'constitutional_decision'
                                decision['collected_at'] = datetime.now().isoformat()
                                decisions.append(decision)
                                current_batch.append(decision)
                        else:
                            decision['document_type'] = 'constitutional_decision'
                            decision['collected_at'] = datetime.now().isoformat()
                            decisions.append(decision)
                            current_batch.append(decision)
                        
                        self.collected_decisions.add(decision_id)
                        self.stats.collected_decisions.add(decision_id)
                        new_decisions += 1
                        
                        logger.info(f"ìƒˆë¡œìš´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘: {decision.get('ì‚¬ê±´ëª…', 'Unknown')} (ID: {decision_id})")
                        
                        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                        if self.config.save_batches and len(current_batch) >= self.config.batch_size:
                            batch_count += 1
                            batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
                            
                            batch_data = {
                                "batch_number": batch_count,
                                "batch_size": len(current_batch),
                                "keyword": keyword,
                                "timestamp": datetime.now().isoformat(),
                                "decisions": current_batch
                            }
                            
                            with open(batch_file, 'w', encoding='utf-8') as f:
                                json.dump(batch_data, f, ensure_ascii=False, indent=2)
                            
                            print(f"  ğŸ’¾ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                            logger.info(f"í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                            
                            current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                
                logger.info(f"í˜ì´ì§€ {page} ì™„ë£Œ: {new_decisions}ê±´ì˜ ìƒˆë¡œìš´ ê²°ì •ë¡€ ìˆ˜ì§‘")
                logger.info(f"ëˆ„ì  ìˆ˜ì§‘: {len(decisions)}/{max_count}ê±´ ({len(decisions)/max_count*100:.1f}%)")
                
                page += 1
                
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                time.sleep(1.0)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                self.stats.errors.append(f"Page {page} collection error: {e}")
                break
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if self.config.save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "keyword": keyword,
                "timestamp": datetime.now().isoformat(),
                "decisions": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
        
        # ë°°ì¹˜ ìš”ì•½ ì •ë³´ ì €ì¥
        if self.config.save_batches and batch_count > 0:
            summary_file = batch_dir / f"constitutional_batch_summary_{timestamp}.json"
            summary_data = {
                "total_batches": batch_count,
                "total_decisions": len(decisions),
                "batch_size": self.config.batch_size,
                "keyword": keyword,
                "timestamp": timestamp,
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "sort_order": self.config.sort_order,
                "include_details": include_details
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ“Š í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ ìš”ì•½ ì €ì¥: {batch_count}ê°œ ë°°ì¹˜, {len(decisions):,}ê°œ í•­ëª© -> {summary_file.name}")
        
        self.stats.total_collected = len(decisions)
        self.stats.batch_count = batch_count
        
        logger.info(f"í‚¤ì›Œë“œ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(decisions)}ê°œ ê²°ì •ë¡€")
        return decisions
    
    def collect_all_decisions(self, 
                            query: str = "",
                            include_details: bool = True) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ (ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ëª¨ë“  ê²°ì •ë¡€)
            include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
            
        Returns:
            ìˆ˜ì§‘ëœ í—Œì¬ê²°ì •ë¡€ ëª©ë¡
        """
        logger.info(f"ì „ì²´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹œì‘ - ì¿¼ë¦¬: '{query}', ìƒì„¸ì •ë³´: {include_details}")
        
        self.stats.start_time = datetime.now()
        
        try:
            # API í´ë¼ì´ì–¸íŠ¸ì˜ ì „ì²´ ìˆ˜ì§‘ ë©”ì„œë“œ ì‚¬ìš©
            decisions = self.client.get_all_constitutional_decisions(
                query=query,
                max_pages=self.config.max_pages,
                sort=self.config.sort_order,
                include_details=include_details,
                batch_size=self.config.batch_size,
                save_batches=self.config.save_batches
            )
            
            self.stats.total_collected = len(decisions)
            self.stats.end_time = datetime.now()
            
            logger.info(f"ì „ì²´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(decisions)}ê°œ ê²°ì •ë¡€")
            return decisions
            
        except Exception as e:
            logger.error(f"ì „ì²´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.stats.errors.append(f"Full collection error: {e}")
            self.stats.end_time = datetime.now()
            return []
    
    def collect_decisions_by_date_range(self, 
                                      start_date: str, 
                                      end_date: str,
                                      include_details: bool = True) -> List[Dict[str, Any]]:
        """
        ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYYMMDD í˜•ì‹)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD í˜•ì‹)
            include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
            
        Returns:
            ìˆ˜ì§‘ëœ í—Œì¬ê²°ì •ë¡€ ëª©ë¡
        """
        logger.info(f"ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹œì‘ - {start_date} ~ {end_date}")
        
        decisions = []
        page = 1
        batch_count = 0
        current_batch = []
        
        # ë°°ì¹˜ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if self.config.save_batches:
            batch_dir = self.config.base_output_dir / "batches"
            batch_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        while True:
            try:
                # ë‚ ì§œ ë²”ìœ„ ê²€ìƒ‰
                response = self.client.search_constitutional_decisions(
                    query="",
                    search=1,
                    display=100,
                    page=page,
                    sort=self.config.sort_order,
                    edYd=f"{start_date}-{end_date}"
                )
                
                self.stats.api_requests_made += 1
                
                if not response or 'DetcSearch' not in response:
                    logger.warning(f"í˜ì´ì§€ {page}ì—ì„œ ì‘ë‹µ ë°ì´í„° ì—†ìŒ")
                    break
                
                search_result = response['DetcSearch']
                if 'detc' not in search_result:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë¹ˆ ê²°ê³¼ - ìˆ˜ì§‘ ì™„ë£Œ")
                    break
                
                # detcê°€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                page_decisions = search_result['detc']
                if isinstance(page_decisions, dict):
                    page_decisions = [page_decisions]
                
                for decision in page_decisions:
                    decision_id = decision.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸')
                    if decision_id and decision_id not in self.collected_decisions:
                        if include_details:
                            try:
                                # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                                detail = self.client.get_constitutional_decision_detail(decision_id)
                                
                                # ëª©ë¡ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                                combined_decision = {
                                    **decision,  # ëª©ë¡ ì •ë³´
                                    'detailed_info': detail,  # ìƒì„¸ ì •ë³´
                                    'document_type': 'constitutional_decision',
                                    'collected_at': datetime.now().isoformat()
                                }
                                decisions.append(combined_decision)
                                current_batch.append(combined_decision)
                                
                                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
                                time.sleep(1.0)
                                
                            except Exception as e:
                                logger.error(f"í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {decision_id} - {e}")
                                decision['document_type'] = 'constitutional_decision'
                                decision['collected_at'] = datetime.now().isoformat()
                                decisions.append(decision)
                                current_batch.append(decision)
                        else:
                            decision['document_type'] = 'constitutional_decision'
                            decision['collected_at'] = datetime.now().isoformat()
                            decisions.append(decision)
                            current_batch.append(decision)
                        
                        self.collected_decisions.add(decision_id)
                        self.stats.collected_decisions.add(decision_id)
                        
                        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥
                        if self.config.save_batches and len(current_batch) >= self.config.batch_size:
                            batch_count += 1
                            batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
                            
                            batch_data = {
                                "batch_number": batch_count,
                                "batch_size": len(current_batch),
                                "date_range": f"{start_date}-{end_date}",
                                "timestamp": datetime.now().isoformat(),
                                "decisions": current_batch
                            }
                            
                            with open(batch_file, 'w', encoding='utf-8') as f:
                                json.dump(batch_data, f, ensure_ascii=False, indent=2)
                            
                            print(f"  ğŸ’¾ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
                            logger.info(f"í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥ ì™„ë£Œ: {len(current_batch)}ê°œ í•­ëª©")
                            
                            current_batch = []  # ë°°ì¹˜ ì´ˆê¸°í™”
                
                logger.info(f"í˜ì´ì§€ {page} ì™„ë£Œ: {len(page_decisions)}ê±´ì˜ ê²°ì •ë¡€ ìˆ˜ì§‘")
                
                page += 1
                
                # ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                time.sleep(1.0)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                self.stats.errors.append(f"Page {page} collection error: {e}")
                break
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ (ë‚¨ì€ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        if self.config.save_batches and current_batch:
            batch_count += 1
            batch_file = batch_dir / f"constitutional_batch_{timestamp}_{batch_count:03d}.json"
            
            batch_data = {
                "batch_number": batch_count,
                "batch_size": len(current_batch),
                "date_range": f"{start_date}-{end_date}",
                "timestamp": datetime.now().isoformat(),
                "decisions": current_batch
            }
            
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, ensure_ascii=False, indent=2)
            
            print(f"  ğŸ’¾ ë§ˆì§€ë§‰ í—Œì¬ê²°ì •ë¡€ ë°°ì¹˜ {batch_count} ì €ì¥: {len(current_batch):,}ê°œ í•­ëª© -> {batch_file.name}")
        
        self.stats.total_collected = len(decisions)
        self.stats.batch_count = batch_count
        
        logger.info(f"ë‚ ì§œ ë²”ìœ„ ê¸°ë°˜ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì™„ë£Œ - ì´ {len(decisions)}ê°œ ê²°ì •ë¡€")
        return decisions
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ìˆ˜ì§‘ í†µê³„ ë°˜í™˜"""
        return {
            "total_collected": self.stats.total_collected,
            "total_pages": self.stats.total_pages,
            "batch_count": self.stats.batch_count,
            "api_requests_made": self.stats.api_requests_made,
            "errors": self.stats.errors,
            "start_time": self.stats.start_time.isoformat() if self.stats.start_time else None,
            "end_time": self.stats.end_time.isoformat() if self.stats.end_time else None,
            "collected_decisions_count": len(self.stats.collected_decisions)
        }
    
    def clear_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = CollectionStats()
        self.collected_decisions.clear()


def create_collector(config: CollectionConfig = None) -> ConstitutionalDecisionCollector:
    """
    í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ê¸° ìƒì„±
    
    Args:
        config: ìˆ˜ì§‘ ì„¤ì •
        
    Returns:
        ConstitutionalDecisionCollector ì¸ìŠ¤í„´ìŠ¤
    """
    return ConstitutionalDecisionCollector(config)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    logging.basicConfig(level=logging.INFO)
    
    print("í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    oc_param = os.getenv("LAW_OPEN_API_OC")
    if not oc_param:
        print("âŒ LAW_OPEN_API_OC í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("export LAW_OPEN_API_OC='your_email@example.com'")
        exit(1)
    
    print(f"âœ… OC íŒŒë¼ë¯¸í„°: {oc_param}")
    
    # ìˆ˜ì§‘ê¸° ìƒì„± ë° í…ŒìŠ¤íŠ¸
    try:
        config = CollectionConfig(
            batch_size=100,
            include_details=True,
            sort_order="dasc"  # ì„ ê³ ì¼ì ì˜¤ë¦„ì°¨ìˆœ
        )
        
        collector = create_collector(config)
        
        # API ì—°ê²° í…ŒìŠ¤íŠ¸
        if collector.client.test_connection():
            print("âœ… API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
            # ìƒ˜í”Œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
            print("\nìƒ˜í”Œ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸:")
            decisions = collector.collect_decisions_by_keyword(
                keyword="í—Œë²•",
                max_count=5,
                include_details=True
            )
            
            if decisions:
                print(f"âœ… ìƒ˜í”Œ ìˆ˜ì§‘ ì„±ê³µ: {len(decisions)}ê°œ ê²°ì •ë¡€")
                for i, decision in enumerate(decisions[:3], 1):
                    print(f"  {i}. {decision.get('ì‚¬ê±´ëª…', 'N/A')}")
            else:
                print("âŒ ìƒ˜í”Œ ìˆ˜ì§‘ ì‹¤íŒ¨")
        else:
            print("âŒ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
