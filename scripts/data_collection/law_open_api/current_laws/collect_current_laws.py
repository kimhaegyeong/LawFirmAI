#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

í˜„í–‰ë²•ë ¹ ëª©ë¡ ì¡°íšŒ í›„ ê° ë²•ë ¹ì˜ ë³¸ë¬¸ì„ ìˆ˜ì§‘í•˜ì—¬ ë°°ì¹˜ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë²¡í„° ì €ì¥ì†Œ ì—…ë°ì´íŠ¸ëŠ” ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import sys
import argparse
import logging
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from scripts.data_collection.law_open_api.current_laws.current_law_collector import (
    CurrentLawCollector, CollectionConfig
)

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    # logs ë””ë ‰í† ë¦¬ ìƒì„±
    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ëª… ìƒì„±
    log_filename = f'logs/current_laws_collection_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filename, encoding='utf-8')
        ]
    )
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
    print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_filename}")
    return log_filename

# ë¡œê¹… ì´ˆê¸°í™”
log_file = setup_logging()
logger = logging.getLogger(__name__)


def validate_environment() -> bool:
    """í™˜ê²½ ë³€ìˆ˜ ê²€ì¦"""
    oc_param = os.getenv("LAW_OPEN_API_OC")
    if not oc_param or oc_param == "{OC}":
        print("âŒ LAW_OPEN_API_OC í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("export LAW_OPEN_API_OC='your_email@example.com'")
        return False
    
    print(f"âœ… OC íŒŒë¼ë¯¸í„°: {oc_param}")
    return True


def collect_current_laws_data(
    query: str = "",
    max_pages: int = None,
    start_page: int = 1,
    batch_size: int = 10,
    include_details: bool = True,
    sort_order: str = "ldes",
    resume_from_checkpoint: bool = False
) -> Dict[str, Any]:
    """
    í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        query: ê²€ìƒ‰ ì§ˆì˜
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
        batch_size: ë°°ì¹˜ í¬ê¸°
        include_details: ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
        sort_order: ì •ë ¬ ìˆœì„œ
        resume_from_checkpoint: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘ ì—¬ë¶€
        
    Returns:
        Dict: ìˆ˜ì§‘ ê²°ê³¼
    """
    logger.info("=" * 60)
    logger.info("í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    logger.info(f"ê²€ìƒ‰ì–´: '{query}'")
    logger.info(f"ìµœëŒ€ í˜ì´ì§€: {max_pages or 'ë¬´ì œí•œ'}")
    logger.info(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
    logger.info(f"ìƒì„¸ ì •ë³´: {'í¬í•¨' if include_details else 'ì œì™¸'}")
    logger.info(f"ì •ë ¬ ìˆœì„œ: {sort_order}")
    logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì¬ì‹œì‘: {'ì˜ˆ' if resume_from_checkpoint else 'ì•„ë‹ˆì˜¤'}")
    logger.info("=" * 60)
    
    result = {
        "status": "success",
        "total_collected": 0,
        "collection_time": None,
        "batch_files": [],
        "summary_file": None,
        "errors": [],
        "start_time": datetime.now().isoformat(),
        "end_time": None
    }
    
    try:
        # ìˆ˜ì§‘ê¸° ì„¤ì •
        config = CollectionConfig(
            batch_size=batch_size,
            include_details=include_details,
            sort_order=sort_order,
            save_batches=True,
            max_pages=max_pages,
            query=query,
            resume_from_checkpoint=resume_from_checkpoint
        )
        
        collector = CurrentLawCollector(config)
        logger.info("ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        print(f"\ní˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"ê²€ìƒ‰ì–´: '{query}'")
        print(f"ìµœëŒ€ í˜ì´ì§€: {max_pages or 'ë¬´ì œí•œ'}")
        print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œ")
        print(f"ìƒì„¸ ì •ë³´: {'í¬í•¨' if include_details else 'ì œì™¸'}")
        print(f"ì •ë ¬ ìˆœì„œ: {sort_order}")
        print("=" * 50)
        
        # ë°ì´í„° ìˆ˜ì§‘
        logger.info("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        collection_start_time = datetime.now()
        
        if query:
            laws = collector.collect_laws_by_query(query, max_pages)
        else:
            laws = collector.collect_all_laws(max_pages, start_page)
        
        collection_end_time = datetime.now()
        collection_duration = (collection_end_time - collection_start_time).total_seconds()
        
        result["total_collected"] = len(laws)
        result["collection_time"] = collection_duration
        
        logger.info(f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(laws):,}ê°œ ({collection_duration:.2f}ì´ˆ)")
        
        if not laws:
            logger.error("ìˆ˜ì§‘ëœ í˜„í–‰ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("âŒ ìˆ˜ì§‘ëœ í˜„í–‰ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤.")
            result["status"] = "failed"
            result["errors"].append("No laws collected")
            return result
        
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(laws):,}ê°œ í˜„í–‰ë²•ë ¹")
        
        # ë°°ì¹˜ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        if config.save_batches:
            batch_dir = Path("data/raw/law_open_api/current_laws/batches")
            if batch_dir.exists():
                batch_files = list(batch_dir.glob(f"current_law_batch_{collector.timestamp}_*.json"))
                result["batch_files"] = [str(f) for f in batch_files]
                print(f"ğŸ“ ë°°ì¹˜ íŒŒì¼: {len(batch_files)}ê°œ")
        
        # ìˆ˜ì§‘ ë³´ê³ ì„œ ì €ì¥
        report_file = collector.save_collection_report(laws)
        result["summary_file"] = report_file
        
        # í†µê³„ ì¶œë ¥
        logger.info("ìˆ˜ì§‘ í†µê³„ ìƒì„± ì¤‘...")
        print("\nğŸ“Š ìˆ˜ì§‘ í†µê³„:")
        stats = collector.get_collection_stats()
        print(f"  ì´ ìˆ˜ì§‘: {stats['total_collected']:,}ê°œ")
        print(f"  ìˆ˜ì§‘ ì‹œê°„: {collection_duration:.2f}ì´ˆ")
        if stats['errors']:
            print(f"  ì˜¤ë¥˜: {len(stats['errors'])}ê°œ")
        
        logger.info(f"ìˆ˜ì§‘ í†µê³„: ì´ {stats['total_collected']:,}ê°œ, ì‹œê°„ {collection_duration:.2f}ì´ˆ")
        
        # ìµœì¢… ê²°ê³¼ ë¡œê·¸
        result["end_time"] = datetime.now().isoformat()
        total_duration = (datetime.now() - datetime.fromisoformat(result["start_time"])).total_seconds()
        result["total_duration"] = total_duration
        
        # datetime ê°ì²´ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        result["start_time"] = result["start_time"]  # ì´ë¯¸ ISO í˜•ì‹
        result["end_time"] = result["end_time"]  # ì´ë¯¸ ISO í˜•ì‹
        
        logger.info("=" * 60)
        logger.info("í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info(f"ì´ ìˆ˜ì§‘: {result['total_collected']:,}ê°œ")
        logger.info(f"ìˆ˜ì§‘ ì‹œê°„: {collection_duration:.2f}ì´ˆ")
        logger.info(f"ì´ ì†Œìš” ì‹œê°„: {total_duration:.2f}ì´ˆ")
        logger.info("=" * 60)
        
    except Exception as e:
        error_msg = f"ìˆ˜ì§‘ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(f"âŒ {error_msg}")
        result["status"] = "failed"
        result["errors"].append(error_msg)
        logger.error(error_msg)
    
    finally:
        result["end_time"] = datetime.now().isoformat()
    
    return result


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    
    # ê¸°ë³¸ ì˜µì…˜
    parser.add_argument("--query", type=str, default="", 
                       help="ê²€ìƒ‰ ì§ˆì˜ (ê¸°ë³¸ê°’: ë¹ˆ ë¬¸ìì—´ - ëª¨ë“  ë²•ë ¹)")
    parser.add_argument("--max-pages", type=int, default=None, 
                       help="ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: ë¬´ì œí•œ)")
    parser.add_argument("--start-page", type=int, default=1, 
                       help="ì‹œì‘ í˜ì´ì§€ (ê¸°ë³¸ê°’: 1)")
    parser.add_argument("--batch-size", type=int, default=10, 
                       help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 10)")
    parser.add_argument("--sort-order", type=str, default="ldes", 
                       choices=["ldes", "lasc", "dasc", "ddes", "nasc", "ndes", "efasc", "efdes"],
                       help="ì •ë ¬ ìˆœì„œ (ê¸°ë³¸ê°’: ldes - ë²•ë ¹ë‚´ë¦¼ì°¨ìˆœ)")
    
    # ê¸°ëŠ¥ ì˜µì…˜
    parser.add_argument("--no-details", action="store_true", 
                       help="ìƒì„¸ ì •ë³´ ì œì™¸")
    parser.add_argument("--resume-checkpoint", action="store_true", 
                       help="ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì˜µì…˜
    parser.add_argument("--test", action="store_true", 
                       help="API ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
    parser.add_argument("--sample", type=int, default=0, 
                       help="ìƒ˜í”Œ ìˆ˜ì§‘ (ì§€ì •ëœ ê°œìˆ˜ë§Œ ìˆ˜ì§‘)")
    
    args = parser.parse_args()
    
    print("í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 50)
    
    # í™˜ê²½ ê²€ì¦
    if not validate_environment():
        return 1
    
    # API í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
    try:
        from source.data.law_open_api_client import LawOpenAPIClient
        client = LawOpenAPIClient()
        if not client.test_connection():
            print("âŒ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return 1
        print("âœ… API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ API í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return 1
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if args.test:
        print("\nâœ… API ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return 0
    
    # ìƒ˜í”Œ ìˆ˜ì§‘ ëª¨ë“œ
    if args.sample > 0:
        print(f"\nìƒ˜í”Œ ìˆ˜ì§‘ ëª¨ë“œ: {args.sample}ê°œ")
        args.max_pages = max(1, args.sample // 100)  # í˜ì´ì§€ë‹¹ 100ê°œì”©
    
    # ìˆ˜ì§‘ ì‹¤í–‰
    try:
        result = collect_current_laws_data(
            query=args.query,
            max_pages=args.max_pages,
            start_page=args.start_page,
            batch_size=args.batch_size,
            include_details=not args.no_details,
            sort_order=args.sort_order,
            resume_from_checkpoint=args.resume_checkpoint
        )
        
        # ê²°ê³¼ ì €ì¥
        result_file = f"results/current_laws_collection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        Path("results").mkdir(exist_ok=True)
        
        # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        def convert_datetime(obj):
            if isinstance(obj, datetime):
                return obj.isoformat()
            return obj
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì˜ ëª¨ë“  datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        serializable_result = json.loads(json.dumps(result, default=convert_datetime, ensure_ascii=False))
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ ê²°ê³¼ ì €ì¥: {result_file}")
        
        # ìµœì¢… ê²°ê³¼
        if result["status"] == "success":
            print(f"\nâœ… í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"   ìˆ˜ì§‘: {result['total_collected']:,}ê°œ")
            print(f"   ë°°ì¹˜ íŒŒì¼: {len(result['batch_files'])}ê°œ")
            print(f"   ìˆ˜ì§‘ ì‹œê°„: {result['collection_time']:.2f}ì´ˆ")
            print(f"\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
            print(f"   1. ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸: python scripts/data_collection/law_open_api/current_laws/update_database.py")
            print(f"   2. ë²¡í„° ì €ì¥ì†Œ ì—…ë°ì´íŠ¸: python scripts/data_collection/law_open_api/current_laws/update_vectors.py")
            return 0
        else:
            print(f"\nâŒ í˜„í–‰ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            if result["errors"]:
                print("ì˜¤ë¥˜ ëª©ë¡:")
                for error in result["errors"]:
                    print(f"  - {error}")
            return 1
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•œ ì¤‘ë‹¨")
        return 0
    except Exception as e:
        print(f"\nâŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        logger.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
