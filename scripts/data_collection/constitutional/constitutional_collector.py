#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ê¸° í´ë˜ìŠ¤

êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° LAW OPEN APIë¥¼ ì‚¬ìš©í•˜ì—¬ í—Œì¬ê²°ì •ë¡€ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- ìµœê·¼ 5ë…„ê°„ í—Œì¬ê²°ì •ë¡€ 1,000ê±´ ìˆ˜ì§‘
- í—Œë²•ì¬íŒì†Œ ê²°ì •ë¡€ì˜ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘
- ê²°ì •ìœ í˜•ë³„ ë¶„ë¥˜ (ìœ„í—Œ, í•©í—Œ, ê°í•˜, ê¸°ê° ë“±)
- í–¥ìƒëœ ì—ëŸ¬ ì²˜ë¦¬, ì„±ëŠ¥ ìµœì í™”, ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥
"""

import os
import sys
import json
import logging
import signal
import atexit
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.law_open_api_client import LawOpenAPIClient, LawOpenAPIConfig

# í—Œë²• ê´€ë ¨ ê²€ìƒ‰ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ë³„)
CONSTITUTIONAL_KEYWORDS = [
    # ìµœê³  ìš°ì„ ìˆœìœ„ (ê° 100ê±´)
    "í—Œë²•ì†Œì›", "ìœ„í—Œë²•ë¥ ì‹¬íŒ", "íƒ„í•µì‹¬íŒ", "ê¶Œí•œìŸì˜ì‹¬íŒ", "ì •ë‹¹í•´ì‚°ì‹¬íŒ",
    
    # ê³ ìš°ì„ ìˆœìœ„ (ê° 50ê±´)
    "ìƒëª…ê¶Œ", "ì‹ ì²´ì˜ ììœ ", "ì‚¬ìƒí™œì˜ ììœ ", "ì–‘ì‹¬ì˜ ììœ ", "ì¢…êµì˜ ììœ ",
    "ì–¸ë¡ ì˜ ììœ ", "ì¶œíŒì˜ ììœ ", "ì§‘íšŒì˜ ììœ ", "ê²°ì‚¬ì˜ ììœ ", "ì¬ì‚°ê¶Œ",
    "ì§ì—…ì„ íƒì˜ ììœ ", "ê±°ì£¼ì´ì „ì˜ ììœ ", "ì°¸ì •ê¶Œ", "êµìœ¡ì„ ë°›ì„ ê¶Œë¦¬",
    "ê·¼ë¡œì˜ ê¶Œë¦¬", "í™˜ê²½ê¶Œ", "ë³´ê±´ê¶Œ", "ì£¼ê±°ê¶Œ", "ë¬¸í™”ë¥¼ í–¥ìœ í•  ê¶Œë¦¬",
    
    # ì¤‘ìš°ì„ ìˆœìœ„ (ê° 30ê±´)
    "í•™ë¬¸ì˜ ììœ ", "ì˜ˆìˆ ì˜ ììœ ", "ìƒì¡´ê¶Œ", "ê·¼ë¡œ3ê¶Œ", "ë³µì§€ë¥¼ ë°›ì„ ê¶Œë¦¬",
    "ë²•ë¥ ì— ì˜í•˜ì§€ ì•„ë‹ˆí•˜ê³ ëŠ” ì²˜ë²Œë°›ì§€ ì•„ë‹ˆí•  ê¶Œë¦¬", "ë¬´ì£„ì¶”ì •ì˜ ì›ì¹™",
    "ì§„ìˆ ê±°ë¶€ê¶Œ", "ë³€í˜¸ì¸ì˜ ì¡°ë ¥ì„ ë°›ì„ ê¶Œë¦¬", "ì‹ ì†í•œ ì¬íŒì„ ë°›ì„ ê¶Œë¦¬",
    "ê³µê°œì¬íŒì„ ë°›ì„ ê¶Œë¦¬", "êµ­íšŒ", "ì •ë¶€", "ë²•ì›", "í—Œë²•ì¬íŒì†Œ",
    "ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ", "ê°ì‚¬ì›", "ëŒ€í†µë ¹", "êµ­ë¬´ì´ë¦¬", "êµ­ë¬´ìœ„ì›",
    "êµ­íšŒì˜ì›", "ëŒ€ë²•ì›ì¥", "í—Œë²•ì¬íŒì†Œì¥", "ê¶Œë¦¬êµ¬ì œí˜• í—Œë²•ì†Œì›",
    "ê·œë²”í†µì œí˜• í—Œë²•ì†Œì›", "í—Œë²•ì¬íŒì†Œì˜ ê´€í• ", "ê¸°ë³¸ê¶Œ ì œí•œ", "ë²•ë¥ ìœ ë³´",
    "ê³¼ì‰ê¸ˆì§€ì˜ ì›ì¹™", "ë³¸ì§ˆì  ë‚´ìš© ì¹¨í•´ ê¸ˆì§€", "ë¹„ë¡€ì˜ ì›ì¹™",
    "ëª…í™•ì„±ì˜ ì›ì¹™", "ì ì •ì„±ì˜ ì›ì¹™", "êµ­ê°€ì˜ ì˜ë¬´", "ê¸°ë³¸ê¶Œ ë³´ì¥ ì˜ë¬´",
    "ìµœì†Œí•œì˜ ìƒí™œ ë³´ì¥", "êµìœ¡ì œë„ í™•ë¦½", "ê·¼ë¡œì¡°ê±´ì˜ ê¸°ì¤€", "í™˜ê²½ë³´ì „",
    "ë¬¸í™”ì§„í¥", "ë³µì§€ì¦ì§„"
]

# ê²°ì •ìœ í˜• ë¶„ë¥˜ í‚¤ì›Œë“œ
DECISION_TYPE_KEYWORDS = {
    "ìœ„í—Œ": ["ìœ„í—Œ", "ìœ„í—Œê²°ì •", "í—Œë²•ì— ìœ„ë°˜"],
    "í•©í—Œ": ["í•©í—Œ", "í•©í—Œê²°ì •", "í—Œë²•ì— í•©ì¹˜"],
    "ê°í•˜": ["ê°í•˜", "ê°í•˜ê²°ì •", "ê°í•˜íŒê²°"],
    "ê¸°ê°": ["ê¸°ê°", "ê¸°ê°ê²°ì •", "ê¸°ê°íŒê²°"],
    "ì¸ìš©": ["ì¸ìš©", "ì¸ìš©ê²°ì •", "ì¸ìš©íŒê²°"],
    "ì¼ë¶€ì¸ìš©": ["ì¼ë¶€ì¸ìš©", "ì¼ë¶€ì¸ìš©ê²°ì •"],
    "ì¼ë¶€ê¸°ê°": ["ì¼ë¶€ê¸°ê°", "ì¼ë¶€ê¸°ê°ê²°ì •"]
}

# í‚¤ì›Œë“œë³„ ìš°ì„ ìˆœìœ„ ë° ëª©í‘œ ê±´ìˆ˜
KEYWORD_PRIORITIES = {
    # ìµœê³  ìš°ì„ ìˆœìœ„ (100ê±´)
    "í—Œë²•ì†Œì›": 100, "ìœ„í—Œë²•ë¥ ì‹¬íŒ": 100, "íƒ„í•µì‹¬íŒ": 100, 
    "ê¶Œí•œìŸì˜ì‹¬íŒ": 100, "ì •ë‹¹í•´ì‚°ì‹¬íŒ": 100,
    
    # ê³ ìš°ì„ ìˆœìœ„ (50ê±´)
    "ìƒëª…ê¶Œ": 50, "ì‹ ì²´ì˜ ììœ ": 50, "ì‚¬ìƒí™œì˜ ììœ ": 50, "ì–‘ì‹¬ì˜ ììœ ": 50,
    "ì¢…êµì˜ ììœ ": 50, "ì–¸ë¡ ì˜ ììœ ": 50, "ì¶œíŒì˜ ììœ ": 50, "ì§‘íšŒì˜ ììœ ": 50,
    "ê²°ì‚¬ì˜ ììœ ": 50, "ì¬ì‚°ê¶Œ": 50, "ì§ì—…ì„ íƒì˜ ììœ ": 50, "ê±°ì£¼ì´ì „ì˜ ììœ ": 50,
    "ì°¸ì •ê¶Œ": 50, "êµìœ¡ì„ ë°›ì„ ê¶Œë¦¬": 50, "ê·¼ë¡œì˜ ê¶Œë¦¬": 50, "í™˜ê²½ê¶Œ": 50,
    "ë³´ê±´ê¶Œ": 50, "ì£¼ê±°ê¶Œ": 50, "ë¬¸í™”ë¥¼ í–¥ìœ í•  ê¶Œë¦¬": 50,
    
    # ì¤‘ìš°ì„ ìˆœìœ„ (30ê±´)
    "í•™ë¬¸ì˜ ììœ ": 30, "ì˜ˆìˆ ì˜ ììœ ": 30, "ìƒì¡´ê¶Œ": 30, "ê·¼ë¡œ3ê¶Œ": 30,
    "ë³µì§€ë¥¼ ë°›ì„ ê¶Œë¦¬": 30, "ë²•ë¥ ì— ì˜í•˜ì§€ ì•„ë‹ˆí•˜ê³ ëŠ” ì²˜ë²Œë°›ì§€ ì•„ë‹ˆí•  ê¶Œë¦¬": 30,
    "ë¬´ì£„ì¶”ì •ì˜ ì›ì¹™": 30, "ì§„ìˆ ê±°ë¶€ê¶Œ": 30, "ë³€í˜¸ì¸ì˜ ì¡°ë ¥ì„ ë°›ì„ ê¶Œë¦¬": 30,
    "ì‹ ì†í•œ ì¬íŒì„ ë°›ì„ ê¶Œë¦¬": 30, "ê³µê°œì¬íŒì„ ë°›ì„ ê¶Œë¦¬": 30,
    "êµ­íšŒ": 30, "ì •ë¶€": 30, "ë²•ì›": 30, "í—Œë²•ì¬íŒì†Œ": 30,
    "ì„ ê±°ê´€ë¦¬ìœ„ì›íšŒ": 30, "ê°ì‚¬ì›": 30, "ëŒ€í†µë ¹": 30, "êµ­ë¬´ì´ë¦¬": 30,
    "êµ­ë¬´ìœ„ì›": 30, "êµ­íšŒì˜ì›": 30, "ëŒ€ë²•ì›ì¥": 30, "í—Œë²•ì¬íŒì†Œì¥": 30,
    "ê¶Œë¦¬êµ¬ì œí˜• í—Œë²•ì†Œì›": 30, "ê·œë²”í†µì œí˜• í—Œë²•ì†Œì›": 30, "í—Œë²•ì¬íŒì†Œì˜ ê´€í• ": 30,
    "ê¸°ë³¸ê¶Œ ì œí•œ": 30, "ë²•ë¥ ìœ ë³´": 30, "ê³¼ì‰ê¸ˆì§€ì˜ ì›ì¹™": 30,
    "ë³¸ì§ˆì  ë‚´ìš© ì¹¨í•´ ê¸ˆì§€": 30, "ë¹„ë¡€ì˜ ì›ì¹™": 30, "ëª…í™•ì„±ì˜ ì›ì¹™": 30,
    "ì ì •ì„±ì˜ ì›ì¹™": 30, "êµ­ê°€ì˜ ì˜ë¬´": 30, "ê¸°ë³¸ê¶Œ ë³´ì¥ ì˜ë¬´": 30,
    "ìµœì†Œí•œì˜ ìƒí™œ ë³´ì¥": 30, "êµìœ¡ì œë„ í™•ë¦½": 30, "ê·¼ë¡œì¡°ê±´ì˜ ê¸°ì¤€": 30,
    "í™˜ê²½ë³´ì „": 30, "ë¬¸í™”ì§„í¥": 30, "ë³µì§€ì¦ì§„": 30
}

# ê¸°ë³¸ ëª©í‘œ ê±´ìˆ˜ (ìš°ì„ ìˆœìœ„ê°€ ì—†ëŠ” í‚¤ì›Œë“œ)
DEFAULT_TARGET_COUNT = 15


class ConstitutionalDecisionCollector:
    """í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self, config: LawOpenAPIConfig):
        self.client = LawOpenAPIClient(config)
        self.output_dir = Path("data/raw/constitutional_decisions")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ìˆ˜ì§‘ ìƒíƒœ ê´€ë¦¬
        self.collected_decisions = set()  # ì¤‘ë³µ ë°©ì§€
        self.detailed_decisions = []
        self.current_batch = []
        self.batch_size = 50  # ë°°ì¹˜ í¬ê¸°
        
        # í†µê³„ ì •ë³´
        self.stats = {
            'start_time': datetime.now().isoformat(),
            'end_time': None,
            'status': 'running',
            'target_count': 0,
            'collected_count': 0,
            'duplicate_count': 0,
            'failed_count': 0,
            'keywords_processed': 0,
            'total_keywords': len(CONSTITUTIONAL_KEYWORDS),
            'api_requests_made': 0,
            'api_errors': 0,
            'last_keyword_processed': None
        }
        
        # Graceful shutdown ê´€ë ¨ ë³€ìˆ˜
        self.shutdown_requested = False
        self.checkpoint_file = None
        self.resume_info = {
            'progress_percentage': 0.0,
            'last_keyword_processed': None,
            'can_resume': False
        }
        
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
        self._setup_signal_handlers()
        
        # ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—… ë“±ë¡
        atexit.register(self._cleanup_on_exit)
    
    def _setup_signal_handlers(self):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        def signal_handler(signum, frame):
            logger = logging.getLogger(__name__)
            logger.info(f"ì‹œê·¸ë„ {signum} ìˆ˜ì‹ . Graceful shutdown ì‹œì‘...")
            self.shutdown_requested = True
        
        signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # ì¢…ë£Œ ì‹ í˜¸
    
    def _cleanup_on_exit(self):
        """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…"""
        if self.detailed_decisions or self.current_batch:
            logger = logging.getLogger(__name__)
            logger.info("ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥ ì¤‘...")
            self._save_checkpoint()
            logger.info(f"ì´ {len(self.detailed_decisions)}ê±´ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _save_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        if not self.checkpoint_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            self.checkpoint_file = self.output_dir / f"collection_checkpoint_{timestamp}.json"
        
        # í˜„ì¬ ë°°ì¹˜ë¥¼ ìƒì„¸ ë°ì´í„°ì— ì¶”ê°€
        if self.current_batch:
            self.detailed_decisions.extend(self.current_batch)
            self.current_batch = []
        
        # ì§„í–‰ë¥  ê³„ì‚°
        if self.stats['total_keywords'] > 0:
            self.resume_info['progress_percentage'] = (
                self.stats['keywords_processed'] / self.stats['total_keywords'] * 100
            )
        
        checkpoint_data = {
            'stats': self.stats,
            'resume_info': self.resume_info,
            'shutdown_info': {
                'graceful_shutdown_supported': True,
                'shutdown_requested': self.shutdown_requested,
                'shutdown_reason': 'User interrupt' if self.shutdown_requested else None
            },
            'detailed_decisions': self.detailed_decisions,
            'collected_decisions': list(self.collected_decisions)
        }
        
        try:
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
            logger = logging.getLogger(__name__)
            logger.debug(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {self.checkpoint_file}")
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _load_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint_files = list(self.output_dir.glob("collection_checkpoint_*.json"))
        if not checkpoint_files:
            return False
        
        # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ë¡œë“œ
        latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
        
        try:
            with open(latest_checkpoint, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
            
            # ìƒíƒœ ë³µì›
            self.stats = checkpoint_data.get('stats', self.stats)
            self.resume_info = checkpoint_data.get('resume_info', self.resume_info)
            self.detailed_decisions = checkpoint_data.get('detailed_decisions', [])
            self.collected_decisions = set(checkpoint_data.get('collected_decisions', []))
            self.checkpoint_file = latest_checkpoint
            
            logger = logging.getLogger(__name__)
            logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(self.detailed_decisions)}ê±´ì˜ ìƒì„¸ ë°ì´í„° ë³µì›")
            return True
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _check_shutdown(self):
        """ì¢…ë£Œ ìš”ì²­ í™•ì¸"""
        if self.shutdown_requested:
            logger = logging.getLogger(__name__)
            logger.info("ì¢…ë£Œ ìš”ì²­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ì‘ì—…ì„ ì™„ë£Œí•œ í›„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return True
        return False
    
    def collect_decisions_by_keyword(self, keyword: str, max_count: int = 50) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œë¡œ í—Œì¬ê²°ì •ë¡€ ê²€ìƒ‰ ë° ìˆ˜ì§‘"""
        logger = logging.getLogger(__name__)
        logger.info(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ í—Œì¬ê²°ì •ë¡€ ê²€ìƒ‰ ì‹œì‘ (ëª©í‘œ: {max_count}ê±´)...")
        
        decisions = []
        page = 1
        
        while len(decisions) < max_count:
            # ì¢…ë£Œ ìš”ì²­ í™•ì¸
            if self._check_shutdown():
                break
                
            try:
                # í˜ì´ì§€ë³„ ì§„í–‰ë¥  í‘œì‹œ
                page_progress = (page - 1) * 20
                logger.info(f"ğŸ“„ í˜ì´ì§€ {page} ìš”ì²­ ì¤‘... (í˜„ì¬ ìˆ˜ì§‘: {len(decisions)}/{max_count}ê±´, ì§„í–‰ë¥ : {len(decisions)/max_count*100:.1f}%)")
                
                # queryê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê²€ìƒ‰, ì—†ìœ¼ë©´ ì „ì²´ ëª©ë¡ ì¡°íšŒ (ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ)
                if keyword and keyword.strip():
                    logger.debug(f"ğŸ” í‚¤ì›Œë“œ '{keyword}'ë¡œ ê²€ìƒ‰ ìš”ì²­ (ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ)")
                    results = self.client.get_constitutional_list(
                        query=keyword,
                        display=20,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹œì‘
                        page=page,
                        search=1  # ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
                    )
                else:
                    logger.debug("ğŸ“‹ ì „ì²´ ëª©ë¡ ì¡°íšŒ ìš”ì²­ (ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ)")
                    results = self.client.get_constitutional_list(
                        display=20,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹œì‘
                        page=page,
                        search=1  # ì„ ê³ ì¼ì ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
                    )
                
                logger.info(f"ğŸ“Š API ì‘ë‹µ ê²°ê³¼: {len(results) if results else 0}ê±´")
                
                if not results:
                    logger.info("ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ì–´ì„œ ê²€ìƒ‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
                
                new_decisions = 0
                for result in results:
                    # ì¢…ë£Œ ìš”ì²­ í™•ì¸
                    if self._check_shutdown():
                        break
                        
                    # í—Œì¬ê²°ì •ë¡€ ID í™•ì¸ (API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼)
                    decision_id = result.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸') or result.get('ID') or result.get('id')
                    if decision_id and decision_id not in self.collected_decisions:
                        decisions.append(result)
                        self.collected_decisions.add(decision_id)
                        self.stats['collected_count'] += 1
                        new_decisions += 1
                        
                        logger.info(f"âœ… ìƒˆë¡œìš´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘: {result.get('ì‚¬ê±´ëª…', 'Unknown')} (ID: {decision_id})")
                        logger.info(f"   ğŸ“ˆ í˜„ì¬ ì§„í–‰ë¥ : {len(decisions)}/{max_count}ê±´ ({len(decisions)/max_count*100:.1f}%)")
                        
                        if len(decisions) >= max_count:
                            logger.info(f"ğŸ¯ ëª©í‘œ ìˆ˜ëŸ‰ {max_count}ê±´ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                            break
                    else:
                        self.stats['duplicate_count'] += 1
                        logger.debug(f"ì¤‘ë³µëœ í—Œì¬ê²°ì •ë¡€ ê±´ë„ˆë›°ê¸°: {decision_id}")
                
                logger.info(f"ğŸ“„ í˜ì´ì§€ {page} ì™„ë£Œ: {new_decisions}ê±´ì˜ ìƒˆë¡œìš´ ê²°ì •ë¡€ ìˆ˜ì§‘")
                logger.info(f"   ğŸ“Š ëˆ„ì  ìˆ˜ì§‘: {len(decisions)}/{max_count}ê±´ ({len(decisions)/max_count*100:.1f}%)")
                
                page += 1
                self.stats['api_requests_made'] += 1
                
                # API ìš”ì²­ ì œí•œ í™•ì¸
                stats = self.client.get_request_stats()
                if stats['remaining_requests'] < 10:
                    logger.warning("API ìš”ì²­ í•œë„ê°€ ê±°ì˜ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                    
            except Exception as e:
                logger.error(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                self.stats['api_errors'] += 1
                break
        
        logger.info(f"í‚¤ì›Œë“œ '{keyword}'ë¡œ ì´ {len(decisions)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
        return decisions
    
    def collect_decisions_by_date_range(self, start_date: str, end_date: str, max_count: int = 1000) -> List[Dict[str, Any]]:
        """ë‚ ì§œ ë²”ìœ„ë¡œ í—Œì¬ê²°ì •ë¡€ ê²€ìƒ‰ ë° ìˆ˜ì§‘"""
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ“… ë‚ ì§œ ë²”ìœ„ {start_date} ~ {end_date}ë¡œ í—Œì¬ê²°ì •ë¡€ ê²€ìƒ‰ ì‹œì‘ (ëª©í‘œ: {max_count:,}ê±´)...")
        
        decisions = []
        page = 1
        total_pages_estimated = max_count // 100 + 1  # ëŒ€ëµì ì¸ í˜ì´ì§€ ìˆ˜ ì¶”ì •
        
        while len(decisions) < max_count:
            # ì¢…ë£Œ ìš”ì²­ í™•ì¸
            if self._check_shutdown():
                break
                
            try:
                # í˜ì´ì§€ë³„ ì§„í–‰ë¥  í‘œì‹œ
                progress = (page - 1) / total_pages_estimated * 100 if total_pages_estimated > 0 else 0
                logger.info(f"ğŸ“„ í˜ì´ì§€ {page} ìš”ì²­ ì¤‘... (í˜„ì¬ ìˆ˜ì§‘: {len(decisions):,}/{max_count:,}ê±´, ì§„í–‰ë¥ : {len(decisions)/max_count*100:.1f}%)")
                
                results = self.client.get_constitutional_list(
                    display=100,
                    page=page,
                    from_date=start_date,
                    to_date=end_date,
                    search=1  # ì‚¬ê±´ëª… ê²€ìƒ‰
                )
                
                logger.info(f"ğŸ“Š API ì‘ë‹µ ê²°ê³¼: {len(results) if results else 0}ê±´")
                
                if not results:
                    logger.info("ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ì–´ì„œ ê²€ìƒ‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
                
                new_decisions = 0
                for result in results:
                    # ì¢…ë£Œ ìš”ì²­ í™•ì¸
                    if self._check_shutdown():
                        break
                        
                    # í—Œì¬ê²°ì •ë¡€ ID í™•ì¸ (API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼)
                    decision_id = result.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸') or result.get('ID') or result.get('id')
                    if decision_id and decision_id not in self.collected_decisions:
                        decisions.append(result)
                        self.collected_decisions.add(decision_id)
                        self.stats['collected_count'] += 1
                        new_decisions += 1
                        
                        # 5ê±´ë§ˆë‹¤ ìˆ˜ì§‘ í˜„í™© í‘œì‹œ (ë” ìì£¼)
                        if len(decisions) % 5 == 0:
                            logger.info(f"âœ… {len(decisions):,}ê±´ ìˆ˜ì§‘ ì™„ë£Œ (ì§„í–‰ë¥ : {len(decisions)/max_count*100:.1f}%)")
                        
                        if len(decisions) >= max_count:
                            logger.info(f"ğŸ¯ ëª©í‘œ ìˆ˜ëŸ‰ {max_count:,}ê±´ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                            break
                    else:
                        self.stats['duplicate_count'] += 1
                
                logger.info(f"ğŸ“„ í˜ì´ì§€ {page} ì™„ë£Œ: {new_decisions}ê±´ì˜ ìƒˆë¡œìš´ ê²°ì •ë¡€ ìˆ˜ì§‘")
                logger.info(f"   ğŸ“Š ëˆ„ì  ìˆ˜ì§‘: {len(decisions):,}/{max_count:,}ê±´ ({len(decisions)/max_count*100:.1f}%)")
                logger.info(f"   â±ï¸  ì˜ˆìƒ ë‚¨ì€ í˜ì´ì§€: {max(0, (max_count - len(decisions)) // 100)}í˜ì´ì§€")
                
                page += 1
                self.stats['api_requests_made'] += 1
                
                # API ìš”ì²­ ì œí•œ í™•ì¸
                stats = self.client.get_request_stats()
                if stats['remaining_requests'] < 10:
                    logger.warning("API ìš”ì²­ í•œë„ê°€ ê±°ì˜ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                    
            except Exception as e:
                logger.error(f"ë‚ ì§œ ë²”ìœ„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                self.stats['api_errors'] += 1
                break
        
        logger.info("=" * 60)
        logger.info(f"ğŸ“… ë‚ ì§œ ë²”ìœ„ ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: {len(decisions):,}ê±´")
        logger.info(f"ğŸ“„ ì²˜ë¦¬ëœ í˜ì´ì§€: {page-1}í˜ì´ì§€")
        logger.info(f"ğŸŒ API ìš”ì²­ ìˆ˜: {self.stats['api_requests_made']:,}íšŒ")
        logger.info(f"âŒ ì¤‘ë³µ ì œì™¸: {self.stats['duplicate_count']:,}ê±´")
        logger.info("=" * 60)
        return decisions
    
    def collect_decision_details(self, decision: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """í—Œì¬ê²°ì •ë¡€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        # í—Œì¬ê²°ì •ë¡€ ID í™•ì¸ (API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼)
        decision_id = decision.get('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸') or decision.get('ID') or decision.get('id')
        if not decision_id:
            logger = logging.getLogger(__name__)
            logger.warning(f"í—Œì¬ê²°ì •ë¡€ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decision}")
            return None
        
        try:
            detail = self.client.get_constitutional_detail(constitutional_id=decision_id)
            if detail:
                # ê¸°ë³¸ ì •ë³´ì™€ ìƒì„¸ ì •ë³´ ê²°í•©
                combined_data = {
                    'basic_info': decision,
                    'detail_info': detail,
                    'collected_at': datetime.now().isoformat()
                }
                return combined_data
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"í—Œì¬ê²°ì •ë¡€ {decision_id} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.stats['api_errors'] += 1
        
        return None
    
    def classify_decision_type(self, decision: Dict[str, Any]) -> str:
        """í—Œì¬ê²°ì •ë¡€ ìœ í˜• ë¶„ë¥˜"""
        case_name = decision.get('ì‚¬ê±´ëª…', '').lower()
        decision_text = decision.get('íŒì‹œì‚¬í•­', '') + ' ' + decision.get('íŒê²°ìš”ì§€', '')
        decision_text = decision_text.lower()
        
        # ê²°ì •ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
        for decision_type, keywords in DECISION_TYPE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in case_name or keyword in decision_text:
                    return decision_type
        
        # ê¸°ë³¸ê¶Œë³„ ë¶„ë¥˜
        if any(keyword in case_name for keyword in ["ìƒëª…ê¶Œ", "ì‹ ì²´ì˜ ììœ "]):
            return "ê¸°ë³¸ê¶Œ_ìƒëª…ì‹ ì²´"
        elif any(keyword in case_name for keyword in ["ì‚¬ìƒí™œ", "ì–‘ì‹¬", "ì¢…êµ"]):
            return "ê¸°ë³¸ê¶Œ_ì‚¬ìƒí™œ"
        elif any(keyword in case_name for keyword in ["ì–¸ë¡ ", "ì¶œíŒ", "ì§‘íšŒ", "ê²°ì‚¬"]):
            return "ê¸°ë³¸ê¶Œ_í‘œí˜„"
        elif any(keyword in case_name for keyword in ["ì¬ì‚°ê¶Œ", "ì§ì—…ì„ íƒ"]):
            return "ê¸°ë³¸ê¶Œ_ê²½ì œ"
        elif any(keyword in case_name for keyword in ["êµìœ¡", "ê·¼ë¡œ", "í™˜ê²½"]):
            return "ê¸°ë³¸ê¶Œ_ì‚¬íšŒ"
        elif any(keyword in case_name for keyword in ["í—Œë²•ì†Œì›", "ìœ„í—Œë²•ë¥ "]):
            return "í—Œë²•ì¬íŒ"
        else:
            return "ê¸°íƒ€"
    
    def save_batch_data(self, batch_data: List[Dict[str, Any]], category: str):
        """ë°°ì¹˜ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"batch_{category}_{timestamp}.json"
        filepath = self.output_dir / filename
        
        batch_info = {
            'metadata': {
                'category': category,
                'count': len(batch_data),
                'timestamp': timestamp,
                'batch_size': self.batch_size
            },
            'data': batch_data
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(batch_info, f, ensure_ascii=False, indent=2)
            logger = logging.getLogger(__name__)
            logger.debug(f"ë°°ì¹˜ ë°ì´í„° ì €ì¥: {filepath}")
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def collect_all_decisions(self, target_count: int = 1000, resume: bool = True, keyword_mode: bool = True):
        """ëª¨ë“  í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘"""
        logger = logging.getLogger(__name__)
        logger.info("=" * 60)
        logger.info(f"ğŸš€ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹œì‘!")
        logger.info(f"ğŸ¯ ëª©í‘œ ìˆ˜ëŸ‰: {target_count:,}ê±´")
        if keyword_mode:
            logger.info(f"ğŸ“ ê²€ìƒ‰ ë°©ì‹: í‚¤ì›Œë“œ ê¸°ë°˜ ({len(CONSTITUTIONAL_KEYWORDS)}ê°œ í‚¤ì›Œë“œ)")
        else:
            logger.info(f"ğŸ“ ê²€ìƒ‰ ë°©ì‹: ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (í‚¤ì›Œë“œ ë¬´ê´€)")
        logger.info(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)
        
        self.stats['target_count'] = target_count
        
        # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë³µì›
        if resume:
            if self._load_checkpoint():
                logger.info(f"ê¸°ì¡´ ì§„í–‰ ìƒí™© ë³µì›: {len(self.detailed_decisions)}ê±´")
                self.resume_info['can_resume'] = True
        
        all_decisions = []
        
        if keyword_mode:
            # 1. ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œë³„ ê²€ìƒ‰
            logger.info(f"ì´ {len(CONSTITUTIONAL_KEYWORDS)}ê°œ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ì‹œì‘")
            
            for i, keyword in enumerate(CONSTITUTIONAL_KEYWORDS):
                # ì´ì „ì— ì™„ë£Œëœ í‚¤ì›Œë“œëŠ” ê±´ë„ˆë›°ê¸°
                if resume and i < self.stats['keywords_processed']:
                    logger.info(f"í‚¤ì›Œë“œ '{keyword}' ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì²˜ë¦¬ë¨)")
                    continue
                    
                if len(all_decisions) >= target_count:
                    logger.info(f"ëª©í‘œ ìˆ˜ëŸ‰ {target_count}ê±´ì— ë„ë‹¬í•˜ì—¬ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
                
                # ì¢…ë£Œ ìš”ì²­ í™•ì¸
                if self._check_shutdown():
                    break
                    
                try:
                    # í‚¤ì›Œë“œë³„ ëª©í‘œ ê±´ìˆ˜ ì„¤ì •
                    max_count = KEYWORD_PRIORITIES.get(keyword, DEFAULT_TARGET_COUNT)
                    max_count = min(max_count, target_count - len(all_decisions))
                    
                    # ì§„í–‰ë¥  ê³„ì‚°
                    progress = (i + 1) / len(CONSTITUTIONAL_KEYWORDS) * 100
                    remaining_keywords = len(CONSTITUTIONAL_KEYWORDS) - i - 1
                    
                    logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({i+1}/{len(CONSTITUTIONAL_KEYWORDS)}) - í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì‹œì‘")
                    logger.info(f"ğŸ¯ ëª©í‘œ: {max_count}ê±´, ìš°ì„ ìˆœìœ„: {KEYWORD_PRIORITIES.get(keyword, 'ê¸°ë³¸')}, ë‚¨ì€ í‚¤ì›Œë“œ: {remaining_keywords}ê°œ")
                    
                    decisions = self.collect_decisions_by_keyword(keyword, max_count)
                    all_decisions.extend(decisions)
                    
                    self.stats['keywords_processed'] += 1
                    self.stats['last_keyword_processed'] = keyword
                    
                    # ìƒì„¸í•œ ì™„ë£Œ ì •ë³´
                    completion_rate = len(all_decisions) / target_count * 100 if target_count > 0 else 0
                    logger.info(f"âœ… í‚¤ì›Œë“œ '{keyword}' ì™„ë£Œ!")
                    logger.info(f"   ğŸ“ˆ ìˆ˜ì§‘: {len(decisions)}ê±´ | ëˆ„ì : {len(all_decisions)}ê±´ | ëª©í‘œ ëŒ€ë¹„: {completion_rate:.1f}%")
                    logger.info(f"   â±ï¸  ë‚¨ì€ í‚¤ì›Œë“œ: {remaining_keywords}ê°œ")
                    
                    # ì§„í–‰ ìƒí™© ì €ì¥ (10ê°œ í‚¤ì›Œë“œë§ˆë‹¤)
                    if self.stats['keywords_processed'] % 10 == 0:
                        logger.info("ì§„í–‰ ìƒí™©ì„ ì²´í¬í¬ì¸íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.")
                        self._save_checkpoint()
                    
                    # API ìš”ì²­ ì œí•œ í™•ì¸
                    stats = self.client.get_request_stats()
                    if stats['remaining_requests'] < 100:
                        logger.warning("API ìš”ì²­ í•œë„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                        break
                        
                except Exception as e:
                    logger.error(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    self.stats['api_errors'] += 1
                    continue
        else:
            # í‚¤ì›Œë“œ ì—†ì´ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
            logger.info("ğŸ” í‚¤ì›Œë“œ ì—†ì´ ì „ì²´ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ ì‹œì‘")
            logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ 5ë…„ (2020ë…„ ~ í˜„ì¬)")
            logger.info(f"ğŸ¯ ëª©í‘œ ìˆ˜ëŸ‰: {target_count:,}ê±´")
            
            # ìµœê·¼ 5ë…„ê°„ ë°ì´í„° ìˆ˜ì§‘
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y%m%d')
            
            logger.info(f"ğŸ“Š ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
            all_decisions = self.collect_decisions_by_date_range(
                start_date, end_date, target_count
            )
        
        # 2. ë‚ ì§œ ë²”ìœ„ë³„ ê²€ìƒ‰ (ìµœê·¼ 5ë…„) - í‚¤ì›Œë“œ ëª¨ë“œì—ì„œë§Œ
        if keyword_mode and len(all_decisions) < target_count and not self._check_shutdown():
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y%m%d')
            
            remaining_count = target_count - len(all_decisions)
            date_decisions = self.collect_decisions_by_date_range(
                start_date, end_date, remaining_count
            )
            all_decisions.extend(date_decisions)
        
        logger.info("=" * 60)
        logger.info(f"ğŸ“‹ 1ë‹¨ê³„ ì™„ë£Œ: ì´ {len(all_decisions)}ê±´ì˜ í—Œì¬ê²°ì •ë¡€ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info("=" * 60)
        
        # 3. ê° í—Œì¬ê²°ì •ë¡€ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        logger.info(f"ğŸ” 2ë‹¨ê³„ ì‹œì‘: ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ({len(all_decisions)}ê±´)")
        for i, decision in enumerate(all_decisions):
            if i >= target_count:
                break
            
            # ì¢…ë£Œ ìš”ì²­ í™•ì¸
            if self._check_shutdown():
                break
                
            try:
                detail = self.collect_decision_details(decision)
                if detail:
                    # ê²°ì •ìœ í˜• ë¶„ë¥˜
                    decision_type = self.classify_decision_type(decision)
                    detail['decision_type'] = decision_type
                    
                    self.current_batch.append(detail)
                    
                    # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì €ì¥
                    if len(self.current_batch) >= self.batch_size:
                        self.save_batch_data(self.current_batch, f"constitutional_decisions_{i//self.batch_size}")
                        self.detailed_decisions.extend(self.current_batch)
                        self.current_batch = []
                
                # ì§„í–‰ë¥  ë¡œê·¸ ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                if (i + 1) % 50 == 0:  # 50ê±´ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    progress = (i + 1) / len(all_decisions) * 100
                    logger.info(f"ğŸ“Š ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì§„í–‰ë¥ : {i + 1:,}/{len(all_decisions):,} ({progress:.1f}%)")
                    self._save_checkpoint()
                elif (i + 1) % 10 == 0:  # 10ê±´ë§ˆë‹¤ ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ
                    progress = (i + 1) / len(all_decisions) * 100
                    logger.info(f"â³ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì§„í–‰ë¥ : {i + 1:,}/{len(all_decisions):,} ({progress:.1f}%)")
                elif (i + 1) % 5 == 0:  # 5ê±´ë§ˆë‹¤ ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ (í‚¤ì›Œë“œ ì—†ì´ ìˆ˜ì§‘ ì‹œ)
                    progress = (i + 1) / len(all_decisions) * 100
                    logger.info(f"ğŸ” ìƒì„¸ ì •ë³´ ìˆ˜ì§‘: {i + 1:,}/{len(all_decisions):,} ({progress:.1f}%)")
                elif (i + 1) % 2 == 0:  # 2ê±´ë§ˆë‹¤ ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ (ë§¤ìš° ìì£¼)
                    progress = (i + 1) / len(all_decisions) * 100
                    logger.info(f"âš¡ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘: {i + 1:,}/{len(all_decisions):,} ({progress:.1f}%)")
                
                # API ìš”ì²­ ì œí•œ í™•ì¸
                stats = self.client.get_request_stats()
                if stats['remaining_requests'] < 10:
                    logger.warning("API ìš”ì²­ í•œë„ê°€ ê±°ì˜ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
                    
            except Exception as e:
                logger.error(f"í—Œì¬ê²°ì •ë¡€ {i} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                self.stats['failed_count'] += 1
                continue
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥
        if self.current_batch:
            self.save_batch_data(self.current_batch, f"constitutional_decisions_final")
            self.detailed_decisions.extend(self.current_batch)
            self.current_batch = []
        
        # ì¢…ë£Œ ìš”ì²­ì´ ìˆì—ˆëŠ”ì§€ í™•ì¸
        if self._check_shutdown():
            logger.info("=" * 60)
            logger.info("âš ï¸ ì‚¬ìš©ì ìš”ì²­ì— ì˜í•´ ìˆ˜ì§‘ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            logger.info(f"ğŸ“Š í˜„ì¬ê¹Œì§€ {len(self.detailed_decisions)}ê±´ì˜ ìƒì„¸ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            logger.info("=" * 60)
            self.stats['status'] = 'interrupted'
        else:
            logger.info("=" * 60)
            logger.info("ğŸ‰ í—Œì¬ê²°ì •ë¡€ ìˆ˜ì§‘ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: {len(self.detailed_decisions)}ê±´")
            logger.info(f"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)
            self.stats['status'] = 'completed'
        
        # ìµœì¢… í†µê³„ ì—…ë°ì´íŠ¸
        self.stats['end_time'] = datetime.now().isoformat()
        self.stats['collected_count'] = len(self.detailed_decisions)
        
        # 4. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ìƒì„±
        self.generate_collection_summary()
        
        # ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬
        self._cleanup_checkpoint_files()
    
    def _cleanup_checkpoint_files(self):
        """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬"""
        try:
            if self.checkpoint_file and self.checkpoint_file.exists():
                # ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ
                if self.stats['status'] == 'completed':
                    self.checkpoint_file.unlink()
                    logger = logging.getLogger(__name__)
                    logger.debug("ì™„ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ")
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def reset_collection(self):
        """ìˆ˜ì§‘ ìƒíƒœ ì´ˆê¸°í™”"""
        try:
            # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë“¤ ì‚­ì œ
            checkpoint_files = list(self.output_dir.glob("collection_checkpoint_*.json"))
            for file_path in checkpoint_files:
                file_path.unlink()
            
            # ìƒíƒœ ì´ˆê¸°í™”
            self.detailed_decisions = []
            self.current_batch = []
            self.collected_decisions = set()
            self.stats = {
                'start_time': datetime.now().isoformat(),
                'end_time': None,
                'status': 'running',
                'target_count': 0,
                'collected_count': 0,
                'duplicate_count': 0,
                'failed_count': 0,
                'keywords_processed': 0,
                'total_keywords': len(CONSTITUTIONAL_KEYWORDS),
                'api_requests_made': 0,
                'api_errors': 0,
                'last_keyword_processed': None
            }
            self.resume_info = {
                'progress_percentage': 0.0,
                'last_keyword_processed': None,
                'can_resume': False
            }
            
            logger = logging.getLogger(__name__)
            logger.info("ìˆ˜ì§‘ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ìˆ˜ì§‘ ìƒíƒœ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def get_collection_status(self):
        """í˜„ì¬ ìˆ˜ì§‘ ìƒíƒœ ë°˜í™˜"""
        return {
            'stats': self.stats,
            'resume_info': self.resume_info,
            'checkpoint_file': str(self.checkpoint_file) if self.checkpoint_file else None,
            'output_directory': str(self.output_dir)
        }
    
    def generate_collection_summary(self):
        """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        # ê²°ì •ìœ í˜•ë³„ í†µê³„
        decision_type_stats = {}
        
        for decision in self.detailed_decisions:
            decision_type = decision.get('decision_type', 'ê¸°íƒ€')
            decision_type_stats[decision_type] = decision_type_stats.get(decision_type, 0) + 1
        
        summary = {
            'collection_date': datetime.now().isoformat(),
            'total_decisions': len(self.detailed_decisions),
            'decision_type_distribution': decision_type_stats,
            'api_stats': self.client.get_request_stats(),
            'collection_stats': self.stats
        }
        
        summary_file = self.output_dir / f"collection_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            logger = logging.getLogger(__name__)
            logger.info(f"ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì €ì¥: {summary_file}")
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.error(f"ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
