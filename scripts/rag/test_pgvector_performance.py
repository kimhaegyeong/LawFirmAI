"""
pgvector ì¸ë±ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import time
from pathlib import Path
from typing import List, Dict, Any

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from lawfirm_langgraph.core.data.db_adapter import DatabaseAdapter
    from lawfirm_langgraph.core.search.engines.semantic_search_engine_v2 import SemanticSearchEngineV2
except ImportError:
    from core.data.db_adapter import DatabaseAdapter
    from core.search.engines.semantic_search_engine_v2 import SemanticSearchEngineV2

def get_database_url():
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ URL ê°€ì ¸ì˜¤ê¸° (POSTGRES_* í™˜ê²½ ë³€ìˆ˜ ì¡°í•©)"""
    import os
    from urllib.parse import quote_plus
    
    # DATABASE_URLì´ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
    database_url = os.getenv("DATABASE_URL")
    if database_url:
        return database_url
    
    # PostgreSQL í™˜ê²½ë³€ìˆ˜ ì¡°í•© (í”„ë¡œì íŠ¸ ë£¨íŠ¸ .env íŒŒì¼ì˜ ì„¤ì • ìš°ì„  ì‚¬ìš©)
    postgres_host = os.getenv("POSTGRES_HOST", "localhost")
    postgres_port = os.getenv("POSTGRES_PORT", "5432")
    postgres_db = os.getenv("POSTGRES_DB", "lawfirmai_local")
    postgres_user = os.getenv("POSTGRES_USER", "lawfirmai")
    postgres_password = os.getenv("POSTGRES_PASSWORD", "local_password")
    
    # URL ì¸ì½”ë”© (íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
    encoded_password = quote_plus(postgres_password)
    
    # PostgreSQL URL ìƒì„±
    database_url = f"postgresql://{postgres_user}:{encoded_password}@{postgres_host}:{postgres_port}/{postgres_db}"
    return database_url

def check_index_usage(query: str, db_adapter: DatabaseAdapter) -> Dict[str, Any]:
    """ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸"""
    with db_adapter.get_connection_context() as conn:
        cursor = conn.cursor()
        
        # EXPLAIN ANALYZE ì‹¤í–‰
        explain_query = f"EXPLAIN (ANALYZE, BUFFERS, VERBOSE) {query}"
        cursor.execute(explain_query)
        explain_result = cursor.fetchall()
        
        # ê²°ê³¼ ë¶„ì„
        plan_text = "\n".join([str(row) for row in explain_result])
        
        # ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        uses_index = False
        index_name = None
        if "Index Scan" in plan_text or "Bitmap Index Scan" in plan_text:
            uses_index = True
            # ì¸ë±ìŠ¤ ì´ë¦„ ì¶”ì¶œ
            for row in explain_result:
                row_str = str(row)
                if "Index Scan" in row_str or "Bitmap Index Scan" in row_str:
                    # ì¸ë±ìŠ¤ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    if "idx_" in row_str:
                        parts = row_str.split("idx_")
                        if len(parts) > 1:
                            index_part = parts[1].split()[0] if parts[1].split() else ""
                            index_name = f"idx_{index_part}"
                    break
        
        return {
            "uses_index": uses_index,
            "index_name": index_name,
            "plan": plan_text
        }

def test_search_performance(search_engine: SemanticSearchEngineV2, query: str, k: int = 10) -> Dict[str, Any]:
    """ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    results = []
    
    # ì›Œë°ì—… (ì²« ê²€ìƒ‰ ì œì™¸)
    try:
        search_engine.search(query, k=1)
    except:
        pass
    
    # ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • (3íšŒ í‰ê· )
    times = []
    result_counts = []
    
    for i in range(3):
        start_time = time.time()
        try:
            search_results = search_engine.search(query, k=k)
            end_time = time.time()
            elapsed = end_time - start_time
            times.append(elapsed)
            result_counts.append(len(search_results) if search_results else 0)
        except Exception as e:
            print(f"  âš ï¸  ê²€ìƒ‰ ì‹¤íŒ¨ (ì‹œë„ {i+1}): {e}")
            continue
    
    if not times:
        return {
            "success": False,
            "error": "ëª¨ë“  ê²€ìƒ‰ ì‹œë„ ì‹¤íŒ¨"
        }
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    avg_results = sum(result_counts) / len(result_counts) if result_counts else 0
    
    return {
        "success": True,
        "query": query,
        "k": k,
        "avg_time": avg_time,
        "min_time": min_time,
        "max_time": max_time,
        "avg_results": avg_results,
        "times": times
    }

def test_vector_query_performance(db_adapter: DatabaseAdapter, table_name: str, vector_column: str, k: int = 10) -> Dict[str, Any]:
    """ë²¡í„° ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸)"""
    # ìƒ˜í”Œ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
    with db_adapter.get_connection_context() as conn:
        cursor = conn.cursor()
        
        # í…Œì´ë¸”ì—ì„œ ì²« ë²ˆì§¸ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        cursor.execute(f"""
            SELECT {vector_column}
            FROM {table_name}
            WHERE {vector_column} IS NOT NULL
            LIMIT 1
        """)
        
        row = cursor.fetchone()
        if not row:
            return {
                "success": False,
                "error": f"{table_name}ì— ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        sample_vector = row[0] if isinstance(row, tuple) else row.get(vector_column)
        if not sample_vector:
            return {
                "success": False,
                "error": f"{table_name}ì—ì„œ ë²¡í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            }
    
    # ë²¡í„° ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    query = f"""
        SELECT id, {vector_column} <=> %s::vector AS distance
        FROM {table_name}
        WHERE {vector_column} IS NOT NULL
        ORDER BY distance
        LIMIT {k}
    """
    
    # ì›Œë°ì—…
    try:
        with db_adapter.get_connection_context() as conn:
            cursor = conn.cursor()
            cursor.execute(query, (sample_vector,))
            cursor.fetchall()
    except:
        pass
    
    # ì„±ëŠ¥ ì¸¡ì • (3íšŒ í‰ê· )
    times = []
    for i in range(3):
        start_time = time.time()
        try:
            with db_adapter.get_connection_context() as conn:
                cursor = conn.cursor()
                cursor.execute(query, (sample_vector,))
                results = cursor.fetchall()
                end_time = time.time()
                elapsed = end_time - start_time
                times.append(elapsed)
        except Exception as e:
            print(f"  âš ï¸  ì¿¼ë¦¬ ì‹¤íŒ¨ (ì‹œë„ {i+1}): {e}")
            continue
    
    if not times:
        return {
            "success": False,
            "error": "ëª¨ë“  ì¿¼ë¦¬ ì‹œë„ ì‹¤íŒ¨"
        }
    
    # ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
    index_info = check_index_usage(query.replace("%s::vector", f"'{sample_vector}'::vector"), db_adapter)
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    
    return {
        "success": True,
        "table_name": table_name,
        "k": k,
        "avg_time": avg_time,
        "min_time": min_time,
        "max_time": max_time,
        "uses_index": index_info["uses_index"],
        "index_name": index_info["index_name"],
        "times": times
    }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("pgvector ì¸ë±ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    database_url = get_database_url()
    db_adapter = DatabaseAdapter(database_url)
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    print("ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    try:
        search_engine = SemanticSearchEngineV2()
        print("âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ê³„ì•½ í•´ì§€",
        "ì†í•´ë°°ìƒ",
        "ì„ëŒ€ì°¨ ê³„ì•½",
        "ë¶€ë™ì‚° ë§¤ë§¤",
        "ìƒì†"
    ]
    
    print("=" * 80)
    print("1. ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    search_results = []
    for query in test_queries:
        print(f"ğŸ“ ì¿¼ë¦¬: '{query}'")
        result = test_search_performance(search_engine, query, k=10)
        if result["success"]:
            print(f"  â±ï¸  í‰ê·  ì‹œê°„: {result['avg_time']:.3f}ì´ˆ (ìµœì†Œ: {result['min_time']:.3f}ì´ˆ, ìµœëŒ€: {result['max_time']:.3f}ì´ˆ)")
            print(f"  ğŸ“Š í‰ê·  ê²°ê³¼ ìˆ˜: {result['avg_results']:.1f}ê°œ")
            search_results.append(result)
        else:
            print(f"  âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        print()
    
    print("=" * 80)
    print("2. ë²¡í„° ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸)")
    print("=" * 80)
    print()
    
    # í…ŒìŠ¤íŠ¸í•  í…Œì´ë¸”
    test_tables = [
        ("statute_embeddings", "embedding_vector"),
        ("precedent_chunks", "embedding_vector"),
        ("embeddings", "vector")
    ]
    
    vector_results = []
    for table_name, vector_column in test_tables:
        print(f"ğŸ“Š í…Œì´ë¸”: {table_name}")
        result = test_vector_query_performance(db_adapter, table_name, vector_column, k=10)
        if result["success"]:
            print(f"  â±ï¸  í‰ê·  ì‹œê°„: {result['avg_time']:.3f}ì´ˆ (ìµœì†Œ: {result['min_time']:.3f}ì´ˆ, ìµœëŒ€: {result['max_time']:.3f}ì´ˆ)")
            if result["uses_index"]:
                print(f"  âœ… ì¸ë±ìŠ¤ ì‚¬ìš©: {result['index_name']}")
            else:
                print(f"  âš ï¸  ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš©")
            vector_results.append(result)
        else:
            print(f"  âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        print()
    
    # ê²°ê³¼ ìš”ì•½
    print("=" * 80)
    print("3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print()
    
    if search_results:
        avg_search_time = sum(r["avg_time"] for r in search_results) / len(search_results)
        print(f"ê²€ìƒ‰ ì„±ëŠ¥:")
        print(f"  í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.3f}ì´ˆ")
        print(f"  ìµœì†Œ ê²€ìƒ‰ ì‹œê°„: {min(r['min_time'] for r in search_results):.3f}ì´ˆ")
        print(f"  ìµœëŒ€ ê²€ìƒ‰ ì‹œê°„: {max(r['max_time'] for r in search_results):.3f}ì´ˆ")
        print()
    
    if vector_results:
        indexed_tables = [r for r in vector_results if r["uses_index"]]
        non_indexed_tables = [r for r in vector_results if not r["uses_index"]]
        
        print(f"ë²¡í„° ì¿¼ë¦¬ ì„±ëŠ¥:")
        if indexed_tables:
            avg_indexed_time = sum(r["avg_time"] for r in indexed_tables) / len(indexed_tables)
            print(f"  ì¸ë±ìŠ¤ ì‚¬ìš© í…Œì´ë¸” í‰ê· : {avg_indexed_time:.3f}ì´ˆ ({len(indexed_tables)}ê°œ)")
        if non_indexed_tables:
            avg_non_indexed_time = sum(r["avg_time"] for r in non_indexed_tables) / len(non_indexed_tables)
            print(f"  ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš© í…Œì´ë¸” í‰ê· : {avg_non_indexed_time:.3f}ì´ˆ ({len(non_indexed_tables)}ê°œ)")
        
        if indexed_tables and non_indexed_tables:
            speedup = avg_non_indexed_time / avg_indexed_time
            print(f"  ì„±ëŠ¥ í–¥ìƒ: {speedup:.2f}ë°°")
        print()
        
        print("ì¸ë±ìŠ¤ ì‚¬ìš© í˜„í™©:")
        for r in vector_results:
            status = "âœ… ì‚¬ìš©" if r["uses_index"] else "âŒ ë¯¸ì‚¬ìš©"
            index_info = f" ({r['index_name']})" if r["uses_index"] and r["index_name"] else ""
            print(f"  {r['table_name']}: {status}{index_info}")

if __name__ == "__main__":
    main()

