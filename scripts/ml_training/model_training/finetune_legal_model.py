"""
ë²•ë¥  ëª¨ë¸ LoRA íŒŒì¸íŠœë‹ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
KoGPT-2 ê¸°ë°˜ ë²•ë¥  íŠ¹í™” ëª¨ë¸ í›ˆë ¨
"""

import argparse
import json
import logging
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
import torch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from source.models.legal_finetuner import LegalModelFineTuner, LegalModelEvaluator, LegalQADataset

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/finetune_legal_model.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class LegalModelTrainingPipeline:
    """ë²•ë¥  ëª¨ë¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.fine_tuner = None
        self.evaluator = None
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        Path("logs").mkdir(exist_ok=True)
        
        logger.info("LegalModelTrainingPipeline initialized")
    
    def load_training_data(self) -> tuple:
        """í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
        logger.info("Loading training data...")
        
        try:
            # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            train_path = Path(self.config["data"]["train_path"])
            val_path = Path(self.config["data"]["val_path"])
            test_path = Path(self.config["data"]["test_path"])
            
            with open(train_path, "r", encoding="utf-8") as f:
                train_data = json.load(f)
            
            with open(val_path, "r", encoding="utf-8") as f:
                val_data = json.load(f)
            
            with open(test_path, "r", encoding="utf-8") as f:
                test_data = json.load(f)
            
            logger.info(f"Data loaded successfully:")
            logger.info(f"  Train: {len(train_data)} samples")
            logger.info(f"  Validation: {len(val_data)} samples")
            logger.info(f"  Test: {len(test_data)} samples")
            
            return train_data, val_data, test_data
            
        except Exception as e:
            logger.error(f"Failed to load training data: {e}")
            raise
    
    def initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info("Initializing model...")
        
        try:
            self.fine_tuner = LegalModelFineTuner(
                model_name=self.config["model"]["name"],
                device=self.config["model"]["device"]
            )
            
            logger.info("Model initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize model: {e}")
            raise
    
    def prepare_datasets(self, train_data: List[Dict], val_data: List[Dict]) -> tuple:
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("Preparing datasets...")
        
        try:
            train_dataset, val_dataset = self.fine_tuner.prepare_training_data(train_data, val_data)
            logger.info("Datasets prepared successfully")
            return train_dataset, val_dataset
            
        except Exception as e:
            logger.error(f"Failed to prepare datasets: {e}")
            raise
    
    def setup_training(self):
        """í›ˆë ¨ ì„¤ì •"""
        logger.info("Setting up training configuration...")
        
        try:
            training_args = self.fine_tuner.setup_training_args(
                output_dir=self.config["training"]["output_dir"],
                num_train_epochs=self.config["training"]["epochs"],
                per_device_train_batch_size=self.config["training"]["batch_size"],
                per_device_eval_batch_size=self.config["training"]["eval_batch_size"],
                gradient_accumulation_steps=self.config["training"]["gradient_accumulation_steps"],
                learning_rate=self.config["training"]["learning_rate"],
                warmup_steps=self.config["training"]["warmup_steps"],
                logging_steps=self.config["training"]["logging_steps"],
                save_steps=self.config["training"]["save_steps"],
                eval_steps=self.config["training"]["eval_steps"]
            )
            
            logger.info("Training configuration setup completed")
            return training_args
            
        except Exception as e:
            logger.error(f"Failed to setup training: {e}")
            raise
    
    def train_model(self, train_dataset: LegalQADataset, val_dataset: LegalQADataset):
        """ëª¨ë¸ í›ˆë ¨"""
        logger.info("Starting model training...")
        
        try:
            trainer = self.fine_tuner.train(train_dataset, val_dataset)
            
            # ëª¨ë¸ ì €ì¥
            self.fine_tuner.save_model(self.config["training"]["output_dir"])
            
            logger.info("Model training completed successfully")
            return trainer
            
        except Exception as e:
            logger.error(f"Model training failed: {e}")
            raise
    
    def evaluate_model(self, test_data: List[Dict]):
        """ëª¨ë¸ í‰ê°€"""
        logger.info("Evaluating model...")
        
        try:
            self.evaluator = LegalModelEvaluator(self.fine_tuner.model, self.fine_tuner.tokenizer)
            
            evaluation_results = self.evaluator.evaluate_legal_qa(test_data)
            
            # í‰ê°€ ê²°ê³¼ ì €ì¥
            eval_path = Path(self.config["training"]["output_dir"]) / "evaluation_results.json"
            with open(eval_path, "w", encoding="utf-8") as f:
                json.dump(evaluation_results, f, ensure_ascii=False, indent=4)
            
            logger.info(f"Model evaluation completed: {evaluation_results}")
            return evaluation_results
            
        except Exception as e:
            logger.error(f"Model evaluation failed: {e}")
            raise
    
    def generate_sample_responses(self, test_data: List[Dict], num_samples: int = 5):
        """ìƒ˜í”Œ ì‘ë‹µ ìƒì„±"""
        logger.info(f"Generating {num_samples} sample responses...")
        
        try:
            sample_responses = []
            
            for i, sample in enumerate(test_data[:num_samples]):
                question = sample.get("question", "")
                ground_truth = sample.get("answer", "")
                
                if not question:
                    continue
                
                # ì‘ë‹µ ìƒì„±
                prompt = f"<|startoftext|>ì§ˆë¬¸: {question}\në‹µë³€:"
                predicted = self.fine_tuner.generate_response(prompt, max_length=200)
                
                sample_responses.append({
                    "question": question,
                    "ground_truth": ground_truth,
                    "predicted": predicted,
                    "sample_id": i + 1
                })
            
            # ìƒ˜í”Œ ì‘ë‹µ ì €ì¥
            samples_path = Path(self.config["training"]["output_dir"]) / "sample_responses.json"
            with open(samples_path, "w", encoding="utf-8") as f:
                json.dump(sample_responses, f, ensure_ascii=False, indent=4)
            
            logger.info(f"Sample responses generated and saved to {samples_path}")
            return sample_responses
            
        except Exception as e:
            logger.error(f"Failed to generate sample responses: {e}")
            raise
    
    def run_training_pipeline(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("Starting legal model training pipeline...")
        
        start_time = datetime.now()
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            train_data, val_data, test_data = self.load_training_data()
            
            # 2. ëª¨ë¸ ì´ˆê¸°í™”
            self.initialize_model()
            
            # 3. ë°ì´í„°ì…‹ ì¤€ë¹„
            train_dataset, val_dataset = self.prepare_datasets(train_data, val_data)
            
            # 4. í›ˆë ¨ ì„¤ì •
            self.setup_training()
            
            # 5. ëª¨ë¸ í›ˆë ¨
            trainer = self.train_model(train_dataset, val_dataset)
            
            # 6. ëª¨ë¸ í‰ê°€
            evaluation_results = self.evaluate_model(test_data)
            
            # 7. ìƒ˜í”Œ ì‘ë‹µ ìƒì„±
            sample_responses = self.generate_sample_responses(test_data)
            
            # í›ˆë ¨ ì™„ë£Œ ë³´ê³ ì„œ ìƒì„±
            self.generate_training_report(evaluation_results, sample_responses, start_time)
            
            logger.info("Legal model training pipeline completed successfully!")
            
        except Exception as e:
            logger.error(f"Training pipeline failed: {e}")
            raise
    
    def generate_training_report(self, evaluation_results: Dict, sample_responses: List[Dict], start_time: datetime):
        """í›ˆë ¨ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("Generating training report...")
        
        try:
            end_time = datetime.now()
            training_duration = end_time - start_time
            
            report = {
                "training_info": {
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_minutes": training_duration.total_seconds() / 60,
                    "model_name": self.config["model"]["name"],
                    "device": self.config["model"]["device"]
                },
                "training_config": self.config["training"],
                "evaluation_results": evaluation_results,
                "sample_responses": sample_responses[:3],  # ì²˜ìŒ 3ê°œë§Œ í¬í•¨
                "summary": {
                    "total_samples": evaluation_results.get("total_samples", 0),
                    "accuracy": evaluation_results.get("accuracy", 0.0),
                    "bleu_score": evaluation_results.get("bleu_score", 0.0),
                    "rouge_score": evaluation_results.get("rouge_score", 0.0),
                    "legal_relevance": evaluation_results.get("legal_relevance", 0.0)
                }
            }
            
            # ë³´ê³ ì„œ ì €ì¥
            report_path = Path(self.config["training"]["output_dir"]) / "training_report.json"
            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=4)
            
            logger.info(f"Training report saved to {report_path}")
            
            # ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
            print("\n" + "="*60)
            print("ğŸ‰ ë²•ë¥  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            print("="*60)
            print(f"â±ï¸  í›ˆë ¨ ì‹œê°„: {training_duration.total_seconds()/60:.1f}ë¶„")
            print(f"ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {evaluation_results.get('total_samples', 0)}ê°œ")
            print(f"ğŸ¯ ì •í™•ë„: {evaluation_results.get('accuracy', 0.0):.3f}")
            print(f"ğŸ“ BLEU ì ìˆ˜: {evaluation_results.get('bleu_score', 0.0):.3f}")
            print(f"ğŸ“„ ROUGE ì ìˆ˜: {evaluation_results.get('rouge_score', 0.0):.3f}")
            print(f"âš–ï¸  ë²•ë¥  ê´€ë ¨ì„±: {evaluation_results.get('legal_relevance', 0.0):.3f}")
            print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {self.config['training']['output_dir']}")
            print("="*60)
            
        except Exception as e:
            logger.error(f"Failed to generate training report: {e}")
            raise


def create_default_config() -> Dict[str, Any]:
    """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
    return {
        "model": {
            "name": "skt/kogpt2-base-v2",
            "device": "cpu"
        },
        "data": {
            "train_path": "data/training/train_split.json",
            "val_path": "data/training/validation_split.json",
            "test_path": "data/training/test_split.json"
        },
        "training": {
            "output_dir": "models/finetuned/kogpt2-legal-lora",
            "epochs": 3,
            "batch_size": 1,
            "eval_batch_size": 1,
            "gradient_accumulation_steps": 8,
            "learning_rate": 5e-5,
            "warmup_steps": 100,
            "logging_steps": 10,
            "save_steps": 500,
            "eval_steps": 500
        }
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ë²•ë¥  ëª¨ë¸ LoRA íŒŒì¸íŠœë‹")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model", type=str, default="skt/kogpt2-base-v2", help="ëª¨ë¸ ì´ë¦„")
    parser.add_argument("--data", type=str, default="data/training", help="ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument("--output", type=str, default="models/finetuned/kogpt2-legal-lora", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--epochs", type=int, default=3, help="í›ˆë ¨ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--batch-size", type=int, default=1, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning-rate", type=float, default=5e-5, help="í•™ìŠµë¥ ")
    parser.add_argument("--device", type=str, default="cpu", help="ë””ë°”ì´ìŠ¤ (cpu/cuda)")
    parser.add_argument("--test-only", action="store_true", help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ (í›ˆë ¨ ì—†ì´ í‰ê°€ë§Œ)")
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ ë˜ëŠ” ìƒì„±
    if args.config and Path(args.config).exists():
        with open(args.config, "r", encoding="utf-8") as f:
            config = json.load(f)
    else:
        config = create_default_config()
        
        # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
        config["model"]["name"] = args.model
        config["model"]["device"] = args.device
        config["data"]["train_path"] = str(Path(args.data) / "train_split.json")
        config["data"]["val_path"] = str(Path(args.data) / "validation_split.json")
        config["data"]["test_path"] = str(Path(args.data) / "test_split.json")
        config["training"]["output_dir"] = args.output
        config["training"]["epochs"] = args.epochs
        config["training"]["batch_size"] = args.batch_size
        config["training"]["learning_rate"] = args.learning_rate
    
    logger.info(f"Starting legal model fine-tuning with config: {config}")
    
    try:
        # í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = LegalModelTrainingPipeline(config)
        
        if args.test_only:
            logger.info("Running in test mode (evaluation only)")
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ í›„ í‰ê°€ë§Œ ìˆ˜í–‰
            pipeline.initialize_model()
            train_data, val_data, test_data = pipeline.load_training_data()
            evaluation_results = pipeline.evaluate_model(test_data)
            sample_responses = pipeline.generate_sample_responses(test_data)
        else:
            # ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            pipeline.run_training_pipeline()
        
        logger.info("Legal model fine-tuning completed successfully!")
        
    except Exception as e:
        logger.error(f"Legal model fine-tuning failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
