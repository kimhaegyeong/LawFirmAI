#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Base Legal Terms Database Migration Script
base_legal_terms ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë©”ì¸ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import os
import sys
import sqlite3
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from source.data.database import DatabaseManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BaseLegalTermsMigrator:
    """Base Legal Terms ë§ˆì´ê·¸ë ˆì´ì…˜ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.source_db_path = Path("data/database/base_legal_terms.db")
        self.target_db_path = Path("data/lawfirm.db")
        
        # ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.source_conn = None
        # íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
        self.target_db = DatabaseManager(str(self.target_db_path))
        
        logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ì†ŒìŠ¤ DB: {self.source_db_path}")
        logger.info(f"íƒ€ê²Ÿ DB: {self.target_db_path}")
    
    def connect_source_database(self):
        """ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            if not self.source_db_path.exists():
                raise FileNotFoundError(f"ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.source_db_path}")
            
            self.source_conn = sqlite3.connect(str(self.source_db_path))
            self.source_conn.row_factory = sqlite3.Row
            logger.info("ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def close_source_database(self):
        """ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.source_conn:
            self.source_conn.close()
            logger.info("ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")
    
    def get_source_data_count(self) -> int:
        """ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ"""
        try:
            cursor = self.source_conn.cursor()
            cursor.execute("SELECT COUNT(*) as count FROM base_legal_term_lists")
            result = cursor.fetchone()
            return result['count'] if result else 0
            
        except Exception as e:
            logger.error(f"ì†ŒìŠ¤ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_source_data_batch(self, offset: int, batch_size: int = 1000) -> List[Dict[str, Any]]:
        """ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°°ì¹˜ë¡œ ë°ì´í„° ì¡°íšŒ"""
        try:
            cursor = self.source_conn.cursor()
            cursor.execute("""
                SELECT ë²•ë ¹ìš©ì–´ID, ë²•ë ¹ìš©ì–´ëª…, ë™ìŒì´ì˜ì–´ì¡´ì¬ì—¬ë¶€, ë¹„ê³ , 
                       ìš©ì–´ê°„ê´€ê³„ë§í¬, ì¡°ë¬¸ê°„ê´€ê³„ë§í¬, ìˆ˜ì§‘ì¼ì‹œ
                FROM base_legal_term_lists 
                ORDER BY id
                LIMIT ? OFFSET ?
            """, (batch_size, offset))
            
            results = []
            for row in cursor.fetchall():
                results.append(dict(row))
            
            return results
            
        except Exception as e:
            logger.error(f"ì†ŒìŠ¤ ë°ì´í„° ë°°ì¹˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def migrate_data(self, batch_size: int = 1000) -> Dict[str, Any]:
        """ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        
        try:
            # ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.connect_source_database()
            
            # ì†ŒìŠ¤ ë°ì´í„° ê°œìˆ˜ í™•ì¸
            total_count = self.get_source_data_count()
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜í•  ì´ ë ˆì½”ë“œ ìˆ˜: {total_count:,}ê°œ")
            
            if total_count == 0:
                logger.warning("ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return {"success": False, "message": "ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ì˜ ê¸°ì¡´ ë°ì´í„° í™•ì¸
            existing_count = self.target_db.get_base_legal_terms_count()
            logger.info(f"íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ì¡´ ë ˆì½”ë“œ ìˆ˜: {existing_count:,}ê°œ")
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„
            stats = {
                "total_source": total_count,
                "existing_target": existing_count,
                "processed": 0,
                "inserted": 0,
                "updated": 0,
                "errors": 0,
                "start_time": datetime.now(),
                "end_time": None
            }
            
            # ë°°ì¹˜ë³„ë¡œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            offset = 0
            while offset < total_count:
                logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {offset:,} ~ {min(offset + batch_size, total_count):,}")
                
                # ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
                batch_data = self.get_source_data_batch(offset, batch_size)
                
                if not batch_data:
                    logger.warning(f"ë°°ì¹˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: offset={offset}")
                    break
                
                # íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
                try:
                    inserted_count = self.target_db.insert_base_legal_terms_batch(batch_data)
                    stats["processed"] += len(batch_data)
                    stats["inserted"] += inserted_count
                    
                    logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(batch_data)}ê°œ ì¡°íšŒ, {inserted_count}ê°œ ì‚½ì…")
                    
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
                    stats["errors"] += len(batch_data)
                
                offset += batch_size
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
            stats["end_time"] = datetime.now()
            stats["duration"] = (stats["end_time"] - stats["start_time"]).total_seconds()
            
            # ìµœì¢… ê²°ê³¼ í™•ì¸
            final_count = self.target_db.get_base_legal_terms_count()
            stats["final_target"] = final_count
            
            logger.info("ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„: {stats}")
            
            return {
                "success": True,
                "stats": stats,
                "message": f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {stats['processed']:,}ê°œ ì²˜ë¦¬, {final_count:,}ê°œ ìµœì¢… ì €ì¥"
            }
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return {"success": False, "message": f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}"}
        
        finally:
            # ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
            self.close_source_database()
    
    def verify_migration(self) -> Dict[str, Any]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦"""
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦ ì‹œì‘")
        
        try:
            # ì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.connect_source_database()
            
            # ì†ŒìŠ¤ ë°ì´í„° ê°œìˆ˜
            source_count = self.get_source_data_count()
            
            # íƒ€ê²Ÿ ë°ì´í„° ê°œìˆ˜
            target_count = self.target_db.get_base_legal_terms_count()
            
            # ìƒ˜í”Œ ë°ì´í„° ë¹„êµ
            source_sample = self.get_source_data_batch(0, 10)
            target_sample = self.target_db.execute_query(
                "SELECT * FROM base_legal_term_lists ORDER BY id LIMIT 10"
            )
            
            verification_result = {
                "source_count": source_count,
                "target_count": target_count,
                "count_match": source_count == target_count,
                "source_sample": source_sample,
                "target_sample": target_sample,
                "sample_match": len(source_sample) == len(target_sample)
            }
            
            logger.info(f"ê²€ì¦ ê²°ê³¼: {verification_result}")
            
            return verification_result
            
        except Exception as e:
            logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
        
        finally:
            self.close_source_database()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("Base Legal Terms Database Migration")
    print("=" * 60)
    
    migrator = BaseLegalTermsMigrator()
    
    try:
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        result = migrator.migrate_data(batch_size=1000)
        
        if result["success"]:
            print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ: {result['message']}")
            
            # ê²€ì¦ ì‹¤í–‰
            verification = migrator.verify_migration()
            
            if verification.get("count_match", False):
                print("âœ… ë°ì´í„° ê°œìˆ˜ ì¼ì¹˜ í™•ì¸")
            else:
                print(f"âš ï¸ ë°ì´í„° ê°œìˆ˜ ë¶ˆì¼ì¹˜: ì†ŒìŠ¤ {verification.get('source_count', 0)}, íƒ€ê²Ÿ {verification.get('target_count', 0)}")
            
            print(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„:")
            stats = result.get("stats", {})
            print(f"   - ì†ŒìŠ¤ ë°ì´í„°: {stats.get('total_source', 0):,}ê°œ")
            print(f"   - ì²˜ë¦¬ëœ ë°ì´í„°: {stats.get('processed', 0):,}ê°œ")
            print(f"   - ì‚½ì…ëœ ë°ì´í„°: {stats.get('inserted', 0):,}ê°œ")
            print(f"   - ì˜¤ë¥˜ ë°œìƒ: {stats.get('errors', 0):,}ê°œ")
            print(f"   - ì†Œìš” ì‹œê°„: {stats.get('duration', 0):.2f}ì´ˆ")
            
        else:
            print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {result['message']}")
            return 1
    
    except Exception as e:
        print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    print("=" * 60)
    print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    print("=" * 60)
    
    return 0


if __name__ == "__main__":
    exit(main())
