#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í˜„í–‰ë²•ë ¹ ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import logging
import argparse
import gc
import psutil
from pathlib import Path
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.database import DatabaseManager
from source.data.vector_store import LegalVectorStore
from source.utils.logger import setup_logging

class ArticleVectorEmbedder:
    """ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, start_batch: int = 1, batch_size: int = 1000, use_gpu: bool = True, max_batches: int = None):
        setup_logging()
        self.logger = logging.getLogger("article_vector_embedder")
        self.db_manager = DatabaseManager()
        
        # GPU ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self.vector_store = LegalVectorStore(use_gpu=use_gpu)
        
        # ë°°ì¹˜ ì„¤ì •
        self.start_batch = start_batch
        self.batch_size = batch_size
        self.max_batches = max_batches  # ì²˜ë¦¬í•  ìµœëŒ€ ë°°ì¹˜ ìˆ˜
        
        # í†µê³„ ì •ë³´
        self.stats = {
            'total_articles': 0,
            'processed_articles': 0,
            'embedding_errors': []
        }
    
    def create_article_embeddings(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë²¡í„° ì„ë² ë”© ìƒì„±"""
        self.logger.info("ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± ì‹œì‘ (ë©”ëª¨ë¦¬ ìµœì í™”)")
        
        try:
            # ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•Šê³  ì´ ê°œìˆ˜ë§Œ ì¡°íšŒ
            total_count = self._get_total_articles_count()
            self.stats['total_articles'] = total_count
            
            if total_count == 0:
                self.logger.warning("ì²˜ë¦¬í•  ì¡°ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return self.stats
            
            self.logger.info(f"ì´ {total_count}ê°œ ì¡°ë¬¸ ë°œê²¬")
            
            # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
            initial_memory = self._get_memory_info()
            self.logger.info(f"ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory['process_memory_mb']:.2f}MB")
            
            # ë°°ì¹˜ë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
            start_index = (self.start_batch - 1) * self.batch_size
            total_batches = (total_count + self.batch_size - 1) // self.batch_size
            
            # ìµœëŒ€ ë°°ì¹˜ ìˆ˜ ì„¤ì •
            if self.max_batches:
                end_batch = min(self.start_batch + self.max_batches - 1, total_batches)
                self.logger.info(f"ë°°ì¹˜ {self.start_batch}ë¶€í„° {end_batch}ê¹Œì§€ ì²˜ë¦¬ ({self.max_batches}ê°œ ë°°ì¹˜)")
            else:
                end_batch = total_batches
                self.logger.info(f"ë°°ì¹˜ {self.start_batch}ë¶€í„° {end_batch}ê¹Œì§€ ì²˜ë¦¬ (ì „ì²´)")
            
            self.logger.info(f"ë°°ì¹˜ í¬ê¸°: {self.batch_size}, ì‹œì‘ ì¸ë±ìŠ¤: {start_index}")
            
            for batch_num in range(self.start_batch, end_batch + 1):
                current_start_index = (batch_num - 1) * self.batch_size
                
                # ë°°ì¹˜ë³„ë¡œ ë°ì´í„° ì¡°íšŒ (ë©”ëª¨ë¦¬ ì ˆì•½)
                batch_articles = self._get_articles_data_streaming(current_start_index, self.batch_size)
                
                if not batch_articles:
                    self.logger.info(f"ë°°ì¹˜ {batch_num}: ë°ì´í„° ì—†ìŒ, ì²˜ë¦¬ ì¢…ë£Œ")
                    break
                    
                self.logger.info(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_articles)}ê°œ ì¡°ë¬¸)")
                
                # ë°°ì¹˜ë³„ ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                documents, metadatas = self._prepare_embedding_data(batch_articles)
                
                # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
                success = self.vector_store.add_documents(documents, metadatas)
                
                if success:
                    self.stats['processed_articles'] += len(documents)
                    self.logger.info(f"âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(documents)}ê°œ ì¡°ë¬¸")
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ëª¨ë‹ˆí„°ë§
                    del batch_articles, documents, metadatas
                    gc.collect()
                    self._monitor_and_cleanup_memory()
                    
                    # ì§„í–‰ë¥  ë° ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
                    total_processing_batches = end_batch - self.start_batch + 1
                    progress_percent = (batch_num - self.start_batch + 1) / total_processing_batches * 100
                    current_memory = self._get_memory_info()
                    self.logger.info(f"ì§„í–‰ë¥ : {progress_percent:.1f}% ({batch_num - self.start_batch + 1}/{total_processing_batches}), í˜„ì¬ ë©”ëª¨ë¦¬: {current_memory['process_memory_mb']:.2f}MB")
                    
                else:
                    self.logger.error(f"âŒ ë°°ì¹˜ {batch_num} ì‹¤íŒ¨")
                    break
            
            # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
            final_memory = self._get_memory_info()
            memory_saved = initial_memory['process_memory_mb'] - final_memory['process_memory_mb']
            self.logger.info(f"ë²¡í„° ì„ë² ë”© ìƒì„± ì™„ë£Œ: ì´ {self.stats['processed_articles']}ê°œ")
            self.logger.info(f"ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {final_memory['process_memory_mb']:.2f}MB")
            if memory_saved > 0:
                self.logger.info(f"ë©”ëª¨ë¦¬ ì ˆì•½: {memory_saved:.2f}MB")
            
            # í†µê³„ ì¶œë ¥
            self._print_statistics()
            
            return self.stats
            
        except Exception as e:
            self.logger.error(f"ë²¡í„° ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _get_total_articles_count(self) -> int:
        """ì „ì²´ ì¡°ë¬¸ ê°œìˆ˜ ì¡°íšŒ (ë©”ëª¨ë¦¬ ì ˆì•½)"""
        query = "SELECT COUNT(*) as total FROM current_laws_articles"
        
        try:
            result = self.db_manager.execute_query(query)
            return result[0]['total'] if result else 0
        except Exception as e:
            self.logger.error(f"ì¡°ë¬¸ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def _get_articles_data_streaming(self, start_index: int, batch_size: int) -> List[Dict[str, Any]]:
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¡°ë¬¸ ë°ì´í„° ì¡°íšŒ (ë©”ëª¨ë¦¬ ì ˆì•½)"""
        query = """
            SELECT ca.*, cl.ministry_name, cl.effective_date
            FROM current_laws_articles ca
            JOIN current_laws cl ON ca.law_id = cl.law_id
            ORDER BY ca.law_name_korean, ca.article_number, ca.paragraph_number, ca.sub_paragraph_number
            LIMIT ? OFFSET ?
        """
        
        try:
            return self.db_manager.execute_query(query, (batch_size, start_index))
        except Exception as e:
            self.logger.error(f"ì¡°ë¬¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_articles_data(self) -> List[Dict[str, Any]]:
        """ì¡°ë¬¸ ë°ì´í„° ì¡°íšŒ (ë ˆê±°ì‹œ ë©”ì„œë“œ - í˜¸í™˜ì„± ìœ ì§€)"""
        query = """
            SELECT ca.*, cl.ministry_name, cl.effective_date
            FROM current_laws_articles ca
            JOIN current_laws cl ON ca.law_id = cl.law_id
            ORDER BY ca.law_name_korean, ca.article_number, ca.paragraph_number, ca.sub_paragraph_number
        """
        
        try:
            return self.db_manager.execute_query(query)
        except Exception as e:
            self.logger.error(f"ì¡°ë¬¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _prepare_embedding_data(self, articles: List[Dict[str, Any]]) -> tuple[List[str], List[Dict[str, Any]]]:
        """ì„ë² ë”©ìš© ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„"""
        documents = []
        metadatas = []
        
        for article in articles:
            try:
                # ì¡°ë¬¸ë³„ ë¬¸ì„œ ìƒì„±
                document = self._create_article_document(article)
                metadata = self._create_article_metadata(article)
                
                documents.append(document)
                metadatas.append(metadata)
                
            except Exception as e:
                error_msg = f"ì¡°ë¬¸ {article.get('article_id', 'Unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                self.logger.error(error_msg)
                self.stats['embedding_errors'].append(error_msg)
        
        return documents, metadatas
    
    def _monitor_and_cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì •ë¦¬"""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / (1024**2)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 4GBë¥¼ ì´ˆê³¼í•˜ë©´ ì •ë¦¬
            if memory_mb > 4000:
                self.logger.warning(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {memory_mb:.2f}MB, ì •ë¦¬ ì‹œì‘...")
                
                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
                collected = gc.collect()
                self.logger.info(f"ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ {collected}ê°œ ê°ì²´ ì •ë¦¬")
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬í™•ì¸
                memory_after = process.memory_info().rss / (1024**2)
                self.logger.info(f"ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_after:.2f}MB")
                
                # ë©”ëª¨ë¦¬ ì ˆì•½ëŸ‰ ê³„ì‚°
                saved_mb = memory_mb - memory_after
                if saved_mb > 0:
                    self.logger.info(f"ë©”ëª¨ë¦¬ ì ˆì•½: {saved_mb:.2f}MB")
                    
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
    
    def _get_memory_info(self) -> Dict[str, float]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜"""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / (1024**2)
            available_memory_gb = psutil.virtual_memory().available / (1024**3)
            
            return {
                'process_memory_mb': memory_mb,
                'available_memory_gb': available_memory_gb,
                'memory_percent': psutil.virtual_memory().percent
            }
        except Exception as e:
            self.logger.error(f"ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'process_memory_mb': 0, 'available_memory_gb': 0, 'memory_percent': 0}
    
    def _create_article_document(self, article: Dict[str, Any]) -> str:
        """ìŠ¤ë§ˆíŠ¸ ìë¥´ê¸° ë°©ì‹ì˜ ì¡°ë¬¸ ë¬¸ì„œ ìƒì„±"""
        content_parts = [
            f"ë²•ë ¹ëª…: {article['law_name_korean']}",
            f"ì¡°ë¬¸ë²ˆí˜¸: ì œ{article['article_number']}ì¡°"
        ]
        
        # ì œëª©ì´ ìˆìœ¼ë©´ ìš°ì„  í¬í•¨
        if article.get('article_title'):
            content_parts.append(f"ì œëª©: {article['article_title']}")
        
        # ë‚´ìš©ì„ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ìë¥´ê¸°
        content = article['article_content']
        max_content_length = 400  # ì „ì²´ ê¸¸ì´ì˜ 80% í• ë‹¹
        
        if len(content) > max_content_length:
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
            truncated_content = self._smart_truncate_text(content, max_content_length)
            content_parts.append(f"ë‚´ìš©: {truncated_content}")
        else:
            content_parts.append(f"ë‚´ìš©: {content}")
        
        # í•­ ë‚´ìš© (ìŠ¤ë§ˆíŠ¸ ìë¥´ê¸° ì ìš©)
        if article.get('paragraph_content'):
            para_content = article['paragraph_content']
            if len(para_content) > 100:
                para_content = self._smart_truncate_text(para_content, 100)
            content_parts.append(f"í•­: {para_content}")
        
        # í˜¸ ë‚´ìš© (ì„ íƒì , ê¸¸ì´ ì œí•œ)
        if article.get('sub_paragraph_content'):
            sub_para_content = article['sub_paragraph_content']
            if len(sub_para_content) > 80:
                sub_para_content = self._smart_truncate_text(sub_para_content, 80)
            content_parts.append(f"í˜¸: {sub_para_content}")
        
        # ì†Œê´€ë¶€ì²˜ ì •ë³´ (ì„ íƒì )
        if article.get('ministry_name'):
            content_parts.append(f"ì†Œê´€ë¶€ì²˜: {article['ministry_name']}")
        
        return "\n".join(content_parts)
    
    def _smart_truncate_text(self, text: str, max_length: int) -> str:
        """ìŠ¤ë§ˆíŠ¸ í…ìŠ¤íŠ¸ ìë¥´ê¸° (ë¬¸ì¥ ë‹¨ìœ„ ë³´ì¡´)"""
        if len(text) <= max_length:
            return text
        
        # í•œêµ­ì–´ ë¬¸ì¥ êµ¬ë¶„ìë“¤
        sentence_endings = ['ã€‚', '.', '!', '?', ';', ':', 'ë‹¤.', 'ë‹ˆë‹¤.', 'ìš”.', 'ì–´ìš”.', 'ì•„ìš”.']
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            if char in sentence_endings:
                sentences.append(current_sentence.strip())
                current_sentence = ""
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        truncated_text = ""
        for sentence in sentences:
            if len(truncated_text + sentence) <= max_length:
                truncated_text += sentence
            else:
                break
        
        # ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        if len(truncated_text) < max_length * 0.5:  # 50% ë¯¸ë§Œì´ë©´
            truncated_text = text[:max_length]
            # ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            last_space = truncated_text.rfind(' ')
            if last_space > max_length * 0.7:  # 70% ì´ìƒì´ë©´
                truncated_text = truncated_text[:last_space]
        
        return truncated_text
    
    def _create_article_metadata(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """ì¡°ë¬¸ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        return {
            'law_id': article['law_id'],
            'law_name': article['law_name_korean'],
            'article_number': str(article['article_number']),
            'article_id': article['article_id'],
            'article_title': article.get('article_title', ''),
            'paragraph_number': str(article.get('paragraph_number', '')),
            'sub_paragraph_number': article.get('sub_paragraph_number', ''),
            'source_system': 'current_laws',
            'document_type': 'current_law_article',
            'quality_score': article.get('quality_score', 0.9),
            'ministry_name': article.get('ministry_name', ''),
            'effective_date': article.get('effective_date', ''),
            'parsing_method': article.get('parsing_method', 'batch_parser'),
            'is_supplementary': article.get('is_supplementary', False)
        }
    
    def _print_statistics(self):
        """í†µê³„ ì •ë³´ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± í†µê³„ (ë©”ëª¨ë¦¬ ìµœì í™”)")
        print("="*60)
        print(f"ì´ ì¡°ë¬¸ ìˆ˜: {self.stats['total_articles']:,}ê°œ")
        print(f"ì²˜ë¦¬ëœ ì¡°ë¬¸: {self.stats['processed_articles']:,}ê°œ")
        print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {len(self.stats['embedding_errors'])}ê°œ")
        
        # ë©”ëª¨ë¦¬ í†µê³„
        memory_info = self._get_memory_info()
        print(f"\nğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        print(f"  í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬: {memory_info['process_memory_mb']:.2f}MB")
        print(f"  ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {memory_info['available_memory_gb']:.2f}GB")
        print(f"  ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory_info['memory_percent']:.1f}%")
        
        if self.stats['embedding_errors']:
            print("\nâš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨ ëª©ë¡:")
            for error in self.stats['embedding_errors'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"  - {error}")
        
        # ë²¡í„° ìŠ¤í† ì–´ í†µê³„
        try:
            vector_stats = self.vector_store.get_stats()
            print(f"\nğŸ“ˆ ë²¡í„° ìŠ¤í† ì–´ í†µê³„:")
            print(f"  ì´ ë¬¸ì„œ ìˆ˜: {vector_stats.get('documents_count', 0):,}ê°œ")
            print(f"  ë²¡í„° ì°¨ì›: {vector_stats.get('vector_dimension', 0)}")
            print(f"  ì¸ë±ìŠ¤ í¬ê¸°: {vector_stats.get('index_size_mb', 0):.2f}MB")
        except Exception as e:
            print(f"ë²¡í„° ìŠ¤í† ì–´ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í˜„í–‰ë²•ë ¹ ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„±')
    parser.add_argument('--start-batch', type=int, default=1, 
                       help='ì‹œì‘í•  ë°°ì¹˜ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)')
    parser.add_argument('--batch-size', type=int, default=1000,
                       help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1000)')
    parser.add_argument('--max-batches', type=int, default=None,
                       help='ì²˜ë¦¬í•  ìµœëŒ€ ë°°ì¹˜ ìˆ˜ (ê¸°ë³¸ê°’: None, ì „ì²´ ì²˜ë¦¬)')
    parser.add_argument('--use-gpu', action='store_true', default=True,
                       help='GPU ì‚¬ìš© (ê¸°ë³¸ê°’: True)')
    parser.add_argument('--use-cpu', action='store_true', default=False,
                       help='CPU ê°•ì œ ì‚¬ìš©')
    
    args = parser.parse_args()
    
    # GPU ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    use_gpu = args.use_gpu and not args.use_cpu
    
    print(f"ğŸš€ ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± ì‹œì‘")
    print(f"   ì‹œì‘ ë°°ì¹˜: {args.start_batch}")
    print(f"   ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"   ìµœëŒ€ ë°°ì¹˜ ìˆ˜: {args.max_batches if args.max_batches else 'ì „ì²´'}")
    print(f"   GPU ì‚¬ìš©: {'Yes' if use_gpu else 'No'}")
    print("-" * 50)
    
    embedder = ArticleVectorEmbedder(
        start_batch=args.start_batch,
        batch_size=args.batch_size,
        use_gpu=use_gpu,
        max_batches=args.max_batches
    )
    stats = embedder.create_article_embeddings()
    
    print(f"\nğŸ‰ ì¡°ë¬¸ë³„ ë²¡í„° ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
    print(f"ì´ {stats['processed_articles']:,}ê°œ ì¡°ë¬¸ì˜ ë²¡í„° ì„ë² ë”©ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
