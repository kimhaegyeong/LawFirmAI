#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°°ì¹˜ íŒŒì¼ì—ì„œ ì¡°ë¬¸ì„ ì¶”ì¶œí•˜ì—¬ ê°œë³„ ì¡°ë¬¸ í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.database import DatabaseManager
from source.utils.logger import setup_logger

class BatchArticleParser:
    """ë°°ì¹˜ íŒŒì¼ì—ì„œ ì¡°ë¬¸ì„ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, batch_dir: str):
        self.batch_dir = Path(batch_dir)
        self.logger = setup_logger("batch_article_parser")
        self.db_manager = DatabaseManager()
        
        # í†µê³„ ì •ë³´
        self.stats = {
            'total_batches': 0,
            'total_laws': 0,
            'total_articles': 0,
            'total_paragraphs': 0,
            'parsing_errors': []
        }
    
    def parse_all_batches(self) -> Dict[str, Any]:
        """ëª¨ë“  ë°°ì¹˜ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì¡°ë¬¸ ì¶”ì¶œ"""
        self.logger.info("ë°°ì¹˜ íŒŒì¼ íŒŒì‹± ì‹œì‘")
        
        # 1. ì¡°ë¬¸ í…Œì´ë¸” ìƒì„±
        self._create_articles_table()
        
        # 2. ë°°ì¹˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        batch_files = self._get_batch_files()
        self.stats['total_batches'] = len(batch_files)
        
        self.logger.info(f"ì´ {len(batch_files)}ê°œ ë°°ì¹˜ íŒŒì¼ ë°œê²¬")
        
        # 3. ê° ë°°ì¹˜ íŒŒì¼ íŒŒì‹±
        all_articles = []
        for batch_file in batch_files:
            try:
                articles = self._parse_batch_file(batch_file)
                all_articles.extend(articles)
                self.logger.info(f"ë°°ì¹˜ íŒŒì¼ {batch_file.name} íŒŒì‹± ì™„ë£Œ: {len(articles)}ê°œ ì¡°ë¬¸")
            except Exception as e:
                error_msg = f"ë°°ì¹˜ íŒŒì¼ {batch_file.name} íŒŒì‹± ì‹¤íŒ¨: {e}"
                self.logger.error(error_msg)
                self.stats['parsing_errors'].append(error_msg)
        
        # 4. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if all_articles:
            self._save_articles_to_database(all_articles)
        
        # 5. í†µê³„ ì¶œë ¥
        self._print_statistics()
        
        return self.stats
    
    def _create_articles_table(self):
        """ì¡°ë¬¸ í…Œì´ë¸” ìƒì„±"""
        with self.db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # current_laws_articles í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS current_laws_articles (
                    article_id TEXT PRIMARY KEY,
                    law_id TEXT NOT NULL,
                    law_name_korean TEXT NOT NULL,
                    article_number INTEGER NOT NULL,
                    article_title TEXT,
                    article_content TEXT NOT NULL,
                    paragraph_number INTEGER,
                    paragraph_content TEXT,
                    sub_paragraph_number TEXT,
                    sub_paragraph_content TEXT,
                    is_supplementary BOOLEAN DEFAULT FALSE,
                    amendment_type TEXT,
                    effective_date TEXT,
                    parsing_method TEXT DEFAULT 'batch_parser',
                    quality_score REAL DEFAULT 0.9,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (law_id) REFERENCES current_laws(law_id)
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_current_laws_articles_law_article 
                ON current_laws_articles(law_id, article_number)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_current_laws_articles_law_name 
                ON current_laws_articles(law_name_korean, article_number)
            """)
            
            # FTS í…Œì´ë¸” ìƒì„±
            cursor.execute("""
                CREATE VIRTUAL TABLE IF NOT EXISTS current_laws_articles_fts USING fts5(
                    article_content,
                    article_title,
                    paragraph_content,
                    content='current_laws_articles',
                    content_rowid='rowid'
                )
            """)
            
            self.logger.info("ì¡°ë¬¸ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
    
    def _get_batch_files(self) -> List[Path]:
        """ë°°ì¹˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        pattern = "current_law_batch_*.json"
        batch_files = list(self.batch_dir.glob(pattern))
        
        # ìš”ì•½ íŒŒì¼ ì œì™¸
        batch_files = [f for f in batch_files if "summary" not in f.name]
        
        return sorted(batch_files)
    
    def _parse_batch_file(self, batch_file: Path) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ íŒŒì¼ì—ì„œ ì¡°ë¬¸ ì¶”ì¶œ"""
        with open(batch_file, 'r', encoding='utf-8') as f:
            batch_data = json.load(f)
        
        articles = []
        laws = batch_data.get('laws', [])
        
        for law in laws:
            try:
                law_articles = self._parse_law_articles(law)
                articles.extend(law_articles)
                self.stats['total_laws'] += 1
            except Exception as e:
                self.logger.error(f"ë²•ë ¹ {law.get('ë²•ë ¹ID', 'Unknown')} íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return articles
    
    def _parse_law_articles(self, law: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë²•ë ¹ì—ì„œ ì¡°ë¬¸ ì¶”ì¶œ"""
        articles = []
        
        law_id = law.get('ë²•ë ¹ID', '')
        law_name = law.get('ë²•ë ¹ëª…í•œê¸€', '')
        detailed_info = law.get('detailed_info', {})
        
        if not detailed_info:
            return articles
        
        # ì¡°ë¬¸ ë°°ì—´ ì¶”ì¶œ (detailed_info -> ë²•ë ¹ -> ì¡°ë¬¸ -> ì¡°ë¬¸ë‹¨ìœ„)
        beopryeong = detailed_info.get('ë²•ë ¹', {})
        law_articles_data = beopryeong.get('ì¡°ë¬¸', {})
        law_articles = law_articles_data.get('ì¡°ë¬¸ë‹¨ìœ„', []) if isinstance(law_articles_data, dict) else []
        
        for article_data in law_articles:
            try:
                # ê¸°ë³¸ ì¡°ë¬¸ ì •ë³´ (ë¦¬ìŠ¤íŠ¸ íƒ€ì… ì²˜ë¦¬)
                article_number_raw = article_data.get('ì¡°ë¬¸ë²ˆí˜¸', 0)
                article_number = int(article_number_raw) if not isinstance(article_number_raw, list) else int(article_number_raw[0]) if article_number_raw else 0
                
                article_title_raw = article_data.get('ì¡°ë¬¸ì œëª©', '')
                article_title = article_title_raw if not isinstance(article_title_raw, list) else ' '.join(str(x) for x in article_title_raw) if article_title_raw else ''
                
                article_content_raw = article_data.get('ì¡°ë¬¸ë‚´ìš©', '')
                article_content = article_content_raw if not isinstance(article_content_raw, list) else ' '.join(str(x) for x in article_content_raw) if article_content_raw else ''
                
                amendment_type_raw = article_data.get('ì¡°ë¬¸ì œê°œì •ìœ í˜•', '')
                amendment_type = amendment_type_raw if not isinstance(amendment_type_raw, list) else ' '.join(str(x) for x in amendment_type_raw) if amendment_type_raw else ''
                
                effective_date_raw = article_data.get('ì¡°ë¬¸ì‹œí–‰ì¼ì', '')
                effective_date = effective_date_raw if not isinstance(effective_date_raw, list) else ' '.join(str(x) for x in effective_date_raw) if effective_date_raw else ''
                
                # í•­(paragraph) ì •ë³´ ì¶”ì¶œ
                paragraphs_data = article_data.get('í•­', [])
                
                # í•­ì´ ë°°ì—´ì¸ì§€ ê°ì²´ì¸ì§€ í™•ì¸
                if isinstance(paragraphs_data, dict):
                    # í•­ì´ ê°ì²´ì¸ ê²½ìš° (í˜¸ê°€ ìˆëŠ” ê²½ìš°)
                    paragraphs = [paragraphs_data]
                elif isinstance(paragraphs_data, list):
                    # í•­ì´ ë°°ì—´ì¸ ê²½ìš°
                    paragraphs = paragraphs_data
                else:
                    paragraphs = []
                
                if paragraphs:
                    # ê° í•­ë³„ë¡œ ì €ì¥
                    for para_data in paragraphs:
                        para_number_raw = para_data.get('í•­ë²ˆí˜¸', '')
                        para_number = self._extract_paragraph_number(para_number_raw)
                        
                        para_content_raw = para_data.get('í•­ë‚´ìš©', '')
                        para_content = para_content_raw if not isinstance(para_content_raw, list) else ' '.join(str(x) for x in para_content_raw) if para_content_raw else ''
                        
                        # í˜¸(sub-paragraph) ì •ë³´ ì¶”ì¶œ
                        sub_paragraphs_data = para_data.get('í˜¸', [])
                        
                        if isinstance(sub_paragraphs_data, list) and sub_paragraphs_data:
                            # ê° í˜¸ë³„ë¡œ ì €ì¥
                            for sub_para_data in sub_paragraphs_data:
                                sub_para_number_raw = sub_para_data.get('í˜¸ë²ˆí˜¸', '')
                                sub_para_number = sub_para_number_raw if not isinstance(sub_para_number_raw, list) else ' '.join(str(x) for x in sub_para_number_raw) if sub_para_number_raw else ''
                                
                                sub_para_content_raw = sub_para_data.get('í˜¸ë‚´ìš©', '')
                                sub_para_content = sub_para_content_raw if not isinstance(sub_para_content_raw, list) else ' '.join(str(x) for x in sub_para_content_raw) if sub_para_content_raw else ''
                                
                                article_id = f"{law_id}_{article_number}_{para_number}_{sub_para_number}"
                                
                                articles.append({
                                    'article_id': article_id,
                                    'law_id': law_id,
                                    'law_name_korean': law_name,
                                    'article_number': article_number,
                                    'article_title': article_title,
                                    'article_content': article_content,
                                    'paragraph_number': para_number,
                                    'paragraph_content': para_content,
                                    'sub_paragraph_number': sub_para_number,
                                    'sub_paragraph_content': sub_para_content,
                                    'is_supplementary': False,
                                    'amendment_type': amendment_type,
                                    'effective_date': effective_date,
                                    'parsing_method': 'batch_parser',
                                    'quality_score': 0.9
                                })
                                
                                self.stats['total_paragraphs'] += 1
                        else:
                            # í•­ë§Œ ìˆëŠ” ê²½ìš°
                            article_id = f"{law_id}_{article_number}_{para_number}"
                            
                            articles.append({
                                'article_id': article_id,
                                'law_id': law_id,
                                'law_name_korean': law_name,
                                'article_number': article_number,
                                'article_title': article_title,
                                'article_content': article_content,
                                'paragraph_number': para_number,
                                'paragraph_content': para_content,
                                'is_supplementary': False,
                                'amendment_type': amendment_type,
                                'effective_date': effective_date,
                                'parsing_method': 'batch_parser',
                                'quality_score': 0.9
                            })
                            
                            self.stats['total_paragraphs'] += 1
                else:
                    # ì¡°ë¬¸ë§Œ ìˆëŠ” ê²½ìš°
                    article_id = f"{law_id}_{article_number}"
                    
                    articles.append({
                        'article_id': article_id,
                        'law_id': law_id,
                        'law_name_korean': law_name,
                        'article_number': article_number,
                        'article_title': article_title,
                        'article_content': article_content,
                        'is_supplementary': False,
                        'amendment_type': amendment_type,
                        'effective_date': effective_date,
                        'parsing_method': 'batch_parser',
                        'quality_score': 0.9
                    })
                
                self.stats['total_articles'] += 1
                
            except Exception as e:
                self.logger.error(f"ì¡°ë¬¸ {article_data.get('ì¡°ë¬¸ë²ˆí˜¸', 'Unknown')} íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return articles
    
    def _extract_paragraph_number(self, para_number_str: str) -> int:
        """í•­ë²ˆí˜¸ ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        if not para_number_str:
            return 0
        
        # â‘ , â‘¡, â‘¢... í˜•íƒœì—ì„œ ìˆ«ì ì¶”ì¶œ
        if para_number_str in ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤', 'â‘¥', 'â‘¦', 'â‘§', 'â‘¨', 'â‘©']:
            return ['â‘ ', 'â‘¡', 'â‘¢', 'â‘£', 'â‘¤', 'â‘¥', 'â‘¦', 'â‘§', 'â‘¨', 'â‘©'].index(para_number_str) + 1
        
        # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
        try:
            return int(para_number_str)
        except ValueError:
            return 0
    
    def _save_articles_to_database(self, articles: List[Dict[str, Any]]):
        """ì¡°ë¬¸ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        self.logger.info(f"ì´ {len(articles)}ê°œ ì¡°ë¬¸ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
        
        batch_size = 100
        total_inserted = 0
        
        for i in range(0, len(articles), batch_size):
            batch = articles[i:i + batch_size]
            
            try:
                inserted_count = self._insert_articles_batch(batch)
                total_inserted += inserted_count
                self.logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì €ì¥ ì™„ë£Œ: {inserted_count}ê°œ")
            except Exception as e:
                self.logger.error(f"ë°°ì¹˜ {i//batch_size + 1} ì €ì¥ ì‹¤íŒ¨: {e}")
        
        self.logger.info(f"ì´ {total_inserted}ê°œ ì¡°ë¬¸ ì €ì¥ ì™„ë£Œ")
    
    def _insert_articles_batch(self, articles: List[Dict[str, Any]]) -> int:
        """ì¡°ë¬¸ ë°°ì¹˜ ì‚½ì…"""
        query = """
            INSERT OR REPLACE INTO current_laws_articles (
                article_id, law_id, law_name_korean, article_number,
                article_title, article_content, paragraph_number, paragraph_content,
                sub_paragraph_number, sub_paragraph_content, is_supplementary,
                amendment_type, effective_date, parsing_method, quality_score
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        with self.db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            params_list = []
            for article in articles:
                params = (
                    article['article_id'],
                    article['law_id'],
                    article['law_name_korean'],
                    article['article_number'],
                    article['article_title'],
                    article['article_content'],
                    article.get('paragraph_number'),
                    article.get('paragraph_content'),
                    article.get('sub_paragraph_number'),
                    article.get('sub_paragraph_content'),
                    article['is_supplementary'],
                    article.get('amendment_type'),
                    article.get('effective_date'),
                    article['parsing_method'],
                    article['quality_score']
                )
                params_list.append(params)
            
            cursor.executemany(query, params_list)
            conn.commit()
            
            return len(params_list)
    
    def _print_statistics(self):
        """í†µê³„ ì •ë³´ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ë°°ì¹˜ íŒŒì¼ íŒŒì‹± í†µê³„")
        print("="*60)
        print(f"ì´ ë°°ì¹˜ íŒŒì¼: {self.stats['total_batches']:,}ê°œ")
        print(f"ì´ ë²•ë ¹: {self.stats['total_laws']:,}ê°œ")
        print(f"ì´ ì¡°ë¬¸: {self.stats['total_articles']:,}ê°œ")
        print(f"ì´ í•­/í˜¸: {self.stats['total_paragraphs']:,}ê°œ")
        print(f"íŒŒì‹± ì˜¤ë¥˜: {len(self.stats['parsing_errors'])}ê°œ")
        
        if self.stats['parsing_errors']:
            print("\nâš ï¸ íŒŒì‹± ì˜¤ë¥˜ ëª©ë¡:")
            for error in self.stats['parsing_errors'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"  - {error}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    batch_dir = "data/raw/law_open_api/current_laws/batches"
    
    if not Path(batch_dir).exists():
        print(f"âŒ ë°°ì¹˜ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {batch_dir}")
        return
    
    parser = BatchArticleParser(batch_dir)
    stats = parser.parse_all_batches()
    
    print(f"\nğŸ‰ ë°°ì¹˜ íŒŒì¼ íŒŒì‹± ì™„ë£Œ!")
    print(f"ì´ {stats['total_articles']:,}ê°œ ì¡°ë¬¸ì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
