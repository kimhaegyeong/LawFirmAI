# -*- coding: utf-8 -*-
"""
ë²•ë¥  ìš©ì–´ ì‚¬ì „ í’ˆì§ˆ ê²€ì¦ ë° ë¶„ì„
"""

import json
import os
from typing import Dict, List, Any
from collections import Counter
import statistics

def analyze_legal_term_dictionary(file_path: str) -> Dict[str, Any]:
    """ë²•ë¥  ìš©ì–´ ì‚¬ì „ ë¶„ì„"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    dictionary = data.get('dictionary', {})
    metadata = data.get('metadata', {})
    
    # ê¸°ë³¸ í†µê³„
    total_terms = len(dictionary)
    domains = metadata.get('domains', [])
    
    # ìš©ì–´ë³„ ë¶„ì„
    term_stats = {
        'total_terms': total_terms,
        'domains': domains,
        'synonyms_count': [],
        'related_terms_count': [],
        'precedent_keywords_count': [],
        'confidence_scores': [],
        'domain_distribution': {},
        'quality_metrics': {}
    }
    
    # ë„ë©”ì¸ë³„ ë¶„í¬ ê³„ì‚°
    domain_counts = Counter()
    
    for term, expansion in dictionary.items():
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ìš©ì–´ ìˆ˜
        synonyms_count = len(expansion.get('synonyms', []))
        related_count = len(expansion.get('related_terms', []))
        keywords_count = len(expansion.get('precedent_keywords', []))
        confidence = expansion.get('confidence', 0.0)
        
        term_stats['synonyms_count'].append(synonyms_count)
        term_stats['related_terms_count'].append(related_count)
        term_stats['precedent_keywords_count'].append(keywords_count)
        term_stats['confidence_scores'].append(confidence)
        
        # ë„ë©”ì¸ë³„ ë¶„ë¥˜ (ìš©ì–´ëª…ìœ¼ë¡œ ì¶”ì •)
        domain = classify_term_domain(term)
        domain_counts[domain] += 1
    
    term_stats['domain_distribution'] = dict(domain_counts)
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
    quality_metrics = {
        'avg_synonyms_per_term': statistics.mean(term_stats['synonyms_count']),
        'avg_related_terms_per_term': statistics.mean(term_stats['related_terms_count']),
        'avg_keywords_per_term': statistics.mean(term_stats['precedent_keywords_count']),
        'avg_confidence': statistics.mean(term_stats['confidence_scores']),
        'min_confidence': min(term_stats['confidence_scores']),
        'max_confidence': max(term_stats['confidence_scores']),
        'terms_with_high_confidence': len([c for c in term_stats['confidence_scores'] if c >= 0.9]),
        'terms_with_medium_confidence': len([c for c in term_stats['confidence_scores'] if 0.7 <= c < 0.9]),
        'terms_with_low_confidence': len([c for c in term_stats['confidence_scores'] if c < 0.7])
    }
    
    term_stats['quality_metrics'] = quality_metrics
    
    return term_stats

def classify_term_domain(term: str) -> str:
    """ìš©ì–´ë¥¼ ë„ë©”ì¸ë³„ë¡œ ë¶„ë¥˜"""
    
    # ë¯¼ì‚¬ë²• ê´€ë ¨ ìš©ì–´
    civil_terms = ['ì†í•´ë°°ìƒ', 'ê³„ì•½', 'ì†Œìœ ê¶Œ', 'ì„ëŒ€ì°¨', 'ë¶ˆë²•í–‰ìœ„', 'ì±„ê¶Œ', 'ì±„ë¬´', 'ë‹´ë³´', 'ë³´ì¦', 'ì—°ëŒ€', 'ë¶ˆê°€ë¶„', 'ë¶„í• ', 'ìƒì†', 'ìœ ì–¸', 'ìœ ì¦', 'ë¶€ì–‘', 'í˜¼ì¸', 'ì´í˜¼', 'ì¹œì']
    
    # í˜•ì‚¬ë²• ê´€ë ¨ ìš©ì–´
    criminal_terms = ['ì‚´ì¸', 'ì ˆë„', 'ì‚¬ê¸°', 'ê°•ë„', 'ê°•ê°„', 'í­í–‰', 'ìƒí•´', 'í˜‘ë°•', 'ê°ê¸ˆ', 'ì•½ì·¨', 'ìœ ì¸', 'ê°•ì œì¶”í–‰', 'ëª…ì˜ˆí›¼ì†', 'ëª¨ë…', 'ì£¼ê±°ì¹¨ì…', 'ë°©í™”', 'ê³µê°ˆ', 'íš¡ë ¹', 'ë°°ì„']
    
    # ìƒì‚¬ë²• ê´€ë ¨ ìš©ì–´
    commercial_terms = ['ì£¼ì‹íšŒì‚¬', 'ìœ í•œíšŒì‚¬', 'ìƒí–‰ìœ„', 'ì–´ìŒ', 'ìˆ˜í‘œ', 'ë³´í—˜', 'í•´ìƒ', 'í•­ê³µ', 'ìš´ì†¡', 'ìœ„ì„', 'ë„ê¸‰', 'ì„ì¹˜', 'ì¡°í•©', 'í•©ì', 'í•©ëª…', 'ìƒí˜¸', 'ìƒí‘œ', 'íŠ¹í—ˆ', 'ì €ì‘ê¶Œ']
    
    # í–‰ì •ë²• ê´€ë ¨ ìš©ì–´
    administrative_terms = ['í–‰ì •ì²˜ë¶„', 'í–‰ì •ì§€ë„', 'í—ˆê°€', 'ì¸ê°€', 'ìŠ¹ì¸', 'ì‹ ê³ ', 'ì‹ ì²­', 'ì²­ì›', 'ì´ì˜ì‹ ì²­', 'í–‰ì •ì‹¬íŒ', 'í–‰ì •ì†Œì†¡', 'êµ­ê°€ë°°ìƒ', 'ì†ì‹¤ë³´ìƒ', 'í–‰ì •ê·œì¹™', 'í–‰ì •ê³„íš', 'í–‰ì •ê³„ì•½', 'ê³µë²•ê´€ê³„', 'ì‚¬ë²•ê´€ê³„']
    
    # ë…¸ë™ë²• ê´€ë ¨ ìš©ì–´
    labor_terms = ['ê·¼ë¡œê³„ì•½', 'ì„ê¸ˆ', 'ê·¼ë¡œì‹œê°„', 'í•´ê³ ', 'ë¶€ë‹¹í•´ê³ ', 'í‡´ì§ê¸ˆ', 'ì‹¤ì—…ê¸‰ì—¬', 'ì‚°ì—…ì¬í•´', 'ì‚°ì—…ì•ˆì „', 'ë…¸ë™ì¡°í•©', 'ë‹¨ì²´êµì„­', 'ë‹¨ì²´í˜‘ì•½', 'ìŸì˜í–‰ìœ„', 'íŒŒì—…', 'ì§ì¥íì‡„', 'ë…¸ë™ìŸì˜', 'ê·¼ë¡œê¸°ì¤€', 'ìµœì €ì„ê¸ˆ', 'ì—°ì¥ê·¼ë¡œ', 'íœ´ê²Œì‹œê°„']
    
    if term in civil_terms:
        return 'ë¯¼ì‚¬ë²•'
    elif term in criminal_terms:
        return 'í˜•ì‚¬ë²•'
    elif term in commercial_terms:
        return 'ìƒì‚¬ë²•'
    elif term in administrative_terms:
        return 'í–‰ì •ë²•'
    elif term in labor_terms:
        return 'ë…¸ë™ë²•'
    else:
        return 'ê¸°íƒ€'

def generate_quality_report(stats: Dict[str, Any]) -> str:
    """í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±"""
    
    report = []
    report.append("=" * 60)
    report.append("ë²•ë¥  ìš©ì–´ ì‚¬ì „ í’ˆì§ˆ ë¶„ì„ ë³´ê³ ì„œ")
    report.append("=" * 60)
    
    # ê¸°ë³¸ ì •ë³´
    report.append(f"\nğŸ“Š ê¸°ë³¸ í†µê³„:")
    report.append(f"  â€¢ ì´ ìš©ì–´ ìˆ˜: {stats['total_terms']}ê°œ")
    report.append(f"  â€¢ ë„ë©”ì¸ ìˆ˜: {len(stats['domains'])}ê°œ")
    report.append(f"  â€¢ ë„ë©”ì¸: {', '.join(stats['domains'])}")
    
    # ë„ë©”ì¸ë³„ ë¶„í¬
    report.append(f"\nğŸ“ˆ ë„ë©”ì¸ë³„ ë¶„í¬:")
    for domain, count in stats['domain_distribution'].items():
        percentage = (count / stats['total_terms']) * 100
        report.append(f"  â€¢ {domain}: {count}ê°œ ({percentage:.1f}%)")
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    metrics = stats['quality_metrics']
    report.append(f"\nğŸ¯ í’ˆì§ˆ ë©”íŠ¸ë¦­:")
    report.append(f"  â€¢ í‰ê·  ë™ì˜ì–´ ìˆ˜: {metrics['avg_synonyms_per_term']:.2f}ê°œ")
    report.append(f"  â€¢ í‰ê·  ê´€ë ¨ ìš©ì–´ ìˆ˜: {metrics['avg_related_terms_per_term']:.2f}ê°œ")
    report.append(f"  â€¢ í‰ê·  íŒë¡€ í‚¤ì›Œë“œ ìˆ˜: {metrics['avg_keywords_per_term']:.2f}ê°œ")
    report.append(f"  â€¢ í‰ê·  ì‹ ë¢°ë„: {metrics['avg_confidence']:.3f}")
    report.append(f"  â€¢ ìµœì†Œ ì‹ ë¢°ë„: {metrics['min_confidence']:.3f}")
    report.append(f"  â€¢ ìµœëŒ€ ì‹ ë¢°ë„: {metrics['max_confidence']:.3f}")
    
    # ì‹ ë¢°ë„ ë¶„í¬
    report.append(f"\nğŸ“Š ì‹ ë¢°ë„ ë¶„í¬:")
    report.append(f"  â€¢ ê³ ì‹ ë¢°ë„ (â‰¥0.9): {metrics['terms_with_high_confidence']}ê°œ")
    report.append(f"  â€¢ ì¤‘ì‹ ë¢°ë„ (0.7-0.9): {metrics['terms_with_medium_confidence']}ê°œ")
    report.append(f"  â€¢ ì €ì‹ ë¢°ë„ (<0.7): {metrics['terms_with_low_confidence']}ê°œ")
    
    # í’ˆì§ˆ í‰ê°€
    report.append(f"\nâ­ í’ˆì§ˆ í‰ê°€:")
    
    # ì „ì²´ì ì¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = 0
    
    # ì‹ ë¢°ë„ ì ìˆ˜ (40%)
    avg_confidence = metrics['avg_confidence']
    confidence_score = avg_confidence * 40
    quality_score += confidence_score
    
    # ìš©ì–´ ë‹¤ì–‘ì„± ì ìˆ˜ (30%)
    avg_total_terms = (metrics['avg_synonyms_per_term'] + 
                      metrics['avg_related_terms_per_term'] + 
                      metrics['avg_keywords_per_term']) / 3
    diversity_score = min(avg_total_terms / 5, 1.0) * 30
    quality_score += diversity_score
    
    # ë„ë©”ì¸ ê· í˜• ì ìˆ˜ (20%)
    domain_balance = 1.0 - (max(stats['domain_distribution'].values()) - min(stats['domain_distribution'].values())) / stats['total_terms']
    balance_score = domain_balance * 20
    quality_score += balance_score
    
    # ì™„ì„±ë„ ì ìˆ˜ (10%)
    completion_score = 10  # ëª¨ë“  ìš©ì–´ê°€ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ
    quality_score += completion_score
    
    report.append(f"  â€¢ ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
    report.append(f"    - ì‹ ë¢°ë„ ì ìˆ˜: {confidence_score:.1f}/40")
    report.append(f"    - ë‹¤ì–‘ì„± ì ìˆ˜: {diversity_score:.1f}/30")
    report.append(f"    - ê· í˜• ì ìˆ˜: {balance_score:.1f}/20")
    report.append(f"    - ì™„ì„±ë„ ì ìˆ˜: {completion_score:.1f}/10")
    
    # ë“±ê¸‰ í‰ê°€
    if quality_score >= 90:
        grade = "A+ (ìš°ìˆ˜)"
    elif quality_score >= 80:
        grade = "A (ì–‘í˜¸)"
    elif quality_score >= 70:
        grade = "B (ë³´í†µ)"
    elif quality_score >= 60:
        grade = "C (ê°œì„  í•„ìš”)"
    else:
        grade = "D (ì¬ì‘ì—… í•„ìš”)"
    
    report.append(f"  â€¢ ë“±ê¸‰: {grade}")
    
    report.append(f"\nâœ… ê²°ë¡ :")
    report.append(f"  ë²•ë¥  ìš©ì–´ ì‚¬ì „ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.")
    report.append(f"  ì´ {stats['total_terms']}ê°œ ìš©ì–´ê°€ {len(stats['domains'])}ê°œ ë„ë©”ì¸ì— ê±¸ì³ í™•ì¥ë˜ì—ˆìœ¼ë©°,")
    report.append(f"  í‰ê·  ì‹ ë¢°ë„ {metrics['avg_confidence']:.3f}ë¡œ ë†’ì€ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤.")
    
    return "\n".join(report)

def safe_print(text: str):
    """ì•ˆì „í•œ í•œê¸€ ì¶œë ¥ í•¨ìˆ˜"""
    try:
        # íŒŒì¼ë¡œ ì¶œë ¥í•˜ì—¬ í•œê¸€ ë¬¸ì œ í•´ê²°
        with open('quality_analysis_output.txt', 'a', encoding='utf-8') as f:
            f.write(text + '\n')
        
        # ì½˜ì†” ì¶œë ¥ì€ ASCIIë¡œ ë³€í™˜í•˜ì—¬ ê¹¨ì§ ë°©ì§€
        try:
            ascii_text = text.encode('ascii', 'ignore').decode('ascii')
            if ascii_text.strip():
                print(ascii_text)
        except:
            print("[í•œê¸€ ì¶œë ¥ - quality_analysis_output.txt íŒŒì¼ ì°¸ì¡°]")
    except Exception:
        # ê¸°íƒ€ ì˜¤ë¥˜ ì‹œ ì›ë³¸ ì¶œë ¥
        print(text)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ
    file_path = "data/comprehensive_legal_term_dictionary.json"
    
    if not os.path.exists(file_path):
        safe_print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return
    
    safe_print("ë²•ë¥  ìš©ì–´ ì‚¬ì „ í’ˆì§ˆ ë¶„ì„ ì‹œì‘...")
    
    try:
        # ë¶„ì„ ì‹¤í–‰
        stats = analyze_legal_term_dictionary(file_path)
        
        # ë³´ê³ ì„œ ìƒì„±
        report = generate_quality_report(stats)
        
        # ë³´ê³ ì„œ ì¶œë ¥
        safe_print(report)
        
        # ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ì¥
        with open("data/quality_analysis_report.txt", 'w', encoding='utf-8') as f:
            f.write(report)
        
        safe_print(f"\nìƒì„¸ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: data/quality_analysis_report.txt")
        
    except Exception as e:
        safe_print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
