"""
Legal Structure Parser for Korean Law Data

This module parses the structural elements of Korean laws including
articles, paragraphs, subparagraphs, enforcement clauses, and amendment history.
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)


class LegalStructureParser:
    """Î≤ïÎ•† Íµ¨Ï°∞ Î∂ÑÏÑùÍ∏?""
    
    def __init__(self):
        """Initialize structure parser with Korean legal structure patterns"""
        self.structure_patterns = {
            'articles': re.compile(r'??\d+)Ï°?s*\(([^)]+)\)'),
            'paragraphs': re.compile(r'??\d+)??),
            'subparagraphs': re.compile(r'??\d+)??),
            'items': re.compile(r'??\d+)Î™?),
            'numbered_items': re.compile(r'(\d+)\.'),
            'lettered_items': re.compile(r'([Í∞Ä-??)\.'),
            'enforcement_clause': re.compile(r'\[?úÌñâ\s+([^\]]+)\]'),
            'amendment_clause': re.compile(r'<Í∞úÏ†ï\s+([^>]+)>'),
            'supplementary_provisions': re.compile(r'Î∂ÄÏπ?s*<([^>]+)>'),
            'purpose_clause': re.compile(r'??Ï°?s*\(Î™©Ï†Å\)'),
            'definition_clause': re.compile(r'??Ï°?s*\(?ïÏùò\)'),
            'scope_clause': re.compile(r'??Ï°?s*\(?ÅÏö©Î≤îÏúÑ\)')
        }
        
        # ?πÎ≥Ñ??Íµ¨Ï°∞ ?®ÌÑ¥??
        self.special_patterns = {
            'penalty_clause': re.compile(r'??d+Ï°?s*\(Î≤åÏπô\)'),
            'transitional_clause': re.compile(r'??d+Ï°?s*\(Í≤ΩÍ≥ºÏ°∞Ïπò\)'),
            'delegation_clause': re.compile(r'??d+Ï°?s*\(?ÑÏûÑ\)'),
            'enforcement_clause': re.compile(r'??d+Ï°?s*\(?úÌñâ\)')
        }
    
    def parse_legal_structure(self, law_content: str) -> Dict[str, Any]:
        """
        Î≤ïÎ•† Íµ¨Ï°∞ Î∂ÑÏÑù
        
        Args:
            law_content (str): Law content text
            
        Returns:
            Dict[str, Any]: Structure analysis results
        """
        try:
            structure_info = {
                'total_articles': 0,
                'total_paragraphs': 0,
                'total_subparagraphs': 0,
                'total_items': 0,
                'articles': [],
                'enforcement_info': {},
                'amendment_history': [],
                'supplementary_provisions': [],
                'special_clauses': [],
                'structure_complexity': 0.0,
                'structure_type': 'unknown',
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            # Ï°∞Î¨∏ Î∂ÑÏÑù
            articles = self._parse_articles(law_content)
            structure_info['articles'] = articles
            structure_info['total_articles'] = len(articles)
            
            # ?? ?? Î™?Î∂ÑÏÑù
            total_paragraphs = 0
            total_subparagraphs = 0
            total_items = 0
            
            for article in articles:
                article_content = article.get('content', '')
                if article_content:
                    paragraphs = self._parse_paragraphs(article_content)
                    total_paragraphs += len(paragraphs)
                    
                    for paragraph in paragraphs:
                        paragraph_content = paragraph.get('content', '')
                        if paragraph_content:
                            subparagraphs = self._parse_subparagraphs(paragraph_content)
                            total_subparagraphs += len(subparagraphs)
                            
                            for subparagraph in subparagraphs:
                                subparagraph_content = subparagraph.get('content', '')
                                if subparagraph_content:
                                    items = self._parse_items(subparagraph_content)
                                    total_items += len(items)
            
            structure_info['total_paragraphs'] = total_paragraphs
            structure_info['total_subparagraphs'] = total_subparagraphs
            structure_info['total_items'] = total_items
            
            # ?úÌñâ Ï°∞Ìï≠ Î∂ÑÏÑù
            structure_info['enforcement_info'] = self._parse_enforcement_clause(law_content)
            
            # Í∞úÏ†ï ?¥Î†• Î∂ÑÏÑù
            structure_info['amendment_history'] = self._parse_amendment_history(law_content)
            
            # Î∂ÄÏπ?Î∂ÑÏÑù
            structure_info['supplementary_provisions'] = self._parse_supplementary_provisions(law_content)
            
            # ?πÎ≥Ñ Ï°∞Ìï≠ Î∂ÑÏÑù
            structure_info['special_clauses'] = self._parse_special_clauses(law_content)
            
            # Íµ¨Ï°∞ Î≥µÏû°??Í≥ÑÏÇ∞
            structure_info['structure_complexity'] = self._calculate_complexity(structure_info)
            
            # Íµ¨Ï°∞ ?†Ìòï Í≤∞Ï†ï
            structure_info['structure_type'] = self._determine_structure_type(structure_info)
            
            return structure_info
            
        except Exception as e:
            logger.error(f"Error parsing legal structure: {e}")
            return {
                'total_articles': 0,
                'structure_complexity': 0.0,
                'error': str(e)
            }
    
    def _parse_articles(self, content: str) -> List[Dict[str, Any]]:
        """Ï°∞Î¨∏ ?åÏã±"""
        articles = []
        article_matches = self.structure_patterns['articles'].findall(content)
        
        for match in article_matches:
            article_num = match[0]
            article_title = match[1]
            
            # Ï°∞Î¨∏ ?¥Ïö© Ï∂îÏ∂ú
            article_pattern = f'??article_num}Ï°?\s*\\([^)]+\\)'
            article_match = re.search(article_pattern, content)
            
            if article_match:
                start_pos = article_match.end()
                # ?§Ïùå Ï°∞Î¨∏ÍπåÏ????¥Ïö© Ï∂îÏ∂ú
                next_article_pattern = f'??int(article_num)+1}Ï°?
                next_match = re.search(next_article_pattern, content)
                
                if next_match:
                    end_pos = next_match.start()
                else:
                    end_pos = len(content)
                
                article_content = content[start_pos:end_pos].strip()
                
                # Ï°∞Î¨∏ ?†Ìòï Î∂ÑÏÑù
                article_type = self._analyze_article_type(article_title, article_content)
                
                # Safe parsing with error handling
                try:
                    paragraphs = self._parse_paragraphs(article_content) if article_content else []
                    
                    articles.append({
                        'article_number': f'??article_num}Ï°?,
                        'article_title': article_title,
                        'content': article_content,  # Use 'content' key for consistency
                        'article_type': article_type,
                        'paragraphs': paragraphs
                    })
                except Exception as e:
                    logger.warning(f"Error parsing article {article_num}: {e}")
                    # Add minimal article info
                    articles.append({
                        'article_number': f'??article_num}Ï°?,
                        'article_title': article_title,
                        'content': article_content,
                        'article_type': 'unknown',
                        'paragraphs': []
                    })
        
        return articles
    
    def _parse_paragraphs(self, content: str) -> List[Dict[str, Any]]:
        """???åÏã±"""
        paragraphs = []
        paragraph_matches = self.structure_patterns['paragraphs'].findall(content)
        
        for match in paragraph_matches:
            para_num = match
            paragraph_pattern = f'??para_num}??
            para_match = re.search(paragraph_pattern, content)
            
            if para_match:
                start_pos = para_match.end()
                # ?§Ïùå ??πåÏßÄ???¥Ïö© Ï∂îÏ∂ú
                next_para_pattern = f'??int(para_num)+1}??
                next_match = re.search(next_para_pattern, content)
                
                if next_match:
                    end_pos = next_match.start()
                else:
                    end_pos = len(content)
                
                paragraph_content = content[start_pos:end_pos].strip()
                
                # Safe parsing with error handling
                try:
                    subparagraphs = self._parse_subparagraphs(paragraph_content) if paragraph_content else []
                    
                    paragraphs.append({
                        'paragraph_number': f'??para_num}??,
                        'content': paragraph_content,  # Use 'content' key for consistency
                        'subparagraphs': subparagraphs
                    })
                except Exception as e:
                    logger.warning(f"Error parsing paragraph {para_num}: {e}")
                    paragraphs.append({
                        'paragraph_number': f'??para_num}??,
                        'content': paragraph_content,
                        'subparagraphs': []
                    })
        
        return paragraphs
    
    def _parse_subparagraphs(self, content: str) -> List[Dict[str, Any]]:
        """???åÏã±"""
        subparagraphs = []
        subpara_matches = self.structure_patterns['subparagraphs'].findall(content)
        
        for match in subpara_matches:
            subpara_num = match
            subpara_pattern = f'??subpara_num}??
            subpara_match = re.search(subpara_pattern, content)
            
            if subpara_match:
                start_pos = subpara_match.end()
                # ?§Ïùå ?∏ÍπåÏßÄ???¥Ïö© Ï∂îÏ∂ú
                next_subpara_pattern = f'??int(subpara_num)+1}??
                next_match = re.search(next_subpara_pattern, content)
                
                if next_match:
                    end_pos = next_match.start()
                else:
                    end_pos = len(content)
                
                subpara_content = content[start_pos:end_pos].strip()
                
                # Safe parsing with error handling
                try:
                    items = self._parse_items(subpara_content) if subpara_content else []
                    
                    subparagraphs.append({
                        'subparagraph_number': f'??subpara_num}??,
                        'content': subpara_content,  # Use 'content' key for consistency
                        'items': items
                    })
                except Exception as e:
                    logger.warning(f"Error parsing subparagraph {subpara_num}: {e}")
                    subparagraphs.append({
                        'subparagraph_number': f'??subpara_num}??,
                        'content': subpara_content,
                        'items': []
                    })
        
        return subparagraphs
    
    def _parse_items(self, content: str) -> List[Dict[str, Any]]:
        """Î™??åÏã±"""
        items = []
        
        # ?´Ïûê Î™?(1., 2., 3.)
        numbered_matches = self.structure_patterns['numbered_items'].findall(content)
        for match in numbered_matches:
            item_num = match
            item_pattern = f'{item_num}\\.'
            item_match = re.search(item_pattern, content)
            
            if item_match:
                start_pos = item_match.end()
                # ?§Ïùå Î™©ÍπåÏßÄ???¥Ïö© Ï∂îÏ∂ú
                next_item_pattern = f'{int(item_num)+1}\\.'
                next_match = re.search(next_item_pattern, content)
                
                if next_match:
                    end_pos = next_match.start()
                else:
                    end_pos = len(content)
                
                item_content = content[start_pos:end_pos].strip()
                
                items.append({
                    'item_number': f'{item_num}.',
                    'item_content': item_content,
                    'item_type': 'numbered'
                })
        
        # Î¨∏Ïûê Î™?(Í∞Ä., ??, ??)
        lettered_matches = self.structure_patterns['lettered_items'].findall(content)
        for match in lettered_matches:
            item_letter = match
            item_pattern = f'{item_letter}\\.'
            item_match = re.search(item_pattern, content)
            
            if item_match:
                start_pos = item_match.end()
                # ?§Ïùå Î™©ÍπåÏßÄ???¥Ïö© Ï∂îÏ∂ú
                next_item_pattern = f'{chr(ord(item_letter)+1)}\\.'
                next_match = re.search(next_item_pattern, content)
                
                if next_match:
                    end_pos = next_match.start()
                else:
                    end_pos = len(content)
                
                item_content = content[start_pos:end_pos].strip()
                
                # Validate item content to avoid empty content errors
                if item_content and len(item_content) > 0:
                    items.append({
                        'item_number': f'{item_letter}.',
                        'item_content': item_content,
                        'item_type': 'lettered'
                    })
        
        return items
    
    def _parse_enforcement_clause(self, content: str) -> Dict[str, Any]:
        """?úÌñâ Ï°∞Ìï≠ ?åÏã±"""
        enforcement_match = self.structure_patterns['enforcement_clause'].search(content)
        
        if enforcement_match:
            enforcement_text = enforcement_match.group(1)
            return {
                'enforcement_date': enforcement_text,
                'enforcement_text': f'[?úÌñâ {enforcement_text}]',
                'parsed_date': self._parse_date(enforcement_text),
                'enforcement_type': 'standard'
            }
        
        return {}
    
    def _parse_amendment_history(self, content: str) -> List[Dict[str, Any]]:
        """Í∞úÏ†ï ?¥Î†• ?åÏã±"""
        amendments = []
        amendment_matches = self.structure_patterns['amendment_clause'].findall(content)
        
        for match in amendment_matches:
            amendment_text = match
            amendments.append({
                'amendment_text': f'<Í∞úÏ†ï {amendment_text}>',
                'amendment_info': amendment_text,
                'parsed_date': self._parse_date(amendment_text),
                'amendment_type': self._classify_amendment_type(amendment_text)
            })
        
        return amendments
    
    def _parse_supplementary_provisions(self, content: str) -> List[Dict[str, Any]]:
        """Î∂ÄÏπ??åÏã±"""
        provisions = []
        provision_matches = self.structure_patterns['supplementary_provisions'].findall(content)
        
        for match in provision_matches:
            provision_text = match
            provisions.append({
                'provision_text': f'Î∂ÄÏπ?<{provision_text}>',
                'provision_info': provision_text,
                'provision_type': self._classify_provision_type(provision_text)
            })
        
        return provisions
    
    def _parse_special_clauses(self, content: str) -> List[Dict[str, Any]]:
        """?πÎ≥Ñ Ï°∞Ìï≠ ?åÏã±"""
        special_clauses = []
        
        for clause_type, pattern in self.special_patterns.items():
            matches = pattern.findall(content)
            for match in matches:
                special_clauses.append({
                    'clause_type': clause_type,
                    'clause_text': match,
                    'clause_number': self._extract_clause_number(match)
                })
        
        return special_clauses
    
    def _analyze_article_type(self, title: str, content: str) -> str:
        """Ï°∞Î¨∏ ?†Ìòï Î∂ÑÏÑù"""
        title_lower = title.lower()
        
        if 'Î™©Ï†Å' in title:
            return 'purpose'
        elif '?ïÏùò' in title:
            return 'definition'
        elif '?ÅÏö©Î≤îÏúÑ' in title:
            return 'scope'
        elif 'Î≤åÏπô' in title:
            return 'penalty'
        elif 'Í≤ΩÍ≥ºÏ°∞Ïπò' in title:
            return 'transitional'
        elif '?ÑÏûÑ' in title:
            return 'delegation'
        elif '?úÌñâ' in title:
            return 'enforcement'
        else:
            return 'general'
    
    def _classify_amendment_type(self, amendment_text: str) -> str:
        """Í∞úÏ†ï ?†Ìòï Î∂ÑÎ•ò"""
        if '?ºÎ?Í∞úÏ†ï' in amendment_text:
            return 'partial_amendment'
        elif '?ÑÎ?Í∞úÏ†ï' in amendment_text:
            return 'full_amendment'
        elif '?†ÏÑ§' in amendment_text:
            return 'new_establishment'
        elif '?êÏ?' in amendment_text:
            return 'abolition'
        else:
            return 'unknown'
    
    def _classify_provision_type(self, provision_text: str) -> str:
        """Î∂ÄÏπ??†Ìòï Î∂ÑÎ•ò"""
        if '?úÌñâ' in provision_text:
            return 'enforcement'
        elif 'Í≤ΩÍ≥º' in provision_text:
            return 'transitional'
        elif '?ÑÏûÑ' in provision_text:
            return 'delegation'
        else:
            return 'general'
    
    def _extract_clause_number(self, clause_text: str) -> str:
        """Ï°∞Ìï≠ Î≤àÌò∏ Ï∂îÏ∂ú"""
        number_match = re.search(r'??\d+)Ï°?, clause_text)
        return number_match.group(1) if number_match else ''
    
    def _parse_date(self, date_text: str) -> Optional[str]:
        """?†Ïßú ?åÏã±"""
        # ?§Ïñë???†Ïßú ?ïÏãù ÏßÄ??
        date_patterns = [
            r'(\d{4})\.(\d{1,2})\.(\d{1,2})\.?',  # 2025.1.1. ?êÎäî 2025.1.1
            r'(\d{4})??s*(\d{1,2})??s*(\d{1,2})??,  # 2025??1??1??
            r'(\d{4})-(\d{2})-(\d{2})',  # 2025-01-01
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, date_text)
            if match:
                year, month, day = match.groups()
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        return None
    
    def _calculate_complexity(self, structure_info: Dict[str, Any]) -> float:
        """Íµ¨Ï°∞ Î≥µÏû°??Í≥ÑÏÇ∞"""
        total_elements = (
            structure_info['total_articles'] +
            structure_info['total_paragraphs'] +
            structure_info['total_subparagraphs'] +
            structure_info['total_items']
        )
        
        # Î≥µÏû°???êÏàò (0-1)
        if total_elements == 0:
            return 0.0
        elif total_elements < 20:
            return 0.2
        elif total_elements < 50:
            return 0.4
        elif total_elements < 100:
            return 0.6
        elif total_elements < 200:
            return 0.8
        else:
            return 1.0
    
    def _determine_structure_type(self, structure_info: Dict[str, Any]) -> str:
        """Íµ¨Ï°∞ ?†Ìòï Í≤∞Ï†ï"""
        total_articles = structure_info['total_articles']
        total_paragraphs = structure_info['total_paragraphs']
        total_subparagraphs = structure_info['total_subparagraphs']
        
        if total_articles == 0:
            return 'unstructured'
        elif total_articles < 10:
            return 'simple'
        elif total_articles < 30:
            if total_paragraphs > total_articles * 2:
                return 'detailed'
            else:
                return 'moderate'
        else:
            if total_subparagraphs > total_articles * 3:
                return 'complex'
            else:
                return 'comprehensive'
    
    def get_structure_statistics(self, structure_info: Dict[str, Any]) -> Dict[str, Any]:
        """Íµ¨Ï°∞ ?µÍ≥Ñ ?ùÏÑ±"""
        return {
            'total_elements': (
                structure_info['total_articles'] +
                structure_info['total_paragraphs'] +
                structure_info['total_subparagraphs'] +
                structure_info['total_items']
            ),
            'average_paragraphs_per_article': (
                structure_info['total_paragraphs'] / structure_info['total_articles']
                if structure_info['total_articles'] > 0 else 0
            ),
            'average_subparagraphs_per_paragraph': (
                structure_info['total_subparagraphs'] / structure_info['total_paragraphs']
                if structure_info['total_paragraphs'] > 0 else 0
            ),
            'structure_density': structure_info['structure_complexity'],
            'structure_type': structure_info['structure_type']
        }
