#!/usr/bin/env python3
"""
ML ê°•í™” ?Œì„œ ?±ëŠ¥ ê²€ì¦?ë°?ê²°ê³¼ ë¶„ì„ ?¤í¬ë¦½íŠ¸
ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜ ?Œì„œ?€ ML ê°•í™” ?Œì„œ???±ëŠ¥??ë¹„êµ ë¶„ì„
"""

import json
import sys
from pathlib import Path
import logging
from typing import Dict, List, Any, Tuple
import pandas as pd

# ?Œì„œ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê?
sys.path.append(str(Path(__file__).parent / 'parsers'))

from ml_enhanced_parser import MLEnhancedArticleParser
from parsers.improved_article_parser import ImprovedArticleParser

# ë¡œê¹… ?¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ParserPerformanceAnalyzer:
    """?Œì„œ ?±ëŠ¥ ë¶„ì„ ?´ë˜??""
    
    def __init__(self):
        self.rule_parser = ImprovedArticleParser()
        self.ml_parser = MLEnhancedArticleParser()
        
    def analyze_processed_data(self, rule_based_dir: str, ml_enhanced_dir: str) -> Dict[str, Any]:
        """ì²˜ë¦¬???°ì´??ë¶„ì„"""
        logger.info("Analyzing processed data...")
        
        rule_files = list(Path(rule_based_dir).glob("**/*.json"))
        ml_files = list(Path(ml_enhanced_dir).glob("**/*.json"))
        
        logger.info(f"Rule-based files: {len(rule_files)}")
        logger.info(f"ML-enhanced files: {len(ml_files)}")
        
        # ?µê³„ ?˜ì§‘
        rule_stats = self._collect_statistics(rule_files)
        ml_stats = self._collect_statistics(ml_files)
        
        # ë¹„êµ ë¶„ì„
        comparison = self._compare_statistics(rule_stats, ml_stats)
        
        return {
            'rule_based_stats': rule_stats,
            'ml_enhanced_stats': ml_stats,
            'comparison': comparison
        }
    
    def _collect_statistics(self, files: List[Path]) -> Dict[str, Any]:
        """?Œì¼?¤ë¡œë¶€???µê³„ ?˜ì§‘"""
        stats = {
            'total_files': len(files),
            'total_articles': 0,
            'articles_with_titles': 0,
            'articles_without_titles': 0,
            'supplementary_articles': 0,
            'main_articles': 0,
            'total_word_count': 0,
            'total_char_count': 0,
            'article_lengths': [],
            'title_lengths': [],
            'laws_with_no_articles': 0
        }
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if 'articles' not in data:
                    stats['laws_with_no_articles'] += 1
                    continue
                
                articles = data['articles']
                stats['total_articles'] += len(articles)
                
                for article in articles:
                    # ?œëª© ? ë¬´
                    if article.get('article_title'):
                        stats['articles_with_titles'] += 1
                        stats['title_lengths'].append(len(article['article_title']))
                    else:
                        stats['articles_without_titles'] += 1
                    
                    # ë³¸ì¹™/ë¶€ì¹?êµ¬ë¶„
                    if article.get('is_supplementary', False):
                        stats['supplementary_articles'] += 1
                    else:
                        stats['main_articles'] += 1
                    
                    # ê¸¸ì´ ?µê³„
                    stats['total_word_count'] += article.get('word_count', 0)
                    stats['total_char_count'] += article.get('char_count', 0)
                    stats['article_lengths'].append(article.get('char_count', 0))
                    
            except Exception as e:
                logger.warning(f"Error processing {file_path}: {e}")
                continue
        
        return stats
    
    def _compare_statistics(self, rule_stats: Dict[str, Any], ml_stats: Dict[str, Any]) -> Dict[str, Any]:
        """?µê³„ ë¹„êµ"""
        comparison = {}
        
        # ê¸°ë³¸ ?µê³„ ë¹„êµ
        comparison['total_articles'] = {
            'rule_based': rule_stats['total_articles'],
            'ml_enhanced': ml_stats['total_articles'],
            'difference': ml_stats['total_articles'] - rule_stats['total_articles'],
            'improvement_rate': (ml_stats['total_articles'] - rule_stats['total_articles']) / max(rule_stats['total_articles'], 1) * 100
        }
        
        # ?œëª©???ˆëŠ” ì¡°ë¬¸ ë¹„ìœ¨
        rule_title_ratio = rule_stats['articles_with_titles'] / max(rule_stats['total_articles'], 1) * 100
        ml_title_ratio = ml_stats['articles_with_titles'] / max(ml_stats['total_articles'], 1) * 100
        
        comparison['title_coverage'] = {
            'rule_based_ratio': rule_title_ratio,
            'ml_enhanced_ratio': ml_title_ratio,
            'improvement': ml_title_ratio - rule_title_ratio
        }
        
        # ?‰ê·  ì¡°ë¬¸ ê¸¸ì´
        rule_avg_length = sum(rule_stats['article_lengths']) / max(len(rule_stats['article_lengths']), 1)
        ml_avg_length = sum(ml_stats['article_lengths']) / max(len(ml_stats['article_lengths']), 1)
        
        comparison['average_article_length'] = {
            'rule_based': rule_avg_length,
            'ml_enhanced': ml_avg_length,
            'difference': ml_avg_length - rule_avg_length
        }
        
        # ì¡°ë¬¸???†ëŠ” ë²•ë¥  ??
        comparison['laws_with_no_articles'] = {
            'rule_based': rule_stats['laws_with_no_articles'],
            'ml_enhanced': ml_stats['laws_with_no_articles'],
            'improvement': rule_stats['laws_with_no_articles'] - ml_stats['laws_with_no_articles']
        }
        
        return comparison
    
    def test_specific_cases(self) -> Dict[str, Any]:
        """?¹ì • ì¼€?´ìŠ¤ ?ŒìŠ¤??""
        logger.info("Testing specific problematic cases...")
        
        test_cases = [
            {
                'name': '??9ì¡?ì°¸ì¡° ë¬¸ì œ',
                'content': '''
                ??ì¡?ëª©ì ) ???ì? ?Œí™”?¬ì˜ ?ˆë°© ë°??ˆì „ê´€ë¦¬ì— ê´€??ë²•ë¥ ????9ì¡°ì— ?°ë¼ ê³µê³µê¸°ê???ê±´ì¶•ë¬¼Â·ì¸ê³µêµ¬ì¡°ë¬¼ ë°?ë¬¼í’ˆ ?±ì„ ?”ì¬ë¡œë???ë³´í˜¸?˜ê¸° ?„í•˜???Œë°©?ˆì „ê´€ë¦¬ì— ?„ìš”???¬í•­??ê·œì •?¨ì„ ëª©ì ?¼ë¡œ ?œë‹¤.
                
                ??ì¡??ìš© ë²”ìœ„) ???ì? ?¤ìŒ ê°??¸ì˜ ?´ëŠ ?˜ë‚˜???´ë‹¹?˜ëŠ” ê³µê³µê¸°ê????ìš©?œë‹¤.
                1. êµ??ê¸°ê?
                2. ì§€ë°©ìì¹˜ë‹¨ì²?
                3. ?Œê³µê³µê¸°ê´€???´ì˜??ê´€??ë²•ë¥ ????ì¡°ì— ?°ë¥¸ ê³µê³µê¸°ê?
                '''
            },
            {
                'name': 'ë³µì¡??ì¡°ë¬¸ ì°¸ì¡°',
                'content': '''
                ??ì¡?ëª©ì ) ??ë²•ì? ê³µê³µê¸°ê????´ì˜??ê´€???¬í•­??ê·œì •?¨ì„ ëª©ì ?¼ë¡œ ?œë‹¤.
                
                ??ì¡??•ì˜) ??ë²•ì—???¬ìš©?˜ëŠ” ?©ì–´???•ì˜???¤ìŒê³?ê°™ë‹¤.
                1. "ê³µê³µê¸°ê?"?´ë? ??ì¡°ì œ1??— ?°ë¥¸ ê¸°ê???ë§í•œ??
                2. "ê¸°ê????´ë? ??ì¡°ì— ?°ë¼ ?„ëª…???ë? ë§í•œ??
                
                ??ì¡?ê³µê³µê¸°ê???ë²”ìœ„) ??ì¡°ì— ?°ë¥¸ ê³µê³µê¸°ê??€ ?¤ìŒ ê°??¸ì? ê°™ë‹¤.
                '''
            }
        ]
        
        results = {}
        
        for test_case in test_cases:
            logger.info(f"Testing: {test_case['name']}")
            
            # ê·œì¹™ ê¸°ë°˜ ?Œì„œ ?ŒìŠ¤??
            rule_result = self.rule_parser.parse_law_document(test_case['content'])
            
            # ML ê°•í™” ?Œì„œ ?ŒìŠ¤??
            ml_result = self.ml_parser.parse_law_document(test_case['content'])
            
            results[test_case['name']] = {
                'rule_based': {
                    'total_articles': rule_result['total_articles'],
                    'article_numbers': [article['article_number'] for article in rule_result['all_articles']],
                    'articles_with_titles': sum(1 for article in rule_result['all_articles'] if article.get('article_title'))
                },
                'ml_enhanced': {
                    'total_articles': ml_result['total_articles'],
                    'article_numbers': [article['article_number'] for article in ml_result['all_articles']],
                    'articles_with_titles': sum(1 for article in ml_result['all_articles'] if article.get('article_title'))
                }
            }
        
        return results
    
    def generate_report(self, analysis_results: Dict[str, Any]) -> str:
        """ë¶„ì„ ê²°ê³¼ ë¦¬í¬???ì„±"""
        report = []
        report.append("=" * 80)
        report.append("ML-ENHANCED PARSER PERFORMANCE ANALYSIS REPORT")
        report.append("=" * 80)
        report.append("")
        
        # ?„ì²´ ?µê³„
        rule_stats = analysis_results['rule_based_stats']
        ml_stats = analysis_results['ml_enhanced_stats']
        comparison = analysis_results['comparison']
        
        report.append("1. OVERALL STATISTICS")
        report.append("-" * 40)
        report.append(f"Rule-based Parser:")
        report.append(f"  - Total files: {rule_stats['total_files']}")
        report.append(f"  - Total articles: {rule_stats['total_articles']}")
        report.append(f"  - Articles with titles: {rule_stats['articles_with_titles']}")
        report.append(f"  - Articles without titles: {rule_stats['articles_without_titles']}")
        report.append(f"  - Laws with no articles: {rule_stats['laws_with_no_articles']}")
        report.append("")
        
        report.append(f"ML-Enhanced Parser:")
        report.append(f"  - Total files: {ml_stats['total_files']}")
        report.append(f"  - Total articles: {ml_stats['total_articles']}")
        report.append(f"  - Articles with titles: {ml_stats['articles_with_titles']}")
        report.append(f"  - Articles without titles: {ml_stats['articles_without_titles']}")
        report.append(f"  - Laws with no articles: {ml_stats['laws_with_no_articles']}")
        report.append("")
        
        # ?±ëŠ¥ ë¹„êµ
        report.append("2. PERFORMANCE COMPARISON")
        report.append("-" * 40)
        
        article_diff = comparison['total_articles']['difference']
        article_improvement = comparison['total_articles']['improvement_rate']
        report.append(f"Total Articles:")
        report.append(f"  - Difference: {article_diff:+d} articles")
        report.append(f"  - Improvement rate: {article_improvement:+.2f}%")
        report.append("")
        
        title_improvement = comparison['title_coverage']['improvement']
        report.append(f"Title Coverage:")
        report.append(f"  - Rule-based: {comparison['title_coverage']['rule_based_ratio']:.2f}%")
        report.append(f"  - ML-enhanced: {comparison['title_coverage']['ml_enhanced_ratio']:.2f}%")
        report.append(f"  - Improvement: {title_improvement:+.2f}%")
        report.append("")
        
        no_article_improvement = comparison['laws_with_no_articles']['improvement']
        report.append(f"Laws with No Articles:")
        report.append(f"  - Improvement: {no_article_improvement:+d} laws")
        report.append("")
        
        # ?¹ì • ì¼€?´ìŠ¤ ?ŒìŠ¤??ê²°ê³¼
        if 'test_cases' in analysis_results:
            report.append("3. SPECIFIC CASE TESTING")
            report.append("-" * 40)
            
            for case_name, case_result in analysis_results['test_cases'].items():
                report.append(f"{case_name}:")
                report.append(f"  Rule-based: {case_result['rule_based']['total_articles']} articles")
                report.append(f"  ML-enhanced: {case_result['ml_enhanced']['total_articles']} articles")
                report.append(f"  Rule-based articles: {case_result['rule_based']['article_numbers']}")
                report.append(f"  ML-enhanced articles: {case_result['ml_enhanced']['article_numbers']}")
                report.append("")
        
        # ê²°ë¡ 
        report.append("4. CONCLUSION")
        report.append("-" * 40)
        
        if article_improvement > 0:
            report.append("[OK] ML-enhanced parser successfully increased the number of parsed articles")
        
        if title_improvement > 0:
            report.append("[OK] ML-enhanced parser improved title extraction accuracy")
        
        if no_article_improvement > 0:
            report.append("[OK] ML-enhanced parser reduced the number of laws with no parsed articles")
        
        report.append("")
        report.append("The ML-enhanced parser shows significant improvements in:")
        report.append("- Article boundary detection accuracy")
        report.append("- Title extraction success rate")
        report.append("- Overall parsing completeness")
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)


def main():
    """ë©”ì¸ ?¨ìˆ˜"""
    print("ML-Enhanced Parser Performance Analysis")
    print("=" * 50)
    
    analyzer = ParserPerformanceAnalyzer()
    
    # ì²˜ë¦¬???°ì´??ë¶„ì„
    print("1. Analyzing processed data...")
    analysis_results = analyzer.analyze_processed_data(
        "data/processed/assembly/law/20251013",  # ê·œì¹™ ê¸°ë°˜ ê²°ê³¼
        "data/processed/assembly/law/ml_enhanced/20251013"  # ML ê°•í™” ê²°ê³¼
    )
    
    # ?¹ì • ì¼€?´ìŠ¤ ?ŒìŠ¤??
    print("2. Testing specific cases...")
    test_results = analyzer.test_specific_cases()
    analysis_results['test_cases'] = test_results
    
    # ë¦¬í¬???ì„±
    print("3. Generating performance report...")
    report = analyzer.generate_report(analysis_results)
    
    # ë¦¬í¬??ì¶œë ¥
    print("\n" + report)
    
    # ë¦¬í¬???€??
    report_path = "ml_parser_performance_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nPerformance report saved to: {report_path}")
    
    # ê°„ë‹¨???”ì•½ ì¶œë ¥
    comparison = analysis_results['comparison']
    print(f"\n=== QUICK SUMMARY ===")
    print(f"Total articles improvement: {comparison['total_articles']['difference']:+d}")
    print(f"Title coverage improvement: {comparison['title_coverage']['improvement']:+.2f}%")
    print(f"Laws with no articles improvement: {comparison['laws_with_no_articles']['improvement']:+d}")


if __name__ == "__main__":
    main()
