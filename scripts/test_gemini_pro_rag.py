#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google AI ëª¨ë¸ RAG Test Script
Google AI ëª¨ë¸ì„ ì‚¬ìš©í•œ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
.env íŒŒì¼ì— ë‹¤ìŒ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:

í•„ìˆ˜ ì„¤ì •:
- LLM_PROVIDER=google
- GOOGLE_API_KEY=your-google-api-key-here

ì„ íƒì  ì„¤ì •:
- LLM_MODEL=gemini-pro (ë˜ëŠ” ë‹¤ë¥¸ Google AI ëª¨ë¸)
- LLM_TEMPERATURE=0.7
- LLM_MAX_TOKENS=1000
- LANGFUSE_ENABLED=false
"""

import os
import sys
import logging
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'source'))

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

from services.langchain_rag_service import LangChainRAGService
from utils.langchain_config import LangChainConfig

# ë¡œê¹… ì„¤ì •
from utils.safe_logging import setup_script_logging
logger = setup_script_logging("test_gemini_pro_rag")


def setup_gemini_environment():
    """Google AI ëª¨ë¸ í™˜ê²½ ì„¤ì •"""
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”
    # Google API í‚¤ í™•ì¸ë§Œ ìˆ˜í–‰
    if not os.getenv('GOOGLE_API_KEY'):
        logger.warning("âš ï¸ GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.info("ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
        logger.info("1. .env íŒŒì¼ì— GOOGLE_API_KEY=your-google-api-key-here ì¶”ê°€")
        logger.info("2. ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì§ì ‘ ì„¤ì •: export GOOGLE_API_KEY=your-google-api-key-here")
        return False
    
    model_name = os.getenv('LLM_MODEL', 'gemini-pro')
    logger.info(f"âœ… {model_name} í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    logger.info(f"   - LLM Provider: {os.getenv('LLM_PROVIDER', 'Not set')}")
    logger.info(f"   - LLM Model: {model_name}")
    logger.info(f"   - Google API Key: {'ì„¤ì •ë¨' if os.getenv('GOOGLE_API_KEY') else 'ë¯¸ì„¤ì •'}")
    logger.info(f"   - Langfuse Enabled: {os.getenv('LANGFUSE_ENABLED', 'Not set')}")
    return True


def test_gemini_configuration():
    """Google AI ëª¨ë¸ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    logger.info("=== Google AI ëª¨ë¸ ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
    
    try:
        config = LangChainConfig.from_env()
        
        # .env íŒŒì¼ì—ì„œ ë¡œë“œëœ ì„¤ì • í™•ì¸
        logger.info("ğŸ“‹ .env íŒŒì¼ì—ì„œ ë¡œë“œëœ ì„¤ì •:")
        logger.info(f"   - LLM Provider: {config.llm_provider.value}")
        logger.info(f"   - LLM Model: {config.llm_model}")
        logger.info(f"   - LLM Temperature: {config.llm_temperature}")
        logger.info(f"   - LLM Max Tokens: {config.llm_max_tokens}")
        logger.info(f"   - Vector Store Type: {config.vector_store_type.value}")
        logger.info(f"   - Embedding Model: {config.embedding_model}")
        logger.info(f"   - Google API Key: {'ì„¤ì •ë¨' if config.google_api_key else 'ë¯¸ì„¤ì •'}")
        logger.info(f"   - Langfuse Enabled: {config.langfuse_enabled}")
        
        # Google AI ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ ê²€ì¦
        if config.llm_provider.value != "google":
            logger.warning(f"âš ï¸ LLM ì œê³µìê°€ 'google'ì´ ì•„ë‹™ë‹ˆë‹¤: {config.llm_provider.value}")
            logger.info(f"{config.llm_model}ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì—ì„œ LLM_PROVIDER=googleìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
            return False
        
        if not config.google_api_key:
            logger.error("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info(f"{config.llm_model}ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì—ì„œ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return False
        
        if config.google_api_key == "your-google-api-key-here" or config.google_api_key == "test-google-api-key":
            logger.warning("âš ï¸ í…ŒìŠ¤íŠ¸ìš© API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            logger.info("ì‹¤ì œ Google API í‚¤ë¡œ êµì²´í•˜ì„¸ìš”.")
        
        logger.info(f"âœ… {config.llm_model} ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        
        # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
        errors = config.validate()
        if errors:
            logger.warning(f"âš ï¸ ì„¤ì • ì˜¤ë¥˜: {errors}")
            return False
        else:
            logger.info("âœ… ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
            
        return config
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None


def test_gemini_rag_service(config: LangChainConfig):
    """Google AI ëª¨ë¸ RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""
    logger.info(f"=== {config.llm_model} RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        service = LangChainRAGService(config)
        logger.info("âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ
        stats = service.get_service_statistics()
        logger.info("ğŸ“Š ì„œë¹„ìŠ¤ í†µê³„:")
        logger.info(f"   - LLM ëª¨ë¸: {stats['llm_model']}")
        logger.info(f"   - LangChain ì‚¬ìš© ê°€ëŠ¥: {stats['langchain_available']}")
        logger.info(f"   - Langfuse í™œì„±í™”: {stats['langfuse_enabled']}")
        
        return service
        
    except Exception as e:
        logger.error(f"âŒ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def test_gemini_query_processing(service: LangChainRAGService):
    """Google AI ëª¨ë¸ ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    # ì„œë¹„ìŠ¤ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
    stats = service.get_service_statistics()
    model_name = stats['llm_model']
    logger.info(f"=== {model_name} ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    test_queries = [
        {
            "query": "ê³„ì•½ì„œì—ì„œ ì¤‘ìš”í•œ ì¡°í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "template_type": "contract_review",
            "description": f"ê³„ì•½ì„œ ê²€í†  ({model_name})"
        },
        {
            "query": "ë¯¼ë²• ì œ1ì¡°ì˜ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "template_type": "legal_qa",
            "description": f"ë²•ë¥  Q&A ({model_name})"
        },
        {
            "query": "ìµœê·¼ íŒë¡€ì˜ ë²•ì  ì‹œì‚¬ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            "template_type": "legal_analysis",
            "description": f"ë²•ë¥  ë¶„ì„ ({model_name})"
        }
    ]
    
    session_id = f"{model_name.replace('-', '_')}_demo_session"
    
    for i, test_case in enumerate(test_queries, 1):
        logger.info(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {test_case['description']}")
        
        try:
            result = service.process_query(
                query=test_case["query"],
                session_id=session_id,
                template_type=test_case["template_type"]
            )
            
            logger.info(f"âœ… ì¿¼ë¦¬ ì²˜ë¦¬ ì„±ê³µ")
            logger.info(f"   - ì‘ë‹µ ì‹œê°„: {result.response_time:.2f}ì´ˆ")
            logger.info(f"   - ì‹ ë¢°ë„: {result.confidence:.2f}")
            logger.info(f"   - í† í° ì‚¬ìš©ëŸ‰: {result.tokens_used}")
            logger.info(f"   - ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(result.retrieved_docs)}")
            logger.info(f"   - ì¶”ì  ID: {result.trace_id}")
            logger.info(f"   - ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {result.answer[:150]}...")
            
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        logger.info("")  # ë¹ˆ ì¤„


def test_gemini_performance(service: LangChainRAGService):
    """Google AI ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    # ì„œë¹„ìŠ¤ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
    stats = service.get_service_statistics()
    model_name = stats['llm_model']
    logger.info(f"=== {model_name} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # ì„œë¹„ìŠ¤ í†µê³„
        logger.info(f"ğŸ“Š {model_name} ì„±ëŠ¥ í†µê³„:")
        logger.info(f"   - ì´ ì¿¼ë¦¬ ìˆ˜: {stats['rag_stats']['total_queries']}")
        logger.info(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {stats['rag_stats']['avg_response_time']:.2f}ì´ˆ")
        logger.info(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['rag_stats']['avg_confidence']:.2f}")
        
        # ìƒì„±ê¸° í†µê³„
        generator_stats = stats['generator_stats']
        logger.info(f"ğŸ¤– {model_name} ìƒì„±ê¸° í†µê³„:")
        logger.info(f"   - ì´ í† í° ì‚¬ìš©ëŸ‰: {generator_stats['total_tokens']}")
        logger.info(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {generator_stats['avg_response_time']:.2f}ì´ˆ")
        logger.info(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿: {generator_stats['templates_available']}")
        
    except Exception as e:
        logger.error(f"âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
    model_name = os.getenv('LLM_MODEL', 'gemini-pro')
    logger.info(f"ğŸš€ {model_name} RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    # 1. í™˜ê²½ ì„¤ì •
    if not setup_gemini_environment():
        logger.error("âŒ í™˜ê²½ ì„¤ì • ì‹¤íŒ¨ë¡œ ì¸í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 2. ì„¤ì • í…ŒìŠ¤íŠ¸
    config = test_gemini_configuration()
    if not config:
        logger.error("âŒ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 3. RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
    service = test_gemini_rag_service(config)
    if not service:
        logger.error("âŒ RAG ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 4. ì¿¼ë¦¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    test_gemini_query_processing(service)
    
    # 5. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    test_gemini_performance(service)
    
    logger.info("=" * 60)
    logger.info(f"âœ… {model_name} RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("")
    logger.info("ğŸ“š ì¶”ê°€ ì •ë³´:")
    logger.info("   - Google AI Studio: https://makersuite.google.com/app/apikey")
    logger.info("   - Gemini Pro ë¬¸ì„œ: https://ai.google.dev/docs")
    logger.info("   - LangChain Google í†µí•©: https://python.langchain.com/docs/integrations/llms/google_vertex_ai")
    logger.info("")
    logger.info("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„:")
    logger.info("   1. Google AI Studioì—ì„œ API í‚¤ ë°œê¸‰ (https://makersuite.google.com/app/apikey)")
    logger.info("   2. .env íŒŒì¼ì—ì„œ GOOGLE_API_KEY=your-actual-api-keyë¡œ ì„¤ì •")
    logger.info("   3. í•„ìš”ì‹œ .env íŒŒì¼ì—ì„œ ë‹¤ë¥¸ ì„¤ì • ì¡°ì • (LLM_MODEL, LLM_TEMPERATURE ë“±)")
    logger.info("   4. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•")
    logger.info(f"   5. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ {model_name} í™œìš©")
    logger.info("")
    logger.info("ğŸ“ .env íŒŒì¼ ì„¤ì • ì˜ˆì‹œ:")
    logger.info("   LLM_PROVIDER=google")
    logger.info(f"   LLM_MODEL={model_name}")
    logger.info("   GOOGLE_API_KEY=your-actual-google-api-key")
    logger.info("   LANGFUSE_ENABLED=false")


if __name__ == "__main__":
    main()
