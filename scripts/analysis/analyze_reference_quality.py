#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ê²€ìƒ‰ ê²°ê³¼ì˜ ì°¸ì¡° ìë£Œ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import sys
import sqlite3
from pathlib import Path
from typing import List, Dict, Any, Optional
import re

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
from scripts.utils.path_utils import setup_project_path
setup_project_path()

from lawfirm_langgraph.core.search.engines.semantic_search_engine_v2 import SemanticSearchEngineV2
from scripts.utils.text_utils import extract_keywords


def analyze_reference_quality(
    query: str,
    results: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„"""
    analysis = {
        'total_results': len(results),
        'by_strategy': {},
        'by_category': {},
        'quality_metrics': {},
        'issues': []
    }
    
    if not results:
        analysis['issues'].append('ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.')
        return analysis
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(query)
    
    # ì „ëµë³„ ë¶„ì„
    for result in results:
        strategy = result.get('metadata', {}).get('chunking_strategy') or 'unknown'
        if strategy not in analysis['by_strategy']:
            analysis['by_strategy'][strategy] = {
                'count': 0,
                'avg_similarity': 0.0,
                'max_similarity': 0.0,
                'min_similarity': 1.0
            }
        
        strategy_data = analysis['by_strategy'][strategy]
        strategy_data['count'] += 1
        similarity = result.get('similarity', 0.0)
        strategy_data['avg_similarity'] += similarity
        strategy_data['max_similarity'] = max(strategy_data['max_similarity'], similarity)
        strategy_data['min_similarity'] = min(strategy_data['min_similarity'], similarity)
    
    # í‰ê·  ê³„ì‚°
    for strategy_data in analysis['by_strategy'].values():
        if strategy_data['count'] > 0:
            strategy_data['avg_similarity'] /= strategy_data['count']
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    for result in results:
        category = result.get('metadata', {}).get('chunk_size_category') or 'unknown'
        if category not in analysis['by_category']:
            analysis['by_category'][category] = {
                'count': 0,
                'avg_similarity': 0.0
            }
        
        category_data = analysis['by_category'][category]
        category_data['count'] += 1
        category_data['avg_similarity'] += result.get('similarity', 0.0)
    
    for category_data in analysis['by_category'].values():
        if category_data['count'] > 0:
            category_data['avg_similarity'] /= category_data['count']
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    similarities = [r.get('similarity', 0.0) for r in results]
    analysis['quality_metrics'] = {
        'avg_similarity': sum(similarities) / len(similarities) if similarities else 0.0,
        'max_similarity': max(similarities) if similarities else 0.0,
        'min_similarity': min(similarities) if similarities else 0.0,
        'high_quality_count': sum(1 for s in similarities if s >= 0.7),
        'medium_quality_count': sum(1 for s in similarities if 0.5 <= s < 0.7),
        'low_quality_count': sum(1 for s in similarities if s < 0.5)
    }
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ì„
    keyword_matches = []
    for result in results:
        text = result.get('text', '')
        matched_keywords = [kw for kw in keywords if kw in text]
        keyword_matches.append({
            'matched_count': len(matched_keywords),
            'total_keywords': len(keywords),
            'match_ratio': len(matched_keywords) / len(keywords) if keywords else 0.0
        })
    
    analysis['keyword_analysis'] = {
        'avg_match_ratio': sum(m['match_ratio'] for m in keyword_matches) / len(keyword_matches) if keyword_matches else 0.0,
        'full_match_count': sum(1 for m in keyword_matches if m['match_ratio'] >= 0.8)
    }
    
    # ë¬¸ì œì  ì‹ë³„
    if analysis['quality_metrics']['avg_similarity'] < 0.6:
        analysis['issues'].append(f'í‰ê·  ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤: {analysis["quality_metrics"]["avg_similarity"]:.4f}')
    
    if analysis['quality_metrics']['low_quality_count'] > len(results) * 0.5:
        analysis['issues'].append(f'ì €í’ˆì§ˆ ê²°ê³¼ê°€ ë§ìŠµë‹ˆë‹¤: {analysis["quality_metrics"]["low_quality_count"]}/{len(results)}')
    
    if analysis['keyword_analysis']['avg_match_ratio'] < 0.5:
        analysis['issues'].append(f'í‚¤ì›Œë“œ ë§¤ì¹­ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤: {analysis["keyword_analysis"]["avg_match_ratio"]:.4f}')
    
    return analysis




def print_analysis_report(query: str, analysis: Dict[str, Any], results: List[Dict[str, Any]]):
    """ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸")
    print("="*80)
    print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    print(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {analysis['total_results']}ê°œ\n")
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    print("ğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­")
    print("-" * 80)
    metrics = analysis['quality_metrics']
    print(f"  í‰ê·  ìœ ì‚¬ë„: {metrics['avg_similarity']:.4f}")
    print(f"  ìµœê³  ìœ ì‚¬ë„: {metrics['max_similarity']:.4f}")
    print(f"  ìµœì € ìœ ì‚¬ë„: {metrics['min_similarity']:.4f}")
    print(f"  ê³ í’ˆì§ˆ (â‰¥0.7): {metrics['high_quality_count']}ê°œ")
    print(f"  ì¤‘í’ˆì§ˆ (0.5-0.7): {metrics['medium_quality_count']}ê°œ")
    print(f"  ì €í’ˆì§ˆ (<0.5): {metrics['low_quality_count']}ê°œ")
    
    # ì „ëµë³„ ë¶„ì„
    if analysis['by_strategy']:
        print("\nğŸ“ˆ ì²­í‚¹ ì „ëµë³„ ë¶„ì„")
        print("-" * 80)
        for strategy, data in analysis['by_strategy'].items():
            strategy_name = (strategy or 'unknown').upper()
            print(f"\n  [{strategy_name}]")
            print(f"    ê²°ê³¼ ìˆ˜: {data['count']}ê°œ")
            print(f"    í‰ê·  ìœ ì‚¬ë„: {data['avg_similarity']:.4f}")
            print(f"    ìµœê³  ìœ ì‚¬ë„: {data['max_similarity']:.4f}")
            print(f"    ìµœì € ìœ ì‚¬ë„: {data['min_similarity']:.4f}")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    if analysis['by_category']:
        print("\nğŸ“¦ í¬ê¸° ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„")
        print("-" * 80)
        for category, data in analysis['by_category'].items():
            print(f"  {category}: {data['count']}ê°œ (í‰ê·  ìœ ì‚¬ë„: {data['avg_similarity']:.4f})")
    
    # í‚¤ì›Œë“œ ë¶„ì„
    if 'keyword_analysis' in analysis:
        print("\nğŸ”‘ í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ì„")
        print("-" * 80)
        kw_analysis = analysis['keyword_analysis']
        print(f"  í‰ê·  í‚¤ì›Œë“œ ë§¤ì¹­ë¥ : {kw_analysis['avg_match_ratio']:.4f}")
        print(f"  ì™„ì „ ë§¤ì¹­ ê²°ê³¼: {kw_analysis['full_match_count']}ê°œ")
    
    # ë¬¸ì œì 
    if analysis['issues']:
        print("\nâš ï¸  ë°œê²¬ëœ ë¬¸ì œì ")
        print("-" * 80)
        for i, issue in enumerate(analysis['issues'], 1):
            print(f"  {i}. {issue}")
    else:
        print("\nâœ… íŠ¹ë³„í•œ ë¬¸ì œì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ìƒìœ„ ê²°ê³¼ ìƒ˜í”Œ
    print("\nğŸ“‹ ìƒìœ„ ê²°ê³¼ ìƒ˜í”Œ (ìƒìœ„ 5ê°œ)")
    print("-" * 80)
    for i, result in enumerate(results[:5], 1):
        print(f"\n  ê²°ê³¼ {i}:")
        print(f"    ìœ ì‚¬ë„: {result.get('similarity', 0):.4f}")
        print(f"    ì²­í‚¹ ì „ëµ: {result.get('metadata', {}).get('chunking_strategy', 'N/A')}")
        print(f"    í¬ê¸° ì¹´í…Œê³ ë¦¬: {result.get('metadata', {}).get('chunk_size_category', 'N/A')}")
        print(f"    í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {result.get('text', '')[:150]}...")
    
    print("\n" + "="*80)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì°¸ì¡° ìë£Œ í’ˆì§ˆ ë¶„ì„')
    parser.add_argument('--query', default='ì „ì„¸ê¸ˆ ë°˜í™˜ ë³´ì¦ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”', help='ê²€ìƒ‰ ì¿¼ë¦¬')
    parser.add_argument('--db', default='data/lawfirm_v2.db', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
    parser.add_argument('--k', type=int, default=10, help='ê²€ìƒ‰ ê²°ê³¼ ìˆ˜')
    
    args = parser.parse_args()
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    engine = SemanticSearchEngineV2(db_path=args.db)
    
    if not engine.is_available():
        print("âŒ ê²€ìƒ‰ ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²€ìƒ‰ ìˆ˜í–‰
    print(f"ê²€ìƒ‰ ì¤‘: {args.query}")
    results = engine.search(
        query=args.query,
        k=args.k,
        similarity_threshold=0.4,
        deduplicate_by_group=True
    )
    
    if not results:
        print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í’ˆì§ˆ ë¶„ì„
    analysis = analyze_reference_quality(args.query, results)
    
    # ë¦¬í¬íŠ¸ ì¶œë ¥
    print_analysis_report(args.query, analysis, results)


if __name__ == '__main__':
    main()

