# -*- coding: utf-8 -*-
"""
ë¡œê·¸ ë¶„ì„ ë° ê°œì„  ì‚¬í•­ ì‹ë³„ ìŠ¤í¬ë¦½íŠ¸
ê° ë‹¨ê³„ë³„ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì„  ì‚¬í•­ì„ ì‹ë³„
"""

import re
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict
from datetime import datetime

def analyze_sources_conversion_logs(log_content: str) -> Dict[str, Any]:
    """Sources ë³€í™˜ ê´€ë ¨ ë¡œê·¸ ë¶„ì„"""
    analysis = {
        "conversion_statistics": [],
        "fallback_usage": [],
        "critical_fallbacks": [],
        "lost_documents": [],
        "total_conversions": 0,
        "total_docs": 0,
        "total_failed": 0,
    }
    
    # Conversion statistics íŒ¨í„´
    pattern = r'\[SOURCES\] ğŸ“Š Conversion statistics: (\d+)/(\d+) docs converted \(([\d.]+)%\), failed: (\d+)'
    matches = re.findall(pattern, log_content)
    for match in matches:
        created, total, rate, failed = match
        analysis["conversion_statistics"].append({
            "created": int(created),
            "total": int(total),
            "rate": float(rate),
            "failed": int(failed)
        })
        analysis["total_conversions"] += int(created)
        analysis["total_docs"] += int(total)
        analysis["total_failed"] += int(failed)
    
    # Fallback source ìƒì„± íŒ¨í„´
    fallback_pattern = r'\[SOURCES\] âœ… Generated fallback source for doc (\d+)/(\d+): (.+)'
    fallback_matches = re.findall(fallback_pattern, log_content)
    for match in fallback_matches:
        analysis["fallback_usage"].append({
            "doc_index": int(match[0]),
            "total_docs": int(match[1]),
            "source": match[2]
        })
    
    # Critical fallback íŒ¨í„´
    critical_pattern = r'\[SOURCES\] âš ï¸ CRITICAL: Using final fallback for doc (\d+)/(\d+): (.+)'
    critical_matches = re.findall(critical_pattern, log_content)
    for match in critical_matches:
        analysis["critical_fallbacks"].append({
            "doc_index": int(match[0]),
            "total_docs": int(match[1]),
            "source": match[2]
        })
    
    # Lost documents íŒ¨í„´
    lost_pattern = r'\[SOURCES\] âš ï¸ Lost document.*?doc_index=(\d+).*?type=([^,]+)'
    lost_matches = re.findall(lost_pattern, log_content)
    for match in lost_matches:
        analysis["lost_documents"].append({
            "doc_index": int(match[0]),
            "type": match[1]
        })
    
    return analysis

def analyze_legal_references_logs(log_content: str) -> Dict[str, Any]:
    """Legal References ê´€ë ¨ ë¡œê·¸ ë¶„ì„"""
    analysis = {
        "extracted_from_sources": 0,
        "extracted_from_content": 0,
        "extracted_from_docs": 0,
        "total_extracted": 0,
        "legal_references": []
    }
    
    # Legal references ì¶”ì¶œ íŒ¨í„´
    pattern = r'\[LEGAL_REFS\] Extracted (\d+) legal references'
    matches = re.findall(pattern, log_content)
    for match in matches:
        analysis["total_extracted"] += int(match)
    
    # Sourcesì—ì„œ ì¶”ì¶œ
    sources_pattern = r'\[LEGAL_REFS\] From sources_detail: (\d+) references'
    sources_matches = re.findall(sources_pattern, log_content)
    for match in sources_matches:
        analysis["extracted_from_sources"] += int(match)
    
    # Contentì—ì„œ ì¶”ì¶œ
    content_pattern = r'\[LEGAL_REFS\] From content: (\d+) references'
    content_matches = re.findall(content_pattern, log_content)
    for match in content_matches:
        analysis["extracted_from_content"] += int(match)
    
    # Docsì—ì„œ ì¶”ì¶œ
    docs_pattern = r'\[LEGAL_REFS\] From retrieved_docs: (\d+) references'
    docs_matches = re.findall(docs_pattern, log_content)
    for match in docs_matches:
        analysis["extracted_from_docs"] += int(match)
    
    return analysis

def analyze_answer_length_logs(log_content: str) -> Dict[str, Any]:
    """ë‹µë³€ ê¸¸ì´ ê´€ë ¨ ë¡œê·¸ ë¶„ì„"""
    analysis = {
        "length_warnings": [],
        "length_adjustments": [],
        "too_short_count": 0,
        "too_long_count": 0,
        "adjusted_count": 0,
    }
    
    # ë„ˆë¬´ ì§§ì€ ê²½ìš°
    short_pattern = r'\[ANSWER LENGTH\] âš ï¸ Too short: (\d+) \(target: (\d+)-(\d+)\)'
    short_matches = re.findall(short_pattern, log_content)
    for match in short_matches:
        analysis["length_warnings"].append({
            "current": int(match[0]),
            "min_target": int(match[1]),
            "max_target": int(match[2])
        })
        analysis["too_short_count"] += 1
    
    # ë„ˆë¬´ ê¸´ ê²½ìš°
    long_pattern = r'\[ANSWER LENGTH\] Too long: (\d+), adjusting to max (\d+)'
    long_matches = re.findall(long_pattern, log_content)
    for match in long_matches:
        analysis["length_adjustments"].append({
            "original": int(match[0]),
            "max": int(match[1])
        })
        analysis["too_long_count"] += 1
        analysis["adjusted_count"] += 1
    
    return analysis

def analyze_context_usage_logs(log_content: str) -> Dict[str, Any]:
    """Context Usage ê´€ë ¨ ë¡œê·¸ ë¶„ì„"""
    analysis = {
        "coverage_scores": [],
        "relevance_scores": [],
        "average_coverage": 0.0,
        "average_relevance": 0.0,
    }
    
    # Coverage ì ìˆ˜ íŒ¨í„´
    coverage_pattern = r'\[COVERAGE\] Coverage score: ([\d.]+)'
    coverage_matches = re.findall(coverage_pattern, log_content)
    for match in coverage_matches:
        score = float(match)
        analysis["coverage_scores"].append(score)
    
    # Relevance ì ìˆ˜ íŒ¨í„´
    relevance_pattern = r'\[RELEVANCE\] Relevance score: ([\d.]+)'
    relevance_matches = re.findall(relevance_pattern, log_content)
    for match in relevance_matches:
        score = float(match)
        analysis["relevance_scores"].append(score)
    
    if analysis["coverage_scores"]:
        analysis["average_coverage"] = sum(analysis["coverage_scores"]) / len(analysis["coverage_scores"])
    
    if analysis["relevance_scores"]:
        analysis["average_relevance"] = sum(analysis["relevance_scores"]) / len(analysis["relevance_scores"])
    
    return analysis

def identify_improvements(analysis_results: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ì‚¬í•­ ì‹ë³„"""
    improvements = []
    
    # Sources ë³€í™˜ë¥  ê°œì„ 
    sources_analysis = analysis_results.get("sources", {})
    if sources_analysis.get("total_docs", 0) > 0:
        avg_conversion_rate = (sources_analysis.get("total_conversions", 0) / 
                              sources_analysis.get("total_docs", 1)) * 100
        if avg_conversion_rate < 90:
            improvements.append({
                "category": "Sources ë³€í™˜ë¥ ",
                "priority": "HIGH",
                "current": f"{avg_conversion_rate:.1f}%",
                "target": "90% ì´ìƒ",
                "description": f"í˜„ì¬ ë³€í™˜ë¥ ì´ {avg_conversion_rate:.1f}%ë¡œ ëª©í‘œ(90%) ë¯¸ë§Œì…ë‹ˆë‹¤.",
                "recommendation": "fallback ë¡œì§ ê°•í™”, source_type ì¶”ë¡  ê°œì„  í•„ìš”"
            })
        
        if sources_analysis.get("critical_fallbacks"):
            improvements.append({
                "category": "Critical Fallback ì‚¬ìš©",
                "priority": "MEDIUM",
                "current": f"{len(sources_analysis['critical_fallbacks'])}ê±´",
                "target": "0ê±´",
                "description": f"ìµœì¢… fallbackì´ {len(sources_analysis['critical_fallbacks'])}ê±´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "recommendation": "metadata ì¶”ì¶œ ë¡œì§ ê°œì„ , content ê¸°ë°˜ ì¶”ë¡  ê°•í™”"
            })
    
    # Legal References ìƒì„±ë¥  ê°œì„ 
    legal_analysis = analysis_results.get("legal_references", {})
    if legal_analysis.get("total_extracted", 0) == 0:
        improvements.append({
            "category": "Legal References ìƒì„±",
            "priority": "HIGH",
            "current": "0ê°œ",
            "target": "statute_article ë¬¸ì„œ ìˆ˜ë§Œí¼",
            "description": "Legal referencesê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "recommendation": "legal_references ì¶”ì¶œ ë¡œì§ ê²€ì¦ ë° ê°œì„  í•„ìš”"
        })
    
    # ë‹µë³€ ê¸¸ì´ ê°œì„ 
    length_analysis = analysis_results.get("answer_length", {})
    if length_analysis.get("too_short_count", 0) > 0:
        improvements.append({
            "category": "ë‹µë³€ ê¸¸ì´",
            "priority": "MEDIUM",
            "current": f"{length_analysis['too_short_count']}ê±´ ë„ˆë¬´ ì§§ìŒ",
            "target": "ëª¨ë“  ë‹µë³€ì´ ìµœì†Œ ê¸¸ì´ ì´ìƒ",
            "description": f"{length_analysis['too_short_count']}ê±´ì˜ ë‹µë³€ì´ ìµœì†Œ ê¸¸ì´ ë¯¸ë§Œì…ë‹ˆë‹¤.",
            "recommendation": "í”„ë¡¬í”„íŠ¸ ê°œì„ , ì»¨í…ìŠ¤íŠ¸ í™œìš© ê°•í™”"
        })
    
    # Context Usage ê°œì„ 
    context_analysis = analysis_results.get("context_usage", {})
    avg_coverage = context_analysis.get("average_coverage", 0.0)
    if avg_coverage < 0.8:
        improvements.append({
            "category": "Context Usage",
            "priority": "MEDIUM",
            "current": f"{avg_coverage:.2f}",
            "target": "0.80 ì´ìƒ",
            "description": f"í‰ê·  coverageê°€ {avg_coverage:.2f}ë¡œ ëª©í‘œ(0.80) ë¯¸ë§Œì…ë‹ˆë‹¤.",
            "recommendation": "í”„ë¡¬í”„íŠ¸ ê°œì„ , ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ"
        })
    
    return improvements

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
    log_file = project_root / "logs" / "lawfirm_ai.log"
    
    if not log_file.exists():
        print(f"âš ï¸  ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file}")
        print("ì‹¤ì œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¡œê·¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    # ë¡œê·¸ íŒŒì¼ ì½ê¸°
    with open(log_file, "r", encoding="utf-8") as f:
        log_content = f.read()
    
    # ê° ì˜ì—­ë³„ ë¶„ì„
    analysis_results = {
        "sources": analyze_sources_conversion_logs(log_content),
        "legal_references": analyze_legal_references_logs(log_content),
        "answer_length": analyze_answer_length_logs(log_content),
        "context_usage": analyze_context_usage_logs(log_content),
    }
    
    # ê°œì„  ì‚¬í•­ ì‹ë³„
    improvements = identify_improvements(analysis_results)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ë¡œê·¸ ë¶„ì„ ê²°ê³¼")
    print("="*80)
    
    print("\nğŸ“Š Sources ë³€í™˜ ë¶„ì„:")
    sources = analysis_results["sources"]
    if sources["total_docs"] > 0:
        avg_rate = (sources["total_conversions"] / sources["total_docs"]) * 100
        print(f"  - í‰ê·  ë³€í™˜ë¥ : {avg_rate:.1f}%")
        print(f"  - ì´ ë³€í™˜: {sources['total_conversions']}/{sources['total_docs']}")
        print(f"  - ì‹¤íŒ¨: {sources['total_failed']}")
        print(f"  - Fallback ì‚¬ìš©: {len(sources['fallback_usage'])}ê±´")
        print(f"  - Critical Fallback: {len(sources['critical_fallbacks'])}ê±´")
    
    print("\nâš–ï¸  Legal References ë¶„ì„:")
    legal = analysis_results["legal_references"]
    print(f"  - ì´ ì¶”ì¶œ: {legal['total_extracted']}ê°œ")
    print(f"  - Sourcesì—ì„œ: {legal['extracted_from_sources']}ê°œ")
    print(f"  - Contentì—ì„œ: {legal['extracted_from_content']}ê°œ")
    print(f"  - Docsì—ì„œ: {legal['extracted_from_docs']}ê°œ")
    
    print("\nğŸ“ ë‹µë³€ ê¸¸ì´ ë¶„ì„:")
    length = analysis_results["answer_length"]
    print(f"  - ë„ˆë¬´ ì§§ìŒ: {length['too_short_count']}ê±´")
    print(f"  - ë„ˆë¬´ ê¹€: {length['too_long_count']}ê±´")
    print(f"  - ì¡°ì •ë¨: {length['adjusted_count']}ê±´")
    
    print("\nğŸ“š Context Usage ë¶„ì„:")
    context = analysis_results["context_usage"]
    print(f"  - í‰ê·  Coverage: {context['average_coverage']:.2f}")
    print(f"  - í‰ê·  Relevance: {context['average_relevance']:.2f}")
    
    print("\n" + "="*80)
    print("ê°œì„  ì‚¬í•­")
    print("="*80)
    
    if improvements:
        for i, improvement in enumerate(improvements, 1):
            print(f"\n{i}. [{improvement['priority']}] {improvement['category']}")
            print(f"   í˜„ì¬: {improvement['current']}")
            print(f"   ëª©í‘œ: {improvement['target']}")
            print(f"   ì„¤ëª…: {improvement['description']}")
            print(f"   ê¶Œì¥ì‚¬í•­: {improvement['recommendation']}")
    else:
        print("\nâœ… ì¶”ê°€ ê°œì„  ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    # ê²°ê³¼ ì €ì¥
    output = {
        "analysis_results": analysis_results,
        "improvements": improvements,
        "timestamp": datetime.now().isoformat()
    }
    
    output_file = project_root / "data" / "ml_metrics" / "log_analysis_results.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë¶„ì„ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

