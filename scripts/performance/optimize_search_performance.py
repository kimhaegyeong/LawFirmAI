#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê²€???±ëŠ¥ ìµœì ???¤í¬ë¦½íŠ¸
"""

import sys
sys.path.append('source')
from source.data.vector_store import LegalVectorStore
import time
import json
from pathlib import Path

def analyze_search_performance():
    """ê²€???±ëŠ¥ ë¶„ì„"""
    print("=== ê²€???±ëŠ¥ ë¶„ì„ ===")
    
    # ë²¡í„° ?¤í† ??ì´ˆê¸°??
    vector_store = LegalVectorStore(
        model_name='jhgan/ko-sroberta-multitask',
        dimension=768,
        index_type='flat'
    )
    
    # ?¸ë±??ë¡œë“œ
    if not vector_store.load_index('data/embeddings/ml_enhanced_ko_sroberta_precedents'):
        print("ë²¡í„° ?¸ë±??ë¡œë“œ ?¤íŒ¨")
        return
    
    print(f"ë²¡í„° ?¸ë±???¬ê¸°: {vector_store.index.ntotal:,}")
    
    # ?¤ì–‘??ê²€???œë‚˜ë¦¬ì˜¤ ?ŒìŠ¤??
    test_scenarios = [
        {
            'name': '?¨ì¼ ?¤ì›Œ??,
            'queries': ['?í•´ë°°ìƒ', 'ê³„ì•½', '?¹í—ˆ', '?´í˜¼', '?•ì‚¬']
        },
        {
            'name': 'ë³µí•© ?¤ì›Œ??,
            'queries': ['?í•´ë°°ìƒ ì²?µ¬', 'ê³„ì•½ ?´ì?', '?¹í—ˆ ì¹¨í•´', '?´í˜¼ ?Œì†¡', '?•ì‚¬ ì²˜ë²Œ']
        },
        {
            'name': 'ê¸?ë¬¸ì¥',
            'queries': [
                '?í•´ë°°ìƒ ì²?µ¬ ?”ê±´ê³??í•´??ë²”ìœ„',
                'ê³„ì•½ ?´ì? ???í•´ë°°ìƒ ì±…ì„',
                '?¹í—ˆ ì¹¨í•´ ??ë²•ì  ?¨ê³¼?€ êµ¬ì œë°©ë²•'
            ]
        }
    ]
    
    results = {}
    
    for scenario in test_scenarios:
        print(f"\n--- {scenario['name']} ?ŒìŠ¤??---")
        scenario_results = []
        
        for query in scenario['queries']:
            # ê²€???œê°„ ì¸¡ì •
            start_time = time.time()
            search_results = vector_store.search(query, top_k=10)
            search_time = time.time() - start_time
            
            # ê²°ê³¼ ë¶„ì„
            if search_results:
                scores = [r.get('score', 0) for r in search_results]
                avg_score = sum(scores) / len(scores)
                max_score = max(scores)
                min_score = min(scores)
                
                print(f"  '{query}': {search_time:.3f}ì´? ?ìˆ˜ ë²”ìœ„: {min_score:.3f}-{max_score:.3f}, ?‰ê· : {avg_score:.3f}")
                
                scenario_results.append({
                    'query': query,
                    'search_time': search_time,
                    'result_count': len(search_results),
                    'avg_score': avg_score,
                    'max_score': max_score,
                    'min_score': min_score
                })
            else:
                print(f"  '{query}': {search_time:.3f}ì´? ê²°ê³¼ ?†ìŒ")
                scenario_results.append({
                    'query': query,
                    'search_time': search_time,
                    'result_count': 0,
                    'avg_score': 0,
                    'max_score': 0,
                    'min_score': 0
                })
        
        # ?œë‚˜ë¦¬ì˜¤ë³??‰ê·  ?±ëŠ¥
        avg_time = sum(r['search_time'] for r in scenario_results) / len(scenario_results)
        avg_score = sum(r['avg_score'] for r in scenario_results) / len(scenario_results)
        
        print(f"  ?‰ê·  ê²€???œê°„: {avg_time:.3f}ì´?)
        print(f"  ?‰ê·  ?ìˆ˜: {avg_score:.3f}")
        
        results[scenario['name']] = {
            'queries': scenario_results,
            'avg_search_time': avg_time,
            'avg_score': avg_score
        }
    
    return results

def optimize_vector_index():
    """ë²¡í„° ?¸ë±??ìµœì ??""
    print("\n=== ë²¡í„° ?¸ë±??ìµœì ??===")
    
    # ?„ì¬ ?¸ë±???•ë³´
    vector_store = LegalVectorStore(
        model_name='jhgan/ko-sroberta-multitask',
        dimension=768,
        index_type='flat'
    )
    
    if not vector_store.load_index('data/embeddings/ml_enhanced_ko_sroberta_precedents'):
        print("ë²¡í„° ?¸ë±??ë¡œë“œ ?¤íŒ¨")
        return
    
    stats = vector_store.get_stats()
    print(f"?„ì¬ ?¸ë±???•ë³´:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # ë©”ëª¨ë¦??¬ìš©???•ì¸
    memory_usage = vector_store.get_memory_usage()
    print(f"\në©”ëª¨ë¦??¬ìš©??")
    for key, value in memory_usage.items():
        print(f"  {key}: {value}")
    
    # ?¸ë±??ìµœì ???œì•ˆ
    print(f"\nìµœì ???œì•ˆ:")
    
    if stats['documents_count'] > 10000:
        print("  - ?€?©ëŸ‰ ?°ì´?? IVF ?¸ë±???¬ìš© ê³ ë ¤")
        print("  - ?‘ì??Quantization) ?œì„±??ê³ ë ¤")
    
    if memory_usage.get('total_memory_mb', 0) > 1000:
        print("  - ë©”ëª¨ë¦??¬ìš©?‰ì´ ?’ìŒ: ì§€??ë¡œë”© ?œì„±??ê³ ë ¤")
    
    print("  - ?•ê¸°?ì¸ ?¸ë±???¬êµ¬??ê¶Œì¥")
    print("  - ê²€??ê²°ê³¼ ìºì‹± êµ¬í˜„ ê³ ë ¤")

def create_optimized_search_config():
    """ìµœì ?”ëœ ê²€???¤ì • ?ì„±"""
    print("\n=== ìµœì ?”ëœ ê²€???¤ì • ?ì„± ===")
    
    config = {
        "search_optimization": {
            "vector_search": {
                "default_top_k": 10,
                "max_top_k": 50,
                "score_threshold": 0.3,
                "enable_reranking": True
            },
            "hybrid_search": {
                "exact_weight": 0.3,
                "semantic_weight": 0.7,
                "diversity_threshold": 0.8,
                "max_results": 20
            },
            "performance": {
                "enable_caching": True,
                "cache_ttl": 3600,
                "batch_size": 100,
                "parallel_processing": True
            }
        },
        "index_optimization": {
            "index_type": "ivf",
            "nlist": 1000,
            "quantization": "pq",
            "enable_lazy_loading": True
        }
    }
    
    # ?¤ì • ?Œì¼ ?€??
    with open('optimized_search_config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print("ìµœì ?”ëœ ê²€???¤ì •??'optimized_search_config.json'???€?¥ë˜?ˆìŠµ?ˆë‹¤.")

def main():
    """ë©”ì¸ ?¨ìˆ˜"""
    print("LawFirmAI ê²€???±ëŠ¥ ìµœì ??)
    print("=" * 50)
    
    # 1. ê²€???±ëŠ¥ ë¶„ì„
    performance_results = analyze_search_performance()
    
    # 2. ë²¡í„° ?¸ë±??ìµœì ??
    optimize_vector_index()
    
    # 3. ìµœì ?”ëœ ?¤ì • ?ì„±
    create_optimized_search_config()
    
    # ê²°ê³¼ ?€??
    with open('search_optimization_results.json', 'w', encoding='utf-8') as f:
        json.dump(performance_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nìµœì ??ê²°ê³¼ê°€ 'search_optimization_results.json'???€?¥ë˜?ˆìŠµ?ˆë‹¤.")
    print("\n=== ìµœì ???„ë£Œ ===")

if __name__ == "__main__":
    main()
