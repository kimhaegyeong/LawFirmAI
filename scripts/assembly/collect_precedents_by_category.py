#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë¶„ì•¼ë³„ íŒë¡€ ìˆ˜ì§‘ (Playwright + ì ì§„ì )

ì‚¬ìš©ë²•:
  python collect_precedents_by_category.py --category civil --sample 50
  python collect_precedents_by_category.py --category criminal --sample 100
  python collect_precedents_by_category.py --category family --sample 30
  python collect_precedents_by_category.py --all-categories --sample 20
"""

import argparse
import sys
import signal
import logging
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.assembly_playwright_client import AssemblyPlaywrightClient
from scripts.assembly.assembly_collector import AssemblyCollector
from scripts.assembly.checkpoint_manager import CheckpointManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("precedent_category_collection")

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
interrupted = False

def signal_handler(signum, frame):
    global interrupted
    print(f"\nğŸš¨ Signal {signum} received. Initiating graceful shutdown...")
    interrupted = True

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ë¶„ì•¼ë³„ ì½”ë“œ ë§¤í•‘
CATEGORY_CODES = {
    'civil': 'PREC00_001',      # ë¯¼ì‚¬
    'criminal': 'PREC00_002',   # í˜•ì‚¬
    'family': 'PREC00_003',     # ê°€ì‚¬
    'administrative': 'PREC00_004',  # í–‰ì •
    'constitutional': 'PREC00_005',  # í—Œë²•
    'labor': 'PREC00_006',      # ë…¸ë™
    'tax': 'PREC00_007',        # ì„¸ë¬´
    'patent': 'PREC00_008',     # íŠ¹í—ˆ
    'maritime': 'PREC00_009',   # í•´ì‚¬
    'military': 'PREC00_010'    # êµ°ì‚¬
}

CATEGORY_NAMES = {
    'civil': 'ë¯¼ì‚¬',
    'criminal': 'í˜•ì‚¬', 
    'family': 'ê°€ì‚¬',
    'administrative': 'í–‰ì •',
    'constitutional': 'í—Œë²•',
    'labor': 'ë…¸ë™',
    'tax': 'ì„¸ë¬´',
    'patent': 'íŠ¹í—ˆ',
    'maritime': 'í•´ì‚¬',
    'military': 'êµ°ì‚¬'
}

def collect_precedents_by_category(
    category: str,
    target_count: int = None,
    page_size: int = 10,
    resume: bool = True,
    start_page: int = 1
):
    """
    ë¶„ì•¼ë³„ íŒë¡€ ìˆ˜ì§‘
    
    Args:
        category: ë¶„ì•¼ ì½”ë“œ (civil, criminal, family ë“±)
        target_count: ëª©í‘œ ìˆ˜ì§‘ ê±´ìˆ˜ (None=ì „ì²´)
        page_size: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (ì‹¤ì œë¡œëŠ” 10ê°œ ê³ ì •)
        resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ ì—¬ë¶€
        start_page: ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸
    """
    category_code = CATEGORY_CODES.get(category)
    category_name = CATEGORY_NAMES.get(category, category)
    
    if not category_code:
        print(f"âŒ Unknown category: {category}")
        print(f"Available categories: {', '.join(CATEGORY_CODES.keys())}")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ PRECEDENT COLLECTION BY CATEGORY STARTED")
    print(f"ğŸ“‹ Category: {category_name} ({category_code})")
    print(f"{'='*60}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €
    checkpoint_mgr = CheckpointManager(f"data/checkpoints/precedents_{category}")
    print(f"ğŸ“ Checkpoint directory: data/checkpoints/precedents_{category}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    actual_start_page = start_page
    checkpoint = None
    
    if resume:
        print(f"ğŸ” Checking for existing checkpoint...")
        checkpoint = checkpoint_mgr.load_checkpoint()
        if checkpoint:
            print(f"ğŸ“‚ Resuming from checkpoint")
            print(f"   Data type: {checkpoint.get('data_type', 'unknown')}")
            print(f"   Category: {checkpoint.get('category', 'None')}")
            print(f"   Page: {checkpoint.get('current_page', 0)}/{checkpoint.get('total_pages', 0)}")
            print(f"   Collected: {checkpoint.get('collected_count', 0)} items")
            print(f"   Memory: {checkpoint.get('memory_usage_mb', 0):.1f}MB")
            actual_start_page = checkpoint['current_page'] + 1
        else:
            print(f"ğŸ“‚ No checkpoint found, starting from page {start_page}")
    else:
        print(f"ğŸ“‚ Resume disabled, starting from page {start_page}")
    
    # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ìµœì í™”)
    print(f"\nğŸ“¦ Initializing collector...")
    collector = AssemblyCollector(
        base_dir="data/raw/assembly",
        data_type="precedent",
        category=category,
        batch_size=20,  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ (50 â†’ 20)
        memory_limit_mb=600  # ë©”ëª¨ë¦¬ ì œí•œ ê°ì†Œ (800 â†’ 600)
    )
    print(f"âœ… Collector initialized")
    
    # ì‹œì‘ ì‹œê°„ ì„¤ì •
    start_time = datetime.now().isoformat()
    collector.set_start_time(start_time)
    
    # ì „ì²´ í˜ì´ì§€ ê³„ì‚° (ì‹¤ì œë¡œëŠ” í˜ì´ì§€ë‹¹ 10ê°œì”© í‘œì‹œë¨)
    if target_count:
        total_pages = actual_start_page + (target_count + 10 - 1) // 10 - 1  # í˜ì´ì§€ë‹¹ 10ê°œ
    else:
        total_pages = 100  # ëŒ€ëµì ì¸ í˜ì´ì§€ ìˆ˜
    
    print(f"\nğŸ“Š Collection Parameters:")
    print(f"   Category: {category_name} ({category_code})")
    print(f"   Target: {target_count or 'ALL'}")
    print(f"   Pages: {actual_start_page} to {total_pages}")
    print(f"   Page size: 10 (fixed)")
    print(f"   Batch size: {collector.batch_size}")
    print(f"   Memory limit: {collector.memory_limit_mb}MB")
    print(f"   Start time: {start_time}")
    
    collected_this_run = 0
    
    try:
        print(f"\nğŸŒ Starting Playwright browser...")
        with AssemblyPlaywrightClient(
            rate_limit=3.0,
            headless=True,
            memory_limit_mb=600  # ë©”ëª¨ë¦¬ ì œí•œ ê°ì†Œ (800 â†’ 600)
        ) as client:
            print(f"âœ… Playwright browser started")
            
            for page in range(actual_start_page, total_pages + 1):
                if interrupted:
                    print(f"\nâš ï¸ INTERRUPTED by user signal")
                    break
                
                print(f"\n{'â”€'*50}")
                print(f"ğŸ“„ Processing Page {page}/{total_pages}")
                print(f"ğŸ“‹ Category: {category_name}")
                print(f"{'â”€'*50}")
                
                memory_mb = client.check_memory_usage()
                print(f"ğŸ“Š Memory usage: {memory_mb:.1f}MB")
                
                print(f"ğŸ” Fetching {category_name} precedent list from page {page}...")
                precedents = client.get_precedent_list_page_by_category(
                    category_code=category_code,
                    page_num=page, 
                    page_size=10
                )
                print(f"âœ… Found {len(precedents)} precedents on page")
                
                if not precedents:
                    print(f"âš ï¸ No precedents found on page {page}, skipping...")
                    continue
                
                # ê° íŒë¡€ ìƒì„¸ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ìµœì í™”)
                print(f"ğŸ“‹ Processing {len(precedents)} precedents...")
                page_precedents = []  # í˜„ì¬ í˜ì´ì§€ì˜ íŒë¡€ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                
                for idx, precedent_item in enumerate(precedents, 1):
                    if interrupted:
                        print(f"\nâš ï¸ INTERRUPTED during precedent processing")
                        break
                    
                    try:
                        print(f"   [{idx:2d}/{len(precedents)}] Processing: {precedent_item['case_name'][:50]}...")
                        
                        detail = client.get_precedent_detail(precedent_item)
                        
                        # ë¶„ì•¼ ì •ë³´ ì¶”ê°€
                        detail.update({
                            'category': category_name,
                            'category_code': category_code
                        })
                        
                        # ë©”ëª¨ë¦¬ ìµœì í™”: content_html í¬ê¸° ì œí•œ
                        if 'content_html' in detail and len(detail['content_html']) > 1000000:  # 1MB ì œí•œ
                            detail['content_html'] = detail['content_html'][:1000000] + "... [TRUNCATED]"
                            print(f"      âš ï¸ HTML content truncated to 1MB")
                        
                        page_precedents.append(detail)  # í˜ì´ì§€ë³„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        collector.save_item(detail)
                        collected_this_run += 1
                        
                        print(f"      âœ… Collected (Total: {collector.collected_count})")
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë§¤ 5ê°œë§ˆë‹¤)
                        if idx % 5 == 0:
                            import gc
                            gc.collect()
                            print(f"      ğŸ§¹ Memory cleanup at item {idx}")
                        
                        # ëª©í‘œ ë‹¬ì„± ì²´í¬
                        if target_count and collected_this_run >= target_count:
                            print(f"\nğŸ¯ TARGET REACHED: {collected_this_run}/{target_count}")
                            break
                        
                    except Exception as e:
                        print(f"      âŒ Failed: {str(e)[:100]}...")
                        collector.add_failed_item(precedent_item, str(e))
                        continue
                
                # í˜„ì¬ í˜ì´ì§€ì˜ íŒë¡€ë“¤ì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ (ë©”ëª¨ë¦¬ ìµœì í™”)
                if page_precedents:
                    timestamp = datetime.now().strftime("%H%M%S")
                    page_filename = f"precedent_{category}_page_{page:03d}_{timestamp}.json"
                    page_filepath = collector.output_dir / page_filename
                    
                    # ë©”ëª¨ë¦¬ ìµœì í™”: ê°„ì†Œí™”ëœ í˜ì´ì§€ ë°ì´í„°
                    page_data = {
                        "category": category_name,
                        "category_code": category_code,
                        "page_number": page,
                        "total_pages": total_pages,
                        "precedents_count": len(page_precedents),
                        "collected_at": datetime.now().isoformat(),
                        "precedents": page_precedents
                    }
                    
                    # ì••ì¶•ëœ JSONìœ¼ë¡œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
                    with open(page_filepath, 'w', encoding='utf-8') as f:
                        json.dump(page_data, f, ensure_ascii=False, separators=(',', ':'))
                    
                    print(f"ğŸ“„ Page {page} saved: {page_filename} ({len(page_precedents)} precedents)")
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬: í˜ì´ì§€ ë°ì´í„° ì¦‰ì‹œ ì‚­ì œ
                    del page_precedents
                    del page_data
                    import gc
                    gc.collect()
                    print(f"ğŸ§¹ Page {page} memory cleaned up")
                
                # ì§„í–‰ë¥  ë¡œê·¸
                print(f"\nğŸ“ˆ Progress Summary:")
                print(f"   Category: {category_name}")
                print(f"   Page: {page}/{total_pages} ({page/total_pages*100:.1f}%)")
                print(f"   Collected this run: {collected_this_run}")
                print(f"   Total collected: {collector.collected_count}")
                print(f"   Failed: {len(collector.failed_items)}")
                print(f"   Success rate: {collector.collected_count/(collector.collected_count + len(collector.failed_items))*100:.1f}%" if (collector.collected_count + len(collector.failed_items)) > 0 else "   Success rate: N/A")
                
                checkpoint_data = {
                    'data_type': 'precedent',
                    'category': category,
                    'category_code': category_code,
                    'current_page': page,
                    'total_pages': total_pages,
                    'collected_count': collector.collected_count,
                    'collected_this_run': collected_this_run,
                    'start_time': checkpoint['start_time'] if checkpoint else start_time,
                    'memory_usage_mb': memory_mb,
                    'target_count': target_count,
                    'page_size': page_size
                }
                
                checkpoint_mgr.save_checkpoint(checkpoint_data)
                print(f"ğŸ’¾ Checkpoint saved at page {page}")
                
                if target_count and collected_this_run >= target_count:
                    print(f"\nğŸ¯ Target achieved, stopping collection")
                    break
            
            print(f"\nğŸ Finalizing collection...")
            collector.finalize()
            
            if not interrupted:
                checkpoint_mgr.clear_checkpoint()
                print(f"\nâœ… COLLECTION COMPLETED SUCCESSFULLY!")
            else:
                print(f"\nâš ï¸ COLLECTION INTERRUPTED (progress saved)")
            
            # ìµœì¢… í†µê³„
            print(f"\nğŸ“Š Final Statistics:")
            print(f"   Category: {category_name}")
            print(f"   Total collected: {collector.collected_count} items")
            print(f"   Failed: {len(collector.failed_items)} items")
            print(f"   Requests made: {client.request_count}")
            print(f"   Rate limit: {client.get_stats()['rate_limit']}s")
            print(f"   Timeout: {client.get_stats()['timeout']}ms")
            
    except Exception as e:
        print(f"\nâŒ CRITICAL ERROR: {e}")
        print(f"ğŸ”§ Finalizing collector...")
        collector.finalize()
        raise

def collect_all_categories(target_count_per_category: int = 50):
    """ëª¨ë“  ë¶„ì•¼ë³„ë¡œ íŒë¡€ ìˆ˜ì§‘"""
    categories = ['civil', 'criminal', 'family']
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ COLLECTING PRECEDENTS FOR ALL CATEGORIES")
    print(f"ğŸ“‹ Categories: {', '.join([CATEGORY_NAMES[cat] for cat in categories])}")
    print(f"ğŸ“Š Target per category: {target_count_per_category}")
    print(f"{'='*60}")
    
    total_collected = 0
    
    for category in categories:
        try:
            print(f"\nğŸ”„ Starting collection for {CATEGORY_NAMES[category]}...")
            collect_precedents_by_category(
                category=category,
                target_count=target_count_per_category,
                resume=False,  # ê° ë¶„ì•¼ë³„ë¡œ ìƒˆë¡œ ì‹œì‘
                start_page=1
            )
            print(f"âœ… Completed {CATEGORY_NAMES[category]} collection")
            
        except Exception as e:
            print(f"âŒ Failed to collect {CATEGORY_NAMES[category]}: {e}")
            continue
    
    print(f"\nğŸ‰ ALL CATEGORIES COLLECTION COMPLETED!")
    print(f"ğŸ“Š Total collected: {total_collected} precedents")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë¶„ì•¼ë³„ íŒë¡€ ìˆ˜ì§‘ (Playwright)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
Available categories:
  civil          - ë¯¼ì‚¬ (PREC00_001)
  criminal        - í˜•ì‚¬ (PREC00_002)  
  family          - ê°€ì‚¬ (PREC00_003)
  administrative  - í–‰ì • (PREC00_004)
  constitutional  - í—Œë²• (PREC00_005)
  labor           - ë…¸ë™ (PREC00_006)
  tax             - ì„¸ë¬´ (PREC00_007)
  patent          - íŠ¹í—ˆ (PREC00_008)
  maritime        - í•´ì‚¬ (PREC00_009)
  military        - êµ°ì‚¬ (PREC00_010)

Examples:
  python collect_precedents_by_category.py --category civil --sample 50
  python collect_precedents_by_category.py --category criminal --sample 100
  python collect_precedents_by_category.py --category family --sample 30
  python collect_precedents_by_category.py --all-categories --sample 20
        """
    )
    
    parser.add_argument('--category', type=str, 
                        choices=list(CATEGORY_CODES.keys()),
                        help='ìˆ˜ì§‘í•  ë¶„ì•¼ ì„ íƒ')
    parser.add_argument('--all-categories', action='store_true',
                        help='ëª¨ë“  ë¶„ì•¼ ìˆ˜ì§‘ (ë¯¼ì‚¬, í˜•ì‚¬, ê°€ì‚¬)')
    parser.add_argument('--sample', type=int, metavar='N',
                        help='ìƒ˜í”Œ ìˆ˜ì§‘ ê°œìˆ˜ (10, 50, 100 ë“±)')
    parser.add_argument('--resume', action='store_true', default=True,
                        help='ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ (ê¸°ë³¸ê°’)')
    parser.add_argument('--no-resume', dest='resume', action='store_false',
                        help='ì²˜ìŒë¶€í„° ì‹œì‘')
    parser.add_argument('--page-size', type=int, default=100,
                        help='í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--start-page', type=int, default=1,
                        help='ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸: 1)')
    parser.add_argument('--log-level', type=str, default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help='ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸: INFO)')
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ë ˆë²¨ ì¬ì„¤ì •
    if args.log_level != 'INFO':
        logger.setLevel(getattr(logging, args.log_level))
    
    if args.all_categories:
        if not args.sample:
            args.sample = 50  # ê¸°ë³¸ê°’
        print(f"ğŸ“¦ All categories mode: {args.sample} items per category")
        collect_all_categories(target_count_per_category=args.sample)
    elif args.category:
        if not args.sample:
            print("âŒ Please specify --sample N")
            sys.exit(1)
        print(f"ğŸ“¦ Category mode: {CATEGORY_NAMES[args.category]} - {args.sample} items")
        collect_precedents_by_category(
            category=args.category,
            target_count=args.sample,
            page_size=args.page_size,
            resume=args.resume,
            start_page=args.start_page
        )
    else:
        parser.print_help()
        logger.error("\nâŒ Please specify --category CATEGORY or --all-categories")
        sys.exit(1)

if __name__ == "__main__":
    main()
