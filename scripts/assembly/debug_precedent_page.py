#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ íŒë¡€ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„
"""

import sys
from pathlib import Path
import json
import time
from playwright.sync_api import sync_playwright

project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.assembly_playwright_client import AssemblyPlaywrightClient

def debug_precedent_page():
    print(f"ğŸ” êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ íŒë¡€ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    
    analysis_results = {
        "page_url": "https://likms.assembly.go.kr/law/lawsPrecInqyList2010.do",
        "html_length": 0,
        "table_structure": {},
        "pagination_info": {},
        "form_elements": {},
        "javascript_functions": [],
        "network_requests": [],
        "console_logs": []
    }

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()
        page.set_default_timeout(60000)
        
        # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¡œê¹…
        page.on("request", lambda request: analysis_results["network_requests"].append({
            "url": request.url,
            "method": request.method,
            "headers": request.headers
        }))
        page.on("response", lambda response: print(f"ğŸ“¥ ì‘ë‹µ: {response.status} {response.url}"))
        page.on("console", lambda msg: analysis_results["console_logs"].append({"type": msg.type, "text": msg.text}))

        # íŒë¡€ ëª©ë¡ í˜ì´ì§€ ì ‘ê·¼
        url = "https://likms.assembly.go.kr/law/lawsPrecInqyList2010.do?genActiontypeCd=2ACT1010&genDoctreattypeCd=&genMenuId=menu_serv_nlaw_lawt_4020&procWorkId="
        print(f"\nğŸŒ í˜ì´ì§€ ì ‘ê·¼: {url}")
        page.goto(url, wait_until='domcontentloaded')
        print(f"â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°...")
        page.wait_for_timeout(5000)

        analysis_results["html_length"] = len(page.content())
        print(f"\nğŸ“Š í˜ì´ì§€ êµ¬ì¡° ë¶„ì„:")
        print(f"ğŸ“„ ì „ì²´ HTML ê¸¸ì´: {analysis_results['html_length']} chars")

        # í…Œì´ë¸” êµ¬ì¡° ë¶„ì„
        print(f"\nğŸ“‹ í…Œì´ë¸” êµ¬ì¡° ë¶„ì„:")
        tables = page.locator("table").all()
        print(f"í…Œì´ë¸” ê°œìˆ˜: {len(tables)}")
        
        for i, table in enumerate(tables):
            try:
                rows = table.locator("tr").all()
                cols = table.locator("td, th").all()
                table_info = {
                    "table_index": i,
                    "row_count": len(rows),
                    "col_count": len(cols),
                    "headers": [],
                    "sample_data": []
                }
                
                # í—¤ë” ë¶„ì„
                if rows:
                    header_row = rows[0]
                    headers = header_row.locator("th, td").all()
                    for header in headers:
                        header_text = header.inner_text().strip()
                        if header_text:
                            table_info["headers"].append(header_text)
                
                # ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ (ì²« ë²ˆì§¸ ë°ì´í„° í–‰)
                if len(rows) > 1:
                    data_row = rows[1]
                    cells = data_row.locator("td").all()
                    for cell in cells:
                        cell_text = cell.inner_text().strip()
                        if cell_text:
                            table_info["sample_data"].append(cell_text)
                
                analysis_results["table_structure"][f"table_{i}"] = table_info
                print(f"   í…Œì´ë¸” {i+1}: {len(rows)}í–‰, {len(cols)}ì—´")
                print(f"   í—¤ë”: {table_info['headers']}")
                print(f"   ìƒ˜í”Œ: {table_info['sample_data'][:3]}...")
                
            except Exception as e:
                print(f"   í…Œì´ë¸” {i+1} ë¶„ì„ ì˜¤ë¥˜: {e}")

        # í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„
        print(f"\nğŸ“„ í˜ì´ì§€ë„¤ì´ì…˜ ë¶„ì„:")
        pagination_selectors = [
            "span.page_no", "div.pagination", "div.page", "ul.pagination",
            "span[class*='page']", "div[class*='page']", "ul[class*='page']"
        ]
        
        pagination_info = {}
        for selector in pagination_selectors:
            elements = page.locator(selector).all()
            if elements:
                pagination_info[selector] = {
                    "count": len(elements),
                    "text": [elem.inner_text().strip() for elem in elements],
                    "html": [elem.inner_html() for elem in elements]
                }
                print(f"   {selector}: {len(elements)}ê°œ ë°œê²¬")
                for elem in elements:
                    text = elem.inner_text().strip()
                    if text:
                        print(f"     í…ìŠ¤íŠ¸: {text[:100]}...")
        
        analysis_results["pagination_info"] = pagination_info

        # í¼ ìš”ì†Œ ë¶„ì„
        print(f"\nğŸ“ í¼ ìš”ì†Œ ë¶„ì„:")
        forms = page.locator("form").all()
        print(f"í¼ ê°œìˆ˜: {len(forms)}")
        
        for i, form in enumerate(forms):
            form_info = {
                "form_index": i,
                "action": form.get_attribute("action"),
                "method": form.get_attribute("method"),
                "inputs": [],
                "selects": [],
                "buttons": []
            }
            
            # ì…ë ¥ í•„ë“œ
            inputs = form.locator("input").all()
            for input_elem in inputs:
                input_info = {
                    "type": input_elem.get_attribute("type"),
                    "name": input_elem.get_attribute("name"),
                    "id": input_elem.get_attribute("id"),
                    "value": input_elem.get_attribute("value")
                }
                form_info["inputs"].append(input_info)
            
            # ì„ íƒ ë°•ìŠ¤
            selects = form.locator("select").all()
            for select_elem in selects:
                select_info = {
                    "name": select_elem.get_attribute("name"),
                    "id": select_elem.get_attribute("id"),
                    "options": []
                }
                options = select_elem.locator("option").all()
                for option in options:
                    option_info = {
                        "value": option.get_attribute("value"),
                        "text": option.inner_text().strip()
                    }
                    select_info["options"].append(option_info)
                form_info["selects"].append(select_info)
            
            # ë²„íŠ¼
            buttons = form.locator("button, input[type='submit'], input[type='button']").all()
            for button in buttons:
                button_info = {
                    "type": button.get_attribute("type"),
                    "value": button.get_attribute("value"),
                    "text": button.inner_text().strip(),
                    "onclick": button.get_attribute("onclick")
                }
                form_info["buttons"].append(button_info)
            
            analysis_results["form_elements"][f"form_{i}"] = form_info
            print(f"   í¼ {i+1}: action='{form_info['action']}', method='{form_info['method']}'")
            print(f"     ì…ë ¥: {len(form_info['inputs'])}ê°œ")
            print(f"     ì„ íƒ: {len(form_info['selects'])}ê°œ")
            print(f"     ë²„íŠ¼: {len(form_info['buttons'])}ê°œ")

        # JavaScript í•¨ìˆ˜ ë¶„ì„
        print(f"\nğŸ”§ JavaScript í•¨ìˆ˜ ë¶„ì„:")
        script_tags = page.locator("script").all()
        js_functions = []
        
        for script in script_tags:
            script_content = script.inner_html()
            if script_content:
                # í•¨ìˆ˜ ì •ì˜ ì°¾ê¸°
                if "function" in script_content:
                    lines = script_content.split('\n')
                    for line in lines:
                        if "function" in line and "(" in line:
                            func_name = line.split("function")[1].split("(")[0].strip()
                            if func_name:
                                js_functions.append(func_name)
        
        analysis_results["javascript_functions"] = list(set(js_functions))
        print(f"ë°œê²¬ëœ í•¨ìˆ˜: {analysis_results['javascript_functions']}")

        # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„
        print(f"\nğŸŒ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶„ì„:")
        print(f"ğŸ“¤ ìš”ì²­ ê°œìˆ˜: {len(analysis_results['network_requests'])}")
        
        # íŒë¡€ ê´€ë ¨ ìš”ì²­ í•„í„°ë§
        precedent_requests = [req for req in analysis_results["network_requests"] 
                            if 'prec' in req['url'].lower() or 'precedent' in req['url'].lower()]
        print(f"ğŸ“‹ íŒë¡€ ê´€ë ¨ ìš”ì²­: {len(precedent_requests)}ê°œ")
        
        for req in precedent_requests[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"   {req['method']} {req['url']}")

        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        screenshot_path = "precedent_page_analysis.png"
        page.screenshot(path=screenshot_path, full_page=True)
        print(f"\nğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")

        # ê²°ê³¼ JSON ì €ì¥
        result_file = "precedent_page_analysis_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_file}")

        print(f"\nğŸ” ë¸Œë¼ìš°ì €ê°€ ì—´ë ¤ìˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ë³´ì„¸ìš”.")
        print(f"â³ 60ì´ˆ í›„ ìë™ìœ¼ë¡œ ë‹«í™ë‹ˆë‹¤...")
        time.sleep(60)
        browser.close()

if __name__ == "__main__":
    debug_precedent_page()
