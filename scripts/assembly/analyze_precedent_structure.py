#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÌåêÎ°Ä ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄ Î™©Ï∞® Íµ¨Ï°∞ Î∂ÑÏÑù
"""

import sys
from pathlib import Path

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏Î•º Python Í≤ΩÎ°úÏóê Ï∂îÍ∞Ä
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.assembly_playwright_client import AssemblyPlaywrightClient

def analyze_precedent_structure():
    """ÌåêÎ°Ä ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄÏùò Î™©Ï∞® Íµ¨Ï°∞ Î∂ÑÏÑù"""
    
    with AssemblyPlaywrightClient(headless=False) as client:
        # ÎØºÏÇ¨ ÌåêÎ°Ä Ï≤´ Î≤àÏß∏ Ìï≠Î™©ÏúºÎ°ú Ïù¥Îèô
        print("üîç Analyzing precedent detail page structure...")
        
        # ÌåêÎ°Ä Î™©Î°ù ÌéòÏù¥ÏßÄÎ°ú Ïù¥Îèô
        precedents = client.get_precedent_list_page_by_category("PREC00_001", 1, 10)
        
        if precedents:
            first_precedent = precedents[0]
            print(f"üìã Analyzing: {first_precedent['case_name']}")
            
            # ÏÉÅÏÑ∏ ÌéòÏù¥ÏßÄÎ°ú Ïù¥Îèô
            url = f"{client.BASE_URL}/law/lawsPrecInqyDetl1010.do"
            url_params = []
            for key, value in first_precedent['params'].items():
                if value:
                    url_params.append(f"{key}={value}")
            
            params_str = "&".join(url_params)
            full_url = f"{url}?{params_str}"
            
            print(f"üåê Navigating to: {full_url}")
            client.page.goto(full_url, wait_until='domcontentloaded')
            client.page.wait_for_timeout(5000)
            
            # ÌéòÏù¥ÏßÄ Íµ¨Ï°∞ Î∂ÑÏÑù
            print("\nüìä Page Structure Analysis:")
            
            # 1. Ìó§Îçî Ï†ïÎ≥¥
            print("\n1Ô∏è‚É£ Header Information:")
            try:
                h1_elements = client.page.locator("h1").all()
                for i, h1 in enumerate(h1_elements):
                    print(f"   H1-{i+1}: {h1.inner_text().strip()}")
            except Exception as e:
                print(f"   H1 Error: {e}")
            
            # 2. Î™©Ï∞®/ÏÑπÏÖò Íµ¨Ï°∞
            print("\n2Ô∏è‚É£ Table of Contents / Sections:")
            try:
                # Îã§ÏñëÌïú Î™©Ï∞® Ìå®ÌÑ¥ ÏãúÎèÑ
                toc_selectors = [
                    "div.toc", "div.table-of-contents", "div.contents",
                    "ul.toc", "ol.toc", "div.section",
                    "div.content-section", "div.precedent-section"
                ]
                
                for selector in toc_selectors:
                    elements = client.page.locator(selector).all()
                    if elements:
                        print(f"   Found {selector}: {len(elements)} elements")
                        for i, elem in enumerate(elements[:3]):  # Ï≤òÏùå 3Í∞úÎßå
                            text = elem.inner_text().strip()
                            if text:
                                print(f"     {i+1}: {text[:100]}...")
                
                # ÏùºÎ∞òÏ†ÅÏù∏ Ìó§Îî© ÌÉúÍ∑∏Îì§
                heading_tags = ["h2", "h3", "h4", "h5", "h6"]
                for tag in heading_tags:
                    elements = client.page.locator(tag).all()
                    if elements:
                        print(f"   {tag.upper()} headings: {len(elements)}")
                        for i, elem in enumerate(elements[:5]):  # Ï≤òÏùå 5Í∞úÎßå
                            text = elem.inner_text().strip()
                            if text:
                                print(f"     {i+1}: {text}")
                
            except Exception as e:
                print(f"   TOC Error: {e}")
            
            # 3. ÌåêÎ°Ä Í¥ÄÎ†® ÌäπÏ†ï ÏÑπÏÖòÎì§
            print("\n3Ô∏è‚É£ Legal Sections:")
            legal_sections = [
                "ÌåêÏãúÏÇ¨Ìï≠", "ÌåêÍ≤∞ÏöîÏßÄ", "ÏÇ¨Í±¥", "ÏõêÍ≥†", "ÌîºÍ≥†", "ÏõêÏã¨", "ÏÉÅÍ≥†", 
                "Ìï≠ÏÜå", "ÏÜåÏÜ°", "Í≥ÑÏïΩ", "ÏÜêÌï¥", "Î∞∞ÏÉÅ", "ÏúÑÏïΩ", "Ìï¥ÏßÄ", "Î¨¥Ìö®", "Ï∑®ÏÜå",
                "Ï£ºÎ¨∏", "Ïù¥Ïú†", "Ï∞∏Ï°∞Ï°∞Î¨∏", "Ï∞∏Ï°∞ÌåêÎ°Ä", "ÌåêÎ°ÄÏßë", "Î≤ïÏõê", "ÏÑ†Í≥†Ïùº"
            ]
            
            for section in legal_sections:
                try:
                    elements = client.page.locator(f"text={section}").all()
                    if elements:
                        print(f"   '{section}': {len(elements)} occurrences")
                        for i, elem in enumerate(elements[:2]):  # Ï≤òÏùå 2Í∞úÎßå
                            parent_text = elem.locator("..").inner_text().strip()
                            if parent_text:
                                print(f"     {i+1}: {parent_text[:100]}...")
                except Exception as e:
                    print(f"   '{section}' Error: {e}")
            
            # 4. ÌÖåÏù¥Î∏î Íµ¨Ï°∞
            print("\n4Ô∏è‚É£ Table Structure:")
            try:
                tables = client.page.locator("table").all()
                print(f"   Tables found: {len(tables)}")
                for i, table in enumerate(tables):
                    rows = table.locator("tr").all()
                    print(f"   Table {i+1}: {len(rows)} rows")
                    if rows:
                        # Ï≤´ Î≤àÏß∏ Ìñâ (Ìó§Îçî) ÌôïÏù∏
                        first_row = rows[0]
                        cells = first_row.locator("td, th").all()
                        headers = [cell.inner_text().strip() for cell in cells]
                        print(f"     Headers: {headers}")
            except Exception as e:
                print(f"   Table Error: {e}")
            
            # 5. Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ Íµ¨Ï°∞ Î∂ÑÏÑù
            print("\n5Ô∏è‚É£ Text Structure Analysis:")
            try:
                full_text = client.page.locator("body").inner_text()
                lines = full_text.split('\n')
                
                print(f"   Total lines: {len(lines)}")
                print(f"   Total characters: {len(full_text)}")
                
                # Îπà Ï§ÑÏù¥ ÏïÑÎãå ÎùºÏù∏Îì§
                non_empty_lines = [line.strip() for line in lines if line.strip()]
                print(f"   Non-empty lines: {len(non_empty_lines)}")
                
                # Í∏¥ ÎùºÏù∏Îì§ (50Ïûê Ïù¥ÏÉÅ)
                long_lines = [line for line in non_empty_lines if len(line) >= 50]
                print(f"   Long lines (50+ chars): {len(long_lines)}")
                
                # Ï≤´ 10Í∞ú Í∏¥ ÎùºÏù∏ Ï∂úÎ†•
                print("   Sample long lines:")
                for i, line in enumerate(long_lines[:10]):
                    print(f"     {i+1}: {line[:80]}...")
                    
            except Exception as e:
                print(f"   Text Analysis Error: {e}")
            
            # 6. HTML Íµ¨Ï°∞ Ï†ÄÏû•
            print("\n6Ô∏è‚É£ Saving HTML structure for analysis...")
            try:
                html_content = client.page.content()
                with open("precedent_structure_analysis.html", "w", encoding="utf-8") as f:
                    f.write(html_content)
                print("   HTML saved to: precedent_structure_analysis.html")
            except Exception as e:
                print(f"   HTML Save Error: {e}")

if __name__ == "__main__":
    analyze_precedent_structure()
