#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë²•ë¥  ìˆ˜ì§‘ (ìµœì í™” ë²„ì „)

ì„±ëŠ¥ ê°œì„  ì‚¬í•­:
1. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
2. ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì²´í¬ ìµœì†Œí™”
3. íŒŒì¼ I/O ìµœì í™”
4. í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ìµœì í™”
5. ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 

ì‚¬ìš©ë²•:
  python collect_laws_optimized.py --sample 10     # ìƒ˜í”Œ 10ê°œ
  python collect_laws_optimized.py --sample 100    # ìƒ˜í”Œ 100ê°œ
  python collect_laws_optimized.py --sample 1000   # ìƒ˜í”Œ 1000ê°œ
  python collect_laws_optimized.py --full          # ì „ì²´ 7602ê°œ
  python collect_laws_optimized.py --resume        # ì¤‘ë‹¨ ì§€ì ì—ì„œ ì¬ê°œ
"""

import argparse
import sys
import signal
import logging
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.data.assembly_playwright_client import AssemblyPlaywrightClient
from scripts.assembly.assembly_collector import AssemblyCollector
from scripts.assembly.checkpoint_manager import CheckpointManager
from scripts.assembly.assembly_logger import setup_logging, log_progress, log_memory_usage, log_collection_stats, log_checkpoint_info
from scripts.monitoring.metrics_collector import LawCollectionMetrics

# ë¡œê±° ì„¤ì •
logger = setup_logging("law_collection_optimized")

# Graceful shutdown ì²˜ë¦¬
interrupted = False

def signal_handler(sig, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (Ctrl+C ë“±)"""
    global interrupted
    logger.warning("\nâš ï¸ Interrupt signal received. Saving progress...")
    interrupted = True

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

class OptimizedLawCollector:
    """ìµœì í™”ëœ ë²•ë¥  ìˆ˜ì§‘ê¸° (í˜ì´ì§€ë³„ ì €ì¥)"""
    
    def __init__(self, base_dir: str = "data/raw/assembly", page_size: int = 10, enable_metrics: bool = True):
        self.base_dir = Path(base_dir)
        self.page_size = page_size
        self.collected_items = []
        self.failed_items = []
        self.start_time = None
        self.enable_metrics = enable_metrics
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir = self.base_dir / "law" / datetime.now().strftime("%Y%m%d")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ Output directory: {self.output_dir}")
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        if self.enable_metrics:
            try:
                # ê¸°ì¡´ ë©”íŠ¸ë¦­ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                import requests
                try:
                    response = requests.get("http://localhost:8000/metrics", timeout=1)
                    if response.status_code == 200:
                        print(f"ğŸ“Š Using existing metrics server")
                        # ê¸°ì¡´ ì„œë²„ë¥¼ ì‚¬ìš©í•˜ë˜, ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤ëŠ” ìƒˆë¡œ ìƒì„±
                        self.metrics = LawCollectionMetrics()
                        self.metrics.start_collection()
                        print(f"ğŸ“Š Connected to existing metrics server")
                    else:
                        raise Exception("Metrics server not responding")
                except:
                    # ë©”íŠ¸ë¦­ ì„œë²„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì‹œì‘
                    print(f"ğŸ“Š Starting new metrics server")
                    self.metrics = LawCollectionMetrics()
                    self.metrics.start_server()
                    self.metrics.start_collection()
                    print(f"ğŸ“Š Metrics server started")
                
                print(f"ğŸ“Š Metrics collection enabled")
            except Exception as e:
                print(f"âš ï¸ Failed to start metrics: {e}")
                self.enable_metrics = False
                self.metrics = None
        else:
            self.metrics = None
            print(f"ğŸ“Š Metrics collection disabled")
    
    def add_item(self, item: Dict):
        """ì•„ì´í…œ ì¶”ê°€ (í˜ì´ì§€ë³„ ì²˜ë¦¬ìš©)"""
        self.collected_items.append(item)
    
    def save_page(self, page_number: int):
        """í˜ì´ì§€ë³„ ì €ì¥ (10ê°œì”©)"""
        if not self.collected_items:
            return
        
        # í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        page_start_time = time.time()
        
        timestamp = datetime.now().strftime("%H%M%S")
        page_filename = f"law_page_{page_number:03d}_{timestamp}.json"
        page_filepath = self.output_dir / page_filename
        
        page_data = {
            "page_info": {
                "page_number": page_number,
                "laws_count": len(self.collected_items),
                "saved_at": datetime.now().isoformat(),
                "page_size": self.page_size
            },
            "laws": self.collected_items
        }
        
        try:
            with open(page_filepath, 'w', encoding='utf-8') as f:
                json.dump(page_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ Page {page_number} saved: {page_filename} ({len(self.collected_items)} laws)")
            
            # ë©”íŠ¸ë¦­ ê¸°ë¡
            if self.metrics:
                page_duration = time.time() - page_start_time
                self.metrics.record_page_processed(page_number)
                self.metrics.record_laws_collected(len(self.collected_items))
                self.metrics.record_page_processing_time(page_duration)
                
                # í˜ì´ì§€ ì •ë³´ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
                page_data["page_info"]["processing_time"] = page_duration
            
            self.collected_items.clear()
            
        except Exception as e:
            print(f"âŒ Failed to save page {page_number}: {e}")
            if self.metrics:
                self.metrics.record_error("file_save_error")
    
    def add_failed_item(self, item: Dict, error: str):
        """ì‹¤íŒ¨í•œ ì•„ì´í…œ ì¶”ê°€"""
        self.failed_items.append({
            'item': item,
            'error': error,
            'timestamp': datetime.now().isoformat()
        })
        
        # ì—ëŸ¬ ë©”íŠ¸ë¦­ ê¸°ë¡
        if self.metrics:
            error_type = "network_error" if "network" in error.lower() else "parsing_error"
            self.metrics.record_error(error_type)
    
    def finalize(self):
        """ìµœì¢… ì €ì¥"""
        if self.collected_items:
            # ë‚¨ì€ ì•„ì´í…œë“¤ì„ ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ ì €ì¥
            timestamp = datetime.now().strftime("%H%M%S")
            page_filename = f"law_page_final_{timestamp}.json"
            page_filepath = self.output_dir / page_filename
            
            page_data = {
                "page_info": {
                    "page_number": "final",
                    "laws_count": len(self.collected_items),
                    "saved_at": datetime.now().isoformat(),
                    "page_size": self.page_size
                },
                "laws": self.collected_items
            }
            
            try:
                with open(page_filepath, 'w', encoding='utf-8') as f:
                    json.dump(page_data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ“„ Final page saved: {page_filename} ({len(self.collected_items)} laws)")
                
                # ë©”íŠ¸ë¦­ ê¸°ë¡
                if self.metrics:
                    self.metrics.record_laws_collected(len(self.collected_items))
                
                self.collected_items.clear()
                
            except Exception as e:
                print(f"âŒ Failed to save final page: {e}")
                if self.metrics:
                    self.metrics.record_error("file_save_error")
        
        # ì‹¤íŒ¨í•œ ì•„ì´í…œë“¤ ì €ì¥
        if self.failed_items:
            failed_filename = f"failed_items_{datetime.now().strftime('%H%M%S')}.json"
            failed_filepath = self.output_dir / failed_filename
            
            with open(failed_filepath, 'w', encoding='utf-8') as f:
                json.dump(self.failed_items, f, ensure_ascii=False, indent=2)
            
            print(f"âŒ Failed items saved: {failed_filename} ({len(self.failed_items)} items)")
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€
        if self.metrics:
            self.metrics.stop_collection()
    
    @property
    def collected_count(self) -> int:
        """ìˆ˜ì§‘ëœ ì´ ì•„ì´í…œ ìˆ˜"""
        # í˜ì´ì§€ íŒŒì¼ë“¤ì—ì„œ ì´ ê°œìˆ˜ ê³„ì‚°
        total_count = len(self.collected_items)  # í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” ì•„ì´í…œë“¤
        
        # ì €ì¥ëœ í˜ì´ì§€ íŒŒì¼ë“¤ì—ì„œ ê°œìˆ˜ í•©ì‚°
        for page_file in self.output_dir.glob("law_page_*.json"):
            try:
                with open(page_file, 'r', encoding='utf-8') as f:
                    page_data = json.load(f)
                    if 'page_info' in page_data and 'laws_count' in page_data['page_info']:
                        total_count += page_data['page_info']['laws_count']
            except Exception:
                continue
        
        return total_count

def collect_laws_optimized(
    target_count: int = None,
    page_size: int = 100,
    resume: bool = True,
    start_page: int = 1,
    laws_per_page: int = 10,
    enable_metrics: bool = True
):
    """
    ìµœì í™”ëœ ì ì§„ì  ë²•ë¥  ìˆ˜ì§‘ (í˜ì´ì§€ë³„ ì €ì¥)
    
    Args:
        target_count: ëª©í‘œ ìˆ˜ì§‘ ê±´ìˆ˜ (None=ì „ì²´)
        page_size: í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (100 ê¶Œì¥)
        resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
        start_page: ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸
        laws_per_page: í˜ì´ì§€ë‹¹ ë²•ë¥  ìˆ˜ (10ê°œ ê³ ì •)
        enable_metrics: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™” ì—¬ë¶€
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ OPTIMIZED LAW COLLECTION STARTED")
    print(f"{'='*60}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €
    checkpoint_mgr = CheckpointManager("data/checkpoints/laws")
    print(f"ğŸ“ Checkpoint directory: data/checkpoints/laws")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    actual_start_page = start_page
    checkpoint = None
    
    if resume:
        print(f"ğŸ” Checking for existing checkpoint...")
        checkpoint = checkpoint_mgr.load_checkpoint()
        if checkpoint:
            print(f"ğŸ“‚ Resuming from checkpoint")
            print(f"   Data type: {checkpoint.get('data_type', 'unknown')}")
            print(f"   Category: {checkpoint.get('category', 'None')}")
            print(f"   Page: {checkpoint.get('current_page', 0)}/{checkpoint.get('total_pages', 0)}")
            print(f"   Collected: {checkpoint.get('collected_count', 0)} items")
            print(f"   Memory: {checkpoint.get('memory_usage_mb', 0):.1f}MB")
            actual_start_page = checkpoint['current_page'] + 1
        else:
            print(f"ğŸ“‚ No checkpoint found, starting from page {start_page}")
    else:
        print(f"ğŸ“‚ Resume disabled, starting from page {start_page}")
    
    # ìµœì í™”ëœ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    print(f"\nğŸ“¦ Initializing optimized collector...")
    collector = OptimizedLawCollector(
        base_dir="data/raw/assembly",
        page_size=laws_per_page,
        enable_metrics=enable_metrics
    )
    print(f"âœ… Optimized collector initialized (page size: {laws_per_page})")
    
    # ì‹œì‘ ì‹œê°„ ì„¤ì •
    start_time = datetime.now().isoformat()
    collector.start_time = start_time
    
    # ì „ì²´ í˜ì´ì§€ ê³„ì‚°
    if target_count:
        total_pages = actual_start_page + (target_count + 9) // 10 - 1  # í˜ì´ì§€ë‹¹ 10ê°œ
    else:
        total_pages = 100  # ëŒ€ëµì ì¸ í˜ì´ì§€ ìˆ˜
    
    print(f"\nğŸ“Š Collection Parameters:")
    print(f"   Target: {target_count or 'ALL (7602)'} items")
    print(f"   Pages: {actual_start_page} to {total_pages}")
    print(f"   Laws per page: {laws_per_page} (fixed)")
    print(f"   Save mode: Page-by-page")
    print(f"   Start time: {start_time}")
    
    collected_this_run = 0
    last_memory_check = 0
    
    try:
        print(f"\nğŸŒ Starting Playwright browser...")
        # Playwright ì‹œì‘ (ìµœì í™”ëœ ì„¤ì •)
        with AssemblyPlaywrightClient(
            rate_limit=3.0,  # Rate limiting ìœ ì§€
            headless=True,
            memory_limit_mb=1000  # ë©”ëª¨ë¦¬ ì œí•œ ì¦ê°€
        ) as client:
            print(f"âœ… Playwright browser started")
            
            for page in range(actual_start_page, total_pages + 1):
                if interrupted:
                    print(f"\nâš ï¸ INTERRUPTED by user signal")
                    break
                
                print(f"\n{'â”€'*50}")
                print(f"ğŸ“„ Processing Page {page}/{total_pages}")
                print(f"{'â”€'*50}")
                
                # ë©”ëª¨ë¦¬ ì²´í¬ ìµœì í™” (10í˜ì´ì§€ë§ˆë‹¤ë§Œ ì²´í¬)
                if page - last_memory_check >= 10:
                    memory_mb = client.check_memory_usage()
                    print(f"ğŸ“Š Memory usage: {memory_mb:.1f}MB")
                    last_memory_check = page
                
                # ëª©ë¡ ì¡°íšŒ
                print(f"ğŸ” Fetching law list from page {page}...")
                laws = client.get_law_list_page(page_num=page, page_size=10)
                print(f"âœ… Found {len(laws)} laws on page")
                
                if not laws:
                    print(f"âš ï¸ No laws found on page {page}, skipping...")
                    continue
                
                # ê° ë²•ë¥  ìƒì„¸ ìˆ˜ì§‘ (ìµœì í™”ëœ ì²˜ë¦¬)
                print(f"ğŸ“‹ Processing {len(laws)} laws...")
                page_start_time = time.time()
                
                for idx, law_item in enumerate(laws, 1):
                    if interrupted:
                        print(f"\nâš ï¸ INTERRUPTED during law processing")
                        break
                    
                    try:
                        print(f"   [{idx:2d}/{len(laws)}] Processing: {law_item['law_name'][:50]}...")
                        
                        detail = client.get_law_detail(
                            law_item['cont_id'],
                            law_item['cont_sid']
                        )
                        
                        # ëª©ë¡ ì •ë³´ ë³‘í•©
                        detail.update({
                            'row_number': law_item['row_number'],
                            'category': law_item['category'],
                            'law_type': law_item['law_type'],
                            'promulgation_number': law_item['promulgation_number'],
                            'promulgation_date': law_item['promulgation_date'],
                            'enforcement_date': law_item['enforcement_date'],
                            'amendment_type': law_item['amendment_type']
                        })
                        
                        collector.add_item(detail)
                        collected_this_run += 1
                        
                        print(f"      âœ… Collected (Page: {len(collector.collected_items)}/{laws_per_page})")
                        
                        # ëª©í‘œ ë‹¬ì„± ì²´í¬
                        if target_count and collected_this_run >= target_count:
                            print(f"\nğŸ¯ TARGET REACHED: {collected_this_run}/{target_count}")
                            break
                        
                    except Exception as e:
                        print(f"      âŒ Failed: {str(e)[:100]}...")
                        collector.add_failed_item(law_item, str(e))
                        continue
                
                # í˜ì´ì§€ë³„ ì €ì¥
                collector.save_page(page)
                
                # í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                page_time = time.time() - page_start_time
                print(f"â±ï¸ Page {page} processed in {page_time:.1f}s")
                
                # ì§„í–‰ë¥  ë¡œê·¸ (ìµœì í™”ëœ ì¶œë ¥)
                print(f"\nğŸ“ˆ Progress Summary:")
                print(f"   Page: {page}/{total_pages} ({page/total_pages*100:.1f}%)")
                print(f"   Collected this run: {collected_this_run}")
                print(f"   Total collected: {collector.collected_count}")
                print(f"   Failed: {len(collector.failed_items)}")
                print(f"   Success rate: {collected_this_run/(collected_this_run + len(collector.failed_items))*100:.1f}%" if (collected_this_run + len(collector.failed_items)) > 0 else "   Success rate: N/A")
                
                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ìµœì í™”ëœ ë¹ˆë„)
                if page % 5 == 0:  # 5í˜ì´ì§€ë§ˆë‹¤ë§Œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    checkpoint_data = {
                        'data_type': 'law',
                        'category': None,
                        'current_page': page,
                        'total_pages': total_pages,
                        'collected_count': collector.collected_count,
                        'collected_this_run': collected_this_run,
                        'start_time': checkpoint['start_time'] if checkpoint else start_time,
                        'memory_usage_mb': client.check_memory_usage(),
                        'target_count': target_count,
                        'page_size': page_size,
                        'laws_per_page': laws_per_page
                    }
                    
                    checkpoint_mgr.save_checkpoint(checkpoint_data)
                    print(f"ğŸ’¾ Checkpoint saved at page {page}")
                
                # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
                if target_count and collected_this_run >= target_count:
                    print(f"\nğŸ¯ Target achieved, stopping collection")
                    break
            
            # ìˆ˜ì§‘ ì™„ë£Œ
            print(f"\nğŸ Finalizing collection...")
            collector.finalize()
            
            if not interrupted:
                checkpoint_mgr.clear_checkpoint()
                print(f"\nâœ… COLLECTION COMPLETED SUCCESSFULLY!")
            else:
                print(f"\nâš ï¸ COLLECTION INTERRUPTED (progress saved)")
            
            # ìµœì¢… í†µê³„
            print(f"\nğŸ“Š Final Statistics:")
            print(f"   Total collected: {collector.collected_count} items")
            print(f"   Failed: {len(collector.failed_items)} items")
            print(f"   Requests made: {client.request_count}")
            print(f"   Rate limit: {client.get_stats()['rate_limit']}s")
            print(f"   Timeout: {client.get_stats()['timeout']}ms")
            
    except Exception as e:
        print(f"\nâŒ CRITICAL ERROR: {e}")
        print(f"ğŸ”§ Finalizing collector...")
        collector.finalize()
        raise

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='êµ­íšŒ ë²•ë¥ ì •ë³´ì‹œìŠ¤í…œ ë²•ë¥  ìˆ˜ì§‘ (ìµœì í™” ë²„ì „)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python collect_laws_optimized.py --sample 10                    # ìƒ˜í”Œ 10ê°œ ìˆ˜ì§‘
  python collect_laws_optimized.py --sample 100                   # ìƒ˜í”Œ 100ê°œ ìˆ˜ì§‘
  python collect_laws_optimized.py --sample 100 --start-page 5     # 5í˜ì´ì§€ë¶€í„° 100ê°œ ìˆ˜ì§‘
  python collect_laws_optimized.py --sample 50 --start-page 10     # 10í˜ì´ì§€ë¶€í„° 50ê°œ ìˆ˜ì§‘
  python collect_laws_optimized.py --full                          # ì „ì²´ 7602ê°œ ìˆ˜ì§‘
  python collect_laws_optimized.py --resume                        # ì¤‘ë‹¨ ì§€ì ì—ì„œ ì¬ê°œ
  python collect_laws_optimized.py --sample 100 --laws-per-page 10   # í˜ì´ì§€ë‹¹ 10ê°œë¡œ ìˆ˜ì§‘
        """
    )
    
    parser.add_argument('--sample', type=int, metavar='N',
                        help='ìƒ˜í”Œ ìˆ˜ì§‘ ê°œìˆ˜ (10, 100, 1000 ë“±)')
    parser.add_argument('--full', action='store_true',
                        help='ì „ì²´ ìˆ˜ì§‘ (7602ê°œ)')
    parser.add_argument('--resume', action='store_true', default=True,
                        help='ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ (ê¸°ë³¸ê°’)')
    parser.add_argument('--no-resume', dest='resume', action='store_false',
                        help='ì²˜ìŒë¶€í„° ì‹œì‘')
    parser.add_argument('--page-size', type=int, default=100,
                        help='í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--start-page', type=int, default=1,
                        help='ì‹œì‘ í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸: 1)')
    parser.add_argument('--laws-per-page', type=int, default=10,
                        help='í˜ì´ì§€ë‹¹ ë²•ë¥  ìˆ˜ (ê¸°ë³¸: 10)')
    parser.add_argument('--enable-metrics', action='store_true', default=True,
                        help='ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™” (ê¸°ë³¸ê°’)')
    parser.add_argument('--disable-metrics', dest='enable_metrics', action='store_false',
                        help='ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¹„í™œì„±í™”')
    parser.add_argument('--log-level', type=str, default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help='ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸: INFO)')
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ë ˆë²¨ ì¬ì„¤ì •
    if args.log_level != 'INFO':
        logger.setLevel(getattr(logging, args.log_level))
    
    if args.sample:
        print(f"ğŸ“¦ Sample mode: {args.sample} items")
        collect_laws_optimized(
            target_count=args.sample,
            page_size=args.page_size,
            resume=args.resume,
            start_page=args.start_page,
            laws_per_page=args.laws_per_page,
            enable_metrics=args.enable_metrics
        )
    elif args.full:
        logger.info(f"ğŸ“¦ Full mode: 7602 items")
        collect_laws_optimized(
            target_count=None,
            page_size=args.page_size,
            resume=args.resume,
            start_page=args.start_page,
            laws_per_page=args.laws_per_page,
            enable_metrics=args.enable_metrics
        )
    else:
        parser.print_help()
        logger.error("\nâŒ Please specify --sample N or --full")
        sys.exit(1)

if __name__ == "__main__":
    main()
