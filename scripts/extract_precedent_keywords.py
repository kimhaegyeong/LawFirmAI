#!/usr/bin/env python3
"""
precedent_cases í…Œì´ë¸”ì—ì„œ íŒë¡€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict, Counter

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from source.data.database import DatabaseManager
from source.services.legal_text_preprocessor import LegalTextPreprocessor

class PrecedentKeywordExtractor:
    """íŒë¡€ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.db_manager = DatabaseManager()
        self.preprocessor = LegalTextPreprocessor()
        self.extracted_keywords = defaultdict(set)
        
    def extract_keywords_from_precedents(self) -> Dict[str, List[str]]:
        """precedent_cases í…Œì´ë¸”ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        print("ğŸ“‹ precedent_cases í…Œì´ë¸”ì—ì„œ íŒë¡€ ì •ë³´ ì¡°íšŒ ì¤‘...")
        
        # íŒë¡€ ë°ì´í„° ì¡°íšŒ (ì„¹ì…˜ ë°ì´í„°ì™€ í•¨ê»˜)
        query = """
        SELECT 
            p.case_name,
            p.case_number,
            p.category,
            p.field,
            p.court,
            p.full_text,
            p.searchable_text,
            s.section_type,
            s.section_content
        FROM precedent_cases p
        LEFT JOIN precedent_sections s ON p.case_id = s.case_id
        WHERE p.full_text IS NOT NULL 
        AND p.full_text != ''
        ORDER BY p.case_name, s.section_type
        LIMIT 20000
        """
        
        precedents = self.db_manager.execute_query(query)
        print(f"âœ… ì´ {len(precedents)}ê°œ íŒë¡€ ë°ì´í„° ë°œê²¬")
        
        # ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
        domain_keywords = defaultdict(set)
        
        for i, precedent in enumerate(precedents):
            if i % 2000 == 0:
                print(f"  ğŸ“„ ì²˜ë¦¬ ì¤‘: {i+1}/{len(precedents)}")
            
            case_name = precedent['case_name']
            case_number = precedent['case_number']
            category = precedent['category'] or 'civil'
            field = precedent['field'] or 'ë¯¼ì‚¬'
            court = precedent['court'] or 'ëŒ€ë²•ì›'
            full_text = precedent['full_text']
            searchable_text = precedent['searchable_text'] or ''
            section_type = precedent['section_type']
            section_content = precedent['section_content'] or ''
            
            # ë„ë©”ì¸ ë¶„ë¥˜
            domain = self._classify_precedent_domain(category, field, case_name)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            extracted = self._extract_keywords_from_precedent(
                full_text, searchable_text, section_content, 
                case_name, case_number, section_type
            )
            domain_keywords[domain].update(extracted)
        
        # Setì„ Listë¡œ ë³€í™˜í•˜ê³  ì •ë ¬
        result = {}
        for domain, keywords in domain_keywords.items():
            result[domain] = sorted(list(keywords))
            
        return result
    
    def _classify_precedent_domain(self, category: str, field: str, case_name: str) -> str:
        """íŒë¡€ë¥¼ ë„ë©”ì¸ë³„ë¡œ ë¶„ë¥˜"""
        case_name_lower = case_name.lower()
        
        # í˜•ì‚¬ë²• ë„ë©”ì¸
        if category == 'criminal' or field == 'í˜•ì‚¬' or any(keyword in case_name_lower for keyword in [
            'í˜•ë²•', 'í˜•ì‚¬', 'ë²”ì£„', 'ì²˜ë²Œ', 'ìˆ˜ì‚¬', 'í˜•ë²Œ', 'ì‚´ì¸', 'ì ˆë„', 'ì‚¬ê¸°', 'ê°•ë„', 'ê°•ê°„', 'ì„±í­ë ¥'
        ]):
            return 'í˜•ì‚¬ë²•'
        
        # ë¯¼ì‚¬ë²• ë„ë©”ì¸
        if category == 'civil' or field == 'ë¯¼ì‚¬' or any(keyword in case_name_lower for keyword in [
            'ë¯¼ë²•', 'ê³„ì•½', 'ì±„ê¶Œ', 'ì±„ë¬´', 'ì†í•´ë°°ìƒ', 'ë¶ˆë²•í–‰ìœ„', 'ë¬¼ê¶Œ', 'ì†Œìœ ê¶Œ', 'ì ìœ ê¶Œ'
        ]):
            return 'ë¯¼ì‚¬ë²•'
        
        # ê°€ì¡±ë²• ë„ë©”ì¸
        if category == 'family' or field == 'ê°€ì‚¬' or any(keyword in case_name_lower for keyword in [
            'ê°€ì¡±', 'í˜¼ì¸', 'ì´í˜¼', 'ì–‘ìœ¡', 'ìƒì†', 'ì¹œì¡±', 'ê°€ì¡±ê´€ê³„', 'ì–‘ìœ¡ê¶Œ', 'ì¹œê¶Œ'
        ]):
            return 'ê°€ì¡±ë²•'
        
        # ìƒì‚¬ë²• ë„ë©”ì¸
        if any(keyword in case_name_lower for keyword in [
            'ìƒë²•', 'íšŒì‚¬', 'ì£¼ì‹', 'ì–´ìŒ', 'ìˆ˜í‘œ', 'ë³´í—˜', 'í•´ìƒ', 'ìƒí–‰ìœ„', 'ë²•ì¸', 'ì£¼ì£¼'
        ]):
            return 'ìƒì‚¬ë²•'
        
        # ë…¸ë™ë²• ë„ë©”ì¸
        if any(keyword in case_name_lower for keyword in [
            'ê·¼ë¡œ', 'ë…¸ë™', 'ì„ê¸ˆ', 'ê³ ìš©', 'í•´ê³ ', 'ì‚°ì—…ì•ˆì „', 'ê·¼ë¡œê¸°ì¤€', 'ë¶€ë‹¹í•´ê³ '
        ]):
            return 'ë…¸ë™ë²•'
        
        # ë¶€ë™ì‚°ë²• ë„ë©”ì¸
        if any(keyword in case_name_lower for keyword in [
            'ë¶€ë™ì‚°', 'í† ì§€', 'ë“±ê¸°', 'ì„ëŒ€ì°¨', 'ì „ì„¸', 'ë§¤ë§¤', 'ë¶€ë™ì‚°ë“±ê¸°', 'ì†Œìœ ê¶Œì´ì „'
        ]):
            return 'ë¶€ë™ì‚°ë²•'
        
        # ì§€ì ì¬ì‚°ê¶Œë²• ë„ë©”ì¸
        if category == 'patent' or field == 'íŠ¹í—ˆ' or any(keyword in case_name_lower for keyword in [
            'íŠ¹í—ˆ', 'ìƒí‘œ', 'ì €ì‘ê¶Œ', 'ë””ìì¸', 'ì˜ì—…ë¹„ë°€', 'ì§€ì ì¬ì‚°', 'íŠ¹í—ˆë²•', 'ìƒí‘œë²•', 'ì €ì‘ê¶Œë²•'
        ]):
            return 'ì§€ì ì¬ì‚°ê¶Œë²•'
        
        # ì„¸ë²• ë„ë©”ì¸
        if category == 'tax' or field == 'ì¡°ì„¸' or any(keyword in case_name_lower for keyword in [
            'ì„¸ë²•', 'ì†Œë“ì„¸', 'ë²•ì¸ì„¸', 'ë¶€ê°€ê°€ì¹˜ì„¸', 'ì¡°ì„¸', 'êµ­ì„¸', 'ì§€ë°©ì„¸', 'ì„¸ë¬´ì¡°ì‚¬'
        ]):
            return 'ì„¸ë²•'
        
        # ë¯¼ì‚¬ì†Œì†¡ë²• ë„ë©”ì¸
        if any(keyword in case_name_lower for keyword in [
            'ë¯¼ì‚¬ì†Œì†¡', 'ì†Œì†¡', 'ì§‘í–‰', 'ê°•ì œì§‘í–‰', 'ë¯¼ì‚¬ì§‘í–‰', 'ë¯¼ì‚¬ì†Œì†¡ë²•', 'ì†Œì¥', 'í•­ì†Œ'
        ]):
            return 'ë¯¼ì‚¬ì†Œì†¡ë²•'
        
        # í˜•ì‚¬ì†Œì†¡ë²• ë„ë©”ì¸
        if any(keyword in case_name_lower for keyword in [
            'í˜•ì‚¬ì†Œì†¡', 'ìˆ˜ì‚¬', 'ê¸°ì†Œ', 'ê³µì†Œ', 'ë³€í˜¸', 'ì¬íŒ', 'í˜•ì‚¬ì†Œì†¡ë²•', 'ê³µì†Œì œê¸°'
        ]):
            return 'í˜•ì‚¬ì†Œì†¡ë²•'
        
        # í–‰ì •ë²• ë„ë©”ì¸
        if category == 'administrative' or field == 'í–‰ì •' or any(keyword in case_name_lower for keyword in [
            'í–‰ì •', 'í—ˆê°€', 'ì¸ê°€', 'ë©´í—ˆ', 'ì‹ ê³ ', 'ì²˜ë¶„', 'í–‰ì •ë²•', 'í–‰ì •ì²˜ë¶„'
        ]):
            return 'í–‰ì •ë²•'
        
        # ê¸°íƒ€
        return 'ê¸°íƒ€/ì¼ë°˜'
    
    def _extract_keywords_from_precedent(self, full_text: str, searchable_text: str, 
                                       section_content: str, case_name: str, 
                                       case_number: str, section_type: str) -> Set[str]:
        """íŒë¡€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = set()
        
        # 1. íŒë¡€ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        case_keywords = self._extract_keywords_from_case_name(case_name)
        keywords.update(case_keywords)
        
        # 2. ì‚¬ê±´ë²ˆí˜¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if case_number:
            keywords.add(case_number)
        
        # 3. ì„¹ì…˜ íƒ€ì…ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
        if section_type and section_content:
            section_keywords = self._extract_keywords_from_section(section_type, section_content)
            keywords.update(section_keywords)
        
        # 4. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if full_text:
            text_keywords = self._extract_keywords_from_text(full_text)
            keywords.update(text_keywords)
        
        # 5. ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if searchable_text:
            search_keywords = self._extract_keywords_from_text(searchable_text)
            keywords.update(search_keywords)
        
        return keywords
    
    def _extract_keywords_from_case_name(self, case_name: str) -> Set[str]:
        """íŒë¡€ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = set()
        
        # íŒë¡€ëª…ì„ íŠ¹ìˆ˜ë¬¸ìë¡œ ë¶„ë¦¬
        words = re.split(r'[^\wê°€-í£]+', case_name)
        
        for word in words:
            if len(word) >= 2:
                keywords.add(word)
        
        # ë²•ë¥ ëª… íŒ¨í„´ ì¶”ì¶œ
        law_patterns = [
            r'([ê°€-í£]+ë²•)',
            r'([ê°€-í£]+ë²•ë¥ )',
            r'([ê°€-í£]+ê·œì¹™)',
            r'([ê°€-í£]+ë ¹)',
            r'([ê°€-í£]+ì‹œí–‰ë ¹)',
            r'([ê°€-í£]+ì‹œí–‰ê·œì¹™)'
        ]
        
        for pattern in law_patterns:
            matches = re.findall(pattern, case_name)
            keywords.update(matches)
        
        return keywords
    
    def _extract_keywords_from_section(self, section_type: str, content: str) -> Set[str]:
        """íŒë¡€ ì„¹ì…˜ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = set()
        
        if not content:
            return keywords
        
        # ì„¹ì…˜ íƒ€ì…ë³„ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ì¶œ
        if section_type == 'points_at_issue':  # íŒì‹œì‚¬í•­
            keywords.update(self._extract_legal_terms_from_text(content))
        elif section_type == 'reasoning':  # íŒê²°ìš”ì§€
            keywords.update(self._extract_legal_terms_from_text(content))
        elif section_type == 'decision_summary':  # íŒê²°ìš”ì•½
            keywords.update(self._extract_legal_terms_from_text(content))
        
        return keywords
    
    def _extract_keywords_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return set()
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        cleaned_text = self.preprocessor.clean_text(text)
        
        keywords = set()
        
        # 1. ë²•ë¥  ì¡°ë¬¸ ë²ˆí˜¸ íŒ¨í„´ (ì œ1ì¡°, ì œ2ì¡° ë“±)
        article_pattern = r'ì œ\d+ì¡°'
        articles = re.findall(article_pattern, cleaned_text)
        keywords.update(articles)
        
        # 2. ë²•ë¥  ìš©ì–´ íŒ¨í„´ (ì¡°, í•­, í˜¸, ëª© ë“±)
        legal_terms = re.findall(r'\d+ì¡°|\d+í•­|\d+í˜¸|\d+ëª©', cleaned_text)
        keywords.update(legal_terms)
        
        # 3. í•œê¸€ ë²•ë¥  ìš©ì–´ (2-8ê¸€ì)
        korean_terms = re.findall(r'[ê°€-í£]{2,8}(?=ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì—|ì˜|ì—ì„œ|ìœ¼ë¡œ|ë¡œ|ì™€|ê³¼|ì—|ì—ê²Œ|ì—ê²Œì„œ)', cleaned_text)
        keywords.update(korean_terms)
        
        # 4. ë²•ë¥  ìš©ì–´ ì¶”ì¶œ
        legal_keywords = self._extract_legal_terms_from_text(cleaned_text)
        keywords.update(legal_keywords)
        
        # 5. íŠ¹ìˆ˜ë¬¸ìì™€ ìˆ«ìê°€ í¬í•¨ëœ ìš©ì–´ ì œê±°
        filtered_keywords = set()
        for keyword in keywords:
            if len(keyword) >= 2 and not re.search(r'[^\wê°€-í£]', keyword):
                filtered_keywords.add(keyword)
        
        return filtered_keywords
    
    def _extract_legal_terms_from_text(self, text: str) -> Set[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë²•ë¥  ìš©ì–´ ì¶”ì¶œ"""
        keywords = set()
        
        # ì¼ë°˜ì ì¸ ë²•ë¥  ìš©ì–´
        common_legal_terms = [
            # ê¸°ë³¸ ë²•ë¥  ìš©ì–´
            'ë²•ë¥ ', 'ë²•ë ¹', 'ê·œì •', 'ì¡°í•­', 'ì¡°ë¬¸', 'í•­ëª©', 'í˜¸ëª©',
            'ì‹œí–‰', 'ê³µí¬', 'ê°œì •', 'íì§€', 'ì œì •', 'ë¶€ì¹™', 'ë³¸ì¹™',
            
            # ê¶Œë¦¬ì™€ ì˜ë¬´
            'ê¶Œë¦¬', 'ì˜ë¬´', 'ì±…ì„', 'ê¶Œí•œ', 'ë²”ìœ„', 'íš¨ë ¥', 'íš¨ê³¼',
            
            # í˜•ì‚¬ë²• ìš©ì–´
            'ì²˜ë²Œ', 'ë²Œê¸ˆ', 'ì§•ì—­', 'í˜•', 'ë²”ì£„', 'êµ¬ì„±ìš”ê±´', 'ê³ ì˜', 'ê³¼ì‹¤',
            'ë¯¸ìˆ˜', 'ê¸°ìˆ˜', 'ê³µë²”', 'ì •ë²”', 'êµì‚¬ë²”', 'ë°©ì¡°ë²”',
            
            # ë¯¼ì‚¬ë²• ìš©ì–´
            'ê³„ì•½', 'ì†í•´ë°°ìƒ', 'ë¶ˆë²•í–‰ìœ„', 'ì±„ê¶Œ', 'ì±„ë¬´', 'ì†Œìœ ê¶Œ', 'ì ìœ ê¶Œ',
            'ë¬¼ê¶Œ', 'ì±„ê¶Œì', 'ì±„ë¬´ì', 'ì´í–‰', 'ë³€ì œ', 'ëŒ€ìœ„', 'ì·¨ì†Œ',
            
            # ê°€ì¡±ë²• ìš©ì–´
            'í˜¼ì¸', 'ì´í˜¼', 'ì–‘ìœ¡', 'ìƒì†', 'ì¹œê¶Œ', 'ì–‘ìœ¡ê¶Œ', 'ì¹œìƒì', 'ì–‘ì',
            'ì¹œì¡±', 'ê°€ì¡±ê´€ê³„', 'í˜¼ì¸ë¬´íš¨', 'í˜¼ì¸ì·¨ì†Œ',
            
            # ìƒì‚¬ë²• ìš©ì–´
            'íšŒì‚¬', 'ì£¼ì‹', 'ì£¼ì£¼', 'ì´ì‚¬', 'ìƒí–‰ìœ„', 'ë²•ì¸', 'ì£¼ì‹íšŒì‚¬',
            'ì–´ìŒ', 'ìˆ˜í‘œ', 'ë³´í—˜', 'í•´ìƒ', 'ìƒë²•',
            
            # ë…¸ë™ë²• ìš©ì–´
            'ê·¼ë¡œ', 'ê³ ìš©', 'ì„ê¸ˆ', 'í•´ê³ ', 'ë¶€ë‹¹í•´ê³ ', 'ê·¼ë¡œê³„ì•½', 'ê·¼ë¡œê¸°ì¤€',
            'ìµœì €ì„ê¸ˆ', 'ê·¼ë¡œì‹œê°„', 'íœ´ê²Œì‹œê°„', 'ì—°ì¥ê·¼ë¡œ',
            
            # ë¶€ë™ì‚°ë²• ìš©ì–´
            'ë¶€ë™ì‚°', 'í† ì§€', 'ë“±ê¸°', 'ë§¤ë§¤', 'ì„ëŒ€', 'ì†Œìœ ê¶Œì´ì „', 'ë“±ê¸°ë¶€',
            'ì„ëŒ€ì°¨', 'ì „ì„¸', 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ',
            
            # ì§€ì ì¬ì‚°ê¶Œë²• ìš©ì–´
            'íŠ¹í—ˆ', 'ìƒí‘œ', 'ì €ì‘ê¶Œ', 'ë””ìì¸', 'ì˜ì—…ë¹„ë°€', 'ì§€ì ì¬ì‚°',
            'íŠ¹í—ˆê¶Œ', 'ìƒí‘œê¶Œ', 'ì €ì‘ê¶Œì¹¨í•´', 'íŠ¹í—ˆì¹¨í•´',
            
            # ì„¸ë²• ìš©ì–´
            'ì„¸ê¸ˆ', 'ì†Œë“ì„¸', 'ë²•ì¸ì„¸', 'ë¶€ê°€ê°€ì¹˜ì„¸', 'ì‹ ê³ ', 'ë‚©ë¶€', 'ì¡°ì„¸',
            'êµ­ì„¸', 'ì§€ë°©ì„¸', 'ì„¸ë¬´ì¡°ì‚¬', 'ê³¼ì„¸', 'ë¹„ê³¼ì„¸',
            
            # ì†Œì†¡ë²• ìš©ì–´
            'ì†Œì†¡', 'ì¬íŒ', 'íŒê²°', 'ì„ ê³ ', 'í™•ì •', 'ìƒê³ ', 'í•­ì†Œ', 'ì†Œì¥',
            'ë‹µë³€ì„œ', 'ì¦ê±°', 'ì…ì¦', 'ì ˆì°¨', 'ì§‘í–‰', 'ê°•ì œì§‘í–‰',
            
            # í˜•ì‚¬ì†Œì†¡ë²• ìš©ì–´
            'ìˆ˜ì‚¬', 'ê¸°ì†Œ', 'ê³µì†Œ', 'ë³€í˜¸', 'ì¬ì‹¬', 'ìë°±', 'ì¦ê±°ëŠ¥ë ¥',
            'ì¦ê±°ë ¥', 'ìˆ˜ì‚¬ê¸°ê´€', 'ê²€ì°°', 'ê²½ì°°', 'ë³€í˜¸ì¸',
            
            # í–‰ì •ë²• ìš©ì–´
            'í–‰ì •', 'í—ˆê°€', 'ì¸ê°€', 'ë©´í—ˆ', 'ì‹ ê³ ', 'ì²˜ë¶„', 'í–‰ì •ì²˜ë¶„',
            'í–‰ì •í–‰ìœ„', 'ì¬ëŸ‰í–‰ìœ„', 'ê¸°ì†í–‰ìœ„',
            
            # íŒë¡€ íŠ¹í™” ìš©ì–´
            'íŒì‹œì‚¬í•­', 'íŒê²°ìš”ì§€', 'íŒê²°ìš”ì•½', 'ì°¸ì¡°íŒë¡€', 'ì°¸ì¡°ì¡°ë¬¸',
            'ëŒ€ë²•ì›', 'ê³ ë“±ë²•ì›', 'ì§€ë°©ë²•ì›', 'íŠ¹í—ˆë²•ì›', 'í–‰ì •ë²•ì›'
        ]
        
        for term in common_legal_terms:
            if term in text:
                keywords.add(term)
        
        # ë²•ë¥ ëª… íŒ¨í„´ ì¶”ì¶œ
        law_name_patterns = [
            r'([ê°€-í£]+ë²•)',
            r'([ê°€-í£]+ë²•ë¥ )',
            r'([ê°€-í£]+ê·œì¹™)',
            r'([ê°€-í£]+ë ¹)',
            r'([ê°€-í£]+ì‹œí–‰ë ¹)',
            r'([ê°€-í£]+ì‹œí–‰ê·œì¹™)'
        ]
        
        for pattern in law_name_patterns:
            matches = re.findall(pattern, text)
            keywords.update(matches)
        
        return keywords
    
    def save_keywords_to_database(self, domain_keywords: Dict[str, List[str]]):
        """ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        print("ğŸ’¾ ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
        
        # ê¸°ì¡´ í‚¤ì›Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
        db_path = "data/legal_terms_database.json"
        if os.path.exists(db_path):
            with open(db_path, 'r', encoding='utf-8') as f:
                existing_db = json.load(f)
        else:
            existing_db = {}
        
        # ìƒˆë¡œìš´ í‚¤ì›Œë“œ ì¶”ê°€
        for domain, keywords in domain_keywords.items():
            if domain not in existing_db:
                existing_db[domain] = {}
            
            for keyword in keywords:
                if keyword not in existing_db[domain]:
                    existing_db[domain][keyword] = {
                        "weight": 0.9,  # íŒë¡€ ê¸°ë°˜ì´ë¯€ë¡œ ë†’ì€ ê°€ì¤‘ì¹˜
                        "synonyms": [],
                        "related_terms": [],
                        "context_keywords": [],
                        "source": "precedent_cases",
                        "confidence": 0.95,
                        "verified": True,
                        "added_date": "2025-10-19"
                    }
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        with open(db_path, 'w', encoding='utf-8') as f:
            json.dump(existing_db, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… í‚¤ì›Œë“œ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {db_path}")
    
    def print_statistics(self, domain_keywords: Dict[str, List[str]]):
        """ì¶”ì¶œ í†µê³„ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š íŒë¡€ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í†µê³„")
        print("="*60)
        
        total_keywords = 0
        for domain, keywords in domain_keywords.items():
            count = len(keywords)
            total_keywords += count
            print(f"  {domain}: {count:,}ê°œ í‚¤ì›Œë“œ")
        
        print(f"\n  ì´ í‚¤ì›Œë“œ ìˆ˜: {total_keywords:,}ê°œ")
        print("="*60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        extractor = PrecedentKeywordExtractor()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        domain_keywords = extractor.extract_keywords_from_precedents()
        
        # í†µê³„ ì¶œë ¥
        extractor.print_statistics(domain_keywords)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        extractor.save_keywords_to_database(domain_keywords)
        
        print("\nâœ… íŒë¡€ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
