#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraph ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸ - 20ê°œ ì´ìƒ ë²•ë¥  ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import asyncio
import tempfile
import time
from pathlib import Path
from typing import List, Dict, Any

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["USE_LANGGRAPH"] = "true"
os.environ["LANGGRAPH_ENABLED"] = "true"

# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ëª©ë¡
TEST_QUESTIONS = [
    # ê³„ì•½ë²• ê´€ë ¨
    "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ê³„ì•½ í•´ì§€ ì¡°ê±´ì´ ë¬´ì—‡ì¸ê°€ìš”?",
    "ë¶ˆê³µì •í•œ ê³„ì•½ ì¡°í•­ì€ ì–´ë–»ê²Œ ëŒ€ì‘í•´ì•¼ í•˜ë‚˜ìš”?",
    "ê³„ì•½ ìœ„ë°˜ ì‹œ ì†í•´ë°°ìƒ ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ì •í•´ì§€ë‚˜ìš”?",
    
    # ê°€ì¡±ë²• ê´€ë ¨
    "ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    "ìœ„ìë£Œ ì‚°ì • ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì–‘ìœ¡ë¹„ ì§€ê¸‰ ê¸°ì¤€ê³¼ ë°©ë²•ì€?",
    "ìƒì† í¬ê¸° ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    
    # í˜•ì‚¬ë²• ê´€ë ¨
    "ì ˆë„ì£„ì˜ êµ¬ì„±ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì‚¬ê¸°ì£„ì™€ íš¡ë ¹ì£„ì˜ ì°¨ì´ì ì€?",
    "í˜•ì‚¬í•©ì˜ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
    "ë³´ì„ ì¡°ê±´ê³¼ ì ˆì°¨ëŠ”?",
    
    # ë¯¼ì‚¬ë²• ê´€ë ¨
    "ì†í•´ë°°ìƒ ì²­êµ¬ ì‹œ ì…ì¦ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‚˜ìš”?",
    "ì†Œë©¸ì‹œíš¨ ì¤‘ë‹¨ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "ì±„ê¶Œì ëŒ€ìœ„ê¶Œ í–‰ì‚¬ ì¡°ê±´ì€?",
    "ë‹´ë³´ë¬¼ê¶Œì˜ ìš°ì„ ìˆœìœ„ëŠ” ì–´ë–»ê²Œ ì •í•´ì§€ë‚˜ìš”?",
    
    # ë…¸ë™ë²• ê´€ë ¨
    "ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ì„ê¸ˆ ì²´ë¶ˆ ì‹œ ëŒ€ì‘ ë°©ë²•ì€?",
    "ê·¼ë¡œì‹œê°„ ì œí•œ ê·œì •ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì‚°ì—…ì¬í•´ ì¸ì • ê¸°ì¤€ì€?",
    
    # ë¶€ë™ì‚°ë²• ê´€ë ¨
    "ë¶€ë™ì‚° ë§¤ë§¤ê³„ì•½ì„œ í•„ìˆ˜ ì¡°í•­ì€?",
    "ì „ì„¸ê¶Œ ì„¤ì • ì ˆì°¨ì™€ íš¨ë ¥ì€?",
    "ì„ëŒ€ì°¨ë³´í˜¸ë²• ì ìš© ë²”ìœ„ëŠ”?",
    "ê±´ì¶•í—ˆê°€ ì·¨ì†Œ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    
    # ì§€ì ì¬ì‚°ê¶Œë²• ê´€ë ¨
    "íŠ¹í—ˆê¶Œ ì¹¨í•´ ì‹œ êµ¬ì œ ë°©ë²•ì€?",
    "ìƒí‘œê¶Œ ë“±ë¡ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ì €ì‘ê¶Œ ì¹¨í•´ ê¸ˆì§€ì²­êµ¬ê¶Œ í–‰ì‚¬ ë°©ë²•ì€?",
    "ì˜ì—…ë¹„ë°€ ë³´í˜¸ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    
    # ì„¸ë²• ê´€ë ¨
    "ì†Œë“ì„¸ ì‹ ê³  ëˆ„ë½ ì‹œ ê°€ì‚°ì„¸ëŠ”?",
    "ë²•ì¸ì„¸ ê³„ì‚° ë°©ë²•ê³¼ ì ˆì°¨ëŠ”?",
    "ë¶€ê°€ê°€ì¹˜ì„¸ í™˜ê¸‰ ì‹ ì²­ ì¡°ê±´ì€?",
    "ìƒì†ì„¸ ê³„ì‚° ì‹œ ê³µì œ í•­ëª©ì€?",
    
    # ê¸°íƒ€ ë²•ë¥  ì§ˆë¬¸
    "ë²•ì •ëŒ€ë¦¬ì¸ì˜ ê¶Œí•œê³¼ ì±…ì„ì€?",
    "ì†Œì†¡ ì œê¸° ì‹œ ê´€í•  ë²•ì›ì€ ì–´ë–»ê²Œ ì •í•´ì§€ë‚˜ìš”?",
    "ì¤‘ì¬ ì ˆì°¨ì™€ ë²•ì› ì†Œì†¡ì˜ ì°¨ì´ì ì€?",
    "ë²•ë¥  ìë¬¸ ë¹„ìš©ì€ ì–´ë–»ê²Œ ì‚°ì •ë˜ë‚˜ìš”?"
]

async def test_single_question(service, question: str, question_id: int) -> Dict[str, Any]:
    """ë‹¨ì¼ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸"""
    try:
        start_time = time.time()
        
        print(f"\n[{question_id:2d}/40] ì§ˆë¬¸: {question}")
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await service.process_query(question)
        
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        test_result = {
            "question_id": question_id,
            "question": question,
            "success": True,
            "processing_time": processing_time,
            "response_length": len(result.get("answer", "")),
            "confidence": result.get("confidence", 0),
            "sources_count": len(result.get("sources", [])),
            "processing_steps": len(result.get("processing_steps", [])),
            "query_type": result.get("query_type", "unknown"),
            "session_id": result.get("session_id", ""),
            "errors": result.get("errors", [])
        }
        
        print(f"    âœ… ì„±ê³µ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, ì‹ ë¢°ë„: {test_result['confidence']:.2f}")
        print(f"    ğŸ“ ë‹µë³€ ê¸¸ì´: {test_result['response_length']}ì, ì†ŒìŠ¤: {test_result['sources_count']}ê°œ")
        
        return test_result
        
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"    âŒ ì‹¤íŒ¨ - ì˜¤ë¥˜: {str(e)}")
        
        return {
            "question_id": question_id,
            "question": question,
            "success": False,
            "processing_time": processing_time,
            "error": str(e),
            "response_length": 0,
            "confidence": 0,
            "sources_count": 0,
            "processing_steps": 0,
            "query_type": "error",
            "session_id": "",
            "errors": [str(e)]
        }

async def run_comprehensive_test():
    """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 80)
    print("LangGraph ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸ - 40ê°œ ë²•ë¥  ì§ˆë¬¸ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from source.services.langgraph.workflow_service import LangGraphWorkflowService
        from source.utils.langgraph_config import LangGraphConfig
        
        # ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì‚¬ìš©
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        # ì„¤ì • ìƒì„±
        config = LangGraphConfig.from_env()
        config.checkpoint_db_path = db_path
        
        # ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        service = LangGraphWorkflowService(config)
        print("âœ… ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = []
        total_start_time = time.time()
        
        for i, question in enumerate(TEST_QUESTIONS, 1):
            result = await test_single_question(service, question, i)
            results.append(result)
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if i % 5 == 0:
                success_count = sum(1 for r in results if r["success"])
                print(f"\nğŸ“Š ì§„í–‰ë¥ : {i}/40 ({i*2.5:.1f}%) - ì„±ê³µ: {success_count}/{i}")
        
        total_time = time.time() - total_start_time
        
        # ê²°ê³¼ ë¶„ì„
        analyze_results(results, total_time)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(db_path)
        
        return results
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []

def analyze_results(results: List[Dict[str, Any]], total_time: float):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
    print("=" * 80)
    
    # ê¸°ë³¸ í†µê³„
    total_questions = len(results)
    successful_tests = [r for r in results if r["success"]]
    failed_tests = [r for r in results if not r["success"]]
    
    success_rate = len(successful_tests) / total_questions * 100
    
    print(f"ğŸ“Š ì „ì²´ í†µê³„:")
    print(f"   - ì´ ì§ˆë¬¸ ìˆ˜: {total_questions}")
    print(f"   - ì„±ê³µ: {len(successful_tests)} ({success_rate:.1f}%)")
    print(f"   - ì‹¤íŒ¨: {len(failed_tests)} ({100-success_rate:.1f}%)")
    print(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_time/total_questions:.2f}ì´ˆ")
    
    if successful_tests:
        # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë“¤ì˜ ìƒì„¸ í†µê³„
        avg_processing_time = sum(r["processing_time"] for r in successful_tests) / len(successful_tests)
        avg_confidence = sum(r["confidence"] for r in successful_tests) / len(successful_tests)
        avg_response_length = sum(r["response_length"] for r in successful_tests) / len(successful_tests)
        avg_sources = sum(r["sources_count"] for r in successful_tests) / len(successful_tests)
        
        print(f"\nğŸ“ˆ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ìƒì„¸ í†µê³„:")
        print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.2f}ì´ˆ")
        print(f"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"   - í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_response_length:.0f}ì")
        print(f"   - í‰ê·  ì†ŒìŠ¤ ìˆ˜: {avg_sources:.1f}ê°œ")
        
        # ì²˜ë¦¬ ì‹œê°„ ë¶„í¬
        fast_tests = [r for r in successful_tests if r["processing_time"] < 30]
        medium_tests = [r for r in successful_tests if 30 <= r["processing_time"] < 60]
        slow_tests = [r for r in successful_tests if r["processing_time"] >= 60]
        
        print(f"\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„ ë¶„í¬:")
        print(f"   - ë¹ ë¦„ (<30ì´ˆ): {len(fast_tests)}ê°œ")
        print(f"   - ë³´í†µ (30-60ì´ˆ): {len(medium_tests)}ê°œ")
        print(f"   - ëŠë¦¼ (â‰¥60ì´ˆ): {len(slow_tests)}ê°œ")
        
        # ì‹ ë¢°ë„ ë¶„í¬
        high_confidence = [r for r in successful_tests if r["confidence"] >= 0.8]
        medium_confidence = [r for r in successful_tests if 0.6 <= r["confidence"] < 0.8]
        low_confidence = [r for r in successful_tests if r["confidence"] < 0.6]
        
        print(f"\nğŸ¯ ì‹ ë¢°ë„ ë¶„í¬:")
        print(f"   - ë†’ìŒ (â‰¥0.8): {len(high_confidence)}ê°œ")
        print(f"   - ë³´í†µ (0.6-0.8): {len(medium_confidence)}ê°œ")
        print(f"   - ë‚®ìŒ (<0.6): {len(low_confidence)}ê°œ")
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ì„
        query_types = {}
        for r in successful_tests:
            qtype = r["query_type"]
            query_types[qtype] = query_types.get(qtype, 0) + 1
        
        print(f"\nğŸ“‹ ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„í¬:")
        for qtype, count in sorted(query_types.items()):
            print(f"   - {qtype}: {count}ê°œ")
    
    # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¶„ì„
    if failed_tests:
        print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for test in failed_tests:
            print(f"   - [{test['question_id']:2d}] {test['question'][:50]}...")
            print(f"     ì˜¤ë¥˜: {test.get('error', 'Unknown error')}")
    
    # ì„±ëŠ¥ í‰ê°€
    print(f"\nğŸ† ì„±ëŠ¥ í‰ê°€:")
    if success_rate >= 95:
        print("   âœ… ìš°ìˆ˜ - 95% ì´ìƒ ì„±ê³µë¥ ")
    elif success_rate >= 90:
        print("   âœ… ì–‘í˜¸ - 90% ì´ìƒ ì„±ê³µë¥ ")
    elif success_rate >= 80:
        print("   âš ï¸ ë³´í†µ - 80% ì´ìƒ ì„±ê³µë¥ ")
    else:
        print("   âŒ ê°œì„  í•„ìš” - 80% ë¯¸ë§Œ ì„±ê³µë¥ ")
    
    if avg_processing_time < 30:
        print("   âœ… ë¹ ë¥¸ ì‘ë‹µ - í‰ê·  30ì´ˆ ë¯¸ë§Œ")
    elif avg_processing_time < 60:
        print("   âœ… ì ì ˆí•œ ì‘ë‹µ - í‰ê·  60ì´ˆ ë¯¸ë§Œ")
    else:
        print("   âš ï¸ ëŠë¦° ì‘ë‹µ - í‰ê·  60ì´ˆ ì´ìƒ")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    results = await run_comprehensive_test()
    
    if results:
        print(f"\nğŸ‰ ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ì´ {len(results)}ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
        success_count = sum(1 for r in results if r["success"])
        print(f"ì„±ê³µë¥ : {success_count}/{len(results)} ({success_count/len(results)*100:.1f}%)")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())
