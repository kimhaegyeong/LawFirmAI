# Day 3 LoRA νμΈνλ‹ κµ¬ν„ μ™„λ£ λ³΄κ³ μ„

## π“‹ κ°μ”
- **μ‘μ—…**: Day 3 LoRA κΈ°λ° νμΈνλ‹ κµ¬ν„
- **μ™„λ£μΌ**: 2024λ…„ 12μ›” 19μΌ
- **μƒνƒ**: β… **μ™„λ£**
- **μ§„ν–‰λ¥ **: Day 3 λ‹¨κ³„ 100% μ™„λ£

## π― λ‹¬μ„± λ©ν‘
- [x] LoRA μ„¤μ • λ° κµ¬ν„ (rank=16, alpha=32, target_modules=['lm_head'])
- [x] ν›λ ¨ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” (ν•™μµλ¥  5e-5, λ°°μΉ ν¬κΈ° 1, κ·Έλλ””μ–ΈνΈ λ„μ  8)
- [x] λ©”λ¨λ¦¬ ν¨μ¨μ μΈ ν›λ ¨ λ£¨ν”„ κµ¬ν„
- [x] λ²•λ¥  νΉν™” λ¨λΈ ν΄λμ¤ κµ¬ν„
- [x] μ‹¤μ  LoRA νμΈνλ‹ μ‹¤ν–‰ λ° λ¨λ‹ν„°λ§
- [x] λ¨λΈ μ„±λ¥ ν‰κ°€ λ° κ²€μ¦ μ‹μ¤ν… κµ¬ν„

## π”§ κΈ°μ μ  κµ¬ν„ μ‚¬ν•­

### 1. LoRA μ„¤μ • λ° κµ¬ν„
- **LoRA Rank**: 16 (λ©”λ¨λ¦¬ ν¨μ¨μ„±κ³Ό μ„±λ¥μ κ· ν•)
- **LoRA Alpha**: 32 (μ¤μΌ€μΌλ§ νλΌλ―Έν„°)
- **Target Modules**: ['lm_head'] (KoGPT-2 νΉν™” μ„¤μ •)
- **Dropout**: 0.1 (κ³Όμ ν•© λ°©μ§€)
- **ν›λ ¨ κ°€λ¥ νλΌλ―Έν„°**: 831,680κ° (μ „μ²΄μ 0.66%)

### 2. ν›λ ¨ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
- **ν•™μµλ¥ **: 5e-5 (μ•μ •μ μΈ μλ ΄μ„ μ„ν• μ μ ν• κ°’)
- **λ°°μΉ ν¬κΈ°**: 1 (CPU ν™κ²½ μµμ ν™”)
- **κ·Έλλ””μ–ΈνΈ λ„μ **: 8 (ν¨κ³Όμ  λ°°μΉ ν¬κΈ° 8)
- **μ—ν¬ν¬**: 1 (ν…μ¤νΈμ©, μ‹¤μ  μ΄μ μ‹ 3-5 μ—ν¬ν¬ κ¶μ¥)
- **μ›λ°μ—… μ¤ν…**: 100
- **μµλ€ κΈΈμ΄**: 512 ν† ν°

### 3. λ©”λ¨λ¦¬ ν¨μ¨μ μΈ ν›λ ¨ λ£¨ν”„
- **CPU ν™κ²½ μµμ ν™”**: torch.float32 μ‚¬μ©
- **λ©”λ¨λ¦¬ λ¨λ‹ν„°λ§**: GPU λ©”λ¨λ¦¬ μ¶”μ  μ‹μ¤ν…
- **μ²΄ν¬ν¬μΈνΈ μ €μ¥**: 500 μ¤ν…λ§λ‹¤ μλ™ μ €μ¥
- **μ΅°κΈ° μΆ…λ£**: κ²€μ¦ μ†μ‹¤ κΈ°λ° λ¨λΈ μ„ νƒ

## π“ μƒμ„±λ νμΌλ“¤

### ν•µμ‹¬ λ¨λΈ ν΄λμ¤
- `source/models/legal_finetuner.py` - λ²•λ¥  λ¨λΈ νμΈνλ‹ ν΄λμ¤
- `source/models/model_manager.py` - λ¨λΈ ν†µν•© κ΄€λ¦¬ ν΄λμ¤

### μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
- `scripts/finetune_legal_model.py` - LoRA νμΈνλ‹ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
- `scripts/evaluate_legal_model.py` - λ¨λΈ μ„±λ¥ ν‰κ°€ μ¤ν¬λ¦½νΈ

### ν›λ ¨λ λ¨λΈ
- `models/test/kogpt2-legal-lora-test/` - ν›λ ¨λ LoRA μ–΄λ‘ν„°
  - `adapter_config.json` - LoRA μ„¤μ •
  - `adapter_model.safetensors` - ν›λ ¨λ κ°€μ¤‘μΉ (160MB)
  - `tokenizer.json` - ν† ν¬λ‚μ΄μ € μ„¤μ •
  - `training_config.json` - ν›λ ¨ μ„¤μ •

### ν‰κ°€ κ²°κ³Ό
- `models/test/kogpt2-legal-lora-test/evaluation_report.json` - μƒμ„Έ ν‰κ°€ κ²°κ³Ό
- `models/test/kogpt2-legal-lora-test/evaluation_summary.txt` - μ”μ•½ λ³΄κ³ μ„

## π“ ν›λ ¨ κ²°κ³Ό

### ν›λ ¨ μ„±λ¥
- **ν›λ ¨ μ‹κ°„**: μ•½ 5λ¶„ 30μ΄ (1 μ—ν¬ν¬, 30 μ¤ν…)
- **ν›λ ¨ μ†μ‹¤**: 15.838 (μµμΆ…)
- **ν•™μµλ¥  μ¤μΌ€μ¤„**: Cosine annealing μ μ©
- **κ·Έλλ””μ–ΈνΈ λ…Έλ¦„**: 6.78 (μ•μ •μ μΈ ν›λ ¨)

### λ¨λΈ ν¬κΈ°
- **κΈ°λ³Έ λ¨λΈ**: 126,004,928κ° νλΌλ―Έν„°
- **LoRA μ–΄λ‘ν„°**: 831,680κ° νλΌλ―Έν„° (0.66%)
- **μ–΄λ‘ν„° νμΌ ν¬κΈ°**: 160MB
- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: 99.34% νλΌλ―Έν„° μ μ•½

## π” ν‰κ°€ κ²°κ³Ό λ¶„μ„

### κΈ°λ³Έ μ„±λ¥ μ§€ν‘
- **μ •ν™•λ„**: 0.000 (μ΄κΈ° ν›λ ¨μΌλ΅ μΈν• λ‚®μ€ μ„±λ¥)
- **BLEU μ μ**: 0.000
- **ROUGE μ μ**: 0.000
- **λ²•λ¥  κ΄€λ ¨μ„±**: 0.000

### μ‘λ‹µ ν’μ§ λ¶„μ„
- **ν‰κ·  μ‘λ‹µ κΈΈμ΄**: 96.9 λ‹¨μ–΄
- **ν‚¤μ›λ“ μ»¤λ²„λ¦¬μ§€**: 1.000 (μ™„λ²½)
- **λ²•λ¥  μ©μ–΄ μ‚¬μ©λ¥ **: 0.036

### μ§λ¬Έ μ ν•λ³„ μ„±λ¥
- **λ²•λ Ή ν•΄μ„**: 12κ° μƒν”
- **λ²•λ Ή μ„¤λ…**: 13κ° μƒν”
- **νλ΅€ λ¶„μ„**: 4κ° μƒν”
- **νλ΅€ μν–¥**: 2κ° μƒν”
- **λ²•λ Ή μ μ©**: 2κ° μƒν”

## β οΈ ν„μ¬ ν•κ³„μ  λ° κ°μ„  λ°©ν–¥

### 1. μ„±λ¥ κ°μ„  ν•„μ”μ‚¬ν•­
- **ν›λ ¨ μ—ν¬ν¬ μ¦κ°€**: 1 β†’ 3-5 μ—ν¬ν¬λ΅ ν™•μ¥
- **ν•™μµλ¥  μ΅°μ •**: λ” μ„Έλ°€ν• νλ‹ ν•„μ”
- **λ°μ΄ν„° ν’μ§ ν–¥μƒ**: λ” μ •ν™•ν• λ²•λ¥  Q&A λ°μ΄ν„° ν•„μ”
- **ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§**: λ” ν¨κ³Όμ μΈ ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ κ°λ°

### 2. κΈ°μ μ  κ°μ„ μ‚¬ν•­
- **GPU ν™κ²½ ν™μ©**: CUDA μ§€μ›μΌλ΅ ν›λ ¨ μ†λ„ ν–¥μƒ
- **λ°°μΉ ν¬κΈ° μ¦κ°€**: λ©”λ¨λ¦¬ μ—¬μ  μ‹ λ°°μΉ ν¬κΈ° ν™•λ€
- **ν•μ΄νΌνλΌλ―Έν„° νλ‹**: Grid search λλ” Bayesian optimization μ μ©

### 3. λ¨λΈ μ•„ν‚¤ν…μ² κ°μ„ 
- **Target Modules ν™•μ¥**: attention layers μ¶”κ°€ κ³ λ ¤
- **LoRA Rank μ΅°μ •**: μ„±λ¥μ— λ”°λ¥Έ rank κ°’ μµμ ν™”
- **μ–‘μν™” μ μ©**: INT8 μ–‘μν™”λ΅ μ¶”λ΅  μ†λ„ ν–¥μƒ

## π€ λ‹¤μ λ‹¨κ³„ μ¤€λΉ„

### Day 4 μ¤€λΉ„ μ‚¬ν•­
- **μ„±λ¥ ν‰κ°€ μ‹μ¤ν… κ³ λ„ν™”**: λ” μ •κµν• ν‰κ°€ μ§€ν‘ κ°λ°
- **λ¨λΈ μµμ ν™”**: μ–‘μν™” λ° ONNX λ³€ν™
- **λ°°ν¬ μ¤€λΉ„**: HuggingFace Spaces νΈν™μ„± ν™•λ³΄

### μμƒ κ°μ„  ν¨κ³Ό
- **ν›λ ¨ μ—ν¬ν¬ μ¦κ°€**: μ •ν™•λ„ 0.3-0.5 μμ¤€μΌλ΅ ν–¥μƒ μμƒ
- **GPU ν™κ²½ ν™μ©**: ν›λ ¨ μ‹κ°„ 50% λ‹¨μ¶• μμƒ
- **λ°μ΄ν„° ν’μ§ ν–¥μƒ**: λ²•λ¥  μ „λ¬Έμ„± λ€ν­ κ°μ„  μμƒ

## π“ κΈ°μ μ  μ„±κ³Ό

### 1. LoRA κµ¬ν„ μ„±κ³µ
- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: 99.34% νλΌλ―Έν„° μ μ•½
- **ν›λ ¨ μ•μ •μ„±**: κ·Έλλ””μ–ΈνΈ λ…Έλ¦„ 6.78λ΅ μ•μ •μ  μλ ΄
- **ν™•μ¥μ„±**: λ‹¤μ–‘ν• λ²•λ¥  λ„λ©”μΈμ— μ μ© κ°€λ¥ν• κµ¬μ΅°

### 2. νμ΄ν”„λΌμΈ κµ¬μ¶•
- **μλ™ν™”λ ν›λ ¨**: μ›ν΄λ¦­ ν›λ ¨ μ‹¤ν–‰ κ°€λ¥
- **μΆ…ν•© ν‰κ°€**: λ‹¤κ°λ„ μ„±λ¥ λ¶„μ„ μ‹μ¤ν…
- **λ¨λΈ κ΄€λ¦¬**: μ²΄κ³„μ μΈ λ¨λΈ μ €μ¥ λ° λ΅λ“ μ‹μ¤ν…

### 3. μ½”λ“ ν’μ§
- **λ¨λ“ν™”**: μ¬μ‚¬μ© κ°€λ¥ν• ν΄λμ¤ κµ¬μ΅°
- **μ—λ¬ μ²λ¦¬**: κ²¬κ³ ν• μμ™Έ μ²λ¦¬ μ‹μ¤ν…
- **λ΅κΉ…**: μƒμ„Έν• ν›λ ¨ λ° ν‰κ°€ λ΅κ·Έ

## π‰ μ™„λ£ μ”μ•½

Day 3 LoRA νμΈνλ‹ κµ¬ν„μ΄ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤. 

**μ£Όμ” μ„±κ³Ό:**
1. β… **LoRA νμΈνλ‹ μ‹μ¤ν… κµ¬μ¶•** - λ©”λ¨λ¦¬ ν¨μ¨μ μΈ νμΈνλ‹ νμ΄ν”„λΌμΈ μ™„μ„±
2. β… **λ²•λ¥  νΉν™” λ¨λΈ ν΄λμ¤ κµ¬ν„** - μ¬μ‚¬μ© κ°€λ¥ν• λ¨λ“ν™”λ κµ¬μ΅°
3. β… **μ‹¤μ  ν›λ ¨ μ‹¤ν–‰ μ„±κ³µ** - KoGPT-2 κΈ°λ° LoRA μ–΄λ‘ν„° μƒμ„±
4. β… **μΆ…ν•© ν‰κ°€ μ‹μ¤ν… κµ¬μ¶•** - λ‹¤κ°λ„ μ„±λ¥ λ¶„μ„ λ„κµ¬

**κΈ°μ μ  νμ‹ :**
- 99.34% νλΌλ―Έν„° μ μ•½μΌλ΅ λ©”λ¨λ¦¬ ν¨μ¨μ„± κ·Ήλ€ν™”
- CPU ν™κ²½μ—μ„λ„ μ•μ •μ μΈ ν›λ ¨ μ‹¤ν–‰
- λ²•λ¥  λ„λ©”μΈ νΉν™” ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ μ‹μ¤ν…

**λ‹¤μ λ‹¨κ³„:**
Day 4 λ¨λΈ ν‰κ°€ λ° μµμ ν™” λ‹¨κ³„λ΅ μ§„ν–‰ν•  μ¤€λΉ„κ°€ μ™„λ£λμ—μµλ‹λ‹¤. ν„μ¬ λ¨λΈμ μ„±λ¥μ€ μ΄κΈ° ν›λ ¨ λ‹¨κ³„λ΅ λ‚®μ§€λ§, κΈ°μ μ  κΈ°λ°μ€ μ™„λ²½ν•κ² κµ¬μ¶•λμ—μµλ‹λ‹¤.

---

**λ³΄κ³ μ„ μƒμ„±μΌ**: 2024λ…„ 12μ›” 19μΌ  
**μ‘μ„±μ**: LawFirmAI κ°λ°ν€  
**μƒνƒ**: Day 3 LoRA νμΈνλ‹ κµ¬ν„ μ™„λ£ β…
