# LangGraph ì„±ëŠ¥ ìµœì í™” ì œì•ˆì„œ

## ğŸ“Š í˜„ì¬ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„

### 1. ë™ê¸°/ë¹„ë™ê¸° í˜¼ìš© ë¬¸ì œ
- **ìœ„ì¹˜**: `legal_workflow_enhanced.py`, `search_execution_processor.py`
- **ë¬¸ì œ**: `ThreadPoolExecutor`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸° ì‘ì—…ì„ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
- **ì˜í–¥**: ë¹„ë™ê¸° ì´ì ì„ í™œìš©í•˜ì§€ ëª»í•˜ê³  ì˜¤ë²„í—¤ë“œ ë°œìƒ

### 2. ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì‹œê°„
- **ìœ„ì¹˜**: ì—¬ëŸ¬ íŒŒì¼ì—ì„œ `time.sleep()` í˜¸ì¶œ
- **ë¬¸ì œ**: 
  - `semantic_search_engine_v2.py`: `time.sleep(0.5)` ì¬ì‹œë„ ëŒ€ê¸°
  - `legal_workflow_enhanced.py`: `time.sleep(1)` ê¸´ê¸‰ë„ í‰ê°€ ëŒ€ê¸°
  - `prompt_chain_executor.py`: `time.sleep(0.5)` ì¬ì‹œë„ ëŒ€ê¸°
- **ì˜í–¥**: ëˆ„ì  ëŒ€ê¸° ì‹œê°„ì´ ì „ì²´ ì‹¤í–‰ ì‹œê°„ì— ì˜í–¥

### 3. ìˆœì°¨ ì‹¤í–‰ìœ¼ë¡œ ì¸í•œ ë³‘ëª©
- **ìœ„ì¹˜**: ê²€ìƒ‰ ì‹¤í–‰, í‚¤ì›Œë“œ í™•ì¥, ë¶„ë¥˜ ì‘ì—…
- **ë¬¸ì œ**: ë³‘ë ¬ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…ë“¤ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë¨
- **ì˜í–¥**: ì „ì²´ ì‹¤í–‰ ì‹œê°„ = ê° ì‘ì—… ì‹œê°„ì˜ í•©

### 4. ëª¨ë¸ ë¡œë”© ìµœì í™” ë¶€ì¡±
- **ìœ„ì¹˜**: `semantic_search_engine_v2.py`
- **ë¬¸ì œ**: SentenceTransformer ëª¨ë¸ì´ ë§¤ë²ˆ ë¡œë“œë˜ê±°ë‚˜ ëŠë¦¬ê²Œ ë¡œë“œë  ìˆ˜ ìˆìŒ
- **ì˜í–¥**: ì²« ì‹¤í–‰ ì‹œ ê¸´ ëŒ€ê¸° ì‹œê°„

### 5. State ì ‘ê·¼ ìµœì í™” ë¶€ì¡±
- **ìœ„ì¹˜**: `search_execution_processor.py`ì˜ `get_search_params()`
- **ë¬¸ì œ**: Stateì—ì„œ ê°’ì„ ê°€ì ¸ì˜¬ ë•Œ ì—¬ëŸ¬ ë²ˆ ì ‘ê·¼ (6ë‹¨ê³„ í™•ì¸)
- **ì˜í–¥**: ë¶ˆí•„ìš”í•œ ë”•ì…”ë„ˆë¦¬ íƒìƒ‰ ì˜¤ë²„í—¤ë“œ

### 6. ìºì‹± í™œìš© ë¶€ì¡±
- **ìœ„ì¹˜**: ê²€ìƒ‰ ê²°ê³¼, í‚¤ì›Œë“œ í™•ì¥, ì¿¼ë¦¬ ìµœì í™”
- **ë¬¸ì œ**: ì¼ë¶€ ì‘ì—…ì— ìºì‹±ì´ ì—†ê±°ë‚˜ ì œí•œì 
- **ì˜í–¥**: ë™ì¼í•œ ì‘ì—… ë°˜ë³µ ì‹¤í–‰

## ğŸš€ ê°œì„  ë°©ì•ˆ

### ìš°ì„ ìˆœìœ„ 1: ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„  (High Impact)

#### 1.1 ThreadPoolExecutor â†’ asyncio.gather ì „í™˜
**í˜„ì¬ ì½”ë“œ**:
```python
# legal_workflow_enhanced.py:3711
with ThreadPoolExecutor(max_workers=2) as executor:
    futures = {
        'urgency': executor.submit(self._assess_urgency_internal, query),
        'multi_turn': executor.submit(self._resolve_multi_turn_internal, query, session_id),
    }
```

**ê°œì„ ì•ˆ**:
```python
# ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë³€ê²½
async def classification_parallel(self, state: LegalWorkflowState) -> LegalWorkflowState:
    query = self._get_state_value(state, "query", "")
    session_id = self._get_state_value(state, "session_id", "")
    
    # ë³‘ë ¬ ë¹„ë™ê¸° ì‹¤í–‰
    urgency_task = asyncio.create_task(
        self._assess_urgency_async(query)
    )
    multi_turn_task = asyncio.create_task(
        self._resolve_multi_turn_async(query, session_id)
    )
    
    # ë™ì‹œ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
    urgency_result, multi_turn_result = await asyncio.gather(
        urgency_task, multi_turn_task, return_exceptions=True
    )
```

**ì˜ˆìƒ ê°œì„ **: 30-50% ì‹œê°„ ë‹¨ì¶• (2ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰)

#### 1.2 ê²€ìƒ‰ ì‘ì—… ë³‘ë ¬í™”
**í˜„ì¬ ì½”ë“œ**:
```python
# search_execution_processor.py:357
with ThreadPoolExecutor(max_workers=2) as executor:
    # ìˆœì°¨ì  ì‹¤í–‰
```

**ê°œì„ ì•ˆ**:
```python
# ëª¨ë“  ê²€ìƒ‰ ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ë³‘ë ¬ ì‹¤í–‰
async def execute_searches_parallel_async(self, state: LegalWorkflowState):
    search_tasks = []
    
    # ëª¨ë“  ê²€ìƒ‰ ì‘ì—…ì„ íƒœìŠ¤í¬ë¡œ ìƒì„±
    for search_type in search_types:
        task = asyncio.create_task(
            self._execute_single_search_async(search_type, state)
        )
        search_tasks.append(task)
    
    # ëª¨ë“  ê²€ìƒ‰ì„ ë™ì‹œì— ì‹¤í–‰
    results = await asyncio.gather(*search_tasks, return_exceptions=True)
    return results
```

**ì˜ˆìƒ ê°œì„ **: 40-60% ì‹œê°„ ë‹¨ì¶• (ê²€ìƒ‰ ì‘ì—… ìˆ˜ì— ë¹„ë¡€)

### ìš°ì„ ìˆœìœ„ 2: ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì‹œê°„ ì œê±° (Medium Impact)

#### 2.1 time.sleep() ì œê±° ë˜ëŠ” ìµœì†Œí™”
**í˜„ì¬ ì½”ë“œ**:
```python
# semantic_search_engine_v2.py:1112
time.sleep(0.5)  # ì¬ì‹œë„ ëŒ€ê¸°
```

**ê°œì„ ì•ˆ**:
```python
# exponential backoff ì‚¬ìš©
import asyncio

async def retry_with_backoff(func, max_retries=3):
    for attempt in range(max_retries):
        try:
            return await func()
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = min(0.1 * (2 ** attempt), 1.0)  # ìµœëŒ€ 1ì´ˆ
                await asyncio.sleep(wait_time)
            else:
                raise
```

**ì˜ˆìƒ ê°œì„ **: 10-20% ì‹œê°„ ë‹¨ì¶• (ëŒ€ê¸° ì‹œê°„ ëˆ„ì  ì œê±°)

### ìš°ì„ ìˆœìœ„ 3: ëª¨ë¸ ë¡œë”© ìµœì í™” (High Impact)

#### 3.1 ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ì¬ì‚¬ìš©
**í˜„ì¬ ì½”ë“œ**:
```python
# semantic_search_engine_v2.py:106
self.model = SentenceTransformer(model_name, device="cpu")
```

**ê°œì„ ì•ˆ**:
```python
# ëª¨ë¸ ì‹±ê¸€í†¤ ë§¤ë‹ˆì €
class ModelManager:
    _instances = {}
    _lock = asyncio.Lock()
    
    @classmethod
    async def get_model(cls, model_name: str):
        if model_name not in cls._instances:
            async with cls._lock:
                if model_name not in cls._instances:
                    cls._instances[model_name] = SentenceTransformer(
                        model_name, device="cpu"
                    )
        return cls._instances[model_name]

# ì‚¬ìš©
self.model = await ModelManager.get_model(model_name)
```

**ì˜ˆìƒ ê°œì„ **: ì²« ì‹¤í–‰ í›„ 80-90% ì‹œê°„ ë‹¨ì¶• (ëª¨ë¸ ë¡œë”© ì œê±°)

### ìš°ì„ ìˆœìœ„ 4: State ì ‘ê·¼ ìµœì í™” (Medium Impact)

#### 4.1 State ì ‘ê·¼ ìºì‹±
**í˜„ì¬ ì½”ë“œ**:
```python
# search_execution_processor.py:58-200
# 6ë‹¨ê³„ë¡œ Stateì—ì„œ optimized_queries ì°¾ê¸°
```

**ê°œì„ ì•ˆ**:
```python
# State ì ‘ê·¼ ê²°ê³¼ ìºì‹±
class StateAccessCache:
    def __init__(self):
        self._cache = {}
        self._cache_key = None
    
    def get_optimized_queries(self, state: LegalWorkflowState):
        # State í•´ì‹œë¡œ ìºì‹œ í‚¤ ìƒì„±
        state_hash = hash(str(sorted(state.items())))
        
        if self._cache_key != state_hash:
            # í•œ ë²ˆë§Œ ì ‘ê·¼í•˜ì—¬ ëª¨ë“  ê°’ ê°€ì ¸ì˜¤ê¸°
            optimized_queries = self._get_optimized_queries_once(state)
            self._cache = {
                'optimized_queries': optimized_queries,
                # ... ê¸°íƒ€ ê°’ë“¤
            }
            self._cache_key = state_hash
        
        return self._cache['optimized_queries']
```

**ì˜ˆìƒ ê°œì„ **: 5-10% ì‹œê°„ ë‹¨ì¶• (State ì ‘ê·¼ ì˜¤ë²„í—¤ë“œ ê°ì†Œ)

### ìš°ì„ ìˆœìœ„ 5: ìºì‹± ê°•í™” (Medium Impact)

#### 5.1 ê²€ìƒ‰ ê²°ê³¼ ìºì‹± í™•ëŒ€
**ê°œì„ ì•ˆ**:
```python
# ê²€ìƒ‰ ê²°ê³¼ ìºì‹± ê°•í™”
class EnhancedSearchCache:
    def __init__(self):
        self.query_cache = {}  # ì¿¼ë¦¬ -> ê²€ìƒ‰ ê²°ê³¼
        self.embedding_cache = {}  # í…ìŠ¤íŠ¸ -> ì„ë² ë”©
    
    async def get_or_search(self, query: str, search_func):
        # ì¿¼ë¦¬ í•´ì‹œë¡œ ìºì‹œ í™•ì¸
        query_hash = hashlib.md5(query.encode()).hexdigest()
        
        if query_hash in self.query_cache:
            return self.query_cache[query_hash]
        
        # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ê²€ìƒ‰ ì‹¤í–‰
        result = await search_func(query)
        self.query_cache[query_hash] = result
        return result
```

**ì˜ˆìƒ ê°œì„ **: ë°˜ë³µ ì¿¼ë¦¬ì—ì„œ 70-90% ì‹œê°„ ë‹¨ì¶•

### ìš°ì„ ìˆœìœ„ 6: ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” (Low-Medium Impact)

#### 6.1 ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬
**ê°œì„ ì•ˆ**:
```python
# ë‹¨ì¼ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
async def embed_batch(self, texts: List[str], batch_size: int = 32):
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        batch_embeddings = await self.model.encode(batch)
        embeddings.extend(batch_embeddings)
    return embeddings
```

**ì˜ˆìƒ ê°œì„ **: ì„ë² ë”© ìƒì„± ì‹œ 20-30% ì‹œê°„ ë‹¨ì¶•

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### ê°œë³„ ê°œì„  íš¨ê³¼
| ê°œì„  í•­ëª© | ì˜ˆìƒ ì‹œê°„ ë‹¨ì¶• | ìš°ì„ ìˆœìœ„ |
|---------|--------------|---------|
| ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„  | 30-60% | High |
| ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì œê±° | 10-20% | Medium |
| ëª¨ë¸ ë¡œë”© ìµœì í™” | 80-90% (ì²« ì‹¤í–‰ í›„) | High |
| State ì ‘ê·¼ ìµœì í™” | 5-10% | Medium |
| ìºì‹± ê°•í™” | 70-90% (ë°˜ë³µ ì¿¼ë¦¬) | Medium |
| ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” | 20-30% | Low-Medium |

### ì¢…í•© ì˜ˆìƒ íš¨ê³¼
- **ì²« ì‹¤í–‰**: 40-50% ì‹œê°„ ë‹¨ì¶•
- **ë°˜ë³µ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸)**: 70-85% ì‹œê°„ ë‹¨ì¶•
- **ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—…**: 50-70% ì‹œê°„ ë‹¨ì¶•

## ğŸ”§ êµ¬í˜„ ë‹¨ê³„

### Phase 1: ë¹ ë¥¸ ê°œì„  (1-2ì¼)
1. âœ… time.sleep() ì œê±° ë˜ëŠ” ìµœì†Œí™”
2. âœ… ëª¨ë¸ ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„
3. âœ… State ì ‘ê·¼ ìºì‹±

### Phase 2: ì¤‘ê¸° ê°œì„  (3-5ì¼)
1. âœ… ThreadPoolExecutor â†’ asyncio.gather ì „í™˜
2. âœ… ê²€ìƒ‰ ì‘ì—… ë³‘ë ¬í™”
3. âœ… ìºì‹± ê°•í™”

### Phase 3: ì¥ê¸° ê°œì„  (1ì£¼ì¼)
1. âœ… ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
2. âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
3. âœ… í”„ë¡œíŒŒì¼ë§ ë° ì¶”ê°€ ìµœì í™”

## ğŸ“ êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­

1. **ë¹„ë™ê¸° ì „í™˜ ì‹œ**: ê¸°ì¡´ ë™ê¸° í•¨ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì „í™˜
2. **ìºì‹± ì‹œ**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•„ìš”
3. **ë³‘ë ¬ ì²˜ë¦¬ ì‹œ**: ë™ì‹œì„± ì œí•œ (max_workers) ì„¤ì •
4. **ëª¨ë¸ ì‹±ê¸€í†¤ ì‹œ**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ (ì •ê¸°ì  ì •ë¦¬)

## ğŸ¯ ì„±ëŠ¥ ì¸¡ì • ë°©ë²•

```python
# ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°
import time
from functools import wraps

def measure_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        duration = time.time() - start_time
        
        logger.info(f"{func.__name__} ì‹¤í–‰ ì‹œê°„: {duration:.2f}ì´ˆ")
        return result
    return wrapper
```

## ğŸ“š ì°¸ê³  ìë£Œ

- LangGraph ê³µì‹ ë¬¸ì„œ: ë¹„ë™ê¸° ì²˜ë¦¬ ê°€ì´ë“œ
- Python asyncio ëª¨ë²” ì‚¬ë¡€
- Sentence Transformers ë°°ì¹˜ ì²˜ë¦¬ ê°€ì´ë“œ

