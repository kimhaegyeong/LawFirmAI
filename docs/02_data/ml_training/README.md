# ML í›ˆë ¨ ë° í‰ê°€ ì‹œìŠ¤í…œ

LawFirmAIì˜ ML í›ˆë ¨ ë° í‰ê°€ ì‹œìŠ¤í…œì— ëŒ€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

LawFirmAIëŠ” RAG ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ML í›ˆë ¨ ë° í‰ê°€ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- **Ground Truth ìƒì„±**: ì˜ì‚¬ ì¿¼ë¦¬ ë° í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ Ground Truth ìƒì„±
- **RAG ê²€ìƒ‰ í‰ê°€**: Recall@K, Precision@K, MRR ë“± ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€
- **ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹**: ìµœì ì˜ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íƒìƒ‰
- **í‰ê°€ ê²°ê³¼ ë¶„ì„**: Test/Val/Train ë°ì´í„°ì…‹ ë¹„êµ ë¶„ì„

## ğŸ“ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°

```
scripts/ml_training/
â”œâ”€â”€ evaluation/              # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ generate_pseudo_queries.py          # ì˜ì‚¬ ì¿¼ë¦¬ ìƒì„±
â”‚   â”œâ”€â”€ generate_clustering_ground_truth.py  # í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ Ground Truth ìƒì„±
â”‚   â”œâ”€â”€ generate_rag_evaluation_dataset.py  # í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±
â”‚   â”œâ”€â”€ evaluate_rag_search.py              # RAG ê²€ìƒ‰ í‰ê°€
â”‚   â”œâ”€â”€ analyze_rag_evaluation_results.py    # í‰ê°€ ê²°ê³¼ ë¶„ì„
â”‚   â”œâ”€â”€ tune_search_parameters.py            # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹
â”‚   â””â”€â”€ check_progress.py                    # ì§„í–‰ ìƒí™© í™•ì¸
â”œâ”€â”€ model_training/          # ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ vector_embedding/        # ë²¡í„° ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. Ground Truth ìƒì„±

#### ì˜ì‚¬ ì¿¼ë¦¬ ìƒì„±

```bash
python scripts/ml_training/evaluation/generate_pseudo_queries.py \
    --vector-store-path data/embeddings/ml_enhanced_ko_sroberta \
    --output-path data/evaluation/ground_truth/pseudo_queries.json \
    --model-name jhgan/ko-sroberta-multitask \
    --llm-provider gemini \
    --batch-size 10 \
    --checkpoint-dir data/evaluation/checkpoints
```

#### í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ Ground Truth ìƒì„±

```bash
python scripts/ml_training/evaluation/generate_clustering_ground_truth.py \
    --vector-store-path data/embeddings/ml_enhanced_ko_sroberta \
    --output-path data/evaluation/ground_truth/clustering_ground_truth.json \
    --model-name jhgan/ko-sroberta-multitask \
    --clustering-method hdbscan \
    --min-cluster-size 5 \
    --checkpoint-dir data/evaluation/checkpoints
```

### 2. í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±

```bash
python scripts/ml_training/evaluation/generate_rag_evaluation_dataset.py \
    --ground-truth-path data/evaluation/ground_truth/pseudo_queries.json \
    --output-dir data/evaluation/datasets \
    --train-ratio 0.7 \
    --val-ratio 0.15 \
    --test-ratio 0.15
```

### 3. RAG ê²€ìƒ‰ í‰ê°€

```bash
python scripts/ml_training/evaluation/evaluate_rag_search.py \
    --ground-truth-path data/evaluation/datasets/test.json \
    --vector-store-path data/embeddings/ml_enhanced_ko_sroberta \
    --output-path data/evaluation/evaluation_reports/rag_evaluation_report_test.json \
    --top-k-list 5,10,20 \
    --checkpoint-dir data/evaluation/checkpoints \
    --checkpoint-interval 100
```

### 4. í‰ê°€ ê²°ê³¼ ë¶„ì„

```bash
python scripts/ml_training/evaluation/analyze_rag_evaluation_results.py \
    --reports-dir data/evaluation/evaluation_reports \
    --output-path data/evaluation/analysis/comparison_report.json
```

### 5. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹

```bash
python scripts/ml_training/evaluation/tune_search_parameters.py \
    --ground-truth-path data/evaluation/datasets/val.json \
    --vector-store-path data/embeddings/ml_enhanced_ko_sroberta \
    --output-path data/evaluation/tuning/parameter_tuning_results.json \
    --top-k-range 5,50,5
```

## ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­

### ê²€ìƒ‰ ì„±ëŠ¥ ë©”íŠ¸ë¦­

- **Recall@K**: ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨
- **Precision@K**: ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨
- **NDCG@K**: ì •ê·œí™”ëœ í• ì¸ ëˆ„ì  ì´ë“ (Normalized Discounted Cumulative Gain)
- **MRR**: í‰ê·  ìƒí˜¸ ìˆœìœ„ (Mean Reciprocal Rank)

### í‰ê°€ ê²°ê³¼ ì˜ˆì‹œ

```json
{
  "aggregated_metrics": {
    "recall@5_mean": 0.7234,
    "recall@5_std": 0.1234,
    "precision@5_mean": 0.6543,
    "precision@5_std": 0.0987,
    "ndcg@5_mean": 0.7890,
    "ndcg@5_std": 0.1123,
    "mrr_mean": 0.8123,
    "mrr_std": 0.0987,
    "total_queries": 1000
  }
}
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥ ìƒì„¸

### 1. ì˜ì‚¬ ì¿¼ë¦¬ ìƒì„± (Pseudo Query Generation)

ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ , ì›ë³¸ ë¬¸ì„œë¥¼ Ground Truthë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

**íŠ¹ì§•**:
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì ì¸ ìƒì„±
- ì²´í¬í¬ì¸íŠ¸ ì§€ì›ìœ¼ë¡œ ì¤‘ë‹¨ í›„ ì¬ê°œ ê°€ëŠ¥
- Gemini API ë¹„ìš© ìµœì í™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from scripts.ml_training.evaluation.generate_pseudo_queries import PseudoQueryGenerator

generator = PseudoQueryGenerator(
    vector_store_path="data/embeddings/ml_enhanced_ko_sroberta",
    model_name="jhgan/ko-sroberta-multitask",
    llm_provider="gemini"
)

ground_truth = generator.generate(
    output_path="data/evaluation/ground_truth/pseudo_queries.json",
    batch_size=10,
    checkpoint_dir="data/evaluation/checkpoints"
)
```

### 2. í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ Ground Truth ìƒì„±

ë²¡í„° ìŠ¤í† ì–´ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬, ê°™ì€ í´ëŸ¬ìŠ¤í„° ë‚´ ë¬¸ì„œë“¤ì„ ì„œë¡œ ê´€ë ¨ ë¬¸ì„œë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

**íŠ¹ì§•**:
- HDBSCAN ë° K-Means í´ëŸ¬ìŠ¤í„°ë§ ì§€ì›
- ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ìë™ íƒìƒ‰
- ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì§€ì›
- ì²´í¬í¬ì¸íŠ¸ ì§€ì›

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from scripts.ml_training.evaluation.generate_clustering_ground_truth import ClusteringGroundTruthGenerator

generator = ClusteringGroundTruthGenerator(
    vector_store_path="data/embeddings/ml_enhanced_ko_sroberta",
    model_name="jhgan/ko-sroberta-multitask",
    clustering_method="hdbscan"
)

ground_truth = generator.generate(
    output_path="data/evaluation/ground_truth/clustering_ground_truth.json",
    min_cluster_size=5,
    checkpoint_dir="data/evaluation/checkpoints"
)
```

### 3. RAG ê²€ìƒ‰ í‰ê°€

ìƒì„±ëœ Ground Truthë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

**íŠ¹ì§•**:
- Recall@K, Precision@K, NDCG@K, MRR ë©”íŠ¸ë¦­ ê³„ì‚°
- ì²´í¬í¬ì¸íŠ¸ ì§€ì›ìœ¼ë¡œ ëŒ€ê·œëª¨ í‰ê°€ ê°€ëŠ¥
- ìƒì„¸í•œ ì¿¼ë¦¬ë³„ ë©”íŠ¸ë¦­ ì œê³µ

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from scripts.ml_training.evaluation.evaluate_rag_search import RAGSearchEvaluator

evaluator = RAGSearchEvaluator(
    vector_store_path="data/embeddings/ml_enhanced_ko_sroberta",
    model_name="jhgan/ko-sroberta-multitask",
    checkpoint_dir="data/evaluation/checkpoints"
)

results = evaluator.run(
    ground_truth_path="data/evaluation/datasets/test.json",
    top_k_list=[5, 10, 20],
    resume_from_checkpoint=True,
    checkpoint_interval=100
)
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™”

- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
- ì²´í¬í¬ì¸íŠ¸ë¥¼ í†µí•œ ì¤‘ê°„ ê²°ê³¼ ì €ì¥
- ë¶ˆí•„ìš”í•œ ë°ì´í„° ì¦‰ì‹œ ì‚­ì œ

### ë¹„ìš© ìµœì í™”

- Gemini API í˜¸ì¶œ ìµœì†Œí™”
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ API í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ
- ìºì‹±ì„ í†µí•œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€

### ì²˜ë¦¬ ì†ë„ ìµœì í™”

- ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
- ì²´í¬í¬ì¸íŠ¸ë¥¼ í†µí•œ ì¤‘ë‹¨ í›„ ì¬ê°œ
- íš¨ìœ¨ì ì¸ ë°ì´í„° êµ¬ì¡° ì‚¬ìš©

## ğŸ” ì§„í–‰ ìƒí™© í™•ì¸

```bash
python scripts/ml_training/evaluation/check_progress.py \
    --checkpoint-dir data/evaluation/checkpoints
```

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [ì˜ì‚¬ ì¿¼ë¦¬ ìµœì í™” ìš”ì•½](../05_quality/pseudo_query_optimization_summary.md)
- [Ground Truth ìƒì„± ì„±ëŠ¥ ê°œì„ ](../05_quality/ground_truth_generation_performance_improvements.md)
- [Gemini API ë¹„ìš© ìµœì í™”](../05_quality/gemini_api_cost_optimization.md)
- [ë©”ëª¨ë¦¬ ìµœì í™” ìš”ì•½](../05_quality/memory_optimization_summary.md)
- [ê·¼ì‚¬ Ground Truth ìƒì„± ê³„íš](../05_quality/approximate_ground_truth_generation_plan.md)

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ

ëŒ€ë¶€ë¶„ì˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì²´í¬í¬ì¸íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì¤‘ë‹¨ëœ ì‘ì—…ì€ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìë™ìœ¼ë¡œ ì¬ê°œë©ë‹ˆë‹¤.

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ì²´í¬í¬ì¸íŠ¸ ê°„ê²©ì„ ì¤„ì—¬ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì œì–´í•˜ì„¸ìš”.

### API ë¹„ìš© ë¬¸ì œ

ë°°ì¹˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ LLM ì œê³µìë¥¼ ë³€ê²½í•˜ì—¬ ë¹„ìš©ì„ ìµœì í™”í•˜ì„¸ìš”.

