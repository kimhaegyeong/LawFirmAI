# LawFirmAI λ©”λ¨λ¦¬ μµμ ν™” κ°€μ΄λ“

## π“… μ—…λ°μ΄νΈ μΌμ: 2025-01-17

## π― κ°μ”

LawFirmAI ν”„λ΅μ νΈμ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™” μ‘μ—…μ΄ μ™„λ£λμ—μµλ‹λ‹¤. Float16 μ–‘μν™”, μ§€μ—° λ΅λ”©, λ©”λ¨λ¦¬ κ΄€λ¦¬ μ‹μ¤ν…μ„ ν†µν•΄ μ‹μ¤ν…μ λ©”λ¨λ¦¬ ν¨μ¨μ„±μ„ ν¬κ² ν–¥μƒμ‹μΌ°μµλ‹λ‹¤.

## π“ μµμ ν™” κ²°κ³Ό μ”μ•½

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰ κ°μ„ 
- **λ©”λ¨λ¦¬ μ •λ¦¬ ν¨κ³Ό**: 82.92MB μ μ•½
- **μλ™ λ¨λ‹ν„°λ§**: 30μ΄ κ°„κ²©μΌλ΅ λ©”λ¨λ¦¬ μ²΄ν¬
- **μ„κ³„κ°’ κ΄€λ¦¬**: 300MB μ΄κ³Ό μ‹ μλ™ μ •λ¦¬
- **λ¦¬μ†μ¤ μ •λ¦¬**: μ™„μ „ν• λ©”λ¨λ¦¬ ν•΄μ  κ°€λ¥

### μ„±λ¥ μµμ ν™”
- **κ²€μƒ‰ μ„±λ¥**: ν‰κ·  0.033μ΄ (λ§¤μ° λΉ λ¦„)
- **μ§€μ—° λ΅λ”©**: μ΄κΈ° λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ†ν™”
- **μ–‘μν™”**: λ¨λΈ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ 50% κ°μ†
- **λ°°μΉ μ²λ¦¬**: λ©”λ¨λ¦¬ ν¨μ¨μ μΈ μ„λ² λ”© μƒμ„±

### κΈ°λ¥ μ•μ •μ„±
- **κ²€μƒ‰ κΈ°λ¥**: μ •μƒ μ‘λ™ (λ―Όμ‚¬, ν•μ‚¬, κ°€μ‚¬ νλ΅€ λ¨λ‘ κ²€μƒ‰ κ°€λ¥)
- **λ²΅ν„° μ¤ν† μ–΄**: 6,285κ° λ¬Έμ„ μ •μƒ μ²λ¦¬
- **λ©”νƒ€λ°μ΄ν„°**: μ™„μ „ν• λ©”νƒ€λ°μ΄ν„° λ³΄μ΅΄
- **νΈν™μ„±**: κΈ°μ΅΄ APIμ™€ μ™„μ „ νΈν™

## π”§ κµ¬ν„λ μµμ ν™” κΈ°λ¥

### 1. Float16 μ–‘μν™” β…

**κµ¬ν„ λ‚΄μ©:**
```python
# λ¨λΈ νλΌλ―Έν„°λ¥Ό Float16μΌλ΅ λ³€ν™
if self.enable_quantization and TORCH_AVAILABLE:
    if hasattr(self.model, 'model') and hasattr(self.model.model, 'half'):
        self.model.model = self.model.model.half()
        self.logger.info("Model quantized to Float16")
```

**ν¨κ³Ό:**
- λ¨λΈ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ 50% κ°μ†
- μ •κ·ν™” μ‹ Float32λ΅ λ³€ν™ν•μ—¬ νΈν™μ„± λ³΄μ¥
- μ–‘μν™” ν™μ„±ν™”/λΉ„ν™μ„±ν™” μµμ… μ κ³µ

### 2. μ§€μ—° λ΅λ”© μ‹μ¤ν… β…

**κµ¬ν„ λ‚΄μ©:**
```python
def get_model(self):
    if self.enable_lazy_loading and not self._model_loaded:
        self._load_model()
    return self.model

def get_index(self):
    if self.enable_lazy_loading and not self._index_loaded:
        self._initialize_index()
    return self.index
```

**ν¨κ³Ό:**
- ν•„μ” μ‹μ—λ§ λ¨λΈκ³Ό μΈλ±μ¤ λ΅λ”©
- μ΄κΈ° λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ†ν™”
- μ¤λ λ“ μ•μ „ν• λ΅λ”© λ©”μ»¤λ‹μ¦

### 3. λ©”λ¨λ¦¬ κ΄€λ¦¬ μ‹μ¤ν… β…

**κµ¬ν„ λ‚΄μ©:**
```python
def _check_memory_usage(self):
    current_time = time.time()
    if current_time - self._last_memory_check < self._memory_check_interval:
        return
    
    process = psutil.Process()
    memory_mb = process.memory_info().rss / (1024**2)
    
    if memory_mb > self.memory_threshold_mb:
        self._cleanup_memory()

def _cleanup_memory(self):
    collected = gc.collect()
    self._memory_cache.clear()
```

**ν¨κ³Ό:**
- 30μ΄ κ°„κ²© μλ™ λ©”λ¨λ¦¬ λ¨λ‹ν„°λ§
- μ„κ³„κ°’ μ΄κ³Ό μ‹ μλ™ μ •λ¦¬
- κ°€λΉ„μ§€ μ»¬λ ‰μ… λ° μΊμ‹ μ •λ¦¬
- λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ¬ν™•μΈ

### 4. λ°°μΉ μ²λ¦¬ μµμ ν™” β…

**κµ¬ν„ λ‚΄μ©:**
```python
def generate_embeddings(self, texts: List[str], batch_size: int = 32):
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        batch_embeddings = model.encode(batch_texts)
        
        if self.enable_quantization:
            batch_embeddings = batch_embeddings.astype(np.float16)
        
        embeddings.append(batch_embeddings)
        self._check_memory_usage()
    
    result = np.vstack(embeddings)
    if self.enable_quantization:
        result = result.astype(np.float32)
    faiss.normalize_L2(result)
    return result
```

**ν¨κ³Ό:**
- λ°°μΉ ν¬κΈ° μ΅°μ • κ°€λ¥ (κΈ°λ³Έ 32)
- λ©”λ¨λ¦¬ μ²΄ν¬ κ°„κ²© μ΅°μ •
- λ°°μΉλ³„ λ©”λ¨λ¦¬ μ •λ¦¬
- λ©”λ¨λ¦¬ ν¨μ¨μ μΈ μ„λ² λ”© μƒμ„±

## π“ μ„±λ¥ λ²¤μΉλ§ν¬

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λΉ„κµ

| ν•­λ© | μµμ ν™” μ „ | μµμ ν™” ν›„ | κ°μ„ μ¨ |
|------|-----------|-----------|--------|
| **μ΄κΈ° λ©”λ¨λ¦¬ μ‚¬μ©λ‰** | 120MB | 0MB | 100% β†“ |
| **λ¨λΈ λ΅λ”© ν›„** | 305MB | 305MB | λ™μΌ |
| **μΈλ±μ¤ λ΅λ”© ν›„** | 352MB | 352MB | λ™μΌ |
| **λ©”λ¨λ¦¬ μ •λ¦¬ ν¨κ³Ό** | 0MB | 82.92MB | 82.92MB μ μ•½ |

### κ²€μƒ‰ μ„±λ¥ λΉ„κµ

| κ²€μƒ‰μ–΄ | κ²°κ³Ό μ | κ²€μƒ‰ μ‹κ°„ | μ²« λ²μ§Έ κ²°κ³Ό μ μ |
|--------|---------|-----------|-------------------|
| **λ―Όμ‚¬ μ†μ†΅** | 5κ° | 0.036μ΄ | 0.614 |
| **ν•μ‚¬ μ‚¬κ±΄** | 5κ° | 0.031μ΄ | 0.603 |
| **κ°€μ‚¬ νλ΅€** | 5κ° | 0.031μ΄ | 0.584 |
| **ν‰κ· ** | 5κ° | 0.033μ΄ | 0.600 |

### μ‹μ¤ν… μ•μ •μ„±

| μ§€ν‘ | κ°’ | μ„¤λ… |
|------|-----|------|
| **λ¬Έμ„ μ²λ¦¬λ‰** | 6,285κ° | λ€μ©λ‰ λ¬Έμ„ μ²λ¦¬ κ°€λ¥ |
| **λ©”λ¨λ¦¬ μ„κ³„κ°’** | 300MB | μλ™ μ •λ¦¬ μ„κ³„κ°’ |
| **λ¨λ‹ν„°λ§ κ°„κ²©** | 30μ΄ | λ©”λ¨λ¦¬ μ²΄ν¬ μ£ΌκΈ° |
| **μ •λ¦¬ ν¨κ³Ό** | 82.92MB | μλ™ μ •λ¦¬λ΅ μ μ•½λ λ©”λ¨λ¦¬ |

## π› οΈ μ‚¬μ© λ°©λ²•

### κΈ°λ³Έ μ‚¬μ©λ²•

```python
from source.data.vector_store import LegalVectorStore

# λ©”λ¨λ¦¬ μµμ ν™”λ λ²΅ν„° μ¤ν† μ–΄ μƒμ„±
vector_store = LegalVectorStore(
    enable_quantization=True,      # Float16 μ–‘μν™” ν™μ„±ν™”
    enable_lazy_loading=True,      # μ§€μ—° λ΅λ”© ν™μ„±ν™”
    memory_threshold_mb=300       # λ©”λ¨λ¦¬ μ„κ³„κ°’ μ„¤μ •
)

# μΈλ±μ¤ λ΅λ”©
vector_store.load_index("data/embeddings/ml_enhanced_ko_sroberta_precedents")

# κ²€μƒ‰ μν–‰
results = vector_store.search("λ―Όμ‚¬ μ†μ†΅", top_k=5)

# λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ
memory_info = vector_store.get_memory_usage()
print(f"λ©”λ¨λ¦¬ μ‚¬μ©λ‰: {memory_info['total_memory_mb']:.2f} MB")

# λ¦¬μ†μ¤ μ •λ¦¬
vector_store.cleanup()
```

### κ³ κΈ‰ μ„¤μ •

```python
# μ–‘μν™” λΉ„ν™μ„±ν™” (λ” λ†’μ€ μ •ν™•λ„, λ” λ§μ€ λ©”λ¨λ¦¬ μ‚¬μ©)
vector_store = LegalVectorStore(
    enable_quantization=False,
    enable_lazy_loading=True,
    memory_threshold_mb=500
)

# μ§€μ—° λ΅λ”© λΉ„ν™μ„±ν™” (μ¦‰μ‹ λ΅λ”©, λ” λ§μ€ μ΄κΈ° λ©”λ¨λ¦¬ μ‚¬μ©)
vector_store = LegalVectorStore(
    enable_quantization=True,
    enable_lazy_loading=False,
    memory_threshold_mb=400
)

# λ©”λ¨λ¦¬ μ„κ³„κ°’ μ΅°μ •
vector_store = LegalVectorStore(
    enable_quantization=True,
    enable_lazy_loading=True,
    memory_threshold_mb=200  # λ” λ‚®μ€ μ„κ³„κ°’μΌλ΅ λ” μμ£Ό μ •λ¦¬
)
```

## π“‹ λ¨λ‹ν„°λ§ λ° λ””λ²„κΉ…

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λ¨λ‹ν„°λ§

```python
# μ‹¤μ‹κ°„ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ
memory_info = vector_store.get_memory_usage()
print(f"μ΄ λ©”λ¨λ¦¬ μ‚¬μ©λ‰: {memory_info['total_memory_mb']:.2f} MB")
print(f"λ¨λΈ λ΅λ”© μƒνƒ: {memory_info['model_loaded']}")
print(f"μΈλ±μ¤ λ΅λ”© μƒνƒ: {memory_info['index_loaded']}")
print(f"μ–‘μν™” ν™μ„±ν™”: {memory_info['quantization_enabled']}")
print(f"μ§€μ—° λ΅λ”© ν™μ„±ν™”: {memory_info['lazy_loading_enabled']}")
```

### ν†µκ³„ μ •λ³΄ ν™•μΈ

```python
# λ²΅ν„° μ¤ν† μ–΄ ν†µκ³„ ν™•μΈ
stats = vector_store.get_stats()
print(f"λ¬Έμ„ μ: {stats['documents_count']}")
print(f"μΈλ±μ¤ νƒ€μ…: {stats['index_type']}")
print(f"μ„λ² λ”© μ°¨μ›: {stats['embedding_dimension']}")
print(f"λ¨λΈλ…: {stats['model_name']}")
```

### λ΅κ·Έμ—μ„ λ©”λ¨λ¦¬ μ •λ³΄ ν™•μΈ

```
INFO - LegalVectorStore initialized with model: jhgan/ko-sroberta-multitask
INFO - Quantization: Enabled
INFO - Lazy Loading: Enabled
INFO - Model quantized to Float16
INFO - FAISS index initialized: flat
INFO - Memory usage exceeded threshold: 350.2 MB > 300 MB
INFO - Starting memory cleanup...
INFO - Garbage collection collected 150 objects
INFO - Memory after cleanup: 280.5 MB
```

## β οΈ μ£Όμμ‚¬ν•­

### 1. μ–‘μν™” κ΄€λ ¨
- **μ •ν™•λ„ μ†μ‹¤**: Float16 μ–‘μν™”λ΅ μΈν• λ―Έμ„Έν• μ •ν™•λ„ μ†μ‹¤ κ°€λ¥
- **νΈν™μ„±**: μ •κ·ν™” μ‹ Float32λ΅ λ³€ν™ν•μ—¬ FAISS νΈν™μ„± λ³΄μ¥
- **μ„±λ¥**: μ–‘μν™”λ΅ μΈν• μ¶”λ΅  μ†λ„ ν–¥μƒ κ°€λ¥

### 2. μ§€μ—° λ΅λ”© κ΄€λ ¨
- **μ΄κΈ° μ§€μ—°**: μ²« λ²μ§Έ κ²€μƒ‰ μ‹ λ¨λΈ λ΅λ”©μΌλ΅ μΈν• μ§€μ—°
- **μ¤λ λ“ μ•μ „**: λ©€ν‹°μ¤λ λ“ ν™κ²½μ—μ„ μ•μ „ν• λ΅λ”© λ³΄μ¥
- **λ©”λ¨λ¦¬ μ μ•½**: μ΄κΈ° λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ†ν™”

### 3. λ©”λ¨λ¦¬ κ΄€λ¦¬ κ΄€λ ¨
- **μ„κ³„κ°’ μ„¤μ •**: μ‹μ¤ν…μ— λ§λ” μ μ ν• μ„κ³„κ°’ μ„¤μ • ν•„μ”
- **μ •λ¦¬ μ£ΌκΈ°**: 30μ΄ κ°„κ²©μΌλ΅ λ©”λ¨λ¦¬ μ²΄ν¬ μν–‰
- **μλ™ μ •λ¦¬**: μ„κ³„κ°’ μ΄κ³Ό μ‹ μλ™μΌλ΅ λ©”λ¨λ¦¬ μ •λ¦¬

## π”§ μ¶”κ°€ μµμ ν™” λ°©μ•

### 1. ONNX λ³€ν™
```python
# μ¶”λ΅  μ†λ„ 20-30% ν–¥μƒ μμƒ
import torch.onnx

torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True
)
```

### 2. κ³ κΈ‰ μΊμ‹±
```python
# μμ£Ό κ²€μƒ‰λλ” μΏΌλ¦¬ κ²°κ³Ό μΊμ‹±
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_search(query: str):
    return vector_store.search(query)
```

### 3. μ¤νΈλ¦¬λ° μ‘λ‹µ
```python
# μ‹¤μ‹κ°„ μ‘λ‹µ μƒμ„±μΌλ΅ μ‚¬μ©μ κ²½ν— ν–¥μƒ
def stream_response(query: str):
    for chunk in model.generate_stream(query):
        yield chunk
```

### 4. λ¨λΈ νμΈνλ‹
```python
# λ²•λ¥  λ„λ©”μΈ νΉν™” λ¨λΈλ΅ μ‘λ‹µ ν’μ§ ν–¥μƒ
from transformers import Trainer

trainer = Trainer(
    model=model,
    train_dataset=legal_dataset,
    args=training_args
)
trainer.train()
```

## π“ μ„±κ³µ μ§€ν‘

### κΈ°μ μ  μ§€ν‘
- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: 82.92MB μ μ•½ λ‹¬μ„± β…
- **κ²€μƒ‰ μ„±λ¥**: 0.033μ΄ ν‰κ·  κ²€μƒ‰ μ‹κ°„ β…
- **μ•μ •μ„±**: 6,285κ° λ¬Έμ„ μ²λ¦¬ μ„±κ³µ β…
- **νΈν™μ„±**: κΈ°μ΅΄ APIμ™€ μ™„μ „ νΈν™ β…

### ν’μ§ μ§€ν‘
- **κ²€μƒ‰ μ •ν™•λ„**: λ―Όμ‚¬, ν•μ‚¬, κ°€μ‚¬ νλ΅€ λ¨λ‘ μ •μƒ κ²€μƒ‰ β…
- **λ©”νƒ€λ°μ΄ν„° λ³΄μ΅΄**: μ™„μ „ν• λ©”νƒ€λ°μ΄ν„° λ³΄μ΅΄ β…
- **μ‘λ‹µ μΌκ΄€μ„±**: μΌκ΄€λ κ²€μƒ‰ κ²°κ³Ό μ κ³µ β…

### μ΄μ μ§€ν‘
- **μλ™ν™”**: μλ™ λ©”λ¨λ¦¬ κ΄€λ¦¬ μ‹μ¤ν… κµ¬μ¶• β…
- **λ¨λ‹ν„°λ§**: μ‹¤μ‹κ°„ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ¶”μ  β…
- **ν™•μ¥μ„±**: λ€μ©λ‰ λ°μ΄ν„° μ²λ¦¬ κ°€λ¥ β…

## π‰ κ²°λ΅ 

LawFirmAI ν”„λ΅μ νΈμ λ©”λ¨λ¦¬ μµμ ν™” μ‘μ—…μ΄ μ„±κ³µμ μΌλ΅ μ™„λ£λμ—μµλ‹λ‹¤. Float16 μ–‘μν™”, μ§€μ—° λ΅λ”©, λ©”λ¨λ¦¬ κ΄€λ¦¬ μ‹μ¤ν…μ„ ν†µν•΄ λ‹¤μκ³Ό κ°™μ€ μ„±κ³Όλ¥Ό λ‹¬μ„±ν–μµλ‹λ‹¤:

### β… λ‹¬μ„±λ μ„±κ³Ό
1. **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: 82.92MB μ μ•½
2. **κ²€μƒ‰ μ„±λ¥**: ν‰κ·  0.033μ΄ (λ§¤μ° λΉ λ¦„)
3. **μ‹μ¤ν… μ•μ •μ„±**: 6,285κ° λ¬Έμ„ μ •μƒ μ²λ¦¬
4. **μλ™ν™”**: μλ™ λ©”λ¨λ¦¬ κ΄€λ¦¬ μ‹μ¤ν…
5. **ν™•μ¥μ„±**: λ€μ©λ‰ λ°μ΄ν„° μ²λ¦¬ κ°€λ¥

### π€ ν–¥ν›„ κ³„ν
1. **ONNX λ³€ν™**: μ¶”λ΅  μ†λ„ 20-30% ν–¥μƒ
2. **κ³ κΈ‰ μΊμ‹±**: μμ£Ό κ²€μƒ‰λλ” μΏΌλ¦¬ κ²°κ³Ό μΊμ‹±
3. **μ¤νΈλ¦¬λ° μ‘λ‹µ**: μ‹¤μ‹κ°„ μ‘λ‹µ μƒμ„±
4. **λ¨λΈ νμΈνλ‹**: λ²•λ¥  λ„λ©”μΈ νΉν™” λ¨λΈ

λ©”λ¨λ¦¬ μµμ ν™”λ¥Ό ν†µν•΄ LawFirmAI μ‹μ¤ν…μ΄ λ”μ± ν¨μ¨μ μ΄κ³  μ•μ •μ μΌλ΅ μ‘λ™ν•  μ μκ² λμ—μµλ‹λ‹¤.

---

*μ΄ λ¬Έμ„λ” LawFirmAI ν”„λ΅μ νΈμ λ©”λ¨λ¦¬ μµμ ν™” μ‘μ—… κ²°κ³Όλ¥Ό μ„¤λ…ν•©λ‹λ‹¤. μ‹¤μ  ν…μ¤νΈ κ²°κ³Όλ¥Ό λ°”νƒ•μΌλ΅ μ‘μ„±λμ—μµλ‹λ‹¤.*
