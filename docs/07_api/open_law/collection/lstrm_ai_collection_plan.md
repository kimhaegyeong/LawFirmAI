# lstrmAI API ë°ì´í„° ìˆ˜ì§‘ ê³„íšì„œ

## ğŸ“‹ ëª©ì°¨

1. [API ê°œìš”](#api-ê°œìš”)
2. [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„](#ë°ì´í„°ë² ì´ìŠ¤-ìŠ¤í‚¤ë§ˆ-ì„¤ê³„)
3. [íŒŒì¼ êµ¬ì¡°](#íŒŒì¼-êµ¬ì¡°)
4. [êµ¬í˜„ ê³„íš](#êµ¬í˜„-ê³„íš)
5. [ìˆ˜ì§‘ ì „ëµ](#ìˆ˜ì§‘-ì „ëµ)
6. [ì£¼ìš” íŠ¹ì§•](#ì£¼ìš”-íŠ¹ì§•)
7. [ì‹¤í–‰ ì˜ˆì‹œ](#ì‹¤í–‰-ì˜ˆì‹œ)
8. [ë°ì´í„° í™•ì¸](#ë°ì´í„°-í™•ì¸)
9. [ì£¼ì˜ì‚¬í•­](#ì£¼ì˜ì‚¬í•­)

---

## API ê°œìš”

### API ì •ë³´

**ìš”ì²­ URL**: `https://www.law.go.kr/DRF/lawSearch.do?target=lstrmAI`  
**Method**: GET  
**ì¶œë ¥ í˜•ì‹**: JSON  
**ìš©ë„**: ë²•ë ¹ìš©ì–´ ê²€ìƒ‰ (ë²•ë ¹ì •ë³´ì§€ì‹ë² ì´ìŠ¤)

### ìš”ì²­ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’/í—ˆìš©ê°’ |
|---------|------|------|------|--------------|
| OC | string | í•„ìˆ˜ | ì‚¬ìš©ì ì´ë©”ì¼ ID (g4c@korea.krì¼ ê²½ìš° OC=g4c) | - |
| target | string | í•„ìˆ˜ | ì„œë¹„ìŠ¤ ëŒ€ìƒ | lstrmAI |
| type | char | í•„ìˆ˜ | ì¶œë ¥ í˜•íƒœ | JSON |
| query | string | ì„ íƒ | ê²€ìƒ‰ ì§ˆì˜ | - |
| display | int | ì„ íƒ | ê²€ìƒ‰ëœ ê²°ê³¼ ê°œìˆ˜ | 20 (max=100) |
| page | int | ì„ íƒ | ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ | 1 |
| homonymYn | char | ì„ íƒ | ë™ìŒì´ì˜ì–´ ì¡´ì¬ì—¬ë¶€ | Y/N |

### ì‘ë‹µ í•„ë“œ

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| target | string | ê²€ìƒ‰ì„œë¹„ìŠ¤ ëŒ€ìƒ |
| í‚¤ì›Œë“œ | string | ê²€ìƒ‰ ë‹¨ì–´ |
| ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜ | int | ê²€ìƒ‰ ê±´ìˆ˜ |
| section | string | ê²€ìƒ‰ë²”ìœ„ |
| page | int | í˜„ì¬ í˜ì´ì§€ë²ˆí˜¸ |
| numOfRows | int | í˜ì´ì§€ ë‹¹ ì¶œë ¥ ê²°ê³¼ ìˆ˜ |
| ë²•ë ¹ìš©ì–´ id | string | ë²•ë ¹ìš©ì–´ ìˆœë²ˆ |
| ë²•ë ¹ìš©ì–´ëª… | string | ë²•ë ¹ìš©ì–´ëª… |
| ë™ìŒì´ì˜ì–´ì¡´ì¬ì—¬ë¶€ | string | ë™ìŒì´ì˜ì–´ ì¡´ì¬ì—¬ë¶€ |
| ë¹„ê³  | string | ë™ìŒì´ì˜ì–´ ë‚´ìš© |
| ìš©ì–´ê°„ê´€ê³„ë§í¬ | string | ë²•ë ¹ìš©ì–´-ì¼ìƒìš©ì–´ ì—°ê³„ ì •ë³´ ìƒì„¸ë§í¬ |
| ì¡°ë¬¸ê°„ê´€ê³„ë§í¬ | string | ë²•ë ¹ìš©ì–´-ì¡°ë¬¸ ì—°ê³„ ì •ë³´ ìƒì„¸ë§í¬ |

### ìƒ˜í”Œ URL

```bash
# JSON í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰
https://www.law.go.kr/DRF/lawSearch.do?OC=test&target=lstrmAI&type=JSON&query=ê³„ì•½

# í˜ì´ì§• ì²˜ë¦¬
https://www.law.go.kr/DRF/lawSearch.do?OC=test&target=lstrmAI&type=JSON&query=ê³„ì•½&page=1&display=100
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„

ì›ë³¸ JSONì„ ê·¸ëŒ€ë¡œ ì €ì¥í•  í…Œì´ë¸” ì„¤ê³„:

```sql
CREATE TABLE IF NOT EXISTS open_law_lstrm_ai_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    
    -- ê²€ìƒ‰ ë©”íƒ€ë°ì´í„°
    search_keyword TEXT,
    search_page INTEGER,
    search_display INTEGER,
    homonym_yn TEXT,
    
    -- API ì‘ë‹µ ì›ë³¸ ë°ì´í„° (JSON)
    raw_response_json TEXT NOT NULL,  -- ì „ì²´ ì‘ë‹µ JSON ì›ë³¸ ì €ì¥
    
    -- ê°œë³„ ê²°ê³¼ í•­ëª© (ë°°ì—´ì˜ ê° í•­ëª©)
    term_id TEXT,                    -- ë²•ë ¹ìš©ì–´ id
    term_name TEXT,                  -- ë²•ë ¹ìš©ì–´ëª…
    homonym_exists TEXT,             -- ë™ìŒì´ì˜ì–´ì¡´ì¬ì—¬ë¶€
    homonym_note TEXT,               -- ë¹„ê³ 
    term_relation_link TEXT,         -- ìš©ì–´ê°„ê´€ê³„ë§í¬
    article_relation_link TEXT,      -- ì¡°ë¬¸ê°„ê´€ê³„ë§í¬
    
    -- ìˆ˜ì§‘ ë©”íƒ€ë°ì´í„°
    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    collection_method TEXT,          -- 'keyword', 'pagination', 'all'
    api_request_url TEXT,            -- ì‹¤ì œ ìš”ì²­ URL
    
    -- í†µê³„ ì •ë³´
    total_count INTEGER,              -- ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜
    page_number INTEGER,              -- page
    num_of_rows INTEGER,             -- numOfRows
    
    -- ì¸ë±ìŠ¤
    UNIQUE(term_id, search_keyword, search_page)
);

CREATE INDEX IF NOT EXISTS idx_lstrm_ai_term_id ON open_law_lstrm_ai_data(term_id);
CREATE INDEX IF NOT EXISTS idx_lstrm_ai_keyword ON open_law_lstrm_ai_data(search_keyword);
CREATE INDEX IF NOT EXISTS idx_lstrm_ai_collected_at ON open_law_lstrm_ai_data(collected_at);
```

### í…Œì´ë¸” ì„¤ê³„ íŠ¹ì§•

1. **ì›ë³¸ JSON ë³´ì¡´**: `raw_response_json` í•„ë“œì— ì „ì²´ API ì‘ë‹µì„ JSON ë¬¸ìì—´ë¡œ ì €ì¥
2. **ê°œë³„ í•­ëª© ì €ì¥**: ê° ê²€ìƒ‰ ê²°ê³¼ í•­ëª©ì„ ê°œë³„ ë ˆì½”ë“œë¡œ ì €ì¥í•˜ì—¬ ê²€ìƒ‰ ë° ë¶„ì„ ìš©ì´
3. **ì¤‘ë³µ ë°©ì§€**: `term_id + search_keyword + search_page` ì¡°í•©ìœ¼ë¡œ UNIQUE ì œì•½
4. **ë©”íƒ€ë°ì´í„° ë³´ì¡´**: ìˆ˜ì§‘ ì‹œì , ë°©ë²•, ìš”ì²­ URL ë“± ì¶”ì  ê°€ëŠ¥

---

## íŒŒì¼ êµ¬ì¡°

```
scripts/ingest/
â”œâ”€â”€ ingest_lstrm_ai.py          # ë©”ì¸ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ ...

lawfirm_langgraph/core/data/
â””â”€â”€ connection_pool.py          # ì—°ê²° í’€ (ê¸°ì¡´)
```

---

## êµ¬í˜„ ê³„íš

### 4.1 API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤

```python
class LstrmAIClient:
    """lstrmAI API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, oc: str, base_url: str = "https://www.law.go.kr/DRF"):
        """
        Args:
            oc: ì‚¬ìš©ì ì´ë©”ì¼ ID
            base_url: API ê¸°ë³¸ URL
        """
        self.oc = oc
        self.base_url = base_url
        self.rate_limit_delay = 0.5  # ìš”ì²­ ê°„ ì§€ì—° (ì´ˆ)
    
    def search_terms(
        self,
        query: str = "",
        page: int = 1,
        display: int = 100,
        homonym_yn: str = None
    ) -> Dict[str, Any]:
        """ë²•ë ¹ìš©ì–´ ê²€ìƒ‰"""
        params = {
            'OC': self.oc,
            'target': 'lstrmAI',
            'type': 'JSON',
            'query': query,
            'page': page,
            'display': display
        }
        if homonym_yn:
            params['homonymYn'] = homonym_yn
        
        return self._make_request(params)
    
    def _make_request(self, params: Dict) -> Dict[str, Any]:
        """API ìš”ì²­ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        url = f"{self.base_url}/lawSearch.do"
        max_retries = 3
        retry_delay = 2.0
        
        for attempt in range(max_retries):
            try:
                time.sleep(self.rate_limit_delay)
                response = requests.get(url, params=params, timeout=30)
                response.raise_for_status()
                return response.json()
            except requests.exceptions.RequestException as e:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                raise
```

### 4.2 ë°ì´í„° ìˆ˜ì§‘ê¸°

```python
class LstrmAICollector:
    """lstrmAI ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, client: LstrmAIClient, db_path: str):
        """
        Args:
            client: LstrmAIClient ì¸ìŠ¤í„´ìŠ¤
            db_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        self.client = client
        self.db_path = db_path
        from lawfirm_langgraph.core.data.connection_pool import get_connection_pool
        self.connection_pool = get_connection_pool(db_path)
    
    def collect_by_keywords(
        self,
        keywords: List[str],
        max_pages_per_keyword: int = None
    ) -> int:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ìˆ˜ì§‘"""
        total_saved = 0
        for keyword in keywords:
            logger.info(f"í‚¤ì›Œë“œ '{keyword}' ìˆ˜ì§‘ ì‹œì‘")
            saved = self.collect_all_pages(
                query=keyword,
                max_pages=max_pages_per_keyword
            )
            total_saved += saved
            logger.info(f"í‚¤ì›Œë“œ '{keyword}' ìˆ˜ì§‘ ì™„ë£Œ: {saved}ê±´")
        return total_saved
    
    def collect_all_pages(
        self,
        query: str = "",
        max_pages: int = None
    ) -> int:
        """ì „ì²´ í˜ì´ì§€ ìˆ˜ì§‘"""
        page = 1
        total_saved = 0
        
        while True:
            if max_pages and page > max_pages:
                break
            
            try:
                response = self.client.search_terms(
                    query=query,
                    page=page,
                    display=100
                )
                
                # ì‘ë‹µ ê²€ì¦
                if not response or 'ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜' not in response:
                    break
                
                total_count = response.get('ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜', 0)
                if total_count == 0:
                    break
                
                # ë°ì´í„° ì €ì¥
                saved = self._save_response(
                    response=response,
                    search_keyword=query,
                    page=page,
                    display=100
                )
                total_saved += saved
                
                logger.info(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì™„ë£Œ: {saved}ê±´ ì €ì¥")
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                num_of_rows = response.get('numOfRows', 0)
                if num_of_rows == 0 or saved == 0:
                    break
                
                page += 1
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                break
        
        return total_saved
    
    def _save_response(
        self,
        response: Dict[str, Any],
        search_keyword: str,
        page: int,
        display: int,
        homonym_yn: str = None
    ) -> int:
        """ì‘ë‹µ ë°ì´í„°ë¥¼ DBì— ì €ì¥ (ì›ë³¸ JSON í¬í•¨)"""
        conn = self.connection_pool.get_connection()
        try:
            cursor = conn.cursor()
            
            # ì „ì²´ ì‘ë‹µì„ JSON ë¬¸ìì—´ë¡œ ì €ì¥
            raw_json = json.dumps(response, ensure_ascii=False, indent=None)
            
            # ê° ê²°ê³¼ í•­ëª©ì„ ê°œë³„ ë ˆì½”ë“œë¡œ ì €ì¥
            items = response.get('items', []) or []
            if not items:
                # itemsê°€ ì—†ì„ ê²½ìš° ë‹¤ë¥¸ í•„ë“œëª… í™•ì¸
                items = response.get('ë²•ë ¹ìš©ì–´', []) or []
            
            saved_count = 0
            
            for item in items:
                # ìš”ì²­ URL ìƒì„±
                request_url = self._build_request_url(
                    search_keyword, page, display, homonym_yn
                )
                
                cursor.execute("""
                    INSERT OR IGNORE INTO open_law_lstrm_ai_data (
                        search_keyword, search_page, search_display, homonym_yn,
                        raw_response_json,
                        term_id, term_name, homonym_exists, homonym_note,
                        term_relation_link, article_relation_link,
                        collection_method, api_request_url,
                        total_count, page_number, num_of_rows,
                        collected_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    search_keyword, page, display, homonym_yn,
                    raw_json,  # ì›ë³¸ JSON ì €ì¥
                    item.get('ë²•ë ¹ìš©ì–´ id') or item.get('ë²•ë ¹ìš©ì–´id'),
                    item.get('ë²•ë ¹ìš©ì–´ëª…'),
                    item.get('ë™ìŒì´ì˜ì–´ì¡´ì¬ì—¬ë¶€'),
                    item.get('ë¹„ê³ '),
                    item.get('ìš©ì–´ê°„ê´€ê³„ë§í¬'),
                    item.get('ì¡°ë¬¸ê°„ê´€ê³„ë§í¬'),
                    'keyword' if search_keyword else 'all',
                    request_url,
                    response.get('ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜'),
                    response.get('page'),
                    response.get('numOfRows'),
                    datetime.now().isoformat()
                ))
                if cursor.rowcount > 0:
                    saved_count += 1
            
            conn.commit()
            return saved_count
        except Exception as e:
            conn.rollback()
            logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
        finally:
            # ì—°ê²° í’€ ì‚¬ìš© ì‹œ close() ë¶ˆí•„ìš”
            pass
    
    def _build_request_url(
        self,
        query: str,
        page: int,
        display: int,
        homonym_yn: str = None
    ) -> str:
        """ìš”ì²­ URL ìƒì„±"""
        params = {
            'OC': self.client.oc,
            'target': 'lstrmAI',
            'type': 'JSON',
            'query': query,
            'page': page,
            'display': display
        }
        if homonym_yn:
            params['homonymYn'] = homonym_yn
        
        query_string = '&'.join([f"{k}={v}" for k, v in params.items() if v])
        return f"{self.client.base_url}/lawSearch.do?{query_string}"
```

### 4.3 ë©”ì¸ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/ingest/ingest_lstrm_ai.py

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
_CURRENT_FILE = Path(__file__).resolve()
_PROJECT_ROOT = _CURRENT_FILE.parents[2]
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

from lawfirm_langgraph.core.data.connection_pool import get_connection_pool

# ë¡œê±° ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def _create_table(conn):
    """í…Œì´ë¸” ìƒì„±"""
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS open_law_lstrm_ai_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            
            -- ê²€ìƒ‰ ë©”íƒ€ë°ì´í„°
            search_keyword TEXT,
            search_page INTEGER,
            search_display INTEGER,
            homonym_yn TEXT,
            
            -- API ì‘ë‹µ ì›ë³¸ ë°ì´í„° (JSON)
            raw_response_json TEXT NOT NULL,
            
            -- ê°œë³„ ê²°ê³¼ í•­ëª©
            term_id TEXT,
            term_name TEXT,
            homonym_exists TEXT,
            homonym_note TEXT,
            term_relation_link TEXT,
            article_relation_link TEXT,
            
            -- ìˆ˜ì§‘ ë©”íƒ€ë°ì´í„°
            collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            collection_method TEXT,
            api_request_url TEXT,
            
            -- í†µê³„ ì •ë³´
            total_count INTEGER,
            page_number INTEGER,
            num_of_rows INTEGER,
            
            UNIQUE(term_id, search_keyword, search_page)
        )
    """)
    
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_lstrm_ai_term_id 
        ON open_law_lstrm_ai_data(term_id)
    """)
    
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_lstrm_ai_keyword 
        ON open_law_lstrm_ai_data(search_keyword)
    """)
    
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_lstrm_ai_collected_at 
        ON open_law_lstrm_ai_data(collected_at)
    """)
    
    conn.commit()
    logger.info("í…Œì´ë¸” ìƒì„± ì™„ë£Œ")


def _load_keywords(keywords_str: str = None, keyword_file: str = None) -> List[str]:
    """í‚¤ì›Œë“œ ë¡œë“œ"""
    keywords = []
    
    if keywords_str:
        keywords.extend([k.strip() for k in keywords_str.split(',') if k.strip()])
    
    if keyword_file:
        file_path = Path(keyword_file)
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                keywords.extend([line.strip() for line in f if line.strip()])
        else:
            logger.warning(f"í‚¤ì›Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {keyword_file}")
    
    return list(set(keywords))  # ì¤‘ë³µ ì œê±°


def main():
    parser = argparse.ArgumentParser(description='lstrmAI API ë°ì´í„° ìˆ˜ì§‘')
    parser.add_argument('--oc', required=True, help='ì‚¬ìš©ì ì´ë©”ì¼ ID')
    parser.add_argument('--keywords', help='ê²€ìƒ‰ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)')
    parser.add_argument('--keyword-file', help='í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--query', default='', help='ê²€ìƒ‰ ì§ˆì˜')
    parser.add_argument('--max-pages', type=int, help='ìµœëŒ€ í˜ì´ì§€ ìˆ˜')
    parser.add_argument('--display', type=int, default=100, help='í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜')
    parser.add_argument('--db-path', default='data/lawfirm.db', help='DB ê²½ë¡œ')
    parser.add_argument('--rate-limit', type=float, default=0.5, help='ìš”ì²­ ê°„ ì§€ì—° (ì´ˆ)')
    
    args = parser.parse_args()
    
    # ì—°ê²° í’€ ì‚¬ìš©
    connection_pool = get_connection_pool(args.db_path)
    
    # í…Œì´ë¸” ìƒì„±
    with connection_pool.get_connection_context() as conn:
        _create_table(conn)
    
    # API í´ë¼ì´ì–¸íŠ¸ ë° ìˆ˜ì§‘ê¸° ìƒì„±
    from scripts.ingest.lstrm_ai_client import LstrmAIClient
    from scripts.ingest.lstrm_ai_collector import LstrmAICollector
    
    client = LstrmAIClient(args.oc)
    client.rate_limit_delay = args.rate_limit
    
    collector = LstrmAICollector(client, args.db_path)
    
    # ìˆ˜ì§‘ ì‹¤í–‰
    if args.keywords or args.keyword_file:
        keywords = _load_keywords(args.keywords, args.keyword_file)
        if not keywords:
            logger.error("í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"í‚¤ì›Œë“œ ê¸°ë°˜ ìˆ˜ì§‘ ì‹œì‘: {len(keywords)}ê°œ í‚¤ì›Œë“œ")
        total = collector.collect_by_keywords(keywords, args.max_pages)
    else:
        logger.info(f"ì „ì²´ ìˆ˜ì§‘ ì‹œì‘: query='{args.query}'")
        total = collector.collect_all_pages(args.query, args.max_pages)
    
    logger.info(f"ìˆ˜ì§‘ ì™„ë£Œ: ì´ {total}ê±´ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")


if __name__ == '__main__':
    main()
```

---

## ìˆ˜ì§‘ ì „ëµ

### 5.1 í‚¤ì›Œë“œ ê¸°ë°˜ ìˆ˜ì§‘ (ê¶Œì¥)

ë²•ë¥  ë„ë©”ì¸ë³„ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘:

```python
# ë¯¼ì‚¬ë²•
keywords = ["ê³„ì•½", "í•´ì§€", "ì†í•´ë°°ìƒ", "ìœ„ì•½ê¸ˆ", "ì±„ë¬´", "ì±„ê¶Œ", "ê³„ì•½í•´ì œ", "ê³„ì•½ë¶ˆì´í–‰"]

# í˜•ì‚¬ë²•
keywords = ["ë²”ì£„", "í˜•ë²Œ", "ë²Œê¸ˆ", "ì§•ì—­", "êµ¬ì†", "ê¸°ì†Œ", "ê³µì†Œ", "ì¬íŒ"]

# ë…¸ë™ë²•
keywords = ["ê·¼ë¡œ", "í•´ê³ ", "ì„ê¸ˆ", "ê·¼ë¡œì‹œê°„", "íœ´ê°€", "ë¶€ë‹¹í•´ê³ ", "ê·¼ë¡œê³„ì•½", "ì„ê¸ˆì²´ë¶ˆ"]

# ê°€ì¡±ë²•
keywords = ["ì´í˜¼", "ì–‘ìœ¡ê¶Œ", "ìœ„ìë£Œ", "ì¬ì‚°ë¶„í• ", "ì¹œê¶Œ", "ë©´ì ‘êµì„­ê¶Œ", "ë¶€ì–‘"]

# ë¶€ë™ì‚°ë²•
keywords = ["ì•„íŒŒíŠ¸", "ë§¤ë§¤", "ì„ëŒ€", "ë“±ê¸°", "ì „ì„¸", "ì›”ì„¸", "ë¶€ë™ì‚°", "ì†Œìœ ê¶Œ"]

# ìƒë²•
keywords = ["íšŒì‚¬", "ì£¼ì‹", "ì´ì‚¬íšŒ", "ì£¼ì£¼", "í•©ë³‘", "ë¶„í• ", "ìƒë²•", "ë²•ì¸"]
```

### 5.2 ì „ì²´ ìˆ˜ì§‘

- `query` ì—†ì´ ì „ì²´ í˜ì´ì§€ ìˆœíšŒ
- í˜ì´ì§•ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
- ì‹œê°„ ì†Œìš”ê°€ í¬ë¯€ë¡œ ì£¼ì˜ í•„ìš”

---

## ì£¼ìš” íŠ¹ì§•

### 1. ì›ë³¸ JSON ë³´ì¡´
- `raw_response_json` í•„ë“œì— ì „ì²´ API ì‘ë‹µì„ JSON ë¬¸ìì—´ë¡œ ì €ì¥
- ë‚˜ì¤‘ì— ì›ë³¸ ë°ì´í„° ë¶„ì„ ë° ì¬ì²˜ë¦¬ ê°€ëŠ¥

### 2. ì—°ê²° í’€ ì‚¬ìš©
- `get_connection_pool()` ì‚¬ìš©í•˜ì—¬ ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë³´ì¥
- ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ

### 3. ì¤‘ë³µ ë°©ì§€
- `term_id + search_keyword + search_page` ì¡°í•©ìœ¼ë¡œ UNIQUE ì œì•½
- ë™ì¼í•œ ë°ì´í„° ì¤‘ë³µ ì €ì¥ ë°©ì§€

### 4. Rate Limiting
- ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ì„¤ì • (ê¸°ë³¸ 0.5ì´ˆ)
- API ì„œë²„ ë¶€í•˜ ë°©ì§€

### 5. ì¬ì‹œë„ ë¡œì§
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- ì§€ìˆ˜ ë°±ì˜¤í”„(exponential backoff) ì ìš©

### 6. ë¡œê¹…
- ìˆ˜ì§‘ ê³¼ì • ìƒì„¸ ë¡œê¹…
- ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡

---

## ì‹¤í–‰ ì˜ˆì‹œ

### í‚¤ì›Œë“œ ê¸°ë°˜ ìˆ˜ì§‘

```bash
# ê¸°ë³¸ í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘
python scripts/ingest/ingest_lstrm_ai.py \
    --oc test \
    --keywords "ê³„ì•½,ì†í•´ë°°ìƒ,ì†Œì†¡" \
    --max-pages 10 \
    --display 100

# í‚¤ì›Œë“œ íŒŒì¼ë¡œ ìˆ˜ì§‘
python scripts/ingest/ingest_lstrm_ai.py \
    --oc test \
    --keyword-file data/keywords/legal_keywords.txt \
    --max-pages 5

# ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ì¡°ì •
python scripts/ingest/ingest_lstrm_ai.py \
    --oc test \
    --keywords "ê³„ì•½" \
    --rate-limit 1.0
```

### ì „ì²´ ìˆ˜ì§‘

```bash
# query ì—†ì´ ì „ì²´ ìˆ˜ì§‘
python scripts/ingest/ingest_lstrm_ai.py \
    --oc test \
    --query "" \
    --max-pages 100

# íŠ¹ì • ì§ˆì˜ë¡œ ìˆ˜ì§‘
python scripts/ingest/ingest_lstrm_ai.py \
    --oc test \
    --query "ë²•ë¥ " \
    --max-pages 50
```

### í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©

```bash
# .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜
export LAW_OPEN_API_OC="your_email_id"

python scripts/ingest/ingest_lstrm_ai.py \
    --oc $LAW_OPEN_API_OC \
    --keywords "ê³„ì•½"
```

---

## ë°ì´í„° í™•ì¸

### ì›ë³¸ JSON í™•ì¸

```sql
-- ì›ë³¸ JSON í™•ì¸
SELECT raw_response_json FROM open_law_lstrm_ai_data LIMIT 1;

-- JSON íŒŒì‹±í•˜ì—¬ í™•ì¸
SELECT 
    json_extract(raw_response_json, '$.ê²€ìƒ‰ê²°ê³¼ê°œìˆ˜') as total_count,
    json_extract(raw_response_json, '$.page') as page
FROM open_law_lstrm_ai_data 
LIMIT 1;
```

### í†µê³„ í™•ì¸

```sql
-- í‚¤ì›Œë“œë³„ í†µê³„
SELECT 
    search_keyword,
    COUNT(*) as count,
    COUNT(DISTINCT term_id) as unique_terms,
    MIN(collected_at) as first_collected,
    MAX(collected_at) as last_collected
FROM open_law_lstrm_ai_data
GROUP BY search_keyword
ORDER BY count DESC;

-- ìˆ˜ì§‘ ì¼ìë³„ í†µê³„
SELECT 
    DATE(collected_at) as collection_date,
    COUNT(*) as count,
    COUNT(DISTINCT term_id) as unique_terms
FROM open_law_lstrm_ai_data
GROUP BY DATE(collected_at)
ORDER BY collection_date DESC;
```

### íŠ¹ì • ìš©ì–´ ê²€ìƒ‰

```sql
-- ìš©ì–´ëª…ìœ¼ë¡œ ê²€ìƒ‰
SELECT * FROM open_law_lstrm_ai_data 
WHERE term_name LIKE '%ê³„ì•½%'
ORDER BY collected_at DESC;

-- ìš©ì–´ IDë¡œ ê²€ìƒ‰
SELECT * FROM open_law_lstrm_ai_data 
WHERE term_id = '12345';
```

### ì›ë³¸ ë°ì´í„° ì¶”ì¶œ

```python
import sqlite3
import json

conn = sqlite3.connect('data/lawfirm.db')
cursor = conn.cursor()

# ì›ë³¸ JSON ì¶”ì¶œ
cursor.execute("SELECT raw_response_json FROM open_law_lstrm_ai_data LIMIT 1")
row = cursor.fetchone()
if row:
    original_data = json.loads(row[0])
    print(json.dumps(original_data, ensure_ascii=False, indent=2))
```

---

## ì£¼ì˜ì‚¬í•­

### 1. API ì œí•œ

- **ìš”ì²­ ê°„ ì§€ì—°**: API ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ìš”ì²­ ê°„ ìµœì†Œ 0.5ì´ˆ ì§€ì—° ê¶Œì¥
- **ì¼ì¼ ìš”ì²­ í•œë„**: êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì˜ ì¼ì¼ ìš”ì²­ í•œë„ í™•ì¸ í•„ìš”
- **ë™ì‹œ ìš”ì²­ ì œí•œ**: ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (ê¶Œì¥: 1ê°œì”© ìˆœì°¨ ì²˜ë¦¬)

### 2. ë°ì´í„° í’ˆì§ˆ

- **ì¤‘ë³µ ì œê±°**: `term_id + search_keyword + search_page` ì¡°í•©ìœ¼ë¡œ ìë™ ì¤‘ë³µ ë°©ì§€
- **ë°ì´í„° ê²€ì¦**: í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
- **ì›ë³¸ ë³´ì¡´**: `raw_response_json`ì— ì›ë³¸ ë°ì´í„° ì €ì¥

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬

- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
- **ì£¼ê¸°ì  ì €ì¥**: ì¼ì • ê°„ê²©ìœ¼ë¡œ ì¤‘ê°„ ì €ì¥
- **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 

### 4. ì—ëŸ¬ ì²˜ë¦¬

- **ì¬ì‹œë„ ë¡œì§**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
- **ì—ëŸ¬ ë¡œê¹…**: ëª¨ë“  ì—ëŸ¬ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
- **ë¶€ë¶„ ì‹¤íŒ¨ ì²˜ë¦¬**: ì¼ë¶€ ìš©ì–´ ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰

### 5. ë°ì´í„°ë² ì´ìŠ¤

- **ì—°ê²° í’€ ì‚¬ìš©**: ë°˜ë“œì‹œ `get_connection_pool()` ì‚¬ìš© (CRITICAL)
- **íŠ¸ëœì­ì…˜ ê´€ë¦¬**: ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°± ì²˜ë¦¬
- **ì¸ë±ìŠ¤ í™œìš©**: ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¸ë±ìŠ¤ í™œìš©

---

## êµ¬í˜„ ë‹¨ê³„

### Phase 1: ê¸°ë³¸ êµ¬í˜„
- [ ] API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ (`LstrmAIClient`)
- [ ] ë°ì´í„° ìˆ˜ì§‘ê¸° êµ¬í˜„ (`LstrmAICollector`)
- [ ] ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
- [ ] ë©”ì¸ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„

### Phase 2: ê³ ê¸‰ ê¸°ëŠ¥
- [ ] ì¬ì‹œë„ ë¡œì§ ê°•í™”
- [ ] ë¡œê¹… ì‹œìŠ¤í…œ ê°œì„ 
- [ ] í†µê³„ ë° ëª¨ë‹ˆí„°ë§
- [ ] ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ (ì„ íƒ)

### Phase 3: í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì‹¤ì œ API í…ŒìŠ¤íŠ¸

### Phase 4: ë¬¸ì„œí™”
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±
- [ ] API ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

## ì°¸ê³  ìë£Œ

### ê´€ë ¨ ë¬¸ì„œ

- [lstrmAIGuide ê°€ì´ë“œ](guides/lstrmAIGuide.md) - lstrmAI API ê°€ì´ë“œ
- [ë²•ë ¹ìš©ì–´ ìˆ˜ì§‘ ê³„íš](legal_term_collection_plan.md) - ë²•ë ¹ìš©ì–´ ìˆ˜ì§‘ ê³„íš
- [Open Law API ê°€ì´ë“œ ë§µ](guide_id_map.md) - ì „ì²´ API ê°€ì´ë“œ ë§µ

### ì™¸ë¶€ ë§í¬

- [êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° Open API](https://open.law.go.kr/LSO/openApi/guideList.do) - ê³µì‹ API ê°€ì´ë“œ
- [LAW OPEN DATA](http://www.law.go.kr/DRF/lawService.do) - API ì—”ë“œí¬ì¸íŠ¸

---

**ì‘ì„±ì¼**: 2024-01-01  
**ìµœì¢… ìˆ˜ì •ì¼**: 2024-01-01  
**ì‘ì„±ì**: LawFirmAI Development Team

