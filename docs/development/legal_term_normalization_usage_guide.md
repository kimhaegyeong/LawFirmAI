# ë²•ë¥  ìš©ì–´ ì •ê·œí™” ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ë²•ë¥  ìš©ì–´ ì •ê·œí™” ì‹œìŠ¤í…œì€ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° OpenAPIë¥¼ í™œìš©í•˜ì—¬ ë²•ë¥  ìš©ì–´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ë‹¤ì¸µ ì •ê·œí™” íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì¼ê´€ëœ ìš©ì–´ë¡œ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export LAW_OPEN_API_OC="your_email@example.com"

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p logs
mkdir -p data/legal_terms
```

### 2. ìš©ì–´ ìˆ˜ì§‘ ë° ì‚¬ì „ êµ¬ì¶•

```bash
# ë²•ë¥  ìš©ì–´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/collect_legal_terms.py
```

### 3. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from source.data.legal_term_normalizer import LegalTermNormalizer

# ì •ê·œí™”ê¸° ì´ˆê¸°í™”
normalizer = LegalTermNormalizer()

# í…ìŠ¤íŠ¸ ì •ê·œí™”
text = "ê³„ì•½ì„œì— ëª…ì‹œëœ ì†í•´ë°°ìƒ ì¡°í•­ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤."
result = normalizer.normalize_text(text)

print(f"ì›ë³¸: {result['original_text']}")
print(f"ì •ê·œí™”: {result['normalized_text']}")
print(f"ìš©ì–´ ë§¤í•‘: {result['term_mappings']}")
print(f"ì‹ ë¢°ë„: {result['confidence_scores']}")
```

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ëª¨ë“ˆ êµ¬ì¡°

```
source/data/
â”œâ”€â”€ legal_term_collection_api.py    # API ì—°ë™ ëª¨ë“ˆ
â”œâ”€â”€ legal_term_dictionary.py        # ìš©ì–´ ì‚¬ì „ ê´€ë¦¬
â”œâ”€â”€ legal_term_normalizer.py        # ì •ê·œí™” íŒŒì´í”„ë¼ì¸
â””â”€â”€ data_processor.py               # í†µí•© ë°ì´í„° ì²˜ë¦¬

scripts/
â””â”€â”€ collect_legal_terms.py          # ìš©ì–´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
```

### ë°ì´í„° íë¦„

```
API ìˆ˜ì§‘ â†’ ìš©ì–´ ì‚¬ì „ êµ¬ì¶• â†’ ì •ê·œí™” íŒŒì´í”„ë¼ì¸ â†’ í†µí•© ë°ì´í„° ì²˜ë¦¬
    â†“           â†“              â†“              â†“
ìš©ì–´ ìˆ˜ì§‘    ì‚¬ì „ ê´€ë¦¬      ë‹¤ì¸µ ì •ê·œí™”     ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©
```

## ğŸ”§ ìƒì„¸ ì‚¬ìš©ë²•

### 1. ìš©ì–´ ìˆ˜ì§‘ API

```python
from source.data.legal_term_collection_api import LegalTermCollectionAPI, TermCollectionConfig

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
config = TermCollectionConfig()
api_client = LegalTermCollectionAPI(config)

# ì¹´í…Œê³ ë¦¬ë³„ ìš©ì–´ ìˆ˜ì§‘
categories = ["ë¯¼ì‚¬ë²•", "í˜•ì‚¬ë²•", "ìƒì‚¬ë²•"]
all_terms = api_client.collect_terms_by_category(categories, max_terms_per_category=200)

# ìš©ì–´ ì •ì˜ ìˆ˜ì§‘
term_ids = ["T001", "T002", "T003"]
definitions = api_client.collect_term_definitions(term_ids)
```

### 2. ìš©ì–´ ì‚¬ì „ ê´€ë¦¬

```python
from source.data.legal_term_dictionary import LegalTermDictionary

# ì‚¬ì „ ì´ˆê¸°í™”
dictionary = LegalTermDictionary()

# ìš©ì–´ ì¶”ê°€
term_data = {
    'term_id': 'T001',
    'term_name': 'ê³„ì•½',
    'definition': 'ë‹¹ì‚¬ì ê°„ ì˜ì‚¬í‘œì‹œì˜ í•©ì¹˜',
    'category': 'ë¯¼ì‚¬ë²•',
    'law_references': ['ë¯¼ë²• ì œ105ì¡°'],
    'related_terms': ['ì±„ê¶Œ', 'ì±„ë¬´', 'ì´í–‰'],
    'frequency': 100
}
dictionary.add_term(term_data)

# ë™ì˜ì–´ ê·¸ë£¹ ìƒì„±
dictionary.create_synonym_group(
    'contract_group',
    'ê³„ì•½',
    ['ê³„ì•½ì„œ', 'ê³„ì•½ê´€ê³„', 'ê³„ì•½ì²´ê²°'],
    0.95
)

# ìš©ì–´ ê²€ìƒ‰
results = dictionary.search_terms('ê³„ì•½', category='ë¯¼ì‚¬ë²•', limit=10)

# ìš©ì–´ ì •ê·œí™”
normalized_term, confidence = dictionary.normalize_term('ê³„ì•½ì„œ')
print(f"ì •ê·œí™” ê²°ê³¼: {normalized_term} (ì‹ ë¢°ë„: {confidence})")
```

### 3. ì •ê·œí™” íŒŒì´í”„ë¼ì¸

```python
from source.data.legal_term_normalizer import LegalTermNormalizer

# ì •ê·œí™”ê¸° ì´ˆê¸°í™”
normalizer = LegalTermNormalizer()

# ë‹¨ì¼ í…ìŠ¤íŠ¸ ì •ê·œí™”
text = "ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë³´ìƒ ì²­êµ¬ê¶Œì´ ì¸ì •ë©ë‹ˆë‹¤."
result = normalizer.normalize_text(text, context="precedent_case")

# ë°°ì¹˜ ì •ê·œí™”
texts = [
    "ê³„ì•½ì„œì— ëª…ì‹œëœ ì†í•´ë°°ìƒ ì¡°í•­ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.",
    "ë¯¼ë²• ì œ105ì¡°ì— ë”°ë¥¸ ê³„ì•½ì˜ íš¨ë ¥ì— ëŒ€í•´ ë…¼ì˜í•˜ê² ìŠµë‹ˆë‹¤.",
    "ì±„ê¶Œìì™€ ì±„ë¬´ì ê°„ì˜ ê³„ì•½ê´€ê³„ê°€ ì„±ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤."
]
contexts = ["contract_review", "law_discussion", "legal_analysis"]

results = normalizer.batch_normalize(texts, contexts)

# ì •ê·œí™” í†µê³„
stats = normalizer.get_normalization_statistics()
print(f"ì •ê·œí™” í†µê³„: {stats}")
```

### 4. ê¸°ì¡´ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ í†µí•©

```python
from source.data.data_processor import LegalDataProcessor

# ì •ê·œí™” ê¸°ëŠ¥ í™œì„±í™”ëœ ë°ì´í„° í”„ë¡œì„¸ì„œ
processor = LegalDataProcessor(enable_term_normalization=True)

# ë²•ë ¹ ë°ì´í„° ì²˜ë¦¬ (ìë™ìœ¼ë¡œ ìš©ì–´ ì •ê·œí™” ì ìš©)
law_data = {...}  # APIì—ì„œ ìˆ˜ì§‘í•œ ë²•ë ¹ ë°ì´í„°
processed_law = processor.process_law_data(law_data)

# íŒë¡€ ë°ì´í„° ì²˜ë¦¬ (ìë™ìœ¼ë¡œ ìš©ì–´ ì •ê·œí™” ì ìš©)
precedent_data = {...}  # APIì—ì„œ ìˆ˜ì§‘í•œ íŒë¡€ ë°ì´í„°
processed_precedent = processor.process_precedent_data(precedent_data)
```

## ğŸ“Š ì •ê·œí™” ë ˆë²¨

### Level 1: ê¸°ë³¸ ì •ê·œí™”
- HTML íƒœê·¸ ì œê±°
- ê³µë°± ì •ê·œí™”
- ë”°ì˜´í‘œ ì •ê·œí™”

### Level 2: ë²•ë¥  ìš©ì–´ í‘œì¤€í™”
- API ìˆ˜ì§‘ ìš©ì–´ ì‚¬ì „ ê¸°ë°˜ ë§¤í•‘
- ë™ì˜ì–´ ê·¸ë£¹ ë§¤í•‘
- ì‹ ë¢°ë„ ê¸°ë°˜ ìš©ì–´ ì„ íƒ

### Level 3: ì˜ë¯¸ì  ì •ê·œí™”
- ì˜ë¯¸ì  ë™ì˜ì–´ ê·¸ë£¹ ë§¤í•‘
- ë²•ë¥  ì˜ì—­ë³„ ìš©ì–´ ë¶„ë¥˜
- ë§¥ë½ ê¸°ë°˜ ìš©ì–´ í•´ì„

### Level 4: êµ¬ì¡°ì  ì •ê·œí™”
- ì¡°ë¬¸ ë²ˆí˜¸ ì •ê·œí™” (ì œXì¡°)
- ë²•ë¥ ëª… ì •ê·œí™” (ë¯¼ë²•, ìƒë²• ë“±)
- ì‚¬ê±´ë²ˆí˜¸ ì •ê·œí™”
- ë‚ ì§œ í˜•ì‹ ì •ê·œí™”

## ğŸ¯ í’ˆì§ˆ ê´€ë¦¬

### í’ˆì§ˆ ì§€í‘œ

```python
# ì •ê·œí™” ê²°ê³¼ í’ˆì§ˆ í™•ì¸
result = normalizer.normalize_text(text)
validation = result['validation']

print(f"ìœ íš¨ì„±: {validation['is_valid']}")
print(f"í’ˆì§ˆ ì ìˆ˜: {validation['quality_score']:.2f}")
print(f"ì´ìŠˆ: {validation['issues']}")
```

### í’ˆì§ˆ ê¸°ì¤€

- **ì •ê·œí™” ì„±ê³µë¥ **: 70% ì´ìƒ
- **ìš©ì–´ ì¼ê´€ì„±**: 90% ì´ìƒ
- **ì²˜ë¦¬ ì†ë„**: 1,000ê°œ ìš©ì–´/ë¶„ ì´ìƒ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 2GB ì´í•˜

## ğŸ” ê³ ê¸‰ ê¸°ëŠ¥

### 1. ì»¤ìŠ¤í…€ ì •ê·œí™” ê·œì¹™

```python
# ì •ê·œí™” ê·œì¹™ ìˆ˜ì •
normalizer.normalization_rules['term_standardization']['confidence_threshold'] = 0.8
normalizer.normalization_rules['legal_structure']['normalize_article_numbers'] = True
```

### 2. ìš©ì–´ ë¹ˆë„ ì—…ë°ì´íŠ¸

```python
# í…ìŠ¤íŠ¸ì—ì„œ ìš©ì–´ ë¹ˆë„ ìë™ ì—…ë°ì´íŠ¸
normalizer.update_term_frequency("ê³„ì•½ì„œì— ëª…ì‹œëœ ì†í•´ë°°ìƒ ì¡°í•­...")
```

### 3. í†µê³„ ë° ëª¨ë‹ˆí„°ë§

```python
# ì •ê·œí™” í†µê³„ ì¡°íšŒ
stats = normalizer.get_normalization_statistics()
print(f"ì´ ì²˜ë¦¬ ê±´ìˆ˜: {stats['total_processed']}")
print(f"ì„±ê³µë¥ : {stats['success_rate']:.2f}")
print(f"ì‹¤íŒ¨ë¥ : {stats['failure_rate']:.2f}")

# í†µê³„ ì €ì¥
normalizer.save_statistics("data/normalization_stats.json")
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **API ì—°ê²° ì‹¤íŒ¨**
   ```bash
   # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
   echo $LAW_OPEN_API_OC
   
   # API í‚¤ ì¬ì„¤ì •
   export LAW_OPEN_API_OC="your_email@example.com"
   ```

2. **ìš©ì–´ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨**
   ```python
   # ì‚¬ì „ íŒŒì¼ ê²½ë¡œ í™•ì¸
   dictionary = LegalTermDictionary("data/legal_terms/legal_term_dictionary.json")
   
   # ì‚¬ì „ ìœ íš¨ì„± ê²€ì‚¬
   validation = dictionary.validate_dictionary()
   print(f"ìœ íš¨ì„±: {validation['is_valid']}")
   ```

3. **ì •ê·œí™” ì„±ëŠ¥ ì €í•˜**
   ```python
   # ì •ê·œí™” ê¸°ëŠ¥ ë¹„í™œì„±í™”
   processor = LegalDataProcessor(enable_term_normalization=False)
   
   # ë°°ì¹˜ í¬ê¸° ì¡°ì •
   results = normalizer.batch_normalize(texts, batch_size=50)
   ```

### ë¡œê·¸ í™•ì¸

```bash
# ìš©ì–´ ìˆ˜ì§‘ ë¡œê·¸
tail -f logs/legal_term_collection.log

# ì •ê·œí™” ë¡œê·¸
tail -f logs/data_processing.log
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. ë©”ëª¨ë¦¬ ìµœì í™”

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
config = TermCollectionConfig()
config.batch_size = 50  # ê¸°ë³¸ê°’: 100
api_client = LegalTermCollectionAPI(config)
```

### 2. ì²˜ë¦¬ ì†ë„ ê°œì„ 

```python
# ì •ê·œí™” ê·œì¹™ ìµœì í™”
normalizer.normalization_rules['term_standardization']['fallback_to_similar'] = False
normalizer.normalization_rules['legal_structure']['normalize_dates'] = False
```

### 3. ìºì‹± í™œìš©

```python
# ìš©ì–´ ì‚¬ì „ ìºì‹±
dictionary = LegalTermDictionary()
# ì‚¬ì „ì€ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ìºì‹±ë¨
```

## ğŸ”„ ì§€ì†ì  ê°œì„ 

### 1. ìš©ì–´ ì‚¬ì „ ì—…ë°ì´íŠ¸

```python
# ìƒˆë¡œìš´ ìš©ì–´ ì¶”ê°€
new_terms = api_client.collect_legal_terms("ìƒˆë¡œìš´_ì¹´í…Œê³ ë¦¬", max_terms=100)
for term in new_terms:
    dictionary.add_term(term)

# ì‚¬ì „ ì €ì¥
dictionary.save_dictionary()
```

### 2. ë™ì˜ì–´ ê·¸ë£¹ í™•ì¥

```python
# ìƒˆë¡œìš´ ë™ì˜ì–´ ê·¸ë£¹ ì¶”ê°€
dictionary.create_synonym_group(
    'new_group',
    'í‘œì¤€ìš©ì–´',
    ['ë³€í˜•1', 'ë³€í˜•2', 'ë³€í˜•3'],
    0.9
)
```

### 3. í’ˆì§ˆ ëª¨ë‹ˆí„°ë§

```python
# ì •ê¸°ì ì¸ í’ˆì§ˆ ê²€ì‚¬
validation = dictionary.validate_dictionary()
if not validation['is_valid']:
    print(f"ì‚¬ì „ í’ˆì§ˆ ì´ìŠˆ: {validation['issues']}")
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [ë²•ë¥  ìš©ì–´ ì •ê·œí™” ì „ëµ ë¬¸ì„œ](legal_term_normalization_strategy.md)
- [í…ìŠ¤íŠ¸ ì²­í‚¹ ì „ëµ ë¬¸ì„œ](text_chunking_strategy.md)
- [êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° OpenAPI ê°€ì´ë“œ](https://open.law.go.kr/LSO/openApi/guideList.do)

---

*ë³¸ ê°€ì´ë“œëŠ” LawFirmAI í”„ë¡œì íŠ¸ì˜ ë²•ë¥  ìš©ì–´ ì •ê·œí™” ì‹œìŠ¤í…œ ì‚¬ìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ê°œë°œíŒ€ì— ì—°ë½í•´ì£¼ì„¸ìš”.*
