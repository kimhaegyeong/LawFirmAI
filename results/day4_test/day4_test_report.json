{
    "test_info": {
        "test_time": "2025-10-10T13:15:17.741241",
        "test_type": "Day 4 Evaluation and Optimization Test",
        "status": "completed"
    },
    "test_results": {
        "advanced_evaluator": {
            "basic_metrics": {
                "bleu_score": 0.0,
                "rouge_score": 0.0,
                "bleu_std": 0.0,
                "rouge_std": 0.0,
                "total_samples": 2
            },
            "advanced_metrics": {
                "semantic_similarity": 0.0,
                "average_response_length": 5.0,
                "keyword_coverage": 0.0,
                "response_length_std": 0.0
            },
            "legal_specific_metrics": {
                "legal_term_usage": 0.0,
                "legal_concept_accuracy": 0.0,
                "legal_procedure_accuracy": 0.0,
                "legal_relevance_score": 0.020833333333333332
            },
            "human_evaluation_metrics": {
                "coherence": 0.0,
                "fluency": 1.0,
                "informativeness": 0.0,
                "overall_human_score": 0.3333333333333333
            },
            "performance_metrics": {
                "average_inference_time": 0.000412,
                "inference_time_std": 3.0999999999999995e-05,
                "min_inference_time": 0.000381,
                "max_inference_time": 0.000443
            },
            "summary": {
                "comprehensive_score": 0.004166666666666667,
                "grade": "D",
                "individual_scores": {
                    "bleu": 0.0,
                    "rouge": 0.0,
                    "legal_accuracy": 0.0,
                    "legal_relevance": 0.020833333333333332,
                    "coherence": 0.0
                }
            }
        },
        "ab_test_framework": {
            "test_info": {
                "test_name": "test_comparison",
                "test_config": {
                    "test_duration_days": 1,
                    "min_sample_size": 10,
                    "confidence_level": 0.95,
                    "primary_metric": "comprehensive_score",
                    "secondary_metrics": [
                        "bleu_score",
                        "rouge_score",
                        "legal_accuracy"
                    ],
                    "test_start_time": "2025-10-10T13:15:17.724341",
                    "test_end_time": "2025-10-10T13:15:17.728409"
                },
                "test_status": "completed",
                "variants": [
                    {
                        "name": "Model_A",
                        "description": "테스트 모델 A"
                    },
                    {
                        "name": "Model_B",
                        "description": "테스트 모델 B"
                    }
                ]
            },
            "test_results": [
                {
                    "variant_name": "Model_A",
                    "metrics": {
                        "comprehensive_score": 0.758,
                        "bleu_score": 0.658,
                        "rouge_score": 0.7080000000000001,
                        "legal_accuracy": 0.8580000000000001,
                        "legal_relevance": 0.9080000000000001,
                        "coherence": 0.758,
                        "fluency": 0.808,
                        "informativeness": 0.758
                    },
                    "sample_count": 10,
                    "confidence_interval": {
                        "comprehensive_score": [
                            0.609432,
                            0.906568
                        ],
                        "bleu_score": [
                            0.529032,
                            0.7869680000000001
                        ],
                        "rouge_score": [
                            0.5692320000000001,
                            0.8467680000000001
                        ],
                        "legal_accuracy": [
                            0.689832,
                            1.0
                        ],
                        "legal_relevance": [
                            0.7300320000000001,
                            1.0
                        ],
                        "coherence": [
                            0.609432,
                            0.906568
                        ],
                        "fluency": [
                            0.649632,
                            0.9663680000000001
                        ],
                        "informativeness": [
                            0.609432,
                            0.906568
                        ]
                    },
                    "statistical_significance": {
                        "comprehensive_score": true,
                        "bleu_score": true,
                        "rouge_score": true,
                        "legal_accuracy": true,
                        "legal_relevance": true,
                        "coherence": true,
                        "fluency": true,
                        "informativeness": true
                    }
                },
                {
                    "variant_name": "Model_B",
                    "metrics": {
                        "comprehensive_score": 0.705,
                        "bleu_score": 0.605,
                        "rouge_score": 0.655,
                        "legal_accuracy": 0.805,
                        "legal_relevance": 0.8550000000000001,
                        "coherence": 0.705,
                        "fluency": 0.755,
                        "informativeness": 0.705
                    },
                    "sample_count": 10,
                    "confidence_interval": {
                        "comprehensive_score": [
                            0.56682,
                            0.8431799999999999
                        ],
                        "bleu_score": [
                            0.48641999999999996,
                            0.72358
                        ],
                        "rouge_score": [
                            0.5266200000000001,
                            0.78338
                        ],
                        "legal_accuracy": [
                            0.64722,
                            0.9627800000000001
                        ],
                        "legal_relevance": [
                            0.68742,
                            1.0
                        ],
                        "coherence": [
                            0.56682,
                            0.8431799999999999
                        ],
                        "fluency": [
                            0.60702,
                            0.90298
                        ],
                        "informativeness": [
                            0.56682,
                            0.8431799999999999
                        ]
                    },
                    "statistical_significance": {
                        "comprehensive_score": true,
                        "bleu_score": true,
                        "rouge_score": true,
                        "legal_accuracy": true,
                        "legal_relevance": true,
                        "coherence": true,
                        "fluency": true,
                        "informativeness": true
                    }
                }
            ],
            "statistical_analysis": {
                "descriptive_statistics": {
                    "Model_A": {
                        "mean": {
                            "comprehensive_score": 0.758,
                            "bleu_score": 0.658,
                            "rouge_score": 0.7080000000000001,
                            "legal_accuracy": 0.8580000000000001,
                            "legal_relevance": 0.9080000000000001,
                            "coherence": 0.758,
                            "fluency": 0.808,
                            "informativeness": 0.758
                        },
                        "sample_size": 10,
                        "confidence_intervals": {
                            "comprehensive_score": [
                                0.609432,
                                0.906568
                            ],
                            "bleu_score": [
                                0.529032,
                                0.7869680000000001
                            ],
                            "rouge_score": [
                                0.5692320000000001,
                                0.8467680000000001
                            ],
                            "legal_accuracy": [
                                0.689832,
                                1.0
                            ],
                            "legal_relevance": [
                                0.7300320000000001,
                                1.0
                            ],
                            "coherence": [
                                0.609432,
                                0.906568
                            ],
                            "fluency": [
                                0.649632,
                                0.9663680000000001
                            ],
                            "informativeness": [
                                0.609432,
                                0.906568
                            ]
                        }
                    },
                    "Model_B": {
                        "mean": {
                            "comprehensive_score": 0.705,
                            "bleu_score": 0.605,
                            "rouge_score": 0.655,
                            "legal_accuracy": 0.805,
                            "legal_relevance": 0.8550000000000001,
                            "coherence": 0.705,
                            "fluency": 0.755,
                            "informativeness": 0.705
                        },
                        "sample_size": 10,
                        "confidence_intervals": {
                            "comprehensive_score": [
                                0.56682,
                                0.8431799999999999
                            ],
                            "bleu_score": [
                                0.48641999999999996,
                                0.72358
                            ],
                            "rouge_score": [
                                0.5266200000000001,
                                0.78338
                            ],
                            "legal_accuracy": [
                                0.64722,
                                0.9627800000000001
                            ],
                            "legal_relevance": [
                                0.68742,
                                1.0
                            ],
                            "coherence": [
                                0.56682,
                                0.8431799999999999
                            ],
                            "fluency": [
                                0.60702,
                                0.90298
                            ],
                            "informativeness": [
                                0.56682,
                                0.8431799999999999
                            ]
                        }
                    }
                },
                "comparative_analysis": {
                    "primary_metric": "comprehensive_score",
                    "scores": {
                        "Model_A": 0.758,
                        "Model_B": 0.705
                    },
                    "best_variant": "Model_A",
                    "score_difference": 0.05300000000000005
                },
                "effect_sizes": {
                    "cohens_d": 2.0,
                    "interpretation": "Very large effect"
                },
                "power_analysis": {
                    "sample_size_adequacy": true,
                    "recommended_sample_size": 20
                }
            },
            "winner": {
                "variant_name": "Model_A",
                "primary_metric_score": 0.758,
                "statistically_significant": true,
                "confidence_level": 0.95,
                "sample_size": 10,
                "confidence_score": 0.75
            },
            "recommendations": [
                "효과 크기가 큽니다. 승자 변형의 배포를 강력히 권장합니다."
            ]
        },
        "model_optimizer": {
            "status": "simulation_completed"
        }
    },
    "summary": {
        "advanced_evaluator": "✅ Completed",
        "ab_test_framework": "✅ Completed",
        "model_optimizer": "✅ Completed"
    }
}