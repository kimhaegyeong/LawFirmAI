# -*- coding: utf-8 -*-
"""
ê²€ìƒ‰ ê²°ê³¼ê°€ generate_answer_enhancedê¹Œì§€ ì „ë‹¬ë˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
"""

import asyncio
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


async def test_search_results_to_answer():
    """ê²€ìƒ‰ ê²°ê³¼ ì „ë‹¬ í…ŒìŠ¤íŠ¸"""
    try:
        from core.agents.workflow_service import LangGraphWorkflowService
        from infrastructure.utils.langgraph_config import LangGraphConfig

        print("=" * 80)
        print("ê²€ìƒ‰ ê²°ê³¼ ì „ë‹¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 80)

        # ì„¤ì • ë¡œë“œ
        config = LangGraphConfig.from_env()
        print(f"âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ")

        # ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        workflow_service = LangGraphWorkflowService(config)
        print(f"âœ… ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

        # í…ŒìŠ¤íŠ¸ ì§ˆì˜
        test_query = "ê³„ì•½ í•´ì§€ ìš”ê±´"
        print(f"\ní…ŒìŠ¤íŠ¸ ì§ˆì˜: {test_query}")

        # ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        print("ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
        result = await workflow_service.process_query(test_query, "test_session", enable_checkpoint=False)

        # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        retrieved_docs = result.get("retrieved_docs", [])
        metadata = result.get("metadata", {})
        search_meta = metadata.get("search", {}) if isinstance(metadata, dict) else {}

        semantic_count = search_meta.get("semantic_results_count", 0)
        keyword_count = search_meta.get("keyword_results_count", 0)
        final_count = len(retrieved_docs)

        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼:")
        print(f"   ì˜ë¯¸ì  ê²€ìƒ‰: {semantic_count}ê°œ")
        print(f"   í‚¤ì›Œë“œ ê²€ìƒ‰: {keyword_count}ê°œ")
        print(f"   ìµœì¢… í†µí•© ê²°ê³¼: {final_count}ê°œ")

        # ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸
        if final_count > 0:
            print(f"\nğŸ“„ ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ:")
            for i, doc in enumerate(retrieved_docs[:3], 1):
                print(f"   {i}. Type: {doc.get('type', 'unknown')}")
                print(f"      Source: {str(doc.get('source', 'unknown'))[:60]}")
                content = str(doc.get('content', '') or doc.get('text', ''))[:100]
                print(f"      Content: {content}...")
        else:
            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")

        # ë‹µë³€ í™•ì¸
        answer = result.get("answer", "")
        print(f"\nâœï¸ generate_answer_enhanced ê²°ê³¼:")
        print(f"   ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
        print(f"   retrieved_docs ê°œìˆ˜: {len(retrieved_docs)}ê°œ")

        if answer:
            print(f"   ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {answer[:150]}...")

            # ê²€ìƒ‰ ê²°ê³¼ê°€ ë‹µë³€ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if retrieved_docs:
                doc_found = False
                for doc in retrieved_docs[:3]:
                    source = str(doc.get("source", ""))
                    if source and len(source) > 10:
                        # ì†ŒìŠ¤ ì´ë¦„ì˜ ì¼ë¶€ê°€ ë‹µë³€ì— ìˆëŠ”ì§€ í™•ì¸
                        source_words = source.split()[:3]  # ì²˜ìŒ 3ë‹¨ì–´
                        for word in source_words:
                            if word and len(word) > 5 and word in answer:
                                doc_found = True
                                print(f"   âœ… ê²€ìƒ‰ ê²°ê³¼ê°€ ë‹µë³€ì— í¬í•¨ë¨: {word}")
                                break
                        if doc_found:
                            break

                if not doc_found:
                    print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ë‹µë³€ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ")

        # ìµœì¢… ê²€ì¦
        print(f"\nâœ… ìµœì¢… ê²€ì¦:")
        print(f"   - ê²€ìƒ‰ ê²°ê³¼ ìˆìŒ: {'âœ…' if final_count > 0 else 'âŒ'}")
        print(f"   - retrieved_docs ì „ë‹¬ë¨: {'âœ…' if len(retrieved_docs) > 0 else 'âŒ'}")
        print(f"   - ë‹µë³€ ìƒì„±ë¨: {'âœ…' if answer else 'âŒ'}")

        # ê²€ì¦
        assert final_count > 0, f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤! (semantic: {semantic_count}, keyword: {keyword_count})"
        assert len(retrieved_docs) > 0, "retrieved_docsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!"
        assert answer and len(answer) > 0, "ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!"

        print(f"\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼! ê²€ìƒ‰ ê²°ê³¼ê°€ generate_answer_enhancedê¹Œì§€ ì˜ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

        return True

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    result = asyncio.run(test_search_results_to_answer())
    sys.exit(0 if result else 1)


