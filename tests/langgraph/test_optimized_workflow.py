# -*- coding: utf-8 -*-
"""
ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ (Adaptive RAG + ê·¸ë˜í”„ ë‹¨ìˆœí™” + ë³‘ë ¬ ì‹¤í–‰)
"""
import asyncio
import logging
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

from core.agents.workflow_service import LangGraphWorkflowService
from infrastructure.utils.langgraph_config import LangGraphConfig


class WorkflowPerformanceTester:
    """ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ í…ŒìŠ¤í„°"""

    def __init__(self):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        config = LangGraphConfig.from_env()
        self.workflow_service = LangGraphWorkflowService(config)
        self.results = []

    async def test_simple_query(self):
        """ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (Adaptive RAG - ê²€ìƒ‰ ìŠ¤í‚µ)"""
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸ 1: ê°„ë‹¨í•œ ì§ˆë¬¸ (Adaptive RAG - ê²€ìƒ‰ ìŠ¤í‚µ)")
        print("=" * 80)

        test_queries = [
            "ì•ˆë…•í•˜ì„¸ìš”",
            "ê³ ë§ˆì›Œìš”",
            "ê³„ì•½ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë²•ë¥  ìš©ì–´ 'ì†Œì†¡'ì˜ ì˜ë¯¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        ]

        for query in test_queries:
            print(f"\nğŸ“ ì§ˆë¬¸: {query}")
            start_time = time.time()

            try:
                result = await self.workflow_service.process_query(query)
                elapsed_time = time.time() - start_time

                # ê²°ê³¼ ë¶„ì„
                answer = result.get("answer", "")
                sources = result.get("sources", [])
                processing_steps = result.get("processing_steps", [])
                query_complexity = result.get("query_complexity", "unknown")
                needs_search = result.get("needs_search", True)

                print(f"  â±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"  ğŸ“Š ë³µì¡ë„: {query_complexity}")
                print(f"  ğŸ” ê²€ìƒ‰ í•„ìš”: {needs_search}")
                print(f"  ğŸ“„ ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
                print(f"  ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(sources)}ê°œ")
                print(f"  ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜: {len(processing_steps)}ê°œ")

                # ê²€ìƒ‰ ìŠ¤í‚µ í™•ì¸
                if query_complexity == "simple":
                    if needs_search == False:
                        print("  âœ… ê²€ìƒ‰ ìŠ¤í‚µ í™•ì¸ë¨ (Adaptive RAG ì‘ë™)")
                    else:
                        print("  âš ï¸  ê²€ìƒ‰ ìŠ¤í‚µ ì˜ˆìƒë˜ì—ˆìœ¼ë‚˜ ì‹¤í–‰ë¨")
                else:
                    print(f"  âš ï¸  ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë˜ì§€ ì•ŠìŒ (ë³µì¡ë„: {query_complexity})")

                # ë‹µë³€ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                if answer:
                    preview = answer[:100] + "..." if len(answer) > 100 else answer
                    print(f"  ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {preview}")

                self.results.append({
                    "query": query,
                    "type": "simple",
                    "elapsed_time": elapsed_time,
                    "complexity": query_complexity,
                    "needs_search": needs_search,
                    "sources_count": len(sources),
                    "steps_count": len(processing_steps),
                    "answer_length": len(answer)
                })

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.exception(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {query}")

    async def test_complexity_classification(self):
        """ë³µì¡ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸: ë³µì¡ë„ ë¶„ë¥˜ í™•ì¸")
        print("=" * 80)

        test_cases = [
            ("ì•ˆë…•í•˜ì„¸ìš”", "simple"),
            ("ê³„ì•½ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?", "simple"),
            ("ë¯¼ë²• ì œ111ì¡°ì˜ ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”", "moderate"),
        ]

        passed = 0
        failed = 0

        for query, expected_complexity in test_cases:
            print(f"\nğŸ“ ì§ˆë¬¸: {query}")
            print(f"  ì˜ˆìƒ ë³µì¡ë„: {expected_complexity}")

            try:
                result = await self.workflow_service.process_query(query)
                actual_complexity = result.get("query_complexity", "unknown")
                needs_search = result.get("needs_search", True)

                print(f"  ì‹¤ì œ ë³µì¡ë„: {actual_complexity}")
                print(f"  ê²€ìƒ‰ í•„ìš”: {needs_search}")

                if actual_complexity == expected_complexity:
                    print("  âœ… ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ë¨")
                    passed += 1
                else:
                    print(f"  âš ï¸  ë³µì¡ë„ ë¶ˆì¼ì¹˜ (ì˜ˆìƒ: {expected_complexity}, ì‹¤ì œ: {actual_complexity})")
                    failed += 1

                self.results.append({
                    "query": query,
                    "type": "classification",
                    "expected": expected_complexity,
                    "actual": actual_complexity,
                    "passed": actual_complexity == expected_complexity
                })

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.exception(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {query}")
                failed += 1

        print(f"\nğŸ“Š ê²°ê³¼: {passed}ê°œ í†µê³¼, {failed}ê°œ ì‹¤íŒ¨")
        return failed == 0

    async def test_moderate_query(self):
        """ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ê²€ìƒ‰ ìˆ˜í–‰)"""
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸ 2: ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ (ê²€ìƒ‰ ìˆ˜í–‰)")
        print("=" * 80)

        test_queries = [
            "ë¯¼ë²• ì œ111ì¡°ì˜ ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ê³„ì•½ í•´ì§€ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì´í˜¼ ì†Œì†¡ ì ˆì°¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        ]

        for query in test_queries:
            print(f"\nğŸ“ ì§ˆë¬¸: {query}")
            start_time = time.time()

            try:
                result = await self.workflow_service.process_query(query)
                elapsed_time = time.time() - start_time

                # ê²°ê³¼ ë¶„ì„
                answer = result.get("answer", "")
                sources = result.get("sources", [])
                processing_steps = result.get("processing_steps", [])
                query_complexity = result.get("query_complexity", "unknown")
                needs_search = result.get("needs_search", True)
                retrieved_docs = result.get("retrieved_docs", [])

                print(f"  â±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"  ğŸ“Š ë³µì¡ë„: {query_complexity}")
                print(f"  ğŸ” ê²€ìƒ‰ í•„ìš”: {needs_search}")
                print(f"  ğŸ“„ ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
                print(f"  ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(sources)}ê°œ")
                print(f"  ğŸ“– ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}ê°œ")
                print(f"  ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜: {len(processing_steps)}ê°œ")

                # ê²€ìƒ‰ ìˆ˜í–‰ í™•ì¸
                if needs_search == True and len(retrieved_docs) > 0:
                    print("  âœ… ê²€ìƒ‰ ìˆ˜í–‰ í™•ì¸ë¨")
                elif needs_search == True and len(retrieved_docs) == 0:
                    print("  âš ï¸  ê²€ìƒ‰ í•„ìš”í–ˆìœ¼ë‚˜ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨")

                self.results.append({
                    "query": query,
                    "type": "moderate",
                    "elapsed_time": elapsed_time,
                    "complexity": query_complexity,
                    "needs_search": needs_search,
                    "sources_count": len(sources),
                    "retrieved_docs_count": len(retrieved_docs),
                    "steps_count": len(processing_steps),
                    "answer_length": len(answer)
                })

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.exception(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {query}")

    async def test_complex_query(self):
        """ë³µì¡í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ì „ì²´ í”Œë¡œìš°)"""
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸ 3: ë³µì¡í•œ ì§ˆë¬¸ (ì „ì²´ í”Œë¡œìš°)")
        print("=" * 80)

        test_queries = [
            "ì´í˜¼ê³¼ ì¬í˜¼ì˜ ì°¨ì´ì ê³¼ ê°ê°ì˜ ë²•ì  ì ˆì°¨ë¥¼ ë¹„êµí•´ì£¼ì„¸ìš”",
            "ê³„ì•½ í•´ì§€ì™€ í•´ì œì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ìµœê·¼ íŒë¡€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì†í•´ë°°ìƒ ì²­êµ¬ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        ]

        for query in test_queries:
            print(f"\nğŸ“ ì§ˆë¬¸: {query}")
            start_time = time.time()

            try:
                result = await self.workflow_service.process_query(query)
                elapsed_time = time.time() - start_time

                # ê²°ê³¼ ë¶„ì„
                answer = result.get("answer", "")
                sources = result.get("sources", [])
                processing_steps = result.get("processing_steps", [])
                query_complexity = result.get("query_complexity", "unknown")
                needs_search = result.get("needs_search", True)
                retrieved_docs = result.get("retrieved_docs", [])

                print(f"  â±ï¸  ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                print(f"  ğŸ“Š ë³µì¡ë„: {query_complexity}")
                print(f"  ğŸ” ê²€ìƒ‰ í•„ìš”: {needs_search}")
                print(f"  ğŸ“„ ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
                print(f"  ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(sources)}ê°œ")
                print(f"  ğŸ“– ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}ê°œ")
                print(f"  ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜: {len(processing_steps)}ê°œ")

                # ì²˜ë¦¬ ë‹¨ê³„ ìƒì„¸
                if processing_steps:
                    print(f"  ğŸ“‹ ì²˜ë¦¬ ë‹¨ê³„:")
                    for idx, step in enumerate(processing_steps[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ
                        print(f"     {idx}. {step}")

                self.results.append({
                    "query": query,
                    "type": "complex",
                    "elapsed_time": elapsed_time,
                    "complexity": query_complexity,
                    "needs_search": needs_search,
                    "sources_count": len(sources),
                    "retrieved_docs_count": len(retrieved_docs),
                    "steps_count": len(processing_steps),
                    "answer_length": len(answer)
                })

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.exception(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {query}")

    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)

        if not self.results:
            print("âŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìœ í˜•ë³„ í†µê³„
        simple_results = [r for r in self.results if r["type"] == "simple"]
        moderate_results = [r for r in self.results if r["type"] == "moderate"]
        complex_results = [r for r in self.results if r["type"] == "complex"]

        print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
        print(f"  - ì´ í…ŒìŠ¤íŠ¸: {len(self.results)}ê°œ")
        print(f"  - ê°„ë‹¨í•œ ì§ˆë¬¸: {len(simple_results)}ê°œ")
        print(f"  - ì¤‘ê°„ ì§ˆë¬¸: {len(moderate_results)}ê°œ")
        print(f"  - ë³µì¡í•œ ì§ˆë¬¸: {len(complex_results)}ê°œ")

        # ì„±ëŠ¥ í†µê³„
        if simple_results:
            avg_time = sum(r["elapsed_time"] for r in simple_results) / len(simple_results)
            min_time = min(r["elapsed_time"] for r in simple_results)
            max_time = max(r["elapsed_time"] for r in simple_results)
            print(f"\nâš¡ ê°„ë‹¨í•œ ì§ˆë¬¸ ì„±ëŠ¥:")
            print(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"  - ìµœì†Œ ì‹œê°„: {min_time:.2f}ì´ˆ")
            print(f"  - ìµœëŒ€ ì‹œê°„: {max_time:.2f}ì´ˆ")
            search_skipped = sum(1 for r in simple_results if r.get("needs_search") == False)
            print(f"  - ê²€ìƒ‰ ìŠ¤í‚µë¥ : {search_skipped}/{len(simple_results)} ({search_skipped/len(simple_results)*100:.1f}%)")

        if moderate_results:
            avg_time = sum(r["elapsed_time"] for r in moderate_results) / len(moderate_results)
            min_time = min(r["elapsed_time"] for r in moderate_results)
            max_time = max(r["elapsed_time"] for r in moderate_results)
            print(f"\nâš¡ ì¤‘ê°„ ì§ˆë¬¸ ì„±ëŠ¥:")
            print(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"  - ìµœì†Œ ì‹œê°„: {min_time:.2f}ì´ˆ")
            print(f"  - ìµœëŒ€ ì‹œê°„: {max_time:.2f}ì´ˆ")
            avg_docs = sum(r.get("retrieved_docs_count", 0) for r in moderate_results) / len(moderate_results)
            print(f"  - í‰ê·  ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {avg_docs:.1f}ê°œ")

        if complex_results:
            avg_time = sum(r["elapsed_time"] for r in complex_results) / len(complex_results)
            min_time = min(r["elapsed_time"] for r in complex_results)
            max_time = max(r["elapsed_time"] for r in complex_results)
            print(f"\nâš¡ ë³µì¡í•œ ì§ˆë¬¸ ì„±ëŠ¥:")
            print(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"  - ìµœì†Œ ì‹œê°„: {min_time:.2f}ì´ˆ")
            print(f"  - ìµœëŒ€ ì‹œê°„: {max_time:.2f}ì´ˆ")
            avg_docs = sum(r.get("retrieved_docs_count", 0) for r in complex_results) / len(complex_results)
            print(f"  - í‰ê·  ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {avg_docs:.1f}ê°œ")
            avg_steps = sum(r.get("steps_count", 0) for r in complex_results) / len(complex_results)
            print(f"  - í‰ê·  ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜: {avg_steps:.1f}ê°œ")

        # ì „ì²´ í‰ê· 
        if self.results:
            avg_time_all = sum(r["elapsed_time"] for r in self.results if "elapsed_time" in r) / len([r for r in self.results if "elapsed_time" in r])
            print(f"\nğŸ“Š ì „ì²´ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time_all:.2f}ì´ˆ")

        print("\n" + "=" * 80)


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸš€ ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    print("\ní…ŒìŠ¤íŠ¸ í•­ëª©:")
    print("  1. ê°„ë‹¨í•œ ì§ˆë¬¸ (Adaptive RAG - ê²€ìƒ‰ ìŠ¤í‚µ)")
    print("  2. ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ (ê²€ìƒ‰ ìˆ˜í–‰)")
    print("  3. ë³µì¡í•œ ì§ˆë¬¸ (ì „ì²´ í”Œë¡œìš°)")
    print("  4. ë³µì¡ë„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸")
    print("  5. ì„±ëŠ¥ ì¸¡ì • ë° ìš”ì•½")

    tester = WorkflowPerformanceTester()

    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await tester.test_simple_query()
        await tester.test_moderate_query()
        await tester.test_complex_query()
        await tester.test_complexity_classification()

        # ê²°ê³¼ ìš”ì•½
        tester.print_summary()

        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    except KeyboardInterrupt:
        print("\nâš ï¸  í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.exception("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜")


if __name__ == "__main__":
    asyncio.run(main())
