# -*- coding: utf-8 -*-
"""
ë…¸ë“œ í†µí•© í…ŒìŠ¤íŠ¸ (Phase 1-3)
"""
import asyncio
import logging
import sys
import time
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

from core.agents.workflow_service import LangGraphWorkflowService
from infrastructure.utils.langgraph_config import LangGraphConfig


def clear_global_cache():
    """í…ŒìŠ¤íŠ¸ ê²©ë¦¬ë¥¼ ìœ„í•œ global cache ì´ˆê¸°í™”"""
    try:
        from core.agents.node_wrappers import _global_search_results_cache
        if _global_search_results_cache is not None:
            _global_search_results_cache.clear()
    except (ImportError, AttributeError, TypeError):
        pass


async def test_simple_query_integration():
    """ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (í†µí•© ë…¸ë“œ ê²€ì¦)"""
    print("=" * 80)
    print("í…ŒìŠ¤íŠ¸: ê°„ë‹¨í•œ ì§ˆë¬¸ (í†µí•© ë…¸ë“œ ê²€ì¦)")
    print("=" * 80)

    # í…ŒìŠ¤íŠ¸ ê²©ë¦¬ë¥¼ ìœ„í•œ cache ì´ˆê¸°í™”
    clear_global_cache()

    config = LangGraphConfig.from_env()
    workflow_service = LangGraphWorkflowService(config)

    query = "ì•ˆë…•í•˜ì„¸ìš”"
    print(f"\nì§ˆë¬¸: {query}")

    start = time.time()
    result = await workflow_service.process_query(query)
    elapsed = time.time() - start

    print(f"\n[ê²°ê³¼]")
    print(f"  ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"  ë³µì¡ë„: {result.get('query_complexity', 'unknown')}")
    print(f"  ê²€ìƒ‰ í•„ìš”: {result.get('needs_search', True)}")
    print(f"  ë‹µë³€ ê¸¸ì´: {len(result.get('answer', ''))}ì")

    # í†µí•© ë…¸ë“œ ê²€ì¦
    processing_steps = result.get('processing_steps', [])
    # processing_stepsëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ
    step_texts = []
    for step in processing_steps:
        if isinstance(step, dict):
            step_texts.append(step.get('step', '') or str(step))
        elif isinstance(step, str):
            step_texts.append(step)
        else:
            step_texts.append(str(step))

    has_format_and_prepare = any('í¬ë§·íŒ…' in step or 'ìµœì¢… ì¤€ë¹„' in step or 'í¬ë§·íŒ…' in step for step in step_texts)

    success = (
        result.get('query_complexity') == 'simple' and
        result.get('needs_search') == False and
        has_format_and_prepare
    )

    if success:
        print("  âœ… [PASS] í†µí•© ë…¸ë“œ ì •ìƒ ì‘ë™")
    else:
        print(f"  âŒ [FAIL] í†µí•© ë…¸ë“œ ê²€ì¦ ì‹¤íŒ¨")
        print(f"        processing_steps: {step_texts[-5:]}")

    return success


async def test_moderate_query_integration():
    """ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (í†µí•© ë…¸ë“œ ê²€ì¦)"""
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸: ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ (í†µí•© ë…¸ë“œ ê²€ì¦)")
    print("=" * 80)

    # í…ŒìŠ¤íŠ¸ ê²©ë¦¬ë¥¼ ìœ„í•œ cache ì´ˆê¸°í™”
    clear_global_cache()

    config = LangGraphConfig.from_env()
    workflow_service = LangGraphWorkflowService(config)

    query = "ë¯¼ë²• ì œ111ì¡°ì˜ ë‚´ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    print(f"\nì§ˆë¬¸: {query}")

    start = time.time()
    result = await workflow_service.process_query(query)
    elapsed = time.time() - start

    print(f"\n[ê²°ê³¼]")
    print(f"  ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"  ë³µì¡ë„: {result.get('query_complexity', 'unknown')}")
    print(f"  ê²€ìƒ‰ í•„ìš”: {result.get('needs_search', True)}")
    print(f"  ë‹µë³€ ê¸¸ì´: {len(result.get('answer', ''))}ì")

    # í†µí•© ë…¸ë“œ ê²€ì¦
    processing_steps = result.get('processing_steps', [])
    # processing_stepsëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ
    step_texts = []
    for step in processing_steps:
        if isinstance(step, dict):
            step_texts.append(step.get('step', '') or str(step))
        elif isinstance(step, str):
            step_texts.append(step)
        else:
            step_texts.append(str(step))

    has_documents_and_terms = any('ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸' in step or 'ìš©ì–´' in step or 'ë¬¸ì„œ' in step for step in step_texts)
    has_format_and_prepare = any('í¬ë§·íŒ…' in step or 'ìµœì¢… ì¤€ë¹„' in step or 'í¬ë§·íŒ…' in step for step in step_texts)

    success = (
        result.get('query_complexity') == 'moderate' and
        result.get('needs_search') == True and
        has_documents_and_terms and
        has_format_and_prepare
    )

    if success:
        print("  âœ… [PASS] í†µí•© ë…¸ë“œ ì •ìƒ ì‘ë™")
    else:
        print(f"  âŒ [FAIL] í†µí•© ë…¸ë“œ ê²€ì¦ ì‹¤íŒ¨")
        print(f"        has_documents_and_terms: {has_documents_and_terms}")
        print(f"        has_format_and_prepare: {has_format_and_prepare}")

    return success




async def main():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "=" * 80)
    print("ë…¸ë“œ í†µí•© í…ŒìŠ¤íŠ¸ (Phase 1-3)")
    print("=" * 80)

    results = []

    # í…ŒìŠ¤íŠ¸ 1: ê°„ë‹¨í•œ ì§ˆë¬¸
    try:
        result1 = await test_simple_query_integration()
        results.append(("ê°„ë‹¨í•œ ì§ˆë¬¸", result1))
    except Exception as e:
        print(f"  âŒ [ERROR] ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        results.append(("ê°„ë‹¨í•œ ì§ˆë¬¸", False))

    # í…ŒìŠ¤íŠ¸ 2: ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸
    try:
        result2 = await test_moderate_query_integration()
        results.append(("ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸", result2))
    except Exception as e:
        print(f"  âŒ [ERROR] ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        results.append(("ì¤‘ê°„ ë³µì¡ë„ ì§ˆë¬¸", False))


    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {test_name}: {status}")

    print(f"\nì „ì²´: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")

    if passed == total:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        print(f"\nâš ï¸ {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
