# -*- coding: utf-8 -*-
"""
UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸
langgraph ì›Œí¬í”Œë¡œìš°ì—ì„œ UnifiedPromptManager í†µí•© ê²€ì¦
"""

import asyncio
import os
import sys
from pathlib import Path

import pytest

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
os.environ["USE_LANGGRAPH"] = "true"
os.environ["LANGGRAPH_ENABLED"] = "true"

from source.services.langgraph.legal_workflow_enhanced import (
    EnhancedLegalQuestionWorkflow,
)
from source.services.langgraph.state_definitions import create_initial_legal_state
from source.services.question_classifier import QuestionType
from source.services.unified_prompt_manager import (
    LegalDomain,
    ModelType,
    UnifiedPromptManager,
)
from source.utils.langgraph_config import LangGraphConfig


class TestUnifiedPromptIntegration:
    """UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def config(self):
        """LangGraph ì„¤ì • ìƒì„±"""
        return LangGraphConfig.from_env()

    @pytest.fixture
    def workflow(self, config):
        """ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return EnhancedLegalQuestionWorkflow(config)

    @pytest.fixture
    def unified_manager(self):
        """UnifiedPromptManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return UnifiedPromptManager()

    def test_unified_prompt_manager_initialized(self, workflow):
        """UnifiedPromptManagerê°€ ì›Œí¬í”Œë¡œìš°ì— ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        assert hasattr(workflow, 'unified_prompt_manager')
        assert workflow.unified_prompt_manager is not None
        print("âœ… UnifiedPromptManagerê°€ ì›Œí¬í”Œë¡œìš°ì— ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def test_prompt_manager_type(self, workflow):
        """UnifiedPromptManager íƒ€ìž… í™•ì¸"""
        assert isinstance(workflow.unified_prompt_manager, UnifiedPromptManager)
        print("âœ… UnifiedPromptManager íƒ€ìž…ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")

    def test_get_optimized_prompt(self, unified_manager):
        """get_optimized_prompt ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
        query = "ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"

        prompt = unified_manager.get_optimized_prompt(
            query=query,
            question_type=QuestionType.LEGAL_ADVICE,
            domain=LegalDomain.FAMILY_LAW,
            context={"context": "í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸"},
            model_type=ModelType.GEMINI
        )

        assert prompt is not None
        assert isinstance(prompt, str)
        assert len(prompt) > 0
        assert "ì´í˜¼" in query
        print("âœ… get_optimized_promptê°€ ì •ìƒì ìœ¼ë¡œ ìž‘ë™í•©ë‹ˆë‹¤.")
        print(f"   ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ìž")

    def test_prompt_with_different_domains(self, unified_manager):
        """ë‹¤ì–‘í•œ ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            (LegalDomain.CIVIL_LAW, QuestionType.LEGAL_ADVICE, "ê³„ì•½ì„œ ìž‘ì„± ë°©ë²•"),
            (LegalDomain.CRIMINAL_LAW, QuestionType.LEGAL_ADVICE, "ì ˆë„ì£„ì˜ ì²˜ë²Œ"),
            (LegalDomain.FAMILY_LAW, QuestionType.LEGAL_ADVICE, "ì´í˜¼ ì ˆì°¨"),
            (LegalDomain.LABOR_LAW, QuestionType.LEGAL_ADVICE, "í•´ê³  ì œí•œ ì¡°ê±´"),
            (LegalDomain.GENERAL, QuestionType.GENERAL_QUESTION, "ë²•ë¥  ìš©ì–´ í•´ì„¤"),
        ]

        for domain, question_type, query in test_cases:
            prompt = unified_manager.get_optimized_prompt(
                query=query,
                question_type=question_type,
                domain=domain,
                context={},
                model_type=ModelType.GEMINI
            )

            assert prompt is not None
            assert len(prompt) > 0
            print(f"âœ… {domain.value} ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ ({len(prompt)}ìž)")

    def test_prompt_with_different_models(self, unified_manager):
        """ë‹¤ì–‘í•œ ëª¨ë¸ íƒ€ìž…ë³„ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            (ModelType.GEMINI, "Gemini"),
            (ModelType.OLLAMA, "Ollama"),
            (ModelType.OPENAI, "OpenAI"),
        ]

        query = "ë¯¼ë²• ì œ750ì¡°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"

        for model_type, model_name in test_cases:
            prompt = unified_manager.get_optimized_prompt(
                query=query,
                question_type=QuestionType.LAW_INQUIRY,
                domain=LegalDomain.CIVIL_LAW,
                context={},
                model_type=model_type
            )

            assert prompt is not None
            assert len(prompt) > 0
            print(f"âœ… {model_name} ëª¨ë¸ íƒ€ìž… í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ ({len(prompt)}ìž)")

    def test_enhanced_workflow_generate_answer(self, workflow):
        """generate_answer_enhancedì—ì„œ UnifiedPromptManager ì‚¬ìš© í™•ì¸"""
        # ì´ˆê¸° ìƒíƒœ ìƒì„±
        state = create_initial_legal_state("ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", "test-session")
        state["query_type"] = "family_law"
        state["retrieved_docs"] = [
            {"content": "ì´í˜¼ ì ˆì°¨ëŠ” í˜‘ì˜ì´í˜¼ê³¼ ìž¬íŒìƒ ì´í˜¼ì´ ìžˆìŠµë‹ˆë‹¤.", "source": "test"}
        ]

        # generate_answer_enhanced í˜¸ì¶œ
        result = workflow.generate_answer_enhanced(state)

        assert "answer" in result
        assert "processing_steps" in result
        assert "UnifiedPromptManager" in " ".join(result.get("processing_steps", []))
        print("âœ… generate_answer_enhancedê°€ UnifiedPromptManagerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    def test_prompt_optimization_features(self, unified_manager):
        """í”„ë¡¬í”„íŠ¸ ìµœì í™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        query = "ì†í•´ë°°ìƒ ì²­êµ¬ ë°©ë²•"

        # Legal Advice íƒ€ìž…
        advice_prompt = unified_manager.get_optimized_prompt(
            query=query,
            question_type=QuestionType.LEGAL_ADVICE,
            domain=LegalDomain.CIVIL_LAW,
            context={"context": "ë¯¼ë²• ì œ750ì¡° ë¶ˆë²•í–‰ìœ„"},
            model_type=ModelType.GEMINI
        )

        # Procedure Guide íƒ€ìž…
        procedure_prompt = unified_manager.get_optimized_prompt(
            query=query,
            question_type=QuestionType.PROCEDURE_GUIDE,
            domain=LegalDomain.CIVIL_PROCEDURE,
            context={"context": "ë¯¼ì‚¬ì†Œì†¡ë²•"},
            model_type=ModelType.GEMINI
        )

        # ë‘ í”„ë¡¬í”„íŠ¸ê°€ ë‹¤ë¥¸ì§€ í™•ì¸
        assert advice_prompt != procedure_prompt
        assert len(advice_prompt) > 0
        assert len(procedure_prompt) > 0

        print(f"âœ… Legal Advice í”„ë¡¬í”„íŠ¸: {len(advice_prompt)}ìž")
        print(f"âœ… Procedure Guide í”„ë¡¬í”„íŠ¸: {len(procedure_prompt)}ìž")
        print("âœ… í”„ë¡¬í”„íŠ¸ê°€ ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìµœì í™”ë©ë‹ˆë‹¤.")

    def test_prompt_with_context(self, unified_manager):
        """ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
        context = {
            "context": "ë¯¼ë²• ì œ750ì¡°ëŠ” ë¶ˆë²•í–‰ìœ„ë¡œ ì¸í•œ ì†í•´ë°°ìƒì²­êµ¬ê¶Œì„ ê·œì •í•©ë‹ˆë‹¤.",
            "legal_references": ["ë¯¼ë²• ì œ750ì¡°"],
            "query_type": "civil_law"
        }

        prompt = unified_manager.get_optimized_prompt(
            query="ë¶ˆë²•í–‰ìœ„ì˜ ì„±ë¦½ìš”ê±´ì€?",
            question_type=QuestionType.LEGAL_ADVICE,
            domain=LegalDomain.CIVIL_LAW,
            context=context,
            model_type=ModelType.GEMINI
        )

        assert prompt is not None
        assert "ë¯¼ë²• ì œ750ì¡°" in prompt or "ë¶ˆë²•í–‰ìœ„" in prompt.lower()
        print("âœ… ì»¨í…ìŠ¤íŠ¸ê°€ í”„ë¡¬í”„íŠ¸ì— ì •ìƒì ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤.")

    def test_workflow_complete_flow(self, workflow):
        """ì „ì²´ ì›Œí¬í”Œë¡œìš° ì—”ë“œ-to-ì—”ë“œ í…ŒìŠ¤íŠ¸"""
        test_queries = [
            ("ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", "family_law"),
            ("ê³„ì•½ì„œ ìž‘ì„± ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”", "contract_review"),
            ("í•´ê³  ì œí•œ ì¡°ê±´ì€?", "labor_law"),
        ]

        for query, expected_type in test_queries:
            state = create_initial_legal_state(query, f"session-{query[:5]}")
            state["query_type"] = expected_type
            state["retrieved_docs"] = [
                {"content": "ê´€ë ¨ ë²•ë¥  ì •ë³´", "source": "test"}
            ]

            # ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            state = workflow.classify_query(state)
            state = workflow.retrieve_documents(state)
            state = workflow.generate_answer_enhanced(state)
            state = workflow.format_response(state)

            assert "answer" in state
            assert len(state["answer"]) > 0
            assert "processing_steps" in state
            print(f"âœ… '{query}' ì²˜ë¦¬ ì™„ë£Œ")

    def test_error_handling(self, unified_manager):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ìž˜ëª»ëœ íŒŒë¼ë¯¸í„°
        try:
            prompt = unified_manager.get_optimized_prompt(
                query="",
                question_type=QuestionType.GENERAL_QUESTION,
                domain=LegalDomain.GENERAL,
                context={},
                model_type=ModelType.GEMINI
            )
            # ë¹ˆ ì¿¼ë¦¬ëŠ” í´ë°± ì²˜ë¦¬ê°€ ë˜ì–´ì•¼ í•¨
            assert isinstance(prompt, str)
            print("âœ… ë¹ˆ ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ (ì˜ˆìƒ ê°€ëŠ¥): {e}")


def run_integration_tests():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸ ì‹œìž‘")
    print("="*80 + "\n")

    # í…ŒìŠ¤íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    config = LangGraphConfig.from_env()
    workflow = EnhancedLegalQuestionWorkflow(config)
    unified_manager = UnifiedPromptManager()

    test_results = []

    # í…ŒìŠ¤íŠ¸ 1: UnifiedPromptManager ì´ˆê¸°í™” í™•ì¸
    print("ðŸ“‹ í…ŒìŠ¤íŠ¸ 1: UnifiedPromptManager ì´ˆê¸°í™” í™•ì¸")
    try:
        assert hasattr(workflow, 'unified_prompt_manager')
        assert workflow.unified_prompt_manager is not None
        print("   âœ… UnifiedPromptManagerê°€ ì›Œí¬í”Œë¡œìš°ì— ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        test_results.append(True)
    except Exception as e:
        print(f"   âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        test_results.append(False)

    # í…ŒìŠ¤íŠ¸ 2: get_optimized_prompt ê¸°ë³¸ ë™ìž‘
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ 2: get_optimized_prompt ê¸°ë³¸ ë™ìž‘")
    try:
        prompt = unified_manager.get_optimized_prompt(
            query="ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            question_type=QuestionType.LEGAL_ADVICE,
            domain=LegalDomain.FAMILY_LAW,
            context={"context": "í…ŒìŠ¤íŠ¸"},
            model_type=ModelType.GEMINI
        )
        assert prompt and len(prompt) > 0
        print(f"   âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ ({len(prompt)}ìž)")
        test_results.append(True)
    except Exception as e:
        print(f"   âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        test_results.append(False)

    # í…ŒìŠ¤íŠ¸ 3: ë‹¤ì–‘í•œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ 3: ë‹¤ì–‘í•œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸")
    domains = [
        (LegalDomain.CIVIL_LAW, "ë¯¼ì‚¬ë²•"),
        (LegalDomain.CRIMINAL_LAW, "í˜•ì‚¬ë²•"),
        (LegalDomain.FAMILY_LAW, "ê°€ì¡±ë²•"),
        (LegalDomain.LABOR_LAW, "ë…¸ë™ë²•"),
    ]

    for domain, name in domains:
        try:
            prompt = unified_manager.get_optimized_prompt(
                query="í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
                question_type=QuestionType.LEGAL_ADVICE,
                domain=domain,
                context={},
                model_type=ModelType.GEMINI
            )
            assert len(prompt) > 0
            print(f"   âœ… {name}: í”„ë¡¬í”„íŠ¸ ìƒì„± ì„±ê³µ")
            test_results.append(True)
        except Exception as e:
            print(f"   âŒ {name}: í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨ - {e}")
            test_results.append(False)

    # í…ŒìŠ¤íŠ¸ 4: ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ 4: ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    try:
        state = create_initial_legal_state("ì´í˜¼ ì ˆì°¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", "test-session")
        state["query_type"] = "family_law"
        state["retrieved_docs"] = [{"content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ", "source": "test"}]

        result = workflow.generate_answer_enhanced(state)
        assert "answer" in result
        print(f"   âœ… ì›Œí¬í”Œë¡œìš° ì²˜ë¦¬ ì™„ë£Œ (ë‹µë³€ ê¸¸ì´: {len(result.get('answer', ''))})")
        test_results.append(True)
    except Exception as e:
        print(f"   âŒ ì›Œí¬í”Œë¡œìš° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        test_results.append(False)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    passed = sum(test_results)
    total = len(test_results)
    print(f"\nâœ… í†µê³¼: {passed}/{total}")
    print(f"âŒ ì‹¤íŒ¨: {total - passed}/{total}")
    print("="*80 + "\n")

    return all(test_results)


if __name__ == "__main__":
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = run_integration_tests()

    if success:
        print("âœ… ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # pytest í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì„ íƒì )
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--pytest":
        print("\nPytestë¥¼ ì‚¬ìš©í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
        pytest.main([__file__, "-v"])
