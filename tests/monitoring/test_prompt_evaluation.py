"""
í”„ë¡¬í”„íŠ¸ í‰ê°€ ë° ê°œì„  í…ŒìŠ¤íŠ¸
generate_answer_enhancedì—ì„œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ì°¾ìŠµë‹ˆë‹¤.
"""
import os
import sys
import re
from pathlib import Path
from typing import Dict, List, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def evaluate_prompt(prompt_text: str) -> Dict[str, Any]:
    """í”„ë¡¬í”„íŠ¸ë¥¼ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ì°¾ìŠµë‹ˆë‹¤."""
    issues = []
    suggestions = []

    # 1. ì¤‘ë³µ ë¬¸ì„œ ì„¹ì…˜ í™•ì¸
    doc_section_patterns = [
        r"##\s*ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ",
        r"##\s*ì œê³µëœ ë²•ë¥  ë¬¸ì„œ",
        r"##\s*ê²€ìƒ‰ëœ íŒë¡€ ë¬¸ì„œ",
        r"##\s*ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ ë° ì •ë³´",
        r"##\s*ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ ë° íŒë¡€"
    ]

    found_sections = []
    for pattern in doc_section_patterns:
        matches = re.findall(pattern, prompt_text, re.IGNORECASE)
        if matches:
            found_sections.extend(matches)

    if len(found_sections) > 1:
        unique_sections = set(found_sections)
        if len(unique_sections) > 1:
            issues.append({
                "type": "ì¤‘ë³µ ë¬¸ì„œ ì„¹ì…˜",
                "severity": "high",
                "description": f"ë¬¸ì„œ ì„¹ì…˜ì´ {len(unique_sections)}ë²ˆ ë‚˜íƒ€ë‚¨",
                "sections": list(unique_sections)
            })
            suggestions.append("ë¬¸ì„œ ì„¹ì…˜ì„ í•œ ë²ˆë§Œ í¬í•¨í•˜ë„ë¡ ìˆ˜ì • í•„ìš”")

    # 2. ì§€ì¹¨ ë¬¸êµ¬ ì¤‘ë³µ í™•ì¸
    instruction_phrases = [
        "ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”",
        "ë°˜ë“œì‹œ ì´ ë¬¸ì„œë“¤ì„ ì°¸ê³ ",
        "ë°˜ë“œì‹œ í™œìš©",
        "ìµœì†Œ 2ê°œ ì´ìƒ ì¸ìš©",
        "ì ˆëŒ€ ê¸ˆì§€"
    ]

    phrase_counts = {}
    for phrase in instruction_phrases:
        count = len(re.findall(re.escape(phrase), prompt_text, re.IGNORECASE))
        if count > 1:
            phrase_counts[phrase] = count

    if phrase_counts:
        issues.append({
            "type": "ì§€ì¹¨ ë¬¸êµ¬ ì¤‘ë³µ",
            "severity": "medium",
            "description": "ê°™ì€ ì§€ì¹¨ì´ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µë¨",
            "phrases": phrase_counts
        })
        suggestions.append("ì§€ì¹¨ ë¬¸êµ¬ë¥¼ í†µí•©í•˜ì—¬ í•œ ë²ˆë§Œ í‘œì‹œ")

    # 3. ë¬¸ì„œ ëª©ë¡ ì¤‘ë³µ í™•ì¸
    # "ë¬¸ì„œ 1:", "ë¬¸ì„œ 2:" ê°™ì€ íŒ¨í„´ ì°¾ê¸°
    doc_number_pattern = r"ë¬¸ì„œ\s*\d+\s*:"
    doc_numbers = re.findall(doc_number_pattern, prompt_text)

    if len(doc_numbers) > len(set(doc_numbers)):
        issues.append({
            "type": "ë¬¸ì„œ ë²ˆí˜¸ ì¤‘ë³µ",
            "severity": "high",
            "description": "ê°™ì€ ë¬¸ì„œ ë²ˆí˜¸ê°€ ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚¨",
            "count": len(doc_numbers)
        })
        suggestions.append("ë¬¸ì„œ ëª©ë¡ ì¤‘ë³µ ì œê±° í•„ìš”")

    # 4. í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í™•ì¸
    prompt_length = len(prompt_text)
    token_estimate = prompt_length // 3  # ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •

    if prompt_length > 8000:
        issues.append({
            "type": "í”„ë¡¬í”„íŠ¸ ê¸¸ì´",
            "severity": "medium",
            "description": f"í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ ({prompt_length}ì, ì•½ {token_estimate} í† í°)",
            "length": prompt_length,
            "estimated_tokens": token_estimate
        })
        suggestions.append("í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ìµœì í™” í•„ìš” (ì¤‘ë³µ ì œê±°, ë¶ˆí•„ìš”í•œ ì„¹ì…˜ ì œê±°)")

    # 5. ë¬¸ì„œ ì—†ìŒ ë©”ì‹œì§€ ì˜¤ë¥˜ í™•ì¸
    if "í˜„ì¬ ê´€ë ¨ ë²•ë¥  ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" in prompt_text:
        # ë¬¸ì„œ ì„¹ì…˜ì´ ìˆëŠ”ì§€ í™•ì¸
        if "ê²€ìƒ‰ëœ ë²•ë¥  ë¬¸ì„œ" in prompt_text or "## ğŸ”" in prompt_text:
            issues.append({
                "type": "ë¡œì§ ì˜¤ë¥˜",
                "severity": "critical",
                "description": "ë¬¸ì„œê°€ ìˆëŠ”ë°ë„ 'ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤' ë©”ì‹œì§€ê°€ í‘œì‹œë¨"
            })
            suggestions.append("final_instruction_section ë¡œì§ ìˆ˜ì • í•„ìš”")

    # 6. í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­ ì„¹ì…˜ í™•ì¸
    if "## âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­" in prompt_text or "## âš ï¸ í•µì‹¬ ì§€ì¹¨" in prompt_text:
        section_match = re.search(r"##\s*âš ï¸\s*(í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­|í•µì‹¬ ì§€ì¹¨)\s*\n\n(.*?)(?=\n##|\Z)", prompt_text, re.DOTALL)
        if section_match:
            section_content = section_match.group(2).strip()
            if len(section_content) < 50:
                issues.append({
                    "type": "ë¹ˆ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­",
                    "severity": "medium",
                    "description": "í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­ ì„¹ì…˜ì´ ê±°ì˜ ë¹„ì–´ìˆìŒ",
                    "content_length": len(section_content)
                })
                suggestions.append("í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­ ì„¹ì…˜ì— ì ì ˆí•œ ë‚´ìš© ì¶”ê°€ í•„ìš”")

    return {
        "issues": issues,
        "suggestions": suggestions,
        "metrics": {
            "prompt_length": prompt_length,
            "estimated_tokens": token_estimate,
            "document_sections": len(found_sections),
            "total_issues": len(issues),
            "critical_issues": len([i for i in issues if i.get("severity") == "critical"]),
            "high_issues": len([i for i in issues if i.get("severity") == "high"]),
            "medium_issues": len([i for i in issues if i.get("severity") == "medium"])
        }
    }

def find_latest_prompt_file() -> str:
    """ê°€ì¥ ìµœê·¼ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì°¾ê¸°"""
    debug_dir = Path("debug/prompts")
    if not debug_dir.exists():
        return None

    prompt_files = list(debug_dir.glob("prompt_*.txt"))
    if not prompt_files:
        return None

    # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    prompt_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return str(prompt_files[0])

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("í”„ë¡¬í”„íŠ¸ í‰ê°€ ë° ê°œì„  í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # ìµœì‹  í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì°¾ê¸°
    prompt_file = find_latest_prompt_file()

    if not prompt_file or not os.path.exists(prompt_file):
        print("âŒ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € LangGraph í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return

    print(f"\nğŸ“„ í”„ë¡¬í”„íŠ¸ íŒŒì¼: {prompt_file}")

    # í”„ë¡¬í”„íŠ¸ ì½ê¸°
    with open(prompt_file, "r", encoding="utf-8") as f:
        prompt_text = f.read()

    print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt_text):,}ì\n")

    # í”„ë¡¬í”„íŠ¸ í‰ê°€
    evaluation = evaluate_prompt(prompt_text)

    # ê²°ê³¼ ì¶œë ¥
    print("=" * 80)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("=" * 80)

    metrics = evaluation["metrics"]
    print(f"\në©”íŠ¸ë¦­:")
    print(f"  - í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {metrics['prompt_length']:,}ì")
    print(f"  - ì˜ˆìƒ í† í° ìˆ˜: {metrics['estimated_tokens']:,}")
    print(f"  - ë¬¸ì„œ ì„¹ì…˜ ìˆ˜: {metrics['document_sections']}")
    print(f"  - ì´ ì´ìŠˆ ìˆ˜: {metrics['total_issues']}")
    print(f"  - ì‹¬ê° ì´ìŠˆ: {metrics['critical_issues']}")
    print(f"  - ë†’ì€ ìš°ì„ ìˆœìœ„ ì´ìŠˆ: {metrics['high_issues']}")
    print(f"  - ì¤‘ê°„ ìš°ì„ ìˆœìœ„ ì´ìŠˆ: {metrics['medium_issues']}")

    # ì´ìŠˆ ì¶œë ¥
    if evaluation["issues"]:
        print(f"\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ ({len(evaluation['issues'])}ê°œ):")
        for idx, issue in enumerate(evaluation["issues"], 1):
            severity_icon = {
                "critical": "ğŸ”´",
                "high": "ğŸŸ ",
                "medium": "ğŸŸ¡",
                "low": "ğŸ”µ"
            }.get(issue["severity"], "âšª")

            print(f"\n{idx}. {severity_icon} [{issue['severity'].upper()}] {issue['type']}")
            print(f"   ì„¤ëª…: {issue['description']}")
            if "details" in issue:
                print(f"   ìƒì„¸: {issue['details']}")

    # ê°œì„  ì œì•ˆ ì¶œë ¥
    if evaluation["suggestions"]:
        print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ ({len(evaluation['suggestions'])}ê°œ):")
        for idx, suggestion in enumerate(evaluation["suggestions"], 1):
            print(f"  {idx}. {suggestion}")

    if not evaluation["issues"]:
        print("\nâœ… í”„ë¡¬í”„íŠ¸ì— ì‹¬ê°í•œ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤!")

    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
