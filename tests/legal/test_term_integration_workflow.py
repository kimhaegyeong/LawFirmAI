# -*- coding: utf-8 -*-
"""
ìš©ì–´ í†µí•© ê¸°ëŠ¥ í¬í•¨ LangGraph ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
TermIntegrationSystem í†µí•© í›„ ì›Œí¬í”Œë¡œìš° ê²€ì¦
"""

import asyncio
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# lawfirm_langgraph ê²½ë¡œ ì¶”ê°€
lawfirm_langgraph_path = project_root / "lawfirm_langgraph"
sys.path.insert(0, str(lawfirm_langgraph_path))

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
os.environ["USE_LANGGRAPH"] = "true"
os.environ["LANGGRAPH_ENABLED"] = "true"

from langgraph_core.services.workflow_service import LangGraphWorkflowService
from langgraph_core.config.langgraph_config import LangGraphConfig


async def test_term_integration_workflow():
    """ìš©ì–´ í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ìš©ì–´ í†µí•© LangGraph ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")

    try:
        # ì„¤ì • ë¡œë“œ
        config = LangGraphConfig.from_env()
        print("âœ… LangGraph ì„¤ì • ë¡œë“œ ì™„ë£Œ")

        # ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        workflow_service = LangGraphWorkflowService(config)
        print("âœ… LangGraphWorkflowService ì´ˆê¸°í™” ì™„ë£Œ")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ - ë²•ë¥  ìš©ì–´ê°€ ë§ì€ ì§ˆë¬¸ë“¤
        test_queries = [
            {
                "query": "ì´í˜¼ ì ˆì°¨ì™€ ì–‘ìœ¡ê¶Œ ë¶„ìŸì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                "description": "ê°€ì¡±ë²• - ìš©ì–´ í†µí•© í…ŒìŠ¤íŠ¸"
            },
            {
                "query": "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì†í•´ë°°ìƒ ì¡°í•­ê³¼ ìœ„ì•½ê¸ˆ ì¡°í•­ì˜ ì°¨ì´ì ì€?",
                "description": "ë¯¼ì‚¬ë²• - ì¤‘ë³µ ìš©ì–´ ì •ë¦¬ í…ŒìŠ¤íŠ¸"
            },
            {
                "query": "í•´ê³  ì œí•œ ì¡°ê±´ê³¼ ë¶€ë‹¹í•´ê³  ë°©ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "description": "ë…¸ë™ë²• - ìœ ì‚¬ ìš©ì–´ ê·¸ë£¹í™” í…ŒìŠ¤íŠ¸"
            },
        ]

        results = []

        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            description = test_case["description"]

            print(f"\n{'='*80}")
            print(f"í…ŒìŠ¤íŠ¸ {i}: {description}")
            print(f"{'='*80}")
            print(f"ì§ˆë¬¸: {query}\n")

            try:
                # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                result = await workflow_service.process_query(query)

                # ê²°ê³¼ ê²€ì¦
                assert "answer" in result, "ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤"
                assert len(result["answer"]) > 0, "ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
                assert "confidence" in result, "ì‹ ë¢°ë„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"

                # ê²°ê³¼ ì¶œë ¥
                answer_length = len(result["answer"])
                confidence = result.get("confidence", 0.0)
                processing_time = result.get("processing_time", 0.0)
                sources_count = len(result.get("sources", []))

                print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
                print(f"   - ë‹µë³€ ê¸¸ì´: {answer_length}ì")
                print(f"   - ì‹ ë¢°ë„: {confidence:.2f}")
                print(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"   - ì¶œì²˜: {sources_count}ê°œ")

                # ìš©ì–´ í†µí•© ê²°ê³¼ í™•ì¸
                metadata = result.get("metadata", {})
                extracted_terms = metadata.get("extracted_terms", [])
                unique_terms = metadata.get("unique_terms", 0)
                total_terms = metadata.get("total_terms_extracted", 0)

                print(f"\nğŸ“ ìš©ì–´ í†µí•© ê²°ê³¼:")
                print(f"   - ì´ ì¶”ì¶œëœ ìš©ì–´: {total_terms}ê°œ")
                print(f"   - ê³ ìœ  ìš©ì–´ (í†µí•© í›„): {unique_terms}ê°œ")
                print(f"   - ì¤‘ë³µ ì œê±°ìœ¨: {(1 - unique_terms/total_terms)*100:.1f}%" if total_terms > 0 else "   - ì¤‘ë³µ ì œê±°ìœ¨: N/A")

                if extracted_terms:
                    print(f"\n   ğŸ”‘ ì£¼ìš” ë²•ë¥  ìš©ì–´ (ìµœëŒ€ 10ê°œ):")
                    for j, term in enumerate(extracted_terms[:10], 1):
                        print(f"   {j}. {term}")
                    if len(extracted_terms) > 10:
                        print(f"   ... ì™¸ {len(extracted_terms) - 10}ê°œ")

                # ì²˜ë¦¬ ë‹¨ê³„ í™•ì¸
                processing_steps = result.get("processing_steps", [])
                if processing_steps:
                    print(f"\n   ğŸ”„ ì²˜ë¦¬ ë‹¨ê³„:")
                    for step in processing_steps:
                        if "ìš©ì–´" in step:
                            print(f"      âœ… {step}")
                        else:
                            print(f"      â€¢ {step}")

                # ì˜¤ë¥˜ í™•ì¸
                errors = result.get("errors", [])
                if errors:
                    print(f"\n   âš ï¸ ì˜¤ë¥˜ ë°œìƒ:")
                    for error in errors:
                        print(f"      - {error}")

                results.append({
                    "success": True,
                    "description": description,
                    "query": query,
                    "processing_time": processing_time,
                    "confidence": confidence,
                    "extracted_terms_count": unique_terms,
                    "total_terms": total_terms
                })

                print(f"\n   âœ… í…ŒìŠ¤íŠ¸ {i} ì„±ê³µ")

            except Exception as e:
                print(f"\n   âŒ í…ŒìŠ¤íŠ¸ {i} ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                results.append({
                    "success": False,
                    "description": description,
                    "query": query,
                    "error": str(e)
                })

        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*80)
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*80)

        successful_tests = [r for r in results if r["success"]]
        failed_tests = [r for r in results if not r["success"]]

        print(f"\nâœ… ì„±ê³µ: {len(successful_tests)}/{len(results)}")
        print(f"âŒ ì‹¤íŒ¨: {len(failed_tests)}/{len(results)}")

        if successful_tests:
            print(f"\nğŸ“Š ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ í†µê³„:")
            avg_time = sum(r["processing_time"] for r in successful_tests) / len(successful_tests)
            avg_confidence = sum(r["confidence"] for r in successful_tests) / len(successful_tests)
            avg_unique_terms = sum(r["extracted_terms_count"] for r in successful_tests) / len(successful_tests)
            avg_total_terms = sum(r["total_terms"] for r in successful_tests) / len(successful_tests)

            print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
            print(f"   - í‰ê·  ê³ ìœ  ìš©ì–´: {avg_unique_terms:.0f}ê°œ")
            print(f"   - í‰ê·  ì´ ìš©ì–´: {avg_total_terms:.0f}ê°œ")

        if failed_tests:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
            for test in failed_tests:
                print(f"   - {test['description']}: {test.get('error', 'Unknown error')}")

        if all(r["success"] for r in results):
            print("\n" + "="*80)
            print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
            print("="*80 + "\n")
            return True
        else:
            print("\n" + "="*80)
            print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("="*80 + "\n")
            return False

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_single_query_detailed():
    """ë‹¨ì¼ ì¿¼ë¦¬ì— ëŒ€í•œ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ìƒì„¸ ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")

    try:
        config = LangGraphConfig.from_env()
        workflow_service = LangGraphWorkflowService(config)

        query = "ì´í˜¼ ì ˆì°¨ì™€ ì–‘ìœ¡ê¶Œ ë¶„ìŸ, ìƒì† ë¬¸ì œì— ëŒ€í•´ ìƒì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”"

        print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {query}\n")

        result = await workflow_service.process_query(query)

        print("\n" + "="*80)
        print("ì›Œí¬í”Œë¡œìš° ì²˜ë¦¬ ê²°ê³¼")
        print("="*80)
        print(f"\në‹µë³€:\n{result['answer']}\n")

        # ë©”íƒ€ë°ì´í„° ìƒì„¸ ì¶œë ¥
        metadata = result.get("metadata", {})
        print(f"ë©”íƒ€ë°ì´í„°:")
        for key, value in metadata.items():
            if isinstance(value, list) and len(value) > 5:
                print(f"  - {key}: {len(value)}ê°œ í•­ëª©")
            else:
                print(f"  - {key}: {value}")

        print(f"\nì²˜ë¦¬ ë‹¨ê³„:")
        for step in result.get("processing_steps", []):
            print(f"  â€¢ {step}")

        if result.get("errors"):
            print(f"\nì˜¤ë¥˜:")
            for error in result["errors"]:
                print(f"  âš ï¸ {error}")

        return True

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_tests():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ìš©ì–´ í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*80)

    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result1 = asyncio.run(test_term_integration_workflow())
    result2 = asyncio.run(test_single_query_detailed())

    success = result1 and result2

    print("\n" + "="*80)
    if success:
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    print("="*80 + "\n")

    return success


if __name__ == "__main__":
    success = run_tests()
    exit(0 if success else 1)
