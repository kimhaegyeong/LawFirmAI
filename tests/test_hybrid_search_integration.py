# -*- coding: utf-8 -*-
"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸
SemanticSearchEngine + LangGraph ì›Œí¬í”Œë¡œìš° í†µí•© ê²€ì¦
"""

import asyncio
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
os.environ["USE_LANGGRAPH"] = "true"
os.environ["LANGGRAPH_ENABLED"] = "true"

from source.services.langgraph.workflow_service import LangGraphWorkflowService
from source.utils.langgraph_config import LangGraphConfig


async def test_hybrid_search_integration():
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ LangGraph ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")

    try:
        # ì„¤ì • ë¡œë“œ
        config = LangGraphConfig.from_env()
        print("âœ… LangGraph ì„¤ì • ë¡œë“œ ì™„ë£Œ")

        # ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        workflow_service = LangGraphWorkflowService(config)
        print("âœ… LangGraphWorkflowService ì´ˆê¸°í™” ì™„ë£Œ")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ - ë‹¤ì–‘í•œ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤
        test_queries = [
            {
                "query": "ì´í˜¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ì§„í–‰í•˜ë‚˜ìš”?",
                "description": "ê°€ì¡±ë²• - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸",
                "expected_sources": ["family_law", "civil_law"]
            },
            {
                "query": "ê³„ì•½ì„œì—ì„œ ì†í•´ë°°ìƒ ì¡°í•­ì€ ì–´ë–»ê²Œ ì‘ì„±í•´ì•¼ í•˜ë‚˜ìš”?",
                "description": "ë¯¼ì‚¬ë²• - ì˜ë¯¸ì  ê²€ìƒ‰ ê°•ì  í…ŒìŠ¤íŠ¸",
                "expected_sources": ["contract_review", "civil_law"]
            },
            {
                "query": "ë¶€ë‹¹í•´ê³ ì˜ êµ¬ì œ ì ˆì°¨ëŠ”?",
                "description": "ë…¸ë™ë²• - í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸",
                "expected_sources": ["labor_law"]
            },
            {
                "query": "íŠ¹í—ˆê¶Œ ì¹¨í•´ ì‹œ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ë‚˜ìš”?",
                "description": "ì§€ì ì¬ì‚°ê¶Œë²• - í˜¼í•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸",
                "expected_sources": ["intellectual_property"]
            }
        ]

        results = []

        for i, test_case in enumerate(test_queries, 1):
            print(f"\n{'='*80}")
            print(f"í…ŒìŠ¤íŠ¸ {i}/{len(test_queries)}: {test_case['description']}")
            print(f"ì§ˆë¬¸: {test_case['query']}")
            print(f"{'='*80}\n")

            try:
                # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                result = await workflow_service.process_query(
                    query=test_case['query'],
                    enable_checkpoint=False
                )

                # ê²°ê³¼ ë¶„ì„
                print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {result.get('answer', '')[:100]}...")

                # ê²€ìƒ‰ ë©”íƒ€ë°ì´í„° í™•ì¸
                metadata = result.get('metadata', {})
                search_metadata = result.get('search_metadata', {})

                print(f"\nğŸ“Š ê²€ìƒ‰ ë©”íƒ€ë°ì´í„°:")
                print(f"  - ì˜ë¯¸ì  ê²€ìƒ‰ ê²°ê³¼: {search_metadata.get('semantic_results_count', 0)}ê°œ")
                print(f"  - í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼: {search_metadata.get('keyword_results_count', 0)}ê°œ")
                print(f"  - ìµœì¢… ë¬¸ì„œ ìˆ˜: {search_metadata.get('final_count', 0)}ê°œ")
                print(f"  - ê²€ìƒ‰ ëª¨ë“œ: {search_metadata.get('search_mode', 'N/A')}")
                print(f"  - ê²€ìƒ‰ ì‹œê°„: {search_metadata.get('search_time', 0):.3f}ì´ˆ")

                # ì²˜ë¦¬ ë‹¨ê³„ í™•ì¸
                steps = result.get('processing_steps', [])
                print(f"\nğŸ” ì²˜ë¦¬ ë‹¨ê³„:")
                for step in steps:
                    if 'ê²€ìƒ‰' in step or 'í•˜ì´ë¸Œë¦¬ë“œ' in step:
                        print(f"  â€¢ {step}")

                # ì†ŒìŠ¤ í™•ì¸
                sources = result.get('sources', [])
                print(f"\nğŸ“š ê²€ìƒ‰ëœ ì†ŒìŠ¤ ({len(sources)}ê°œ):")
                for j, source in enumerate(sources[:5], 1):
                    print(f"  {j}. {source}")

                results.append({
                    'test_case': test_case,
                    'success': True,
                    'result': result,
                    'search_metadata': search_metadata
                })

            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
                results.append({
                    'test_case': test_case,
                    'success': False,
                    'error': str(e)
                })

        # ì¢…í•© ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*80}")
        print("ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print(f"{'='*80}\n")

        success_count = sum(1 for r in results if r.get('success'))
        total_count = len(results)

        print(f"âœ… ì„±ê³µ: {success_count}/{total_count}")
        print(f"âŒ ì‹¤íŒ¨: {total_count - success_count}/{total_count}\n")

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¶„ì„
        hybrid_search_used = sum(1 for r in results
                                 if r.get('success') and
                                 r.get('search_metadata', {}).get('search_mode') == 'hybrid')

        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë“œ ì‚¬ìš©: {hybrid_search_used}/{success_count}íšŒ")

        # ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„
        if success_count > 0:
            avg_semantic = sum(r.get('search_metadata', {}).get('semantic_results_count', 0)
                              for r in results if r.get('success')) / success_count
            avg_keyword = sum(r.get('search_metadata', {}).get('keyword_results_count', 0)
                             for r in results if r.get('success')) / success_count
            avg_final = sum(r.get('search_metadata', {}).get('final_count', 0)
                           for r in results if r.get('success')) / success_count

            print(f"\nğŸ“ˆ í‰ê·  ê²€ìƒ‰ ì„±ëŠ¥:")
            print(f"  - ì˜ë¯¸ì  ê²€ìƒ‰ ê²°ê³¼: {avg_semantic:.1f}ê°œ")
            print(f"  - í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼: {avg_keyword:.1f}ê°œ")
            print(f"  - ìµœì¢… ì„ íƒ ë¬¸ì„œ: {avg_final:.1f}ê°œ")

        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*80}")
        print("ìƒì„¸ ê²°ê³¼")
        print(f"{'='*80}\n")

        for i, result in enumerate(results, 1):
            if result.get('success'):
                test_case = result['test_case']
                metadata = result['search_metadata']
                print(f"\n{i}. {test_case['description']}")
                print(f"   ê²€ìƒ‰: ì˜ë¯¸ì  {metadata.get('semantic_results_count', 0)}ê°œ + "
                      f"í‚¤ì›Œë“œ {metadata.get('keyword_results_count', 0)}ê°œ â†’ "
                      f"ìµœì¢… {metadata.get('final_count', 0)}ê°œ")
            else:
                print(f"\n{i}. âŒ ì‹¤íŒ¨: {result['test_case']['description']}")
                print(f"   ì˜¤ë¥˜: {result.get('error', 'Unknown error')}")

        print(f"\n{'='*80}")
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print(f"{'='*80}\n")

        return results

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


async def test_semantic_search_only():
    """ì˜ë¯¸ì  ê²€ìƒ‰ ì—”ì§„ ë‹¨ë… í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("SemanticSearchEngine ë‹¨ë… í…ŒìŠ¤íŠ¸")
    print("="*80 + "\n")

    try:
        from source.services.semantic_search_engine import SemanticSearchEngine

        # SemanticSearchEngine ì´ˆê¸°í™”
        print("SemanticSearchEngine ì´ˆê¸°í™” ì¤‘...")
        search_engine = SemanticSearchEngine()
        print("âœ… SemanticSearchEngine ì´ˆê¸°í™” ì™„ë£Œ")

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "ì´í˜¼ ì ˆì°¨",
            "ê³„ì•½ì„œ ì†í•´ë°°ìƒ",
            "ë¶€ë‹¹í•´ê³  êµ¬ì œ",
            "íŠ¹í—ˆê¶Œ ì¹¨í•´"
        ]

        for query in test_queries:
            print(f"\nê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            print("-" * 80)

            results = search_engine.search(query, k=5)

            if results:
                print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ\n")
                for i, result in enumerate(results[:3], 1):
                    print(f"{i}. [Score: {result.get('score', 0):.3f}]")
                    print(f"   í…ìŠ¤íŠ¸: {result.get('text', '')[:100]}...")
                    print(f"   ì†ŒìŠ¤: {result.get('source', 'Unknown')}")
                    print()
            else:
                print("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n")

        print("âœ… SemanticSearchEngine ë‹¨ë… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ SemanticSearchEngine í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n")

    # 1. SemanticSearchEngine ë‹¨ë… í…ŒìŠ¤íŠ¸
    asyncio.run(test_semantic_search_only())

    # 2. ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸
    asyncio.run(test_hybrid_search_integration())
