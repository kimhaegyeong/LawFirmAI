# -*- coding: utf-8 -*-
"""
LawFirmAI ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
ì‘ë‹µ ì‹œê°„, ì²˜ë¦¬ëŸ‰, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¸¡ì •
"""

import unittest
import time
import tempfile
import os
import sys
import psutil
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import statistics

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from source.services.chat_service import ChatService
from source.services.integrated_session_manager import IntegratedSessionManager
from source.services.multi_turn_handler import MultiTurnQuestionHandler
from source.services.context_compressor import ContextCompressor
from source.services.user_profile_manager import UserProfileManager
from source.services.emotion_intent_analyzer import EmotionIntentAnalyzer
from source.services.conversation_flow_tracker import ConversationFlowTracker
from source.services.contextual_memory_manager import ContextualMemoryManager
from source.services.conversation_quality_monitor import ConversationQualityMonitor
from source.utils.performance_optimizer import PerformanceMonitor, MemoryOptimizer, CacheManager


class TestPerformanceBenchmark(unittest.TestCase):
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.temp_dir = tempfile.mkdtemp()
        self.db_path = os.path.join(self.temp_dir, "test_benchmark.db")
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.session_manager = IntegratedSessionManager(self.db_path)
        self.multi_turn_handler = MultiTurnQuestionHandler()
        self.context_compressor = ContextCompressor(max_tokens=1000)
        self.user_profile_manager = UserProfileManager(self.session_manager.conversation_store)
        self.emotion_analyzer = EmotionIntentAnalyzer()
        self.flow_tracker = ConversationFlowTracker()
        self.memory_manager = ContextualMemoryManager(self.session_manager.conversation_store)
        self.quality_monitor = ConversationQualityMonitor(self.session_manager.conversation_store)
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸
        self.performance_monitor = PerformanceMonitor()
        self.memory_optimizer = MemoryOptimizer()
        self.cache_manager = CacheManager(max_size=1000, ttl=3600)
        
        # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°
        self.benchmark_queries = [
            "ì†í•´ë°°ìƒì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ê³„ì•½ í•´ì§€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë¯¼ë²• ì œ750ì¡°ì˜ ìš”ê±´ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ë¶ˆë²•í–‰ìœ„ì˜ ì„±ë¦½ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê³¼ì‹¤ë¹„ìœ¨ì€ ì–´ë–»ê²Œ ì‚°ì •ë˜ë‚˜ìš”?"
        ]
        
    def tearDown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_response_time_benchmark(self):
        """ì‘ë‹µ ì‹œê°„ ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== ì‘ë‹µ ì‹œê°„ ë²¤ì¹˜ë§ˆí¬ ===")
        
        response_times = []
        
        for i, query in enumerate(self.benchmark_queries):
            # ê° ì¿¼ë¦¬ë³„ ì‘ë‹µ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            
            # Phase 1: ëŒ€í™” ë§¥ë½ ì²˜ë¦¬
            context = self.session_manager.add_turn(
                f"benchmark_session_{i}",
                query,
                f"ë²¤ì¹˜ë§ˆí¬ ì‘ë‹µ {i}",
                "legal_advice",
                f"benchmark_user_{i}"
            )
            
            # Phase 2: ê°ì • ë¶„ì„
            emotion_result = self.emotion_analyzer.analyze_emotion(query)
            
            # Phase 3: ë©”ëª¨ë¦¬ ì €ì¥
            facts = {"legal_knowledge": [f"ë²¤ì¹˜ë§ˆí¬ ì‚¬ì‹¤ {i}"]}
            self.memory_manager.store_important_facts(
                f"benchmark_session_{i}", f"benchmark_user_{i}", facts
            )
            
            end_time = time.time()
            response_time = end_time - start_time
            response_times.append(response_time)
            
            print(f"ì¿¼ë¦¬ {i+1}: {response_time:.3f}ì´ˆ")
        
        # í†µê³„ ê³„ì‚°
        avg_response_time = statistics.mean(response_times)
        median_response_time = statistics.median(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)
        std_response_time = statistics.stdev(response_times) if len(response_times) > 1 else 0
        
        print(f"\nì‘ë‹µ ì‹œê°„ í†µê³„:")
        print(f"  í‰ê· : {avg_response_time:.3f}ì´ˆ")
        print(f"  ì¤‘ê°„ê°’: {median_response_time:.3f}ì´ˆ")
        print(f"  ìµœì†Œ: {min_response_time:.3f}ì´ˆ")
        print(f"  ìµœëŒ€: {max_response_time:.3f}ì´ˆ")
        print(f"  í‘œì¤€í¸ì°¨: {std_response_time:.3f}ì´ˆ")
        
        # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
        self.assertLess(avg_response_time, 2.0)  # í‰ê·  2ì´ˆ ì´ë‚´
        self.assertLess(max_response_time, 5.0)  # ìµœëŒ€ 5ì´ˆ ì´ë‚´
        
        print("âœ… ì‘ë‹µ ì‹œê°„ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def test_throughput_benchmark(self):
        """ì²˜ë¦¬ëŸ‰ ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== ì²˜ë¦¬ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ===")
        
        # ë‹¤ì–‘í•œ ë¶€í•˜ ìˆ˜ì¤€ì—ì„œ ì²˜ë¦¬ëŸ‰ ì¸¡ì •
        load_levels = [10, 50, 100, 200]
        throughput_results = []
        
        for load in load_levels:
            print(f"\në¶€í•˜ ìˆ˜ì¤€: {load}ê°œ ìš”ì²­")
            
            start_time = time.time()
            successful_requests = 0
            
            for i in range(load):
                try:
                    # ìš”ì²­ ì²˜ë¦¬
                    context = self.session_manager.add_turn(
                        f"throughput_session_{load}_{i}",
                        f"ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}",
                        f"ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ ì‘ë‹µ {i}",
                        "test",
                        f"throughput_user_{i % 10}"
                    )
                    
                    # ë©”ëª¨ë¦¬ ì €ì¥
                    facts = {"test_data": [f"ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° {i}"]}
                    self.memory_manager.store_important_facts(
                        f"throughput_session_{load}_{i}", f"throughput_user_{i % 10}", facts
                    )
                    
                    successful_requests += 1
                    
                except Exception as e:
                    print(f"  ìš”ì²­ {i} ì‹¤íŒ¨: {e}")
            
            end_time = time.time()
            total_time = end_time - start_time
            throughput = successful_requests / total_time if total_time > 0 else 0
            
            throughput_results.append({
                "load": load,
                "successful_requests": successful_requests,
                "total_time": total_time,
                "throughput": throughput
            })
            
            print(f"  ì„±ê³µí•œ ìš”ì²­: {successful_requests}/{load}")
            print(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"  ì²˜ë¦¬ëŸ‰: {throughput:.1f}ìš”ì²­/ì´ˆ")
        
        # ì²˜ë¦¬ëŸ‰ ë¶„ì„
        print(f"\nì²˜ë¦¬ëŸ‰ ë¶„ì„:")
        for result in throughput_results:
            print(f"  ë¶€í•˜ {result['load']}: {result['throughput']:.1f}ìš”ì²­/ì´ˆ")
        
        # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
        max_throughput = max(r["throughput"] for r in throughput_results)
        self.assertGreater(max_throughput, 10)  # ìµœì†Œ 10ìš”ì²­/ì´ˆ
        
        print("âœ… ì²˜ë¦¬ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def test_memory_usage_benchmark(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ===")
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        initial_memory_obj = self.memory_optimizer.get_memory_usage()
        initial_memory = initial_memory_obj.process_memory / 1024 / 1024  # MBë¡œ ë³€í™˜
        print(f"ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory:.1f} MB")
        
        memory_usage_history = [initial_memory]
        
        # ë‹¨ê³„ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        stages = [
            ("ì„¸ì…˜ ê´€ë¦¬ì ì´ˆê¸°í™”", lambda: None),
            ("100ê°œ ì„¸ì…˜ ìƒì„±", self._create_100_sessions),
            ("1000ê°œ ë©”ëª¨ë¦¬ ì €ì¥", self._store_1000_memories),
            ("ìºì‹œ 500ê°œ í•­ëª©", self._cache_500_items),
            ("ë©”ëª¨ë¦¬ ìµœì í™”", self._optimize_memory)
        ]
        
        for stage_name, stage_func in stages:
            print(f"\n{stage_name}...")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
            memory_before_obj = self.memory_optimizer.get_memory_usage()
            memory_before = memory_before_obj.process_memory / 1024 / 1024  # MBë¡œ ë³€í™˜
            
            # ì‘ì—… ì‹¤í–‰
            stage_func()
            
            memory_after_obj = self.memory_optimizer.get_memory_usage()
            memory_after = memory_after_obj.process_memory / 1024 / 1024  # MBë¡œ ë³€í™˜
            memory_increase = memory_after - memory_before
            
            memory_usage_history.append(memory_after)
            
            print(f"  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_after:.1f} MB")
            print(f"  ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰: {memory_increase:.1f} MB")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
        peak_memory = max(memory_usage_history)
        final_memory = memory_usage_history[-1]
        total_memory_increase = final_memory - initial_memory
        
        print(f"\në©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„:")
        print(f"  ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.1f} MB")
        print(f"  ìµœëŒ€ ë©”ëª¨ë¦¬: {peak_memory:.1f} MB")
        print(f"  ìµœì¢… ë©”ëª¨ë¦¬: {final_memory:.1f} MB")
        print(f"  ì´ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰: {total_memory_increase:.1f} MB")
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê²€ì¦
        self.assertLess(total_memory_increase, 200)  # 200MB ì´í•˜ ì¦ê°€
        self.assertLess(peak_memory, 1000)  # 1000MB ì´í•˜ ìµœëŒ€ ì‚¬ìš©ëŸ‰
        
        print("âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def test_cpu_usage_benchmark(self):
        """CPU ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== CPU ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ===")
        
        # CPU ì§‘ì•½ì  ì‘ì—…ë“¤
        cpu_intensive_tasks = [
            ("ë‹¤ì¤‘ í„´ ì²˜ë¦¬", self._cpu_intensive_multi_turn),
            ("ì»¨í…ìŠ¤íŠ¸ ì••ì¶•", self._cpu_intensive_compression),
            ("ê°ì • ë¶„ì„", self._cpu_intensive_emotion_analysis),
            ("ë©”ëª¨ë¦¬ ê²€ìƒ‰", self._cpu_intensive_memory_search)
        ]
        
        cpu_usage_results = []
        
        for task_name, task_func in cpu_intensive_tasks:
            print(f"\n{task_name} í…ŒìŠ¤íŠ¸...")
            
            # CPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì‹œì‘
            cpu_monitor = threading.Thread(target=self._monitor_cpu_usage)
            cpu_monitor.daemon = True
            cpu_monitor.start()
            
            # ì‘ì—… ì‹¤í–‰
            start_time = time.time()
            task_func()
            end_time = time.time()
            
            # CPU ì‚¬ìš©ëŸ‰ ì¸¡ì •
            cpu_usage = psutil.cpu_percent(interval=1)
            processing_time = end_time - start_time
            
            cpu_usage_results.append({
                "task": task_name,
                "cpu_usage": cpu_usage,
                "processing_time": processing_time
            })
            
            print(f"  CPU ì‚¬ìš©ë¥ : {cpu_usage:.1f}%")
            print(f"  ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
        
        # CPU ì‚¬ìš©ëŸ‰ ë¶„ì„
        avg_cpu_usage = statistics.mean([r["cpu_usage"] for r in cpu_usage_results])
        max_cpu_usage = max([r["cpu_usage"] for r in cpu_usage_results])
        
        print(f"\nCPU ì‚¬ìš©ëŸ‰ ë¶„ì„:")
        print(f"  í‰ê·  CPU ì‚¬ìš©ë¥ : {avg_cpu_usage:.1f}%")
        print(f"  ìµœëŒ€ CPU ì‚¬ìš©ë¥ : {max_cpu_usage:.1f}%")
        
        # CPU íš¨ìœ¨ì„± ê²€ì¦
        self.assertLess(avg_cpu_usage, 80)  # í‰ê·  80% ì´í•˜
        self.assertLess(max_cpu_usage, 95)  # ìµœëŒ€ 95% ì´í•˜
        
        print("âœ… CPU ì‚¬ìš©ëŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def test_scalability_benchmark(self):
        """í™•ì¥ì„± ë²¤ì¹˜ë§ˆí¬"""
        print("\n=== í™•ì¥ì„± ë²¤ì¹˜ë§ˆí¬ ===")
        
        # ë‹¤ì–‘í•œ ê·œëª¨ì—ì„œ ì„±ëŠ¥ ì¸¡ì •
        scales = [1, 5, 10, 20, 50]
        scalability_results = []
        
        for scale in scales:
            print(f"\nê·œëª¨ {scale} í…ŒìŠ¤íŠ¸...")
            
            start_time = time.time()
            
            # ê·œëª¨ì— ë”°ë¥¸ ì‘ì—… ìˆ˜í–‰
            for i in range(scale):
                # ì„¸ì…˜ ìƒì„±
                context = self.session_manager.add_turn(
                    f"scale_session_{scale}_{i}",
                    f"í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}",
                    f"í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì‘ë‹µ {i}",
                    "test",
                    f"scale_user_{i % 10}"
                )
                
                # ë©”ëª¨ë¦¬ ì €ì¥
                facts = {"scale_data": [f"í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„° {i}"]}
                self.memory_manager.store_important_facts(
                    f"scale_session_{scale}_{i}", f"scale_user_{i % 10}", facts
                )
                
                # ìºì‹œ ì €ì¥
                self.cache_manager.set(f"scale_cache_{scale}_{i}", {
                    "data": f"í™•ì¥ì„± ìºì‹œ ë°ì´í„° {i}",
                    "timestamp": datetime.now().isoformat()
                })
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
            throughput = scale / processing_time if processing_time > 0 else 0
            avg_time_per_item = processing_time / scale if scale > 0 else 0
            
            scalability_results.append({
                "scale": scale,
                "processing_time": processing_time,
                "throughput": throughput,
                "avg_time_per_item": avg_time_per_item
            })
            
            print(f"  ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
            print(f"  ì²˜ë¦¬ëŸ‰: {throughput:.1f}í•­ëª©/ì´ˆ")
            print(f"  í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: {avg_time_per_item:.3f}ì´ˆ")
        
        # í™•ì¥ì„± ë¶„ì„
        print(f"\ní™•ì¥ì„± ë¶„ì„:")
        for result in scalability_results:
            print(f"  ê·œëª¨ {result['scale']}: {result['throughput']:.1f}í•­ëª©/ì´ˆ")
        
        # í™•ì¥ì„± ê²€ì¦ (ì²˜ë¦¬ëŸ‰ì´ ê·œëª¨ì— ë¹„ë¡€í•´ì„œ ì¦ê°€í•˜ëŠ”ì§€)
        throughputs = [r["throughput"] for r in scalability_results]
        if len(throughputs) > 1:
            # ì²˜ë¦¬ëŸ‰ì´ ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸
            self.assertGreaterEqual(throughputs[-1], throughputs[0] * 0.5)  # ìµœì†Œ 50% ìœ ì§€
        
        print("âœ… í™•ì¥ì„± ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def _create_100_sessions(self):
        """100ê°œ ì„¸ì…˜ ìƒì„±"""
        for i in range(100):
            self.session_manager.add_turn(
                f"memory_test_session_{i}",
                f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}",
                f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì‘ë‹µ {i}",
                "test",
                f"memory_test_user_{i % 20}"
            )
    
    def _store_1000_memories(self):
        """1000ê°œ ë©”ëª¨ë¦¬ ì €ì¥"""
        for i in range(1000):
            facts = {"memory_test": [f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° {i}"]}
            self.memory_manager.store_important_facts(
                f"memory_test_session_{i % 100}", f"memory_test_user_{i % 20}", facts
            )
    
    def _cache_500_items(self):
        """500ê°œ ìºì‹œ í•­ëª© ì €ì¥"""
        for i in range(500):
            self.cache_manager.set(f"cache_test_{i}", {
                "data": f"ìºì‹œ í…ŒìŠ¤íŠ¸ ë°ì´í„° {i}",
                "timestamp": datetime.now().isoformat()
            })
    
    def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        self.memory_optimizer.optimize_memory()
    
    def _cpu_intensive_multi_turn(self):
        """CPU ì§‘ì•½ì  ë‹¤ì¤‘ í„´ ì²˜ë¦¬"""
        for i in range(50):
            context = self.session_manager.add_turn(
                f"cpu_test_session_{i}",
                f"CPU í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}",
                f"CPU í…ŒìŠ¤íŠ¸ ì‘ë‹µ {i}",
                "test",
                f"cpu_test_user_{i % 10}"
            )
            self.multi_turn_handler.build_complete_query(f"í›„ì† ì§ˆë¬¸ {i}", context)
    
    def _cpu_intensive_compression(self):
        """CPU ì§‘ì•½ì  ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
        # ê¸´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        long_context = self.session_manager.add_turn(
            "cpu_compression_session",
            "ê¸´ ì§ˆë¬¸ " + "x" * 1000,
            "ê¸´ ì‘ë‹µ " + "y" * 1000,
            "test",
            "cpu_compression_user"
        )
        
        for i in range(20):
            self.context_compressor.compress_long_conversation(long_context)
    
    def _cpu_intensive_emotion_analysis(self):
        """CPU ì§‘ì•½ì  ê°ì • ë¶„ì„"""
        test_queries = [f"ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i} " + "ê°ì •" * 10 for i in range(100)]
        
        for query in test_queries:
            self.emotion_analyzer.analyze_emotion(query)
    
    def _cpu_intensive_memory_search(self):
        """CPU ì§‘ì•½ì  ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        for i in range(100):
            self.memory_manager.retrieve_relevant_memory(
                f"cpu_search_session_{i % 10}", f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}", f"cpu_search_user_{i % 5}"
            )
    
    def _monitor_cpu_usage(self):
        """CPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        while True:
            cpu_usage = psutil.cpu_percent(interval=0.1)
            if cpu_usage > 90:
                print(f"  ë†’ì€ CPU ì‚¬ìš©ë¥  ê°ì§€: {cpu_usage:.1f}%")
            time.sleep(0.5)


def run_performance_benchmark():
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("=" * 60)
    print("LawFirmAI ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±
    test_suite = unittest.TestSuite()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestPerformanceBenchmark))
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì‹¤í–‰ëœ í…ŒìŠ¤íŠ¸: {result.testsRun}")
    print(f"ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"ì‹¤íŒ¨: {len(result.failures)}")
    print(f"ì˜¤ë¥˜: {len(result.errors)}")
    
    if result.failures:
        print("\nì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback.split('AssertionError:')[-1].strip()}")
    
    if result.errors:
        print("\nì˜¤ë¥˜ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback.split('Exception:')[-1].strip()}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nì „ì²´ í†µê³¼ìœ¨: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥! ì‹œìŠ¤í…œì´ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    elif success_rate >= 75:
        print("âœ… ì–‘í˜¸í•œ ì„±ëŠ¥! ì¼ë¶€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì„ ìµœì í™”í•´ì£¼ì„¸ìš”.")
    
    return result


if __name__ == "__main__":
    run_performance_benchmark()
