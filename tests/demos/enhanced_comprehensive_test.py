# -*- coding: utf-8 -*-
"""
Enhanced Comprehensive Answer Quality Test with Real AI Models
ì‹¤ì œ AI ëª¨ë¸ê³¼ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ ì¢…í•© ë‹µë³€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
"""

import asyncio
import os
import sys
import time
from typing import Any, Dict, List

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, '.')
sys.path.insert(0, 'source')
sys.path.insert(0, 'source/services')
sys.path.insert(0, 'source/utils')
sys.path.insert(0, 'source/models')
sys.path.insert(0, 'source/data')

# Langfuse ëª¨ë‹ˆí„°ë§ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼ì—ì„œ ë¡œë“œ)
try:
    from dotenv import load_dotenv
    load_dotenv()  # .env íŒŒì¼ ë¡œë“œ
    print("âœ… .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œë¨")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install python-dotenv")
except Exception as e:
    print(f"âš ï¸ .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

print("ğŸš€ Enhanced ì¢…í•© ë‹µë³€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ AI ëª¨ë¸ ì‚¬ìš©)")
print("=" * 70)

try:
    from source.services.chat.enhanced_chat_service import EnhancedChatService
    from source.utils.config import Config
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    sys.exit(1)

try:
    from langfuse import Langfuse
    LANGFUSE_AVAILABLE = True
except ImportError:
    LANGFUSE_AVAILABLE = False

class LangfuseMonitor:
    def __init__(self):
        self.enabled = self._check_langfuse_enabled()
        self.traces = []
        self.events = []
        self.langfuse_client = None

        if self.enabled and LANGFUSE_AVAILABLE:
            try:
                self.langfuse_client = Langfuse(
                    public_key=os.environ.get('LANGFUSE_PUBLIC_KEY'),
                    secret_key=os.environ.get('LANGFUSE_SECRET_KEY'),
                    host=os.environ.get('LANGFUSE_HOST', 'https://cloud.langfuse.com')
                )
            except Exception:
                self.langfuse_client = None

    def _check_langfuse_enabled(self):
        """Langfuse í™œì„±í™” ì—¬ë¶€ í™•ì¸"""
        return (
            os.environ.get('LANGFUSE_PUBLIC_KEY') and
            os.environ.get('LANGFUSE_SECRET_KEY') and
            os.environ.get('LANGFUSE_ENABLED', 'false').lower() == 'true' and
            LANGFUSE_AVAILABLE
        )

    def is_enabled(self):
        return self.enabled

    def create_trace(self, name, user_id, session_id):
        """íŠ¸ë ˆì´ìŠ¤ ìƒì„± - ì‹¤ì œ Langfuse API ì‚¬ìš©"""
        if not self.enabled:
            return None

        if self.langfuse_client:
            try:
                span_context = self.langfuse_client.start_as_current_span(
                    name=name,
                    metadata={
                        'user_id': user_id,
                        'session_id': session_id,
                        'test_type': 'enhanced_comprehensive_quality_test'
                    }
                )
                return span_context
            except Exception:
                return None
        else:
            trace = {
                'id': f"trace_{len(self.traces)}_{int(time.time())}",
                'name': name,
                'user_id': user_id,
                'session_id': session_id,
                'start_time': time.time(),
                'events': []
            }
            self.traces.append(trace)
            return trace

    def log_generation(self, trace_id, name, input_data, output_data, metadata):
        """ìƒì„± ì´ë²¤íŠ¸ ë¡œê¹…"""
        if not self.enabled:
            return

        if self.langfuse_client:
            try:
                return self.langfuse_client.create_event(
                    name=name,
                    input=input_data,
                    output=output_data,
                    metadata=metadata
                )
            except Exception:
                self._log_local_event(trace_id, name, input_data, output_data, metadata, 'generation')
        else:
            self._log_local_event(trace_id, name, input_data, output_data, metadata, 'generation')

    def log_event(self, trace_id, name, input_data, output_data, metadata):
        """ì¼ë°˜ ì´ë²¤íŠ¸ ë¡œê¹…"""
        if not self.enabled:
            return

        if self.langfuse_client:
            try:
                return self.langfuse_client.create_event(
                    name=name,
                    input=input_data,
                    output=output_data,
                    metadata=metadata
                )
            except Exception:
                self._log_local_event(trace_id, name, input_data, output_data, metadata, 'event')
        else:
            self._log_local_event(trace_id, name, input_data, output_data, metadata, 'event')

    def _log_local_event(self, trace_id, name, input_data, output_data, metadata, event_type):
        """ë¡œì»¬ ì´ë²¤íŠ¸ ë¡œê¹…"""
        event = {
            'type': event_type,
            'trace_id': str(trace_id.get('id', trace_id)) if isinstance(trace_id, dict) else str(trace_id),
            'name': name,
            'input_data': input_data,
            'output_data': output_data,
            'metadata': metadata,
            'timestamp': time.time()
        }
        self.events.append(event)

    def flush(self):
        """ë°ì´í„° í”ŒëŸ¬ì‹œ"""
        if not self.enabled:
            return

        if self.langfuse_client:
            try:
                self.langfuse_client.flush()
            except Exception:
                pass

    def get_stats(self):
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        if not self.enabled:
            return {"enabled": False}

        return {
            "enabled": True,
            "traces_count": len(self.traces),
            "events_count": len(self.events),
            "public_key": os.environ.get('LANGFUSE_PUBLIC_KEY', '')[:10] + "...",
            "host": os.environ.get('LANGFUSE_HOST', ''),
            "client_available": self.langfuse_client is not None,
            "langfuse_package_available": LANGFUSE_AVAILABLE
        }

def get_langfuse_monitor():
    return LangfuseMonitor()


def generate_enhanced_test_questions() -> List[Dict[str, Any]]:
    """í–¥ìƒëœ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìƒì„± - ì‹¤ì œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸ìš©"""
    questions = [
        # ë…¸ë™ë²• ê´€ë ¨ ì§ˆë¬¸ (ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤)
        {
            "question": "íšŒì‚¬ì—ì„œ ì•¼ê°„ ê·¼ë¬´ë¥¼ í•˜ëŠ”ë°, ì•¼ê°„ ìˆ˜ë‹¹ê³¼ ì—°ì¥ê·¼ë¬´ ìˆ˜ë‹¹ì´ ì¤‘ë³µ ì§€ê¸‰ë˜ëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê·¼ë¡œê¸°ì¤€ë²•ìƒ ì–´ë–¤ ê·œì •ì´ ìˆë‚˜ìš”?",
            "category": "ë…¸ë™ë²•",
            "expected_type": "labor_law",
            "priority": "high",
            "expected_style": "detailed",
            "complexity": "high",
            "requires_calculation": True
        },

        # # ìƒì†ë²• ê´€ë ¨ ì§ˆë¬¸ (ì‹¤ì œ ì‚¬ë¡€)
        # {
        #     "question": "ì•„ë²„ì§€ê°€ ëŒì•„ê°€ì…¨ëŠ”ë° ìœ ì–¸ì¥ì´ ì—†ê³ , ì–´ë¨¸ë‹ˆì™€ í˜•ì œ 2ëª…ì´ ìˆìŠµë‹ˆë‹¤. ìƒì†ë¶„ì€ ì–´ë–»ê²Œ ë˜ê³ , ìƒì†í¬ê¸°ë¥¼ í•˜ë ¤ë©´ ì–´ë–¤ ì ˆì°¨ê°€ í•„ìš”í•œê°€ìš”?",
        #     "category": "ìƒì†ë²•",
        #     "expected_type": "inheritance",
        #     "priority": "high",
        #     "expected_style": "professional",
        #     "complexity": "medium",
        #     "requires_calculation": True
        # },

        # # í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ (êµ¬ì²´ì  ìƒí™©)
        # {
        #     "question": "ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì—ì„œ ê°€ì§œ ìƒí’ˆì„ íŒë§¤í–ˆë‹¤ê°€ ê³ ê°ì´ ì‹ ê³ í–ˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ì‚¬ê¸°ì£„ê°€ ì„±ë¦½í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì²˜ë²Œ ê¸°ì¤€ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        #     "category": "í˜•ì‚¬ë²•",
        #     "expected_type": "criminal_law",
        #     "priority": "high",
        #     "expected_style": "concise",
        #     "complexity": "medium",
        #     "requires_calculation": False
        # },

        # # ì§€ì ì¬ì‚°ê¶Œë²• ê´€ë ¨ ì§ˆë¬¸ (ì‹¤ë¬´ì  ì§ˆë¬¸)
        # {
        #     "question": "ìœ íŠœë¸Œì—ì„œ ë‹¤ë¥¸ ì‚¬ëŒì˜ ìŒì•…ì„ ë°°ê²½ìŒì•…ìœ¼ë¡œ ì‚¬ìš©í–ˆëŠ”ë° ì €ì‘ê¶Œ ì¹¨í•´ë¡œ ì‹ ê³ ë°›ì•˜ìŠµë‹ˆë‹¤. ì–´ë–¤ ëŒ€ì‘ ë°©ì•ˆì´ ìˆê³ , ì†í•´ë°°ìƒì€ ì–¼ë§ˆë‚˜ ë  ìˆ˜ ìˆë‚˜ìš”?",
        #     "category": "ì§€ì ì¬ì‚°ê¶Œ",
        #     "expected_type": "intellectual_property",
        #     "priority": "medium",
        #     "expected_style": "interactive",
        #     "complexity": "high",
        #     "requires_calculation": True
        # },

        # # í–‰ì •ë²• ê´€ë ¨ ì§ˆë¬¸ (ë³µì¡í•œ ì ˆì°¨)
        # {
        #     "question": "ì•„íŒŒíŠ¸ ê±´ì¶•í—ˆê°€ë¥¼ ë°›ì•˜ëŠ”ë° ì¸ê·¼ ì£¼ë¯¼ë“¤ì´ ì†ŒìŒê³¼ ì¼ì¡°ê¶Œ ì¹¨í•´ë¥¼ ì´ìœ ë¡œ ì´ì˜ë¥¼ ì œê¸°í–ˆìŠµë‹ˆë‹¤. í–‰ì •ì‹¬íŒì„ ì‹ ì²­í•˜ë ¤ë©´ ì–´ë–¤ ì ˆì°¨ì™€ ì„œë¥˜ê°€ í•„ìš”í•œê°€ìš”?",
        #     "category": "í–‰ì •ë²•",
        #     "expected_type": "administrative_law",
        #     "priority": "medium",
        #     "expected_style": "friendly",
        #     "complexity": "high",
        #     "requires_calculation": False
        # },
    ]

    return questions


class EnhancedComprehensiveTest:
    """ì‹¤ì œ AI ëª¨ë¸ê³¼ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ ì¢…í•© í…ŒìŠ¤íŠ¸"""

    def __init__(self):
        self.config = Config()
        self.langfuse_monitor = get_langfuse_monitor()
        self.enhanced_chat_service = None

    async def initialize_services(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            self.enhanced_chat_service = EnhancedChatService(self.config)
            return True
        except Exception as e:
            print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def test_with_real_ai(self):
        """ì‹¤ì œ AI ëª¨ë¸ê³¼ RAG ì‹œìŠ¤í…œ ì‚¬ìš© í…ŒìŠ¤íŠ¸"""
        print("\nğŸš€ Enhanced ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)

        if not await self.initialize_services():
            print("âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return []

        langfuse_enabled = self.langfuse_monitor.is_enabled()
        if langfuse_enabled:
            print("ğŸ“Š Langfuse ëª¨ë‹ˆí„°ë§ í™œì„±í™”")

        test_questions = generate_enhanced_test_questions()
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {len(test_questions)}ê°œ")

        results = []
        start_time = time.time()

        for i, test_case in enumerate(test_questions, 1):
            question = test_case["question"]
            category = test_case["category"]

            print(f"\n[{i}/{len(test_questions)}] {category}: {question[:60]}...")

            trace = None
            if self.langfuse_monitor.is_enabled():
                trace = self.langfuse_monitor.create_trace(
                    name=f"enhanced_test_question_{i}",
                    user_id=f"enhanced_test_user_{i}",
                    session_id=f"enhanced_test_session_{i}"
                )

            try:
                result = await self.enhanced_chat_service.process_message(
                    message=question,
                    user_id=f"enhanced_test_user_{i}",
                    session_id=f"enhanced_test_session_{i}"
                )

                confidence = result.get('confidence', 0.0)
                processing_time = result.get('processing_time', 0.0)
                generation_method = result.get('generation_method', 'unknown')
                langgraph_used = result.get('langgraph_enabled', False)
                sources_count = len(result.get('sources', []))

                print(f"   âœ“ ì‹ ë¢°ë„: {confidence:.2f} | ì‹œê°„: {processing_time:.2f}ì´ˆ | "
                      f"ë°©ë²•: {generation_method} | LangGraph: {langgraph_used} | ì†ŒìŠ¤: {sources_count}ê°œ")

                if self.langfuse_monitor.is_enabled() and trace:
                    self.langfuse_monitor.log_generation(
                        trace_id=trace,
                        name="enhanced_ai_response",
                        input_data={"question": question, "category": category},
                        output_data={
                            "confidence": confidence,
                            "processing_time": processing_time,
                            "generation_method": generation_method,
                            "langgraph_used": langgraph_used
                        },
                        metadata={"test_case_id": i}
                    )

                results.append({
                    'test_case': test_case,
                    'result': result,
                    'success': True,
                    'processing_time': processing_time,
                    'confidence': confidence,
                    'generation_method': generation_method,
                    'langgraph_used': langgraph_used,
                    'sources_count': sources_count
                })

            except Exception as e:
                print(f"   âœ— ì‹¤íŒ¨: {e}")

                if self.langfuse_monitor.is_enabled() and trace:
                    self.langfuse_monitor.log_event(
                        trace_id=trace,
                        name="enhanced_test_error",
                        input_data={"question": question, "category": category},
                        output_data={"error": str(e)},
                        metadata={"test_case_id": i, "success": False}
                    )

                results.append({
                    'test_case': test_case,
                    'result': None,
                    'success': False,
                    'error': str(e)
                })

        total_time = time.time() - start_time
        total_tests = len(results)
        successful_tests = sum(1 for r in results if r['success'])
        langgraph_tests = sum(1 for r in results if r.get('langgraph_used', False))

        print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print(f"   ì´: {total_tests} | ì„±ê³µ: {successful_tests} | ì‹¤íŒ¨: {total_tests - successful_tests}")
        print(f"   LangGraph ì‚¬ìš©: {langgraph_tests}/{total_tests} | ì´ ì‹œê°„: {total_time:.1f}ì´ˆ")

        if successful_tests > 0:
            avg_confidence = sum(r.get('confidence', 0) for r in results if r['success']) / successful_tests
            avg_time = sum(r.get('processing_time', 0) for r in results if r['success']) / successful_tests
            print(f"   í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f} | í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")

        if self.langfuse_monitor.is_enabled():
            self.langfuse_monitor.flush()

        return results


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Enhanced Comprehensive Answer Quality Test")
    print("=" * 70)

    test_instance = EnhancedComprehensiveTest()
    results = await test_instance.test_with_real_ai()

    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
