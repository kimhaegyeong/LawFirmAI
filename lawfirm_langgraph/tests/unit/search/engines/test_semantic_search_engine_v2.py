# -*- coding: utf-8 -*-
"""
SemanticSearchEngineV2 í…ŒìŠ¤íŠ¸ ì½”ë“œ
"""

import sys
import os
import time
import sqlite3
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (í•˜ìœ„ í´ë”ë¡œ ì´ë™í•˜ì—¬ parent í•˜ë‚˜ ì¶”ê°€)
project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "lawfirm_langgraph"))

# conftest.pyì—ì„œ db_path ì°¾ê¸° ë¡œì§ ì¬ì‚¬ìš©
from lawfirm_langgraph.tests.unit.search.conftest import db_path as get_db_path

import warnings
warnings.filterwarnings('ignore', message='.*python-dotenv.*')

from lawfirm_langgraph.core.search.engines.semantic_search_engine_v2 import SemanticSearchEngineV2


class TestSemanticSearchEngineV2:
    """SemanticSearchEngineV2 í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™”"""
        self.engine = None
        self.db_path = None
        
    def setup(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        # conftest.pyì˜ db_path ì°¾ê¸° ë¡œì§ ì‚¬ìš©
        from lawfirm_langgraph.tests.unit.search.conftest import project_root as _project_root
        
        possible_db_paths = [
            "data/lawfirm_v2.db",
            "./data/lawfirm_v2.db",
            str(_project_root / "data" / "lawfirm_v2.db")
        ]
        
        for path in possible_db_paths:
            if Path(path).exists():
                self.db_path = path
                break
        
        if not self.db_path:
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            self.engine = SemanticSearchEngineV2(
                db_path=self.db_path,
                use_external_index=False
            )
            print(f"âœ… SemanticSearchEngineV2 ì´ˆê¸°í™” ì„±ê³µ (DB: {self.db_path})")
            return True
        except Exception as e:
            print(f"âŒ SemanticSearchEngineV2 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def test_normalize_query(self):
        """ì¿¼ë¦¬ ì •ê·œí™” í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ì¿¼ë¦¬ ì •ê·œí™”")
        try:
            # ê³µë°± ì •ê·œí™”
            result1 = self.engine._normalize_query("  ì„ëŒ€ì°¨   ê³„ì•½  ")
            assert result1 == "ì„ëŒ€ì°¨ ê³„ì•½", f"Expected 'ì„ëŒ€ì°¨ ê³„ì•½', got '{result1}'"
            
            # ëŒ€ì†Œë¬¸ì ì •ê·œí™”
            result2 = self.engine._normalize_query("ì„ëŒ€ì°¨ ê³„ì•½")
            result3 = self.engine._normalize_query("ì„ëŒ€ì°¨ ê³„ì•½")
            assert result2 == result3, "ëŒ€ì†Œë¬¸ì ì •ê·œí™” ì‹¤íŒ¨"
            
            # ë¹ˆ ë¬¸ìì—´
            result4 = self.engine._normalize_query("")
            assert result4 == "", f"Expected '', got '{result4}'"
            
            print("   âœ… ì¿¼ë¦¬ ì •ê·œí™” í…ŒìŠ¤íŠ¸ í†µê³¼")
            return True
        except Exception as e:
            print(f"   âŒ ì¿¼ë¦¬ ì •ê·œí™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_cache_ttl(self):
        """ìºì‹œ TTL í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ìºì‹œ TTL")
        try:
            # ìºì‹œì— í•­ëª© ì €ì¥
            test_key = "test_key"
            test_value = {"test": "data"}
            self.engine._set_to_cache(test_key, test_value)
            
            # ì¦‰ì‹œ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)
            cached = self.engine._get_from_cache(test_key)
            assert cached == test_value, "ìºì‹œ ì €ì¥/ì¡°íšŒ ì‹¤íŒ¨"
            
            # TTLì„ ì§§ê²Œ ì„¤ì •í•˜ì—¬ ë§Œë£Œ í…ŒìŠ¤íŠ¸
            original_ttl = self.engine._metadata_cache_ttl
            self.engine._metadata_cache_ttl = 0.1  # 0.1ì´ˆ
            
            # ìºì‹œì— ë‹¤ì‹œ ì €ì¥
            self.engine._set_to_cache(test_key, test_value)
            
            # 0.2ì´ˆ ëŒ€ê¸° (TTL ì´ˆê³¼)
            time.sleep(0.2)
            
            # ë§Œë£Œëœ í•­ëª© ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤)
            expired = self.engine._get_from_cache(test_key)
            assert expired is None, "ë§Œë£Œëœ ìºì‹œ í•­ëª©ì´ ì œê±°ë˜ì§€ ì•ŠìŒ"
            
            # TTL ë³µì›
            self.engine._metadata_cache_ttl = original_ttl
            
            print("   âœ… ìºì‹œ TTL í…ŒìŠ¤íŠ¸ í†µê³¼")
            return True
        except Exception as e:
            print(f"   âŒ ìºì‹œ TTL í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_cache_cleanup(self):
        """ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ìºì‹œ ì •ë¦¬")
        try:
            # ì—¬ëŸ¬ í•­ëª© ì €ì¥
            for i in range(10):
                self.engine._set_to_cache(f"key_{i}", {"data": i})
            
            initial_size = len(self.engine._metadata_cache)
            assert initial_size == 10, f"Expected 10 items, got {initial_size}"
            
            # TTLì„ ì§§ê²Œ ì„¤ì •
            original_ttl = self.engine._metadata_cache_ttl
            original_cleanup_interval = self.engine._metadata_cache_cleanup_interval
            self.engine._metadata_cache_ttl = 0.1
            self.engine._metadata_cache_cleanup_interval = 0.05  # 0.05ì´ˆ
            
            # ì‹œê°„ ê²½ê³¼ ëŒ€ê¸°
            time.sleep(0.15)
            
            # ì •ë¦¬ ì‹¤í–‰
            self.engine._cleanup_expired_cache()
            
            # ë§Œë£Œëœ í•­ëª©ì´ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
            cleaned_size = len(self.engine._metadata_cache)
            assert cleaned_size == 0, f"Expected 0 items after cleanup, got {cleaned_size}"
            
            # ì„¤ì • ë³µì›
            self.engine._metadata_cache_ttl = original_ttl
            self.engine._metadata_cache_cleanup_interval = original_cleanup_interval
            
            print("   âœ… ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")
            return True
        except Exception as e:
            print(f"   âŒ ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_batch_load_chunk_metadata(self):
        """ë°°ì¹˜ chunk_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ë°°ì¹˜ chunk_metadata ì¡°íšŒ")
        try:
            conn = self.engine._get_connection()
            if not conn:
                print("   âš ï¸  DB ì—°ê²° ì‹¤íŒ¨, í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
                return True
            
            # ì‹¤ì œ chunk_id ì¡°íšŒ
            cursor = conn.execute("SELECT id FROM text_chunks LIMIT 5")
            chunk_ids = [row[0] for row in cursor.fetchall()]
            
            if not chunk_ids:
                print("   âš ï¸  chunk_idê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
                return True
            
            # ë°°ì¹˜ ì¡°íšŒ
            result = self.engine._batch_load_chunk_metadata(conn, chunk_ids)
            
            assert len(result) == len(chunk_ids), f"Expected {len(chunk_ids)} results, got {len(result)}"
            
            # ê²°ê³¼ ê²€ì¦
            for chunk_id in chunk_ids:
                assert chunk_id in result, f"chunk_id {chunk_id} not in result"
                assert 'meta' in result[chunk_id], f"chunk_id {chunk_id} missing 'meta' field"
                assert 'source_type' in result[chunk_id], f"chunk_id {chunk_id} missing 'source_type' field"
                assert 'source_id' in result[chunk_id], f"chunk_id {chunk_id} missing 'source_id' field"
            
            # ìºì‹œ í…ŒìŠ¤íŠ¸ (ë‘ ë²ˆì§¸ ì¡°íšŒëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
            cache_hits_before = self.engine._metadata_cache_hits
            result2 = self.engine._batch_load_chunk_metadata(conn, chunk_ids)
            cache_hits_after = self.engine._metadata_cache_hits
            
            assert cache_hits_after > cache_hits_before, "ìºì‹œ íˆíŠ¸ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ"
            
            conn.close()
            print(f"   âœ… ë°°ì¹˜ chunk_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸ í†µê³¼ (ì¡°íšŒ: {len(chunk_ids)}ê°œ, ìºì‹œ íˆíŠ¸: {cache_hits_after - cache_hits_before}ê°œ)")
            return True
        except Exception as e:
            print(f"   âŒ ë°°ì¹˜ chunk_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_batch_load_source_metadata(self):
        """ë°°ì¹˜ source_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ë°°ì¹˜ source_metadata ì¡°íšŒ")
        try:
            conn = self.engine._get_connection()
            if not conn:
                print("   âš ï¸  DB ì—°ê²° ì‹¤íŒ¨, í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
                return True
            
            # ì‹¤ì œ source_type, source_id ì¡°íšŒ
            cursor = conn.execute("""
                SELECT DISTINCT source_type, source_id 
                FROM text_chunks 
                WHERE source_type IS NOT NULL AND source_id IS NOT NULL
                LIMIT 5
            """)
            source_items = [(row[0], row[1]) for row in cursor.fetchall()]
            
            if not source_items:
                print("   âš ï¸  source_itemsê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
                return True
            
            # ë°°ì¹˜ ì¡°íšŒ
            result = self.engine._batch_load_source_metadata(conn, source_items)
            
            # ê²°ê³¼ ê²€ì¦
            for source_type, source_id in source_items:
                # source_idê°€ ë¬¸ìì—´ì¸ ê²½ìš° ì •ìˆ˜ë¡œ ë³€í™˜ ì‹œë„
                if isinstance(source_id, str):
                    import re
                    numbers = re.findall(r'\d+', str(source_id))
                    if numbers:
                        source_id = int(numbers[-1])
                    else:
                        continue
                
                key = (source_type, source_id)
                if key in result:
                    assert isinstance(result[key], dict), f"source_metadata for {key} is not a dict"
            
            # ìºì‹œ í…ŒìŠ¤íŠ¸
            cache_hits_before = self.engine._metadata_cache_hits
            result2 = self.engine._batch_load_source_metadata(conn, source_items)
            cache_hits_after = self.engine._metadata_cache_hits
            
            assert cache_hits_after > cache_hits_before, "ìºì‹œ íˆíŠ¸ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ"
            
            conn.close()
            print(f"   âœ… ë°°ì¹˜ source_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸ í†µê³¼ (ì¡°íšŒ: {len(source_items)}ê°œ, ìºì‹œ íˆíŠ¸: {cache_hits_after - cache_hits_before}ê°œ)")
            return True
        except Exception as e:
            print(f"   âŒ ë°°ì¹˜ source_metadata ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_search_basic(self):
        """ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸: ê¸°ë³¸ ê²€ìƒ‰")
        try:
            query = "ì„ëŒ€ì°¨ ê³„ì•½"
            results = self.engine.search(
                query=query,
                k=5,
                similarity_threshold=0.3
            )
            
            assert isinstance(results, list), "ê²€ìƒ‰ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜"
            assert len(results) <= 5, f"ê²€ìƒ‰ ê²°ê³¼ê°€ kë³´ë‹¤ ë§ìŒ: {len(results)}"
            
            # ê²°ê³¼ ê²€ì¦
            for result in results:
                assert 'text' in result or 'content' in result, "ê²€ìƒ‰ ê²°ê³¼ì— text/contentê°€ ì—†ìŒ"
                assert 'score' in result or 'similarity' in result, "ê²€ìƒ‰ ê²°ê³¼ì— score/similarityê°€ ì—†ìŒ"
            
            print(f"   âœ… ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í†µê³¼ (ê²°ê³¼: {len(results)}ê°œ)")
            return True
        except Exception as e:
            print(f"   âŒ ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("="*80)
        print("SemanticSearchEngineV2 í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)
        
        if not self.setup():
            print("\nâŒ í…ŒìŠ¤íŠ¸ ì„¤ì • ì‹¤íŒ¨")
            return False
        
        tests = [
            ("ì¿¼ë¦¬ ì •ê·œí™”", self.test_normalize_query),
            ("ìºì‹œ TTL", self.test_cache_ttl),
            ("ìºì‹œ ì •ë¦¬", self.test_cache_cleanup),
            ("ë°°ì¹˜ chunk_metadata ì¡°íšŒ", self.test_batch_load_chunk_metadata),
            ("ë°°ì¹˜ source_metadata ì¡°íšŒ", self.test_batch_load_source_metadata),
            ("ê¸°ë³¸ ê²€ìƒ‰", self.test_search_basic),
        ]
        
        results = []
        for test_name, test_func in tests:
            try:
                result = test_func()
                results.append((test_name, result))
            except Exception as e:
                print(f"\nâŒ {test_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                results.append((test_name, False))
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*80)
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        passed = sum(1 for _, result in results if result)
        total = len(results)
        
        for test_name, result in results:
            status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
            print(f"  {test_name}: {status}")
        
        print(f"\nì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
        print("="*80)
        
        return passed == total


if __name__ == "__main__":
    tester = TestSemanticSearchEngineV2()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)

