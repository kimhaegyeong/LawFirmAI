# -*- coding: utf-8 -*-
"""
HuggingFace ëª¨ë¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸

Usage:
    python lawfirm_langgraph/tests/script_unit/performance/test_keyword_extraction_hf.py
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
performance_dir = script_dir.parent
unit_dir = performance_dir.parent
tests_dir = unit_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

import logging
try:
    from lawfirm_langgraph.core.utils.logger import get_logger
except ImportError:
    from core.utils.logger import get_logger

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = get_logger(__name__)

def test_keyword_extraction():
    """í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("HuggingFace ëª¨ë¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.workflow.legal_workflow_enhanced import EnhancedLegalQuestionWorkflow
        from core.utils.langgraph_config import LangGraphConfig
        
        # ì„¤ì • ë¡œë“œ
        try:
            config = LangGraphConfig.from_env()
        except:
            from core.utils.config import Config
            config = Config()
        
        # ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        workflow = EnhancedLegalQuestionWorkflow(config)
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_query = "ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        state = {
            "query": test_query,
            "query_type": "legal_advice",
            "legal_field": "ë¯¼ì‚¬ë²•"
        }
        
        print(f"\ní…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_query}")
        print(f"HybridQueryProcessor ì‚¬ìš© ê°€ëŠ¥: {workflow.hybrid_query_processor is not None}")
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰
        result = workflow.expand_keywords(state)
        
        # ê²°ê³¼ í™•ì¸
        extracted_keywords = result.get("extracted_keywords", [])
        if not extracted_keywords:
            # ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ í™•ì¸
            if "search" in result and isinstance(result["search"], dict):
                extracted_keywords = result["search"].get("extracted_keywords", [])
        
        print(f"\n{'='*80}")
        print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {len(extracted_keywords)}ê°œ")
        print(f"{'='*80}")
        if extracted_keywords:
            print(f"\nì¶”ì¶œëœ í‚¤ì›Œë“œ:")
            for i, kw in enumerate(extracted_keywords[:15], 1):
                print(f"  {i}. {kw}")
        else:
            print("\nâš ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if len(extracted_keywords) > 0:
            print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(extracted_keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œë¨")
            return True
        else:
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: í‚¤ì›Œë“œê°€ ì¶”ì¶œë˜ì§€ ì•ŠìŒ")
            return False
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    print("ğŸš€ HuggingFace ëª¨ë¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    success = test_keyword_extraction()
    
    if success:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        sys.exit(0)
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)

