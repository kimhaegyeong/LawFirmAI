# -*- coding: utf-8 -*-
"""
ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ ê°€ì¤‘ì¹˜ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬ ìµœì ì˜ ì„¤ì •ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import sys
import os
from pathlib import Path
import json
from datetime import datetime
import subprocess

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
project_root = Path(__file__).parent.parent.parent.parent.parent
lawfirm_langgraph_dir = project_root / "lawfirm_langgraph"
sys.path.insert(0, str(lawfirm_langgraph_dir))
sys.path.insert(0, str(project_root))

# í…ŒìŠ¤íŠ¸í•  ê°€ì¤‘ì¹˜ ì¡°í•©ë“¤
WEIGHT_CONFIGS = [
    {
        "name": "ê¸°ë³¸ ì„¤ì •",
        "hybrid_law": {"semantic": 0.3, "keyword": 0.7},
        "hybrid_case": {"semantic": 0.7, "keyword": 0.3},
        "hybrid_general": {"semantic": 0.5, "keyword": 0.5},
        "doc_type_boost": {"statute": 1.2, "case": 1.15},
        "quality_weight": 0.2,
        "keyword_adjustment": 1.8
    },
    {
        "name": "í‚¤ì›Œë“œ ê°•ì¡°",
        "hybrid_law": {"semantic": 0.2, "keyword": 0.8},
        "hybrid_case": {"semantic": 0.6, "keyword": 0.4},
        "hybrid_general": {"semantic": 0.4, "keyword": 0.6},
        "doc_type_boost": {"statute": 1.3, "case": 1.1},
        "quality_weight": 0.15,
        "keyword_adjustment": 2.0
    },
    {
        "name": "ì˜ë¯¸ ê²€ìƒ‰ ê°•ì¡°",
        "hybrid_law": {"semantic": 0.4, "keyword": 0.6},
        "hybrid_case": {"semantic": 0.8, "keyword": 0.2},
        "hybrid_general": {"semantic": 0.6, "keyword": 0.4},
        "doc_type_boost": {"statute": 1.1, "case": 1.2},
        "quality_weight": 0.25,
        "keyword_adjustment": 1.6
    },
    {
        "name": "ê· í˜• ì„¤ì •",
        "hybrid_law": {"semantic": 0.35, "keyword": 0.65},
        "hybrid_case": {"semantic": 0.65, "keyword": 0.35},
        "hybrid_general": {"semantic": 0.5, "keyword": 0.5},
        "doc_type_boost": {"statute": 1.15, "case": 1.1},
        "quality_weight": 0.2,
        "keyword_adjustment": 1.7
    },
    {
        "name": "í’ˆì§ˆ ê°•ì¡°",
        "hybrid_law": {"semantic": 0.3, "keyword": 0.7},
        "hybrid_case": {"semantic": 0.7, "keyword": 0.3},
        "hybrid_general": {"semantic": 0.5, "keyword": 0.5},
        "doc_type_boost": {"statute": 1.2, "case": 1.15},
        "quality_weight": 0.3,
        "keyword_adjustment": 1.8
    }
]

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
TEST_QUERIES = [
    "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
]

def update_weight_config(config):
    """ê°€ì¤‘ì¹˜ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸"""
    config_file = lawfirm_langgraph_dir / "core" / "search" / "processors" / "search_result_processor.py"
    
    # íŒŒì¼ ì½ê¸°
    with open(config_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì • ì°¾ì•„ì„œ êµì²´
    old_config = """        self.weight_config = weight_config or {
            "hybrid_law": {"semantic": 0.3, "keyword": 0.7},
            "hybrid_case": {"semantic": 0.7, "keyword": 0.3},
            "hybrid_general": {"semantic": 0.5, "keyword": 0.5},
            "doc_type_boost": {"statute": 1.2, "case": 1.15},
            "quality_weight": 0.2,
            "keyword_adjustment": 1.8
        }"""
    
    new_config = f"""        self.weight_config = weight_config or {{
            "hybrid_law": {{"semantic": {config["hybrid_law"]["semantic"]}, "keyword": {config["hybrid_law"]["keyword"]}}},
            "hybrid_case": {{"semantic": {config["hybrid_case"]["semantic"]}, "keyword": {config["hybrid_case"]["keyword"]}}},
            "hybrid_general": {{"semantic": {config["hybrid_general"]["semantic"]}, "keyword": {config["hybrid_general"]["keyword"]}}},
            "doc_type_boost": {{"statute": {config["doc_type_boost"]["statute"]}, "case": {config["doc_type_boost"]["case"]}}},
            "quality_weight": {config["quality_weight"]},
            "keyword_adjustment": {config["keyword_adjustment"]}
        }}"""
    
    content = content.replace(old_config, new_config)
    
    # íŒŒì¼ ì“°ê¸°
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(content)

def run_test(query):
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    test_script = project_root / "lawfirm_langgraph" / "tests" / "scripts" / "run_query_test.py"
    result = subprocess.run(
        [sys.executable, str(test_script), query],
        capture_output=True,
        text=True,
        encoding='utf-8',
        cwd=str(project_root)
    )
    return result.stdout, result.stderr

def extract_metrics(output):
    """ì¶œë ¥ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ"""
    metrics = {}
    
    # Avg Relevance ì¶”ì¶œ
    import re
    avg_match = re.search(r'Avg Relevance: ([\d.]+)', output)
    if avg_match:
        metrics['avg_relevance'] = float(avg_match.group(1))
    
    min_match = re.search(r'Min: ([\d.]+)', output)
    if min_match:
        metrics['min_relevance'] = float(min_match.group(1))
    
    max_match = re.search(r'Max: ([\d.]+)', output)
    if max_match:
        metrics['max_relevance'] = float(max_match.group(1))
    
    keyword_match = re.search(r'Keyword Coverage: ([\d.]+)', output)
    if keyword_match:
        metrics['keyword_coverage'] = float(keyword_match.group(1))
    
    return metrics

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ê°€ì¤‘ì¹˜ ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"í…ŒìŠ¤íŠ¸ ì„¤ì • ìˆ˜: {len(WEIGHT_CONFIGS)}")
    print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {len(TEST_QUERIES)}")
    print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(WEIGHT_CONFIGS) * len(TEST_QUERIES)}\n")
    
    all_results = []
    original_config = None
    
    try:
        # ì›ë³¸ ì„¤ì • ë°±ì—…
        config_file = lawfirm_langgraph_dir / "core" / "search" / "processors" / "search_result_processor.py"
        with open(config_file, 'r', encoding='utf-8') as f:
            original_config = f.read()
        
        for i, config in enumerate(WEIGHT_CONFIGS, 1):
            print(f"\n{'='*80}")
            print(f"í…ŒìŠ¤íŠ¸ {i}/{len(WEIGHT_CONFIGS)}: {config['name']}")
            print(f"{'='*80}\n")
            
            # ê°€ì¤‘ì¹˜ ì„¤ì • ì—…ë°ì´íŠ¸
            update_weight_config(config)
            
            for query in TEST_QUERIES:
                print(f"ğŸ“ ì¿¼ë¦¬: {query}")
                stdout, stderr = run_test(query)
                
                metrics = extract_metrics(stdout)
                
                result = {
                    "config_name": config['name'],
                    "config": config,
                    "query": query,
                    "timestamp": datetime.now().isoformat(),
                    "metrics": metrics,
                    "stdout": stdout[-2000:] if len(stdout) > 2000 else stdout,  # ë§ˆì§€ë§‰ 2000ìë§Œ
                    "stderr": stderr[-1000:] if len(stderr) > 1000 else stderr
                }
                
                all_results.append(result)
                
                if metrics:
                    print(f"  âœ… Avg Relevance: {metrics.get('avg_relevance', 'N/A')}")
                    print(f"  âœ… Keyword Coverage: {metrics.get('keyword_coverage', 'N/A')}")
                else:
                    print(f"  âš ï¸  ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹¤íŒ¨")
        
        # ì›ë³¸ ì„¤ì • ë³µì›
        if original_config:
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(original_config)
            print("\nâœ… ì›ë³¸ ì„¤ì • ë³µì› ì™„ë£Œ")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì›ë³¸ ì„¤ì • ë³µì›
        if original_config:
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(original_config)
    
    # ê²°ê³¼ ì €ì¥
    output_file = project_root / "logs" / "test" / f"weight_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "configs": WEIGHT_CONFIGS,
            "queries": TEST_QUERIES,
            "results": all_results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ. ê²°ê³¼ ì €ì¥: {output_file}")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"{'ì„¤ì •':<20} {'Avg Relevance':<15} {'Keyword Coverage':<15}")
    print("-" * 50)
    for result in all_results:
        metrics = result.get('metrics', {})
        print(f"{result['config_name']:<20} {metrics.get('avg_relevance', 'N/A'):<15} {metrics.get('keyword_coverage', 'N/A'):<15}")

if __name__ == "__main__":
    main()

