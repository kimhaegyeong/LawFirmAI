# -*- coding: utf-8 -*-
"""
HybridQueryProcessor í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
HuggingFace + LLM í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸

Usage:
    python lawfirm_langgraph/tests/scripts/test_hybrid_query_processor.py
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
    scripts_dir = script_dir.parent
    tests_dir = scripts_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

import logging
from typing import Dict, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
TEST_QUERIES = [
    {
        "query": "ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "query_type": "legal_advice",
        "legal_field": "",
        "complexity": "moderate"
    },
    {
        "query": "ì†í•´ë°°ìƒ ì²­êµ¬ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "query_type": "legal_advice",
        "legal_field": "ë¯¼ì‚¬ë²•",
        "complexity": "moderate"
    },
    {
        "query": "ë¯¼ë²• ì œ750ì¡°",
        "query_type": "statute",
        "legal_field": "ë¯¼ì‚¬ë²•",
        "complexity": "simple"
    }
]


def test_hybrid_query_processor():
    """HybridQueryProcessor í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("HybridQueryProcessor í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    try:
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        from core.agents.keyword_extractor import KeywordExtractor
        from core.search.optimizers.keyword_mapper import LegalKeywordMapper
        try:
            from core.processing.integration.term_integration_system import TermIntegrator
        except ImportError:
            try:
                from core.services.term_integration_system import TermIntegrator
            except ImportError:
                TermIntegrator = None
        from core.workflow.initializers.llm_initializer import LLMInitializer
        from core.utils.config import Config
        from core.utils.langgraph_config import LangGraphConfig
        from core.search.optimizers.hybrid_query_processor import HybridQueryProcessor
        
        # ì„¤ì • ë¡œë“œ
        try:
            config = LangGraphConfig.from_env()
        except:
            config = Config()
        
        # KeywordExtractor ì´ˆê¸°í™”
        keyword_extractor = KeywordExtractor(use_morphology=True, logger_instance=logger)
        logger.info("âœ… KeywordExtractor initialized")
        
        # TermIntegrator ì´ˆê¸°í™”
        if TermIntegrator:
            term_integrator = TermIntegrator()
            logger.info("âœ… TermIntegrator initialized")
        else:
            term_integrator = None
            logger.warning("âš ï¸ TermIntegrator not available, using None")
        
        # LLM ì´ˆê¸°í™”
        try:
            llm_initializer = LLMInitializer(config=config)
            llm = llm_initializer.initialize_llm()
            logger.info("âœ… LLM initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ LLM initialization failed: {e}, using None")
            llm = None
        
        # HybridQueryProcessor ì´ˆê¸°í™”
        embedding_model_name = getattr(config, 'embedding_model', None)
        hybrid_processor = HybridQueryProcessor(
            keyword_extractor=keyword_extractor,
            term_integrator=term_integrator,
            llm=llm,
            embedding_model_name=embedding_model_name,
            logger=logger
        )
        logger.info("âœ… HybridQueryProcessor initialized")
        
        # ê° í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
        results = []
        for i, test_query in enumerate(TEST_QUERIES, 1):
            print(f"\n{'=' * 80}")
            print(f"í…ŒìŠ¤íŠ¸ {i}/{len(TEST_QUERIES)}: {test_query['query']}")
            print(f"{'=' * 80}")
            
            try:
                # í‚¤ì›Œë“œ ì¶”ì¶œ
                extracted_keywords = keyword_extractor.extract_keywords(
                    test_query["query"],
                    max_keywords=10,
                    prefer_morphology=True
                )
                print(f"ğŸ“ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {extracted_keywords}")
                
                # HybridQueryProcessor ì‹¤í–‰
                optimized_queries, cache_hit = hybrid_processor.process_query_hybrid(
                    query=test_query["query"],
                    search_query=test_query["query"],
                    query_type=test_query["query_type"],
                    extracted_keywords=extracted_keywords,
                    legal_field=test_query["legal_field"],
                    complexity=test_query["complexity"],
                    is_retry=False
                )
                
                # ê²°ê³¼ ì¶œë ¥
                print(f"\nâœ… ì¿¼ë¦¬ ìµœì í™” ì™„ë£Œ:")
                print(f"  - Semantic Query: {optimized_queries.get('semantic_query', 'N/A')}")
                print(f"  - Keyword Queries: {len(optimized_queries.get('keyword_queries', []))}ê°œ")
                print(f"  - Expanded Keywords: {len(optimized_queries.get('expanded_keywords', []))}ê°œ")
                print(f"  - Multi Queries: {len(optimized_queries.get('multi_queries', []))}ê°œ")
                print(f"  - HF Models Used: {optimized_queries.get('hf_models_used', False)}")
                print(f"  - LLM Enhanced: {optimized_queries.get('llm_enhanced', False)}")
                
                if optimized_queries.get('multi_queries'):
                    print(f"  - Multi Queries ë‚´ìš©:")
                    for j, mq in enumerate(optimized_queries['multi_queries'][:3], 1):
                        print(f"    {j}. {mq}")
                
                results.append({
                    "test_query": test_query,
                    "optimized_queries": optimized_queries,
                    "success": True
                })
                
            except Exception as e:
                logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
                results.append({
                    "test_query": test_query,
                    "error": str(e),
                    "success": False
                })
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'=' * 80}")
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"{'=' * 80}")
        success_count = sum(1 for r in results if r.get("success", False))
        print(f"âœ… ì„±ê³µ: {success_count}/{len(TEST_QUERIES)}")
        print(f"âŒ ì‹¤íŒ¨: {len(TEST_QUERIES) - success_count}/{len(TEST_QUERIES)}")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        return None


def test_individual_components():
    """ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.search.optimizers.legal_query_analyzer import LegalQueryAnalyzer
        from core.search.optimizers.legal_keyword_expander import LegalKeywordExpander
        from core.search.optimizers.legal_query_optimizer import LegalQueryOptimizer
        from core.search.optimizers.legal_query_validator import LegalQueryValidator
        from core.agents.keyword_extractor import KeywordExtractor
        
        keyword_extractor = KeywordExtractor(use_morphology=True, logger_instance=logger)
        
        # LegalQueryAnalyzer í…ŒìŠ¤íŠ¸
        print("\n1. LegalQueryAnalyzer í…ŒìŠ¤íŠ¸")
        analyzer = LegalQueryAnalyzer(
            keyword_extractor=keyword_extractor,
            logger=logger
        )
        analysis_result = analyzer.analyze_query(
            query="ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            query_type="legal_advice",
            legal_field=""
        )
        print(f"  âœ… Core Keywords: {analysis_result.get('core_keywords', [])}")
        print(f"  âœ… Query Intent: {analysis_result.get('query_intent', 'N/A')}")
        print(f"  âœ… Key Concepts: {analysis_result.get('key_concepts', [])}")
        
        # LegalKeywordExpander í…ŒìŠ¤íŠ¸
        print("\n2. LegalKeywordExpander í…ŒìŠ¤íŠ¸")
        expander = LegalKeywordExpander(logger=logger)
        expansion_result = expander.expand_keywords(
            query="ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            core_keywords=analysis_result.get('core_keywords', []),
            extracted_keywords=analysis_result.get('core_keywords', []),
            legal_field=""
        )
        print(f"  âœ… Expanded Keywords: {len(expansion_result.get('expanded_keywords', []))}ê°œ")
        print(f"  âœ… Synonyms: {len(expansion_result.get('synonyms', []))}ê°œ")
        
        # LegalQueryOptimizer í…ŒìŠ¤íŠ¸
        print("\n3. LegalQueryOptimizer í…ŒìŠ¤íŠ¸")
        optimizer = LegalQueryOptimizer(logger=logger)
        optimization_result = optimizer.optimize_query(
            query="ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            core_keywords=analysis_result.get('core_keywords', []),
            expanded_keywords=expansion_result.get('expanded_keywords', []),
            query_type="legal_advice"
        )
        print(f"  âœ… Semantic Query: {optimization_result.get('semantic_query', 'N/A')}")
        print(f"  âœ… Keyword Query: {optimization_result.get('keyword_query', 'N/A')}")
        print(f"  âœ… Quality Score: {optimization_result.get('quality_score', 0.0):.2f}")
        
        # LegalQueryValidator í…ŒìŠ¤íŠ¸
        print("\n4. LegalQueryValidator í…ŒìŠ¤íŠ¸")
        validator = LegalQueryValidator(logger=logger)
        validation_result = validator.validate_query(
            optimized_queries=optimization_result,
            original_query="ê³„ì•½ í•´ì§€ ì‚¬ìœ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        )
        print(f"  âœ… Is Valid: {validation_result.get('is_valid', False)}")
        print(f"  âœ… Quality Score: {validation_result.get('quality_score', 0.0):.2f}")
        print(f"  âœ… Improvements: {validation_result.get('improvements', [])}")
        
        print("\nâœ… ëª¨ë“  ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)


if __name__ == "__main__":
    print("ğŸš€ HybridQueryProcessor í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
    test_individual_components()
    
    # í†µí•© í…ŒìŠ¤íŠ¸
    results = test_hybrid_query_processor()
    
    if results:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)

