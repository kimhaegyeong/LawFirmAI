# -*- coding: utf-8 -*-
"""
LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)

Usage:
    python lawfirm_langgraph/tests/scripts/run_query_test.py "ì§ˆì˜ ë‚´ìš©"
    python lawfirm_langgraph/tests/scripts/run_query_test.py 0  # ê¸°ë³¸ ì§ˆì˜ ì„ íƒ
    $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python run_query_test.py  # í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
"""

import sys
import io
import os

# python-dotenv ê²½ê³  ì–µì œ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
# stderrë¥¼ ì™„ì „íˆ ë¦¬ë‹¤ì´ë ‰íŠ¸í•˜ì§€ ì•Šê³ , warningsë§Œ í•„í„°ë§
_original_stderr = sys.stderr
# stderr ë¦¬ë‹¤ì´ë ‰íŠ¸ ì œê±° - ë¡œê¹… ì˜¤ë¥˜ ë°©ì§€
# try:
#     # Windowsì™€ Unix ëª¨ë‘ ì§€ì›
#     if sys.platform == 'win32':
#         sys.stderr = open('nul', 'w', encoding='utf-8', errors='replace')
#     else:
#         sys.stderr = open('/dev/null', 'w', encoding='utf-8', errors='replace')
# except Exception:
#     # ì‹¤íŒ¨ ì‹œ ì›ë³¸ stderr ìœ ì§€
#     pass

# warnings ëª¨ë“ˆë„ í•„í„°ë§
import warnings
warnings.filterwarnings('ignore', message='.*python-dotenv.*')
warnings.filterwarnings('ignore', category=UserWarning, message='.*python-dotenv.*')
warnings.filterwarnings('ignore', category=Warning)

import asyncio
import logging
from pathlib import Path
from datetime import datetime

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Windows PowerShell í˜¸í™˜)
_original_stdout = sys.stdout
_original_stderr = sys.stderr

if sys.platform == 'win32':
    import io
    if hasattr(sys.stdout, 'buffer'):
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        except (ValueError, AttributeError):
            pass
    if hasattr(sys.stderr, 'buffer'):
        try:
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        except (ValueError, AttributeError):
            pass
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”í•˜ì—¬ generate_answer_final ì‚¬ìš©
# APIì—ì„œëŠ” USE_STREAMING_MODE=trueë¡œ ì„¤ì •í•˜ì—¬ generate_answer_stream ì‚¬ìš©
os.environ['USE_STREAMING_MODE'] = 'false'

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜: lawfirm_langgraph/tests/scripts/run_query_test.py
try:
    script_dir = Path(__file__).parent
except NameError:
    # __file__ì´ ì—†ëŠ” ê²½ìš° (ì˜ˆ: execë¡œ ì‹¤í–‰ëœ ê²½ìš°)
    script_dir = Path.cwd() / "lawfirm_langgraph" / "tests" / "scripts"
tests_dir = script_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

# sys.path ì„¤ì • (ìˆœí™˜ import ë°©ì§€)
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

# ë¡œê¹… ì„¤ì • (SafeStreamHandler ì‚¬ìš©)
def setup_logging(log_level: str = "INFO"):
    """ë¡œê¹… ì„¤ì • (Windows PowerShell í˜¸í™˜)"""
    logger = logging.getLogger("lawfirm_langgraph.tests")
    logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))
    logger.handlers.clear()
    
    # SafeStreamHandler í´ë˜ìŠ¤ ì •ì˜
    class SafeStreamHandler(logging.StreamHandler):
        """ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬"""
        
        def __init__(self, stream, original_stdout_ref=None):
            super().__init__(stream)
            self._original_stdout = original_stdout_ref
            self._fallback_stream = None
        
        def _get_safe_stream(self):
            """ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ ë°˜í™˜"""
            streams_to_try = []
            if self.stream and hasattr(self.stream, 'write'):
                streams_to_try.append(self.stream)
            if self._original_stdout is not None and hasattr(self._original_stdout, 'write'):
                streams_to_try.append(self._original_stdout)
            if sys.stdout and hasattr(sys.stdout, 'write'):
                streams_to_try.append(sys.stdout)
            if sys.stderr and hasattr(sys.stderr, 'write'):
                streams_to_try.append(sys.stderr)
            
            for stream in streams_to_try:
                try:
                    if hasattr(stream, 'buffer') or hasattr(stream, 'write'):
                        return stream
                except (ValueError, AttributeError, OSError):
                    continue
            return None
        
        def _is_stream_valid(self, stream):
            """ìŠ¤íŠ¸ë¦¼ì´ ìœ íš¨í•œì§€ í™•ì¸"""
            if stream is None:
                return False
            try:
                if hasattr(stream, 'buffer'):
                    buffer = stream.buffer
                    if buffer is None:
                        return False
                    if hasattr(buffer, 'raw'):
                        raw = buffer.raw
                        if raw is None:
                            return False
                if not hasattr(stream, 'write'):
                    return False
                return True
            except (ValueError, AttributeError, OSError):
                return False
        
        def emit(self, record):
            """ì•ˆì „í•œ ë¡œê·¸ ì¶œë ¥ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
            try:
                msg = self.format(record) + self.terminator
                safe_stream = self._get_safe_stream()
                if safe_stream is not None:
                    try:
                        # ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ê²€ì¦
                        if hasattr(safe_stream, 'buffer'):
                            try:
                                buffer = safe_stream.buffer
                                if buffer is None:
                                    raise ValueError("Buffer is None")
                            except (ValueError, AttributeError):
                                # bufferê°€ ë¶„ë¦¬ëœ ê²½ìš°, ì§ì ‘ write ì‹œë„
                                if hasattr(safe_stream, 'write'):
                                    safe_stream.write(msg)
                                    return
                                else:
                                    raise ValueError("No write method")
                        else:
                            safe_stream.write(msg)
                        
                        try:
                            safe_stream.flush()
                        except (ValueError, AttributeError, OSError):
                            pass
                        return
                    except (ValueError, AttributeError, OSError) as e:
                        # ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ì¸ ê²½ìš° ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                        if "detached" in str(e).lower() or "raw stream" in str(e).lower():
                            pass
                        else:
                            pass
                
                # Fallback: stderr ì‚¬ìš©
                try:
                    if sys.stderr and hasattr(sys.stderr, 'write'):
                        # stderrë„ ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                        try:
                            sys.stderr.write(msg)
                            try:
                                sys.stderr.flush()
                            except (ValueError, AttributeError, OSError):
                                pass
                            return
                        except (ValueError, AttributeError, OSError) as e:
                            if "detached" in str(e).lower() or "raw stream" in str(e).lower():
                                pass
                except (ValueError, AttributeError, OSError):
                    pass
            except Exception:
                # ëª¨ë“  ì˜ˆì™¸ ë¬´ì‹œ (ë¡œê¹… ì‹¤íŒ¨ê°€ ì „ì²´ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•Šë„ë¡)
                pass
        
        def flush(self):
            """ì•ˆì „í•œ flush (ì˜¤ë¥˜ ë¬´ì‹œ)"""
            try:
                safe_stream = self._get_safe_stream()
                if safe_stream is not None:
                    try:
                        safe_stream.flush()
                    except (ValueError, AttributeError, OSError):
                        pass
            except (ValueError, AttributeError, OSError):
                pass
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ìƒì„±
    try:
        base_handler = logging.StreamHandler(_original_stdout)
    except (ValueError, AttributeError):
        try:
            base_handler = logging.StreamHandler(sys.stdout)
        except (ValueError, AttributeError):
            base_handler = logging.StreamHandler(sys.stderr)
    
    # SafeStreamHandlerë¡œ êµì²´
    safe_handler = SafeStreamHandler(base_handler.stream, _original_stdout)
    safe_handler.setLevel(getattr(logging, log_level.upper(), logging.INFO))
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    safe_handler.setFormatter(formatter)
    logger.addHandler(safe_handler)
    
    return logger

logger = setup_logging(os.getenv("TEST_LOG_LEVEL", "INFO"))


def get_query_from_args() -> str:
    """ëª…ë ¹ì¤„ ì¸ìì—ì„œ ì§ˆì˜ ì¶”ì¶œ"""
    default_queries = [
        "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    ]
    
    # 1. í™˜ê²½ ë³€ìˆ˜
    test_query = os.getenv('TEST_QUERY')
    if test_query and test_query.strip():
        return test_query.strip()
    
    # 2. ëª…ë ¹ì¤„ ì¸ì
    if len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        
        # íŒŒì¼ ì˜µì…˜
        if arg in ['-f', '--file']:
            if len(sys.argv) > 2:
                file_path = sys.argv[2]
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        return f.read().strip()
                except Exception as e:
                    logger.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    return default_queries[1]
            else:
                logger.error("íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”")
                return default_queries[1]
        
        # ìˆ«ì ì„ íƒ
        if arg.isdigit():
            idx = int(arg)
            if 0 <= idx < len(default_queries):
                return default_queries[idx]
        
        # ì§ì ‘ ì§ˆì˜
        return " ".join(sys.argv[1:])
    
    # ê¸°ë³¸ ì§ˆì˜
    return default_queries[1]


async def run_query_test(query: str):
    """ì§ˆì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("\n" + "="*80)
    logger.info("LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸")
    logger.info("="*80)
    logger.info(f"\nğŸ“‹ ì§ˆì˜: {query}\n")
    
    try:
        # python-dotenv ê²½ê³  ì–µì œë¥¼ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        import os
        os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
        
        # Import (ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
        # sys.pathê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì§ì ‘ import ê°€ëŠ¥
        try:
            from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        except ImportError:
            # Fallback: ìƒëŒ€ ê²½ë¡œ
            sys.path.insert(0, str(lawfirm_langgraph_dir))
            from config.langgraph_config import LangGraphConfig
        
        try:
            from lawfirm_langgraph.core.workflow.workflow_service import LangGraphWorkflowService
        except ImportError:
            # Fallback: ìƒëŒ€ ê²½ë¡œ
            sys.path.insert(0, str(lawfirm_langgraph_dir))
            from core.workflow.workflow_service import LangGraphWorkflowService
        
        # ì„¤ì • ë¡œë“œ
        logger.info("1ï¸âƒ£  ì„¤ì • ë¡œë“œ ì¤‘...")
        
        # MLflow ì¸ë±ìŠ¤ ì‚¬ìš© ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if not os.getenv('USE_MLFLOW_INDEX'):
            os.environ['USE_MLFLOW_INDEX'] = 'true'
            logger.info("   ğŸ“Œ USE_MLFLOW_INDEX=true ì„¤ì •ë¨")
        
        if not os.getenv('MLFLOW_TRACKING_URI'):
            # MLflow tracking URI ì„¤ì •
            mlflow_uri = str(project_root / "mlflow" / "mlruns")
            os.environ['MLFLOW_TRACKING_URI'] = f"file:///{mlflow_uri.replace(chr(92), '/')}"
            logger.info(f"   ğŸ“Œ MLFLOW_TRACKING_URI ì„¤ì •ë¨")
        
        # MLFLOW_RUN_IDê°€ ì—†ìœ¼ë©´ í”„ë¡œë•ì…˜ run ìë™ ì¡°íšŒ (ë¹„ì›Œë‘ë©´ ìë™)
        if not os.getenv('MLFLOW_RUN_ID'):
            logger.info("   ğŸ“Œ MLFLOW_RUN_ID ë¹„ì–´ìˆìŒ - í”„ë¡œë•ì…˜ run ìë™ ì¡°íšŒ ì˜ˆì •")
        else:
            logger.info(f"   ğŸ“Œ MLFLOW_RUN_ID={os.getenv('MLFLOW_RUN_ID')} ì„¤ì •ë¨")
        
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        logger.info(f"   âœ… LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        logger.info(f"   âœ… ì²´í¬í¬ì¸íŠ¸: {config.enable_checkpoint}")
        
        # MLflow ì¸ë±ìŠ¤ ì„¤ì • í™•ì¸
        from lawfirm_langgraph.core.utils.config import Config
        config_obj = Config()
        if config_obj.use_mlflow_index:
            logger.info(f"   âœ… MLflow ì¸ë±ìŠ¤ ì‚¬ìš©: run_id={config_obj.mlflow_run_id or 'ìë™ ì¡°íšŒ'}")
        else:
            logger.info(f"   â„¹ï¸  MLflow ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš© (DB ê¸°ë°˜ ì¸ë±ìŠ¤ ì‚¬ìš©)")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("\n2ï¸âƒ£  LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        service = LangGraphWorkflowService(config)
        logger.info("   âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì§ˆì˜ ì²˜ë¦¬
        logger.info("\n3ï¸âƒ£  ì§ˆì˜ ì²˜ë¦¬ ì¤‘...")
        logger.info("   (ì´ ì‘ì—…ì€ ëª‡ ì´ˆì—ì„œ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        result = await service.process_query(
            query=query,
            session_id="query_test",
            enable_checkpoint=False,
            use_astream_events=True
        )
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n4ï¸âƒ£  ê²°ê³¼:")
        logger.info("="*80)
        
        # ë‹µë³€
        answer = result.get("answer", "")
        if isinstance(answer, dict):
            answer = answer.get("content", answer.get("text", str(answer)))
        
        if answer:
            logger.info(f"\nğŸ“ ë‹µë³€ ({len(str(answer))}ì):")
            logger.info("-" * 80)
            logger.info(str(answer))
        else:
            logger.warning("<ë‹µë³€ ì—†ìŒ>")
        
        # retrieved_docs (ë°ì´í„°ë² ì´ìŠ¤/ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•œ ì°¸ê³ ìë£Œ)
        retrieved_docs = result.get("retrieved_docs", [])
        if retrieved_docs:
            logger.info(f"\nğŸ” ê²€ìƒ‰ëœ ì°¸ê³ ìë£Œ (retrieved_docs) ({len(retrieved_docs)}ê°œ):")
            
            # íƒ€ì…ë³„ ë¶„í¬ í™•ì¸
            type_counts = {}
            statute_articles = []
            version_counts = {}
            scores = []
            for doc in retrieved_docs:
                if isinstance(doc, dict):
                    doc_type = doc.get("type") or doc.get("source_type") or doc.get("metadata", {}).get("source_type", "unknown")
                    type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
                    if doc_type == "statute_article":
                        statute_articles.append(doc)
                    
                    # ë²„ì „ ì •ë³´ ìˆ˜ì§‘
                    version_id = doc.get("embedding_version_id") or doc.get("metadata", {}).get("embedding_version_id")
                    if version_id:
                        version_counts[version_id] = version_counts.get(version_id, 0) + 1
                    
                    # ìœ ì‚¬ë„ ì ìˆ˜ ìˆ˜ì§‘
                    score = doc.get("score") or doc.get("similarity") or doc.get("relevance_score")
                    if score is not None:
                        scores.append(float(score))
            
            logger.info(f"   íƒ€ì… ë¶„í¬: {type_counts}")
            if statute_articles:
                logger.info(f"   statute_article íƒ€ì… ë¬¸ì„œ: {len(statute_articles)}ê°œ")
            
            # ë²„ì „ ë¶„í¬ ì¶œë ¥
            if version_counts:
                logger.info(f"   ğŸ“Š Embedding ë²„ì „ ë¶„í¬: {version_counts}")
            else:
                logger.warning("   âš ï¸  ê²€ìƒ‰ ê²°ê³¼ì— embedding_version_idê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            # ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬ ë¶„ì„
            if scores:
                avg_score = sum(scores) / len(scores)
                max_score = max(scores)
                min_score = min(scores)
                logger.info(f"   ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬: í‰ê· ={avg_score:.3f}, ìµœëŒ€={max_score:.3f}, ìµœì†Œ={min_score:.3f}")
            
            for i, doc in enumerate(retrieved_docs[:10], 1):
                if isinstance(doc, dict):
                    doc_id = doc.get("doc_id") or doc.get("id") or doc.get("_id") or f"doc_{i}"
                    doc_type = doc.get("type") or doc.get("source_type") or doc.get("metadata", {}).get("source_type", "unknown")
                    title = doc.get("title") or doc.get("name") or doc.get("content", "")[:50] or "ì œëª© ì—†ìŒ"
                    search_type = doc.get("search_type") or doc.get("search_method") or "unknown"
                    logger.info(f"   {i}. [{doc_type}] {title} (ID: {doc_id}, ê²€ìƒ‰ë°©ë²•: {search_type})")
                    
                    # statute_article íƒ€ì… ë¬¸ì„œì˜ ê²½ìš° ìƒì„¸ ì •ë³´ ì¶œë ¥
                    if doc_type == "statute_article":
                        statute_name = doc.get("statute_name") or doc.get("law_name") or doc.get("metadata", {}).get("statute_name") or doc.get("metadata", {}).get("law_name")
                        article_no = doc.get("article_no") or doc.get("article_number") or doc.get("metadata", {}).get("article_no") or doc.get("metadata", {}).get("article_number")
                        clause_no = doc.get("clause_no") or doc.get("metadata", {}).get("clause_no")
                        item_no = doc.get("item_no") or doc.get("metadata", {}).get("item_no")
                        logger.info(f"      - statute_name: {statute_name}")
                        logger.info(f"      - article_no: {article_no}")
                        logger.info(f"      - clause_no: {clause_no}")
                        logger.info(f"      - item_no: {item_no}")
                    
                    # ìƒì„¸ ì •ë³´ (ì„ íƒì )
                    if doc.get("score"):
                        logger.info(f"      - ì ìˆ˜: {doc.get('score'):.4f}")
                    
                    # ë²„ì „ ì •ë³´ ì¶œë ¥
                    version_id = doc.get("embedding_version_id") or doc.get("metadata", {}).get("embedding_version_id")
                    if version_id:
                        logger.info(f"      - embedding_version_id: {version_id}")
                    
                    if doc.get("metadata") and doc_type != "statute_article":
                        logger.info(f"      - ë©”íƒ€ë°ì´í„°: {doc.get('metadata')}")
                else:
                    logger.info(f"   {i}. {str(doc)[:100]}")
            if len(retrieved_docs) > 10:
                logger.info(f"   ... (ì´ {len(retrieved_docs)}ê°œ)")
        else:
            logger.warning("\nâš ï¸  ê²€ìƒ‰ëœ ì°¸ê³ ìë£Œ (retrieved_docs)ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning("   - ë°ì´í„°ë² ì´ìŠ¤/ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜")
            logger.warning("   - ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì†ŒìŠ¤ (retrieved_docsì—ì„œ ë³€í™˜ëœ sources)
        sources = result.get("sources", [])
        if sources:
            logger.info(f"\nğŸ“š ì†ŒìŠ¤ (sources) ({len(sources)}ê°œ):")
            for i, source in enumerate(sources[:10], 1):
                if isinstance(source, dict):
                    source_id = source.get("id") or source.get("doc_id") or source.get("_id") or f"source_{i}"
                    source_name = source.get("name") or source.get("title") or source.get("content", "")[:50] or "ì œëª© ì—†ìŒ"
                    logger.info(f"   {i}. {source_name} (ID: {source_id})")
                else:
                    logger.info(f"   {i}. {source}")
            if len(sources) > 10:
                logger.info(f"   ... (ì´ {len(sources)}ê°œ)")
        else:
            logger.warning("\nâš ï¸  ì†ŒìŠ¤ (sources)ê°€ ì—†ìŠµë‹ˆë‹¤!")
            if retrieved_docs:
                logger.warning(f"   - retrieved_docsëŠ” {len(retrieved_docs)}ê°œ ìˆì§€ë§Œ sourcesë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.warning("   - prepare_final_response_partì—ì„œ sources ìƒì„± ê³¼ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                logger.warning("   - retrieved_docsë„ ì—†ì–´ sourcesë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # sources_detail
        sources_detail = result.get("sources_detail", [])
        if sources_detail:
            logger.info(f"\nğŸ“‹ ì†ŒìŠ¤ ìƒì„¸ (sources_detail) ({len(sources_detail)}ê°œ):")
            for i, detail in enumerate(sources_detail[:5], 1):
                if isinstance(detail, dict):
                    name = detail.get("name") or detail.get("title") or "ì œëª© ì—†ìŒ"
                    doc_id = detail.get("id") or detail.get("doc_id") or f"detail_{i}"
                    source_type = detail.get("type") or detail.get("source_type") or "unknown"
                    logger.info(f"   {i}. [{source_type}] {name} (ID: {doc_id})")
                else:
                    logger.info(f"   {i}. {detail}")
            if len(sources_detail) > 5:
                logger.info(f"   ... (ì´ {len(sources_detail)}ê°œ)")
        
        # ë²•ë¥  ì°¸ì¡°
        legal_references = result.get("legal_references", [])
        if legal_references:
            logger.info(f"\nâš–ï¸  ë²•ë¥  ì°¸ì¡° ({len(legal_references)}ê°œ):")
            for i, ref in enumerate(legal_references[:5], 1):
                logger.info(f"   {i}. {ref}")
            if len(legal_references) > 5:
                logger.info(f"   ... (ì´ {len(legal_references)}ê°œ)")
        else:
            logger.warning("\nâš ï¸  ë²•ë¥  ì°¸ì¡° (legal_references)ê°€ ì—†ìŠµë‹ˆë‹¤!")
            if retrieved_docs:
                # statute_article íƒ€ì… ë¬¸ì„œ í™•ì¸
                statute_articles = [doc for doc in retrieved_docs if isinstance(doc, dict) and (doc.get("type") == "statute_article" or doc.get("source_type") == "statute_article" or doc.get("metadata", {}).get("source_type") == "statute_article")]
                if statute_articles:
                    logger.warning(f"   - retrieved_docsì— statute_article íƒ€ì… ë¬¸ì„œê°€ {len(statute_articles)}ê°œ ìˆì§€ë§Œ legal_referencesë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    logger.info("\n   statute_article ë¬¸ì„œ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                    for i, doc in enumerate(statute_articles[:3], 1):
                        logger.info(f"   {i}. type: {doc.get('type')}, statute_name: {doc.get('statute_name')}, law_name: {doc.get('law_name')}, article_no: {doc.get('article_no')}, metadata: {doc.get('metadata', {})}")
                else:
                    logger.warning("   - retrieved_docsì— statute_article íƒ€ì… ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    logger.info("\n   retrieved_docs íƒ€ì… ë¶„í¬:")
                    type_counts = {}
                    for doc in retrieved_docs:
                        if isinstance(doc, dict):
                            doc_type = doc.get("type") or doc.get("source_type") or doc.get("metadata", {}).get("source_type", "unknown")
                            type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
                    for doc_type, count in type_counts.items():
                        logger.info(f"      - {doc_type}: {count}ê°œ")
        
        # ê´€ë ¨ ì§ˆë¬¸ (related_questions)
        related_questions = result.get("metadata", {}).get("related_questions", [])
        if related_questions:
            logger.info(f"\nâ“ ê´€ë ¨ ì§ˆë¬¸ (related_questions) ({len(related_questions)}ê°œ):")
            for i, question in enumerate(related_questions[:5], 1):
                logger.info(f"   {i}. {question}")
            if len(related_questions) > 5:
                logger.info(f"   ... (ì´ {len(related_questions)}ê°œ)")
        else:
            logger.warning("\nâš ï¸  ê´€ë ¨ ì§ˆë¬¸ (related_questions)ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning("   ê°€ëŠ¥í•œ ì›ì¸:")
            logger.warning("   1. phase_infoì— suggested_questionsê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   2. conversation_flow_trackerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   3. metadataì— ì €ì¥ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ë©”íƒ€ë°ì´í„°
        metadata = result.get("metadata", {})
        if metadata:
            logger.info(f"\nğŸ“Š ë©”íƒ€ë°ì´í„°:")
            for key, value in list(metadata.items())[:10]:
                if key == "related_questions":
                    logger.info(f"   {key}: {value} ({len(value) if isinstance(value, list) else 'N/A'}ê°œ)")
                else:
                    logger.info(f"   {key}: {value}")
        
        # ì‹ ë¢°ë„
        confidence = result.get("confidence", 0.0)
        if confidence:
            logger.info(f"\nğŸ¯ ì‹ ë¢°ë„: {confidence:.2f}")
        
        # ì²˜ë¦¬ ì‹œê°„
        processing_time = result.get("processing_time", 0.0)
        if processing_time:
            logger.info(f"\nâ±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        
        # ë””ë²„ê¹…: retrieved_docsì™€ sources ê´€ê³„ ë¶„ì„
        logger.info("\n" + "="*80)
        logger.info("ğŸ” ë””ë²„ê¹… ì •ë³´:")
        logger.info("="*80)
        
        if retrieved_docs and not sources:
            logger.warning("âš ï¸  retrieved_docsëŠ” ìˆì§€ë§Œ sourcesê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning("   ê°€ëŠ¥í•œ ì›ì¸:")
            logger.warning("   1. prepare_final_response_partê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   2. retrieved_docsì˜ í˜•ì‹ì´ sources ìƒì„± ë¡œì§ê³¼ ë§ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   3. source_typeì´ ì—†ê±°ë‚˜ ì¸ì‹ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.info("\n   retrieved_docs ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
            for i, doc in enumerate(retrieved_docs[:3], 1):
                logger.info(f"   {i}. {doc}")
        elif not retrieved_docs and not sources:
            logger.warning("âš ï¸  retrieved_docsì™€ sources ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning("   ê°€ëŠ¥í•œ ì›ì¸:")
            logger.warning("   1. ê²€ìƒ‰ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (direct_answer ë…¸ë“œ ì‚¬ìš©).")
            logger.warning("   2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   3. retrieved_docsê°€ stateì—ì„œ ì†ì‹¤ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif retrieved_docs and sources:
            logger.info(f"âœ… retrieved_docs ({len(retrieved_docs)}ê°œ) â†’ sources ({len(sources)}ê°œ) ë³€í™˜ ì„±ê³µ")
            if len(retrieved_docs) > len(sources):
                logger.warning(f"   âš ï¸  ì¼ë¶€ retrieved_docsê°€ sourcesë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logger.warning(f"   ({len(retrieved_docs) - len(sources)}ê°œ ëˆ„ë½)")
        
        # legal_references ë””ë²„ê¹…
        if retrieved_docs and not legal_references:
            statute_articles = [doc for doc in retrieved_docs if isinstance(doc, dict) and (doc.get("type") == "statute_article" or doc.get("source_type") == "statute_article" or doc.get("metadata", {}).get("source_type") == "statute_article")]
            if statute_articles:
                logger.warning(f"\nâš ï¸  retrieved_docsì— statute_article íƒ€ì… ë¬¸ì„œê°€ {len(statute_articles)}ê°œ ìˆì§€ë§Œ legal_referencesë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                logger.warning("   ê°€ëŠ¥í•œ ì›ì¸:")
                logger.warning("   1. prepare_final_response_partê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logger.warning("   2. statute_nameì´ë‚˜ article_no í•„ë“œê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logger.warning("   3. legal_references ìƒì„± ë¡œì§ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logger.info("\n   statute_article ë¬¸ì„œ ìƒì„¸ (ì²˜ìŒ 3ê°œ):")
                for i, doc in enumerate(statute_articles[:3], 1):
                    logger.info(f"   {i}. ì „ì²´ êµ¬ì¡°:")
                    logger.info(f"      {doc}")
        
        # related_questions ë””ë²„ê¹…
        if not related_questions:
            logger.warning(f"\nâš ï¸  related_questionsê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.warning("   ê°€ëŠ¥í•œ ì›ì¸:")
            logger.warning("   1. phase_infoì— suggested_questionsê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   2. conversation_flow_trackerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            logger.warning("   3. metadataì— ì €ì¥ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # phase_info í™•ì¸
            if "phase_info" in result:
                phase_info = result.get("phase_info", {})
                logger.info(f"\n   phase_info í™•ì¸:")
                logger.info(f"      phase_info keys: {list(phase_info.keys()) if isinstance(phase_info, dict) else 'N/A'}")
                if isinstance(phase_info, dict) and "phase2" in phase_info:
                    phase2 = phase_info.get("phase2", {})
                    if isinstance(phase2, dict) and "flow_tracking_info" in phase2:
                        flow_tracking = phase2.get("flow_tracking_info", {})
                        if isinstance(flow_tracking, dict) and "suggested_questions" in flow_tracking:
                            suggested_questions = flow_tracking.get("suggested_questions", [])
                            logger.info(f"      suggested_questions in phase_info: {len(suggested_questions)}ê°œ")
                        else:
                            logger.warning("      suggested_questionsê°€ phase_infoì— ì—†ìŠµë‹ˆë‹¤.")
        
        # needs_search í™•ì¸
        needs_search = result.get("needs_search", True)
        logger.info(f"\n   needs_search: {needs_search}")
        if not needs_search:
            logger.info("   â†’ direct_answer ë…¸ë“œê°€ ì‚¬ìš©ë˜ì–´ ê²€ìƒ‰ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        logger.info("\n" + "="*80)
        logger.info("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        logger.info("="*80)
        
        return result
        
    except ImportError as e:
        logger.error(f"\nâŒ Import ì˜¤ë¥˜: {e}")
        logger.error("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        logger.error(f"   í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
        logger.error(f"   lawfirm_langgraph ë””ë ‰í† ë¦¬: {lawfirm_langgraph_dir}")
        import sys
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}", exc_info=True)
        import sys
        sys.exit(1)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # stderr ë³µì› (ëª¨ë“ˆ import í›„) - ì´ë¯¸ ë¦¬ë‹¤ì´ë ‰íŠ¸í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”
        # global _original_stderr
        # try:
        #     if hasattr(sys.stderr, 'close'):
        #         sys.stderr.close()
        # except:
        #     pass
        # sys.stderr = _original_stderr
        
        query = get_query_from_args()
        
        if not query:
            logger.error("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            logger.info("\nì‚¬ìš©ë²•:")
            logger.info("  python run_query_test.py \"ì§ˆì˜ ë‚´ìš©\"")
            logger.info("  python run_query_test.py 0  # ê¸°ë³¸ ì§ˆì˜ ì„ íƒ")
            logger.info("  $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python run_query_test.py")
            return 1
        
        result = asyncio.run(run_query_test(query))
        return 0
        
    except KeyboardInterrupt:
        logger.warning("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        logger.error(f"\n\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())

