# -*- coding: utf-8 -*-
"""
í”„ë¡¬í”„íŠ¸ ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
tests_dir = script_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

def test_query_diversifier():
    """ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™” í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("1. ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™” í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.workflow.utils.query_diversifier import QueryDiversifier
        
        diversifier = QueryDiversifier()
        test_query = "ì „ì„¸ê¸ˆ ë°˜í™˜ ë³´ì¦ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        
        diversified = diversifier.diversify_search_queries(test_query)
        
        print(f"\nğŸ“ ì›ë³¸ ì¿¼ë¦¬: {test_query}")
        print(f"\nğŸ“Š ë‹¤ë³€í™”ëœ ì¿¼ë¦¬:")
        for query_type, queries in diversified.items():
            print(f"   - {query_type}: {len(queries)}ê°œ")
            for i, q in enumerate(queries[:3], 1):
                print(f"     {i}. {q}")
        
        # ê²€ì¦
        assert "statute" in diversified, "statute ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"
        assert "case" in diversified, "case ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"
        assert "decision" in diversified, "decision ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"
        assert "interpretation" in diversified, "interpretation ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"
        
        print("\nâœ… ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™” í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    except Exception as e:
        print(f"\nâŒ ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_search_result_balancer():
    """ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì • í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("2. ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì • í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.workflow.utils.search_result_balancer import SearchResultBalancer
        
        balancer = SearchResultBalancer(min_per_type=1, max_per_type=5)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_results = {
            "statute_article": [
                {"type": "statute_article", "relevance_score": 0.8, "content": "ë²•ë ¹ ì¡°ë¬¸ 1"},
                {"type": "statute_article", "relevance_score": 0.7, "content": "ë²•ë ¹ ì¡°ë¬¸ 2"},
            ],
            "case_paragraph": [
                {"type": "case_paragraph", "relevance_score": 0.9, "content": "íŒë¡€ 1"},
                {"type": "case_paragraph", "relevance_score": 0.85, "content": "íŒë¡€ 2"},
                {"type": "case_paragraph", "relevance_score": 0.8, "content": "íŒë¡€ 3"},
                {"type": "case_paragraph", "relevance_score": 0.75, "content": "íŒë¡€ 4"},
                {"type": "case_paragraph", "relevance_score": 0.7, "content": "íŒë¡€ 5"},
            ],
            "decision_paragraph": [
                {"type": "decision_paragraph", "relevance_score": 0.6, "content": "ê²°ì •ë¡€ 1"},
            ],
            "interpretation_paragraph": [
                {"type": "interpretation_paragraph", "relevance_score": 0.5, "content": "í•´ì„ë¡€ 1"},
            ]
        }
        
        balanced = balancer.balance_search_results(test_results, total_limit=10)
        
        print(f"\nğŸ“Š ê· í˜• ì¡°ì • ì „:")
        for doc_type, docs in test_results.items():
            print(f"   - {doc_type}: {len(docs)}ê°œ")
        
        print(f"\nğŸ“Š ê· í˜• ì¡°ì • í›„:")
        balanced_types = {}
        for doc in balanced:
            doc_type = doc.get("type", "unknown")
            balanced_types[doc_type] = balanced_types.get(doc_type, 0) + 1
        
        for doc_type, count in balanced_types.items():
            print(f"   - {doc_type}: {count}ê°œ")
        
        # ê²€ì¦: ê° íƒ€ì…ì—ì„œ ìµœì†Œ 1ê°œì”© ìˆëŠ”ì§€ í™•ì¸
        assert balanced_types.get("statute_article", 0) >= 1, "ë²•ë ¹ ì¡°ë¬¸ì´ 1ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        assert balanced_types.get("case_paragraph", 0) >= 1, "íŒë¡€ê°€ 1ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        assert balanced_types.get("decision_paragraph", 0) >= 1, "ê²°ì •ë¡€ê°€ 1ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        assert balanced_types.get("interpretation_paragraph", 0) >= 1, "í•´ì„ë¡€ê°€ 1ê°œ ì´ìƒ ìˆì–´ì•¼ í•©ë‹ˆë‹¤"
        
        print("\nâœ… ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì • í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    except Exception as e:
        print(f"\nâŒ ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dynamic_prompt_builder():
    """ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("3. ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.agents.prompt_builders.dynamic_prompt_builder import DynamicPromptBuilder
        
        builder = DynamicPromptBuilder()
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
        test_documents = [
            {"type": "statute_article", "content": "ë²•ë ¹ ì¡°ë¬¸ ë‚´ìš©"},
            {"type": "case_paragraph", "content": "íŒë¡€ ë‚´ìš©"},
            {"type": "case_paragraph", "content": "íŒë¡€ ë‚´ìš© 2"},
            {"type": "decision_paragraph", "content": "ê²°ì •ë¡€ ë‚´ìš©"},
        ]
        
        # ë¬¸ì„œ íƒ€ì… ë¶„ì„
        doc_types = builder.analyze_document_types(test_documents)
        print(f"\nğŸ“Š ë¬¸ì„œ íƒ€ì… ë¶„í¬:")
        for doc_type, count in doc_types.items():
            print(f"   - {doc_type}: {count}ê°œ")
        
        # Citation ì§€ì¹¨ ìƒì„±
        citation_guidance = builder.build_citation_guidance(doc_types, len(test_documents))
        print(f"\nğŸ“ Citation ì§€ì¹¨:")
        print(citation_guidance)
        
        # ë¬¸ì„œ íƒ€ì…ë³„ í™œìš© ì§€ì¹¨ ìƒì„±
        type_guidance = builder.build_document_type_guidance(doc_types)
        print(f"\nğŸ“ ë¬¸ì„œ íƒ€ì…ë³„ í™œìš© ì§€ì¹¨:")
        print(type_guidance)
        
        # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜ ìƒì„±
        prompt_section = builder.build_simplified_prompt_section(test_documents, len(test_documents))
        print(f"\nğŸ“ ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜:")
        print(prompt_section[:500] + "..." if len(prompt_section) > 500 else prompt_section)
        
        # ê²€ì¦
        assert "statute_article" in doc_types, "ë²•ë ¹ ì¡°ë¬¸ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤"
        assert "case_paragraph" in doc_types, "íŒë¡€ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤"
        assert len(citation_guidance) > 0, "Citation ì§€ì¹¨ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        
        print("\nâœ… ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    except Exception as e:
        print(f"\nâŒ ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_unified_prompt_manager_integration():
    """UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("4. UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from core.agents.prompt_builders.unified_prompt_manager import UnifiedPromptManager, LegalDomain, ModelType
        from core.classification.classifiers.question_classifier import QuestionType
        
        manager = UnifiedPromptManager()
        
        # í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        test_context = {
            "structured_documents": {
                "documents": [
                    {
                        "type": "case_paragraph",
                        "content": "íŒë¡€ ë‚´ìš© í…ŒìŠ¤íŠ¸",
                        "relevance_score": 0.8,
                        "source": "íŒë¡€ 1"
                    },
                    {
                        "type": "case_paragraph",
                        "content": "íŒë¡€ ë‚´ìš© í…ŒìŠ¤íŠ¸ 2",
                        "relevance_score": 0.7,
                        "source": "íŒë¡€ 2"
                    }
                ]
            },
            "document_count": 2
        }
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = manager.get_optimized_prompt(
            query="ì „ì„¸ê¸ˆ ë°˜í™˜ ë³´ì¦ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            question_type=QuestionType.TERM_EXPLANATION,
            domain=LegalDomain.GENERAL,
            context=test_context,
            model_type=ModelType.GEMINI
        )
        
        print(f"\nğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")
        print(f"\nğŸ“‹ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
        print(prompt[:500] + "...")
        
        # ê²€ì¦
        assert len(prompt) > 0, "í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        assert "ì „ì„¸ê¸ˆ ë°˜í™˜ ë³´ì¦" in prompt, "ì§ˆë¬¸ì´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        
        # ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë”ê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
        # (í”„ë¡¬í”„íŠ¸ì— ë¬¸ì„œ íƒ€ì… ë¶„í¬ë‚˜ ë™ì  ì§€ì¹¨ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸)
        has_dynamic_content = (
            "ë¬¸ì„œ íƒ€ì… ë¶„í¬" in prompt or
            "Citation ìš”êµ¬ì‚¬í•­" in prompt or
            "ë¬¸ì„œ íƒ€ì…ë³„ í™œìš©" in prompt
        )
        
        if has_dynamic_content:
            print("\nâœ… ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë”ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("\nâš ï¸ ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë”ê°€ ì‚¬ìš©ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì •ìƒì¼ ìˆ˜ ìˆìŒ)")
        
        print("\nâœ… UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    except Exception as e:
        print(f"\nâŒ UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "=" * 80)
    print("í”„ë¡¬í”„íŠ¸ ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    results = []
    
    # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™” í…ŒìŠ¤íŠ¸
    results.append(("ê²€ìƒ‰ ì¿¼ë¦¬ ë‹¤ë³€í™”", test_query_diversifier()))
    
    # 2. ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì • í…ŒìŠ¤íŠ¸
    results.append(("ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… ê· í˜• ì¡°ì •", test_search_result_balancer()))
    
    # 3. ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í…ŒìŠ¤íŠ¸
    results.append(("ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë”", test_dynamic_prompt_builder()))
    
    # 4. UnifiedPromptManager í†µí•© í…ŒìŠ¤íŠ¸
    results.append(("UnifiedPromptManager í†µí•©", test_unified_prompt_manager_integration()))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    passed = 0
    failed = 0
    
    for test_name, result in results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"{status}: {test_name}")
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\nì´ {len(results)}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {passed}ê°œ í†µê³¼, {failed}ê°œ ì‹¤íŒ¨")
    
    if failed == 0:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        print(f"\nâš ï¸ {failed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1

if __name__ == "__main__":
    sys.exit(main())

