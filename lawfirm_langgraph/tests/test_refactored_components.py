# -*- coding: utf-8 -*-
"""ë¦¬íŒ©í† ë§ëœ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def test_source_extractor():
    """SourceExtractor í…ŒìŠ¤íŠ¸"""
    print("\n=== SourceExtractor í…ŒìŠ¤íŠ¸ ===")
    
    from lawfirm_langgraph.core.agents.handlers.extractors.source_extractor import SourceExtractor
    
    extractor = SourceExtractor()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: detail ìµœìƒìœ„ ë ˆë²¨ì— ê°’ì´ ìˆëŠ” ê²½ìš°
    detail1 = {
        "type": "statute_article",
        "statute_name": "ë¯¼ë²•",
        "article_no": "ì œ1ì¡°",
        "metadata": {}
    }
    result1 = extractor.extract_statute_info(detail1)
    assert result1 == ("ë¯¼ë²•", "ì œ1ì¡°"), f"Expected ('ë¯¼ë²•', 'ì œ1ì¡°'), got {result1}"
    print("âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: detail ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì¶”ì¶œ")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: metadataì— ê°’ì´ ìˆëŠ” ê²½ìš°
    detail2 = {
        "type": "statute_article",
        "metadata": {
            "statute_name": "í˜•ë²•",
            "article_no": "ì œ2ì¡°"
        }
    }
    result2 = extractor.extract_statute_info(detail2)
    assert result2 == ("í˜•ë²•", "ì œ2ì¡°"), f"Expected ('í˜•ë²•', 'ì œ2ì¡°'), got {result2}"
    print("âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: metadataì—ì„œ ì¶”ì¶œ")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ë‹¤ë¥¸ í•„ë“œëª… ì‚¬ìš©
    detail3 = {
        "type": "statute_article",
        "law_name": "ìƒë²•",
        "article_number": "ì œ3ì¡°",
        "metadata": {}
    }
    result3 = extractor.extract_statute_info(detail3)
    assert result3 == ("ìƒë²•", "ì œ3ì¡°"), f"Expected ('ìƒë²•', 'ì œ3ì¡°'), got {result3}"
    print("âœ… í…ŒìŠ¤íŠ¸ 3 í†µê³¼: ë‹¤ë¥¸ í•„ë“œëª…ì—ì„œ ì¶”ì¶œ")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 4: legal_references ìƒì„±
    sources_detail = [
        {
            "type": "statute_article",
            "statute_name": "ë¯¼ë²•",
            "article_no": "ì œ1ì¡°",
            "clause_no": "1",
            "item_no": "1",
            "metadata": {}
        },
        {
            "type": "statute_article",
            "metadata": {
                "statute_name": "í˜•ë²•",
                "article_no": "ì œ2ì¡°"
            }
        }
    ]
    legal_refs = extractor.extract_legal_references_from_sources_detail(sources_detail)
    assert len(legal_refs) == 2, f"Expected 2 legal references, got {len(legal_refs)}"
    assert "ë¯¼ë²• ì œ1ì¡° ì œ1í•­ ì œ1í˜¸" in legal_refs, "ë¯¼ë²• ì œ1ì¡° ì œ1í•­ ì œ1í˜¸ should be in legal_refs"
    assert "í˜•ë²• ì œ2ì¡°" in legal_refs, "í˜•ë²• ì œ2ì¡° should be in legal_refs"
    print("âœ… í…ŒìŠ¤íŠ¸ 4 í†µê³¼: legal_references ìƒì„±")
    
    print("\nâœ… SourceExtractor ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_confidence_manager():
    """ConfidenceManager í…ŒìŠ¤íŠ¸"""
    print("\n=== ConfidenceManager í…ŒìŠ¤íŠ¸ ===")
    
    from lawfirm_langgraph.core.agents.handlers.managers.confidence_manager import ConfidenceManager
    
    manager = ConfidenceManager()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ì‹ ë¢°ë„ êµì²´
    text = "**ì‹ ë¢°ë„: 50.0%**\nğŸŸ¡ **ì‹ ë¢°ë„: 60.0%**"
    confidence = 0.75
    result = manager.replace_in_text(text, confidence)
    assert "75.0%" in result, "ì‹ ë¢°ë„ ê°’ì´ êµì²´ë˜ì–´ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: ì‹ ë¢°ë„ ê°’ êµì²´")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ì´ëª¨ì§€ ë° ë ˆë²¨ í™•ì¸
    emoji = manager.get_emoji(0.75)
    level = manager.get_level(0.75)
    assert emoji == "ğŸŸ¡", f"Expected ğŸŸ¡, got {emoji}"
    assert level == "medium", f"Expected medium, got {level}"
    print("âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: ì´ëª¨ì§€ ë° ë ˆë²¨ ë°˜í™˜")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì‹ ë¢°ë„ ì„¹ì…˜ êµì²´
    text_with_section = "### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\nğŸŸ¡ **ì‹ ë¢°ë„: 60.0%** (medium)\n\n---"
    result = manager.replace_confidence_section(text_with_section, 0.85)
    assert "85.0%" in result, "ì‹ ë¢°ë„ ì„¹ì…˜ì´ êµì²´ë˜ì–´ì•¼ í•¨"
    assert "high" in result, "ë ˆë²¨ì´ highì—¬ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 3 í†µê³¼: ì‹ ë¢°ë„ ì„¹ì…˜ êµì²´")
    
    print("\nâœ… ConfidenceManager ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_answer_cleaner():
    """AnswerCleaner í…ŒìŠ¤íŠ¸"""
    print("\n=== AnswerCleaner í…ŒìŠ¤íŠ¸ ===")
    
    from lawfirm_langgraph.core.agents.handlers.cleaners.answer_cleaner import AnswerCleaner
    
    cleaner = AnswerCleaner()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ë©”íƒ€ë°ì´í„° ì„¹ì…˜ ì œê±°
    text_with_metadata = "ë‹µë³€ ë‚´ìš©\n\n### ğŸ’¡ ì‹ ë¢°ë„ì •ë³´\nì‹ ë¢°ë„: 75%\n\n### ğŸ“š ì°¸ê³ ìë£Œ\nì°¸ê³  ìë£Œ\n\nì‹¤ì œ ë‹µë³€ ë‚´ìš©"
    result = cleaner.remove_metadata_sections(text_with_metadata)
    assert "ì‹ ë¢°ë„ì •ë³´" not in result, f"ì‹ ë¢°ë„ ì •ë³´ ì„¹ì…˜ì´ ì œê±°ë˜ì–´ì•¼ í•¨. ê²°ê³¼: {result[:200]}"
    assert "ì°¸ê³ ìë£Œ" not in result, f"ì°¸ê³ ìë£Œ ì„¹ì…˜ì´ ì œê±°ë˜ì–´ì•¼ í•¨. ê²°ê³¼: {result[:200]}"
    assert "ë‹µë³€ ë‚´ìš©" in result or "ì‹¤ì œ ë‹µë³€" in result, f"ì‹¤ì œ ë‹µë³€ì€ ìœ ì§€ë˜ì–´ì•¼ í•¨. ê²°ê³¼: {result[:200]}"
    print("âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: ë©”íƒ€ë°ì´í„° ì„¹ì…˜ ì œê±°")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ì¤‘ë³µ í—¤ë” ì œê±°
    text_with_duplicate = "## ë‹µë³€\n\n### ë‹µë³€\n\nì‹¤ì œ ë‚´ìš©"
    result = cleaner.remove_duplicate_headers(text_with_duplicate)
    assert result.count("ë‹µë³€") <= 1, "ì¤‘ë³µ í—¤ë”ê°€ ì œê±°ë˜ì–´ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: ì¤‘ë³µ í—¤ë” ì œê±°")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ë‹µë³€ í—¤ë” ì œê±°
    text_with_header = "## ë‹µë³€\n\nì‹¤ì œ ë‹µë³€ ë‚´ìš©"
    result = cleaner.remove_answer_header(text_with_header)
    assert "## ë‹µë³€" not in result, "ë‹µë³€ í—¤ë”ê°€ ì œê±°ë˜ì–´ì•¼ í•¨"
    assert "ì‹¤ì œ ë‹µë³€ ë‚´ìš©" in result, "ì‹¤ì œ ë‚´ìš©ì€ ìœ ì§€ë˜ì–´ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 3 í†µê³¼: ë‹µë³€ í—¤ë” ì œê±°")
    
    print("\nâœ… AnswerCleaner ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_length_adjuster():
    """AnswerLengthAdjuster í…ŒìŠ¤íŠ¸"""
    print("\n=== AnswerLengthAdjuster í…ŒìŠ¤íŠ¸ ===")
    
    from lawfirm_langgraph.core.agents.handlers.formatters.length_adjuster import AnswerLengthAdjuster
    
    adjuster = AnswerLengthAdjuster()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ì ì ˆí•œ ê¸¸ì´ì˜ ë‹µë³€
    short_answer = "ì§§ì€ ë‹µë³€" * 50
    result = adjuster.adjust_length(short_answer, "simple_question", "simple")
    assert len(result) == len(short_answer), "ì ì ˆí•œ ê¸¸ì´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: ì ì ˆí•œ ê¸¸ì´ ìœ ì§€")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë„ˆë¬´ ê¸´ ë‹µë³€
    long_answer = "ê¸´ ë‹µë³€ ë‚´ìš©ì…ë‹ˆë‹¤. " * 500
    result = adjuster.adjust_length(long_answer, "simple_question", "simple")
    assert len(result) < len(long_answer), "ë„ˆë¬´ ê¸´ ë‹µë³€ì€ ì¤„ì–´ë“¤ì–´ì•¼ í•¨"
    print("âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: ê¸´ ë‹µë³€ ì¶•ì†Œ")
    
    print("\nâœ… AnswerLengthAdjuster ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼")


if __name__ == "__main__":
    print("=" * 60)
    print("ë¦¬íŒ©í† ë§ëœ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    try:
        test_source_extractor()
        test_confidence_manager()
        test_answer_cleaner()
        test_length_adjuster()
        
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("=" * 60)
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

