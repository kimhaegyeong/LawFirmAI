# -*- coding: utf-8 -*-
"""
LangGraph ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python lawfirm_langgraph/tests/run_single_query_test.py "ì§ˆì˜ ë‚´ìš©"
    ì§ˆì˜ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë²•ë¥  ì§ˆë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
import os
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Windows PowerShell í˜¸í™˜)
# ì£¼ì˜: sys.stdout ì¬ì„¤ì •ì€ ë¡œê¹… ì„¤ì • ì „ì— ìˆ˜í–‰í•´ì•¼ í•¨
# ë¡œê¹… í•¸ë“¤ëŸ¬ëŠ” ì›ë³¸ sys.stdoutì„ ì°¸ì¡°í•˜ë„ë¡ ì„¤ì •
_original_stdout = sys.stdout
_original_stderr = sys.stderr

if sys.platform == 'win32':
    # Windowsì—ì„œ UTF-8 ì¶œë ¥ ì„¤ì •
    import io
    
    # í‘œì¤€ ì¶œë ¥/ì—ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ UTF-8ë¡œ ì„¤ì •
    # ë‹¨, ë¡œê¹… í•¸ë“¤ëŸ¬ëŠ” ì›ë³¸ì„ ì‚¬ìš©í•˜ë„ë¡ ì£¼ì˜
    if hasattr(sys.stdout, 'buffer'):
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        except (ValueError, AttributeError):
            # ë²„í¼ê°€ ì´ë¯¸ ë¶„ë¦¬ëœ ê²½ìš° ì›ë³¸ ì‚¬ìš©
            pass
    if hasattr(sys.stderr, 'buffer'):
        try:
            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        except (ValueError, AttributeError):
            # ë²„í¼ê°€ ì´ë¯¸ ë¶„ë¦¬ëœ ê²½ìš° ì›ë³¸ ì‚¬ìš©
            pass
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    
    # PowerShell ì¸ì½”ë”© ì„¤ì • ì‹œë„
    try:
        import subprocess
        # PowerShell ì½”ë“œ í˜ì´ì§€ë¥¼ UTF-8ë¡œ ì„¤ì •
        subprocess.run(['chcp', '65001'], shell=True, capture_output=True, check=False)
    except Exception:
        pass  # chcp ëª…ë ¹ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# lawfirm_langgraph ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
lawfirm_langgraph_path = Path(__file__).parent.parent
sys.path.insert(0, str(lawfirm_langgraph_path))

# ë¡œê¹… ì„¤ì •
def setup_test_logging(log_to_file: bool = False, log_level: str = "INFO"):
    """
    í…ŒìŠ¤íŠ¸ ë¡œê¹… ì„¤ì •
    
    Args:
        log_to_file: ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        log_level: ë¡œê¹… ë ˆë²¨ (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    """
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œê¹… ë ˆë²¨ ì½ê¸°
    env_log_level = os.getenv("TEST_LOG_LEVEL", log_level).upper()
    log_level_map = {
        "DEBUG": logging.DEBUG,
        "INFO": logging.INFO,
        "WARNING": logging.WARNING,
        "ERROR": logging.ERROR,
        "CRITICAL": logging.CRITICAL,
    }
    level = log_level_map.get(env_log_level, logging.INFO)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger("lawfirm_langgraph.tests")
    logger.setLevel(level)
    logger.propagate = False  # ì¤‘ë³µ ë¡œê·¸ ë°©ì§€ë¥¼ ìœ„í•´ Falseë¡œ ì„¤ì •
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    for handler in list(logger.handlers):
        try:
            logger.removeHandler(handler)
        except Exception:
            pass
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
    # Windowsì—ì„œ sys.stdout ì¬ì„¤ì • í›„ ë²„í¼ ë¶„ë¦¬ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´
    # ì›ë³¸ stdoutì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
    console_handler = None
    
    # ëª¨ë“ˆ ë ˆë²¨ ë³€ìˆ˜ ì°¸ì¡° (í•¨ìˆ˜ ë‚´ì—ì„œ ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥)
    # Pythonì—ì„œëŠ” í•¨ìˆ˜ ë‚´ì—ì„œ ëª¨ë“ˆ ë ˆë²¨ ë³€ìˆ˜ë¥¼ ì½ì„ ìˆ˜ ìˆìŒ
    try:
        # ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì •ì˜ëœ _original_stdout ì°¸ì¡°
        # í•¨ìˆ˜ ë‚´ì—ì„œ ëª¨ë“ˆ ë ˆë²¨ ë³€ìˆ˜ëŠ” ì§ì ‘ ì°¸ì¡° ê°€ëŠ¥ (global ì„ ì–¸ ì—†ì´ ì½ê¸° ê°€ëŠ¥)
        original_stdout_ref = _original_stdout
    except NameError:
        # ëª¨ë“ˆ ë ˆë²¨ ë³€ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° None
        original_stdout_ref = None
    
    try:
        # ì›ë³¸ stdout ì‚¬ìš© ì‹œë„ (ê°€ì¥ ì•ˆì „í•œ ë°©ë²•)
        if original_stdout_ref is not None:
            try:
                console_handler = logging.StreamHandler(original_stdout_ref)
            except (ValueError, AttributeError, OSError):
                # ì›ë³¸ stdout ì‚¬ìš© ì‹¤íŒ¨ ì‹œ í˜„ì¬ stdout ì‚¬ìš©
                console_handler = logging.StreamHandler(sys.stdout)
        else:
            # ì›ë³¸ì´ ì—†ëŠ” ê²½ìš° í˜„ì¬ stdout ì‚¬ìš©
            console_handler = logging.StreamHandler(sys.stdout)
    except (NameError, AttributeError, ValueError, OSError):
        # ì›ë³¸ stdout ì‚¬ìš© ì‹¤íŒ¨ ì‹œ í˜„ì¬ stdout ì‚¬ìš©
        try:
            console_handler = logging.StreamHandler(sys.stdout)
        except (ValueError, AttributeError, OSError):
            # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ stderr ì‚¬ìš© (ìµœí›„ì˜ ìˆ˜ë‹¨)
            try:
                console_handler = logging.StreamHandler(sys.stderr)
            except Exception:
                # ëª¨ë“  í•¸ë“¤ëŸ¬ ìƒì„± ì‹¤íŒ¨
                console_handler = None
    
    if console_handler is None:
        # í•¸ë“¤ëŸ¬ ìƒì„± ì‹¤íŒ¨ ì‹œ íŒŒì¼ í•¸ë“¤ëŸ¬ë§Œ ì‚¬ìš©
        pass
    else:
        console_handler.setLevel(level)
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(console_formatter)
        
        # ì•ˆì „í•œ emit ë©”ì„œë“œ ìƒì„± (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
        # í´ë¡œì €ë¥¼ ì‚¬ìš©í•˜ì—¬ original_stdout_refë¥¼ ìº¡ì²˜
        def create_safe_handler(base_handler, original_stdout):
            """ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ìƒì„± í•¨ìˆ˜"""
            class SafeStreamHandler(logging.StreamHandler):
                """ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬"""
                
                def __init__(self, stream, original_stdout_ref=None):
                    super().__init__(stream)
                    self._original_stdout = original_stdout_ref
                
                def emit(self, record):
                    """ì•ˆì „í•œ ë¡œê·¸ ì¶œë ¥ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
                    try:
                        # ì›ë³¸ emit ì‹œë„
                        super().emit(record)
                    except (ValueError, AttributeError, OSError) as e:
                        # ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²´ ë°©ë²• ì‹œë„
                        try:
                            # í¬ë§·ëœ ë©”ì‹œì§€ë¥¼ ì§ì ‘ ì¶œë ¥ ì‹œë„
                            msg = self.format(record) + self.terminator
                            
                            # ìŠ¤íŠ¸ë¦¼ì´ ìœ íš¨í•œì§€ í™•ì¸
                            stream = self.stream
                            if stream is None:
                                stream = sys.stderr
                            
                            # ìŠ¤íŠ¸ë¦¼ì— ì§ì ‘ ì“°ê¸° ì‹œë„
                            try:
                                if hasattr(stream, 'write'):
                                    stream.write(msg)
                                    if hasattr(stream, 'flush'):
                                        stream.flush()
                            except (ValueError, AttributeError, OSError):
                                # ì›ë³¸ stdoutì— ì§ì ‘ ì“°ê¸° ì‹œë„
                                if self._original_stdout is not None:
                                    try:
                                        if hasattr(self._original_stdout, 'write'):
                                            self._original_stdout.write(msg)
                                            if hasattr(self._original_stdout, 'flush'):
                                                self._original_stdout.flush()
                                    except (ValueError, AttributeError, OSError):
                                        # ì›ë³¸ stdout ì‹¤íŒ¨ ì‹œ í˜„ì¬ stdout ì‹œë„
                                        try:
                                            if hasattr(sys.stdout, 'write'):
                                                sys.stdout.write(msg)
                                                if hasattr(sys.stdout, 'flush'):
                                                    sys.stdout.flush()
                                        except (ValueError, AttributeError, OSError):
                                            # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ stderr ì‚¬ìš©
                                            try:
                                                sys.stderr.write(msg)
                                                sys.stderr.flush()
                                            except Exception:
                                                pass
                                else:
                                    # ì›ë³¸ì´ ì—†ëŠ” ê²½ìš° í˜„ì¬ stdout ì‹œë„
                                    try:
                                        if hasattr(sys.stdout, 'write'):
                                            sys.stdout.write(msg)
                                            if hasattr(sys.stdout, 'flush'):
                                                sys.stdout.flush()
                                    except (ValueError, AttributeError, OSError):
                                        try:
                                            sys.stderr.write(msg)
                                            sys.stderr.flush()
                                        except Exception:
                                            pass
                        except Exception:
                            # ëª¨ë“  ë¡œê¹… ì‹œë„ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ (ì•ˆì „í•œ ì‹¤íŒ¨)
                            # í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì§€ ì•Šë„ë¡ í•¨
                            pass
            
            # ì•ˆì „í•œ í•¸ë“¤ëŸ¬ë¡œ êµì²´
            safe_handler = SafeStreamHandler(base_handler.stream, original_stdout)
            safe_handler.setLevel(base_handler.level)
            safe_handler.setFormatter(base_handler.formatter)
            safe_handler.terminator = base_handler.terminator
            return safe_handler
        
        # ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ìƒì„± ë° ì¶”ê°€
        safe_handler = create_safe_handler(console_handler, original_stdout_ref)
        logger.addHandler(safe_handler)
        
        # ì „ì—­ ë¡œê¹… ì„¤ì •: ëª¨ë“  ë¡œê±°ì— ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì ìš© (ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ ëŒ€ë¹„)
        # transformers, sentence_transformers ë“± ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê±°ì—ë„ ì ìš©
        
        # ë¡œê¹… ì˜ˆì™¸ ë¬´ì‹œ ì„¤ì • (ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
        logging.raiseExceptions = False
        
        root_logger = logging.getLogger()
        root_logger.setLevel(level)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì¤‘ ë²„í¼ ë¶„ë¦¬ ë¬¸ì œê°€ ìˆëŠ” í•¸ë“¤ëŸ¬ ì œê±°
        handlers_to_remove = []
        for handler in list(root_logger.handlers):
            if isinstance(handler, logging.StreamHandler):
                try:
                    # ë²„í¼ ë¶„ë¦¬ ë¬¸ì œê°€ ìˆëŠ” í•¸ë“¤ëŸ¬ í™•ì¸
                    if hasattr(handler, 'stream'):
                        stream = handler.stream
                        if stream is not None:
                            try:
                                # ë²„í¼ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
                                if hasattr(stream, 'buffer'):
                                    _ = stream.buffer
                            except (ValueError, AttributeError, OSError):
                                # ë²„í¼ ë¶„ë¦¬ ë¬¸ì œê°€ ìˆëŠ” í•¸ë“¤ëŸ¬ ì œê±°
                                handlers_to_remove.append(handler)
                                continue
                except Exception:
                    handlers_to_remove.append(handler)
        
        # ì•ˆì „í•˜ê²Œ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in handlers_to_remove:
            try:
                root_logger.removeHandler(handler)
            except Exception:
                pass
        
        # root loggerì— ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì¶”ê°€ (ì—†ëŠ” ê²½ìš°ì—ë§Œ)
        has_safe_handler = any(
            isinstance(h, type(safe_handler)) for h in root_logger.handlers
        )
        if not has_safe_handler:
            root_safe_handler = create_safe_handler(console_handler, original_stdout_ref)
            root_logger.addHandler(root_safe_handler)
        
        # transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê±°ì—ë„ ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì ìš©
        transformers_logger = logging.getLogger("transformers")
        transformers_logger.setLevel(logging.WARNING)  # WARNING ì´ìƒë§Œ ì¶œë ¥
        transformers_logger.propagate = False  # root loggerë¡œ ì „íŒŒ ë°©ì§€
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in list(transformers_logger.handlers):
            try:
                transformers_logger.removeHandler(handler)
            except Exception:
                pass
        
        # ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì¶”ê°€
        transformers_safe_handler = create_safe_handler(console_handler, original_stdout_ref)
        transformers_logger.addHandler(transformers_safe_handler)
        
        # sentence_transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê±°ì—ë„ ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì ìš©
        sentence_transformers_logger = logging.getLogger("sentence_transformers")
        sentence_transformers_logger.setLevel(logging.WARNING)  # WARNING ì´ìƒë§Œ ì¶œë ¥
        sentence_transformers_logger.propagate = False  # root loggerë¡œ ì „íŒŒ ë°©ì§€
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in list(sentence_transformers_logger.handlers):
            try:
                sentence_transformers_logger.removeHandler(handler)
            except Exception:
                pass
        
        # ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì¶”ê°€
        st_safe_handler = create_safe_handler(console_handler, original_stdout_ref)
        sentence_transformers_logger.addHandler(st_safe_handler)
        
        # transformers.utils.logging ë¡œê±°ì—ë„ ì ìš©
        transformers_utils_logger = logging.getLogger("transformers.utils.logging")
        transformers_utils_logger.setLevel(logging.WARNING)
        transformers_utils_logger.propagate = False
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in list(transformers_utils_logger.handlers):
            try:
                transformers_utils_logger.removeHandler(handler)
            except Exception:
                pass
        
        # ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì¶”ê°€
        transformers_utils_safe_handler = create_safe_handler(console_handler, original_stdout_ref)
        transformers_utils_logger.addHandler(transformers_utils_safe_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€ (ì˜µì…˜)
    if log_to_file:
        log_dir = project_root / "logs" / "tests"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"langgraph_test_{timestamp}.log"
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)  # íŒŒì¼ì—ëŠ” ëª¨ë“  ë¡œê·¸ ì €ì¥
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
        
        logger.info(f"ë¡œê·¸ íŒŒì¼ ì €ì¥: {log_file}")
        return logger, log_file
    
    return logger, None

# ë¡œê¹… ì´ˆê¸°í™” (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
LOG_TO_FILE = os.getenv("TEST_LOG_TO_FILE", "false").lower() == "true"
test_logger, log_file = setup_test_logging(log_to_file=LOG_TO_FILE)


def _try_recover_garbled_text(garbled_text: str) -> Optional[str]:
    """
    ê¹¨ì§„ í…ìŠ¤íŠ¸ë¥¼ ë³µêµ¬í•˜ëŠ” í•¨ìˆ˜ (PowerShell ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)
    
    PowerShellì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ í•œê¸€ì„ ì„¤ì •í•  ë•Œ:
    - UTF-8 bytesê°€ CP949ë¡œ ì˜ëª» í•´ì„ë¨
    - ì˜ˆ: "ê³„ì•½ì„œ" (UTF-8: 0xEA 0xB3 0x84 0xEC 0x95 0xBD 0xEC 0x84 0x9C)
    -      -> CP949ë¡œ í•´ì„: "æ€¨ê¾©ë¹Ÿ"
    
    ë³µêµ¬ ë°©ë²•:
    - ê¹¨ì§„ í…ìŠ¤íŠ¸ë¥¼ CP949ë¡œ ì¸ì½”ë”©í•˜ë©´ ì›ë³¸ UTF-8 bytesë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
    - ê·¸ bytesë¥¼ UTF-8ë¡œ ë””ì½”ë”©í•˜ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ ë³µêµ¬ ê°€ëŠ¥
    
    Args:
        garbled_text: ê¹¨ì§„ í…ìŠ¤íŠ¸
    
    Returns:
        ë³µêµ¬ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
    """
    if not garbled_text:
        return None
    
    # ë³µêµ¬ ì „ëµ 1: CP949 -> UTF-8 ë³µêµ¬ (ê°€ì¥ ì¼ë°˜ì ì¸ PowerShell ì¸ì½”ë”© ë¬¸ì œ)
    # PowerShellì—ì„œ UTF-8 í…ìŠ¤íŠ¸ê°€ CP949ë¡œ ì˜ëª» í•´ì„ëœ ê²½ìš°
    # ì˜ˆ: "ê³„ì•½ì„œ" (UTF-8: 0xEA 0xB3 0x84 0xEC 0x95 0xBD 0xEC 0x84 0x9C)
    #     -> CP949ë¡œ í•´ì„: "æ€¨ê¾©ë¹Ÿ"
    # ë³µêµ¬: "æ€¨ê¾©ë¹Ÿ"ì„ CP949ë¡œ ì¸ì½”ë”©í•˜ë©´ ì›ë³¸ UTF-8 bytesë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
    try:
        # ê¹¨ì§„ í…ìŠ¤íŠ¸ë¥¼ CP949 bytesë¡œ ì¸ì½”ë”©í•˜ë©´ ì›ë³¸ UTF-8 bytesë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
        garbled_bytes = garbled_text.encode('cp949', errors='ignore')
        # ì›ë³¸ UTF-8 bytesë¡œ ë³µêµ¬
        recovered = garbled_bytes.decode('utf-8', errors='replace')
        if recovered and recovered != garbled_text and len(recovered) > 0:
            # ë³µêµ¬ëœ í…ìŠ¤íŠ¸ê°€ í•œê¸€ì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
            has_korean = any(0xAC00 <= ord(c) <= 0xD7A3 for c in recovered)
            # '?' ë¬¸ìê°€ ì ê³ , í•œê¸€ì´ ìˆìœ¼ë©´ ë³µêµ¬ ì„±ê³µ ê°€ëŠ¥ì„± ë†’ìŒ
            question_ratio = recovered.count('?') / max(len(recovered), 1)
            # ê¹¨ì§„ ë¬¸ì ë¹„ìœ¨ í™•ì¸ (í•œê¸€ ì™„ì„±í˜• ë²”ìœ„ ì™¸ì˜ ë¬¸ì)
            garbled_chars = sum(1 for c in recovered if ord(c) > 0xFF and (ord(c) < 0xAC00 or ord(c) > 0xD7A3))
            garbled_ratio = garbled_chars / max(len(recovered), 1)
            
            # ë³µêµ¬ ì„±ê³µ ì¡°ê±´: í•œê¸€ì´ ìˆê³ , '?' ë¹„ìœ¨ì´ ë‚®ê³ , ê¹¨ì§„ ë¬¸ì ë¹„ìœ¨ì´ ë‚®ìŒ
            if has_korean and question_ratio < 0.2 and garbled_ratio < 0.3:
                test_logger.info(f"âœ… Recovered text using CP949->UTF-8: '{garbled_text[:30]}...' -> '{recovered[:30]}...'")
                return recovered
            else:
                test_logger.debug(f"CP949->UTF-8 recovery failed: has_korean={has_korean}, question_ratio={question_ratio:.2f}, garbled_ratio={garbled_ratio:.2f}")
    except Exception as e:
        test_logger.debug(f"CP949->UTF-8 recovery failed: {e}")
        pass
    
    # ë³µêµ¬ ì „ëµ 1-2: UTF-16 -> UTF-8 ë³µêµ¬ (PowerShellì´ UTF-16ìœ¼ë¡œ ì¸ì½”ë”©í•œ ê²½ìš°)
    try:
        # PowerShellì´ UTF-16ìœ¼ë¡œ ì¸ì½”ë”©í•œ ê²½ìš°ë¥¼ ëŒ€ë¹„
        # ê¹¨ì§„ í…ìŠ¤íŠ¸ë¥¼ UTF-16ìœ¼ë¡œ ì¸ì½”ë”© í›„ UTF-8ë¡œ ë””ì½”ë”© ì‹œë„
        garbled_bytes = garbled_text.encode('utf-16-le', errors='ignore')
        recovered = garbled_bytes.decode('utf-8', errors='replace')
        if recovered and recovered != garbled_text and len(recovered) > 0:
            has_korean = any(0xAC00 <= ord(c) <= 0xD7A3 for c in recovered)
            question_ratio = recovered.count('?') / max(len(recovered), 1)
            garbled_chars = sum(1 for c in recovered if ord(c) > 0xFF and (ord(c) < 0xAC00 or ord(c) > 0xD7A3))
            garbled_ratio = garbled_chars / max(len(recovered), 1)
            
            if has_korean and question_ratio < 0.2 and garbled_ratio < 0.3:
                test_logger.debug(f"Recovered text using UTF-16->UTF-8: '{garbled_text[:30]}...' -> '{recovered[:30]}...'")
                return recovered
    except Exception as e:
        test_logger.debug(f"UTF-16->UTF-8 recovery failed: {e}")
        pass
    
    # ë³µêµ¬ ì „ëµ 2: ì—¬ëŸ¬ ì¸ì½”ë”© ì¡°í•© ì‹œë„
    encodings = ['cp949', 'euc-kr', 'latin1']
    for src_enc in encodings:
        for dst_enc in ['utf-8']:
            if src_enc == dst_enc:
                continue
            try:
                # ì†ŒìŠ¤ ì¸ì½”ë”©ìœ¼ë¡œ ì¸ì½”ë”© í›„ ëŒ€ìƒ ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”©
                recovered = garbled_text.encode(src_enc, errors='ignore').decode(dst_enc, errors='replace')
                if recovered and recovered != garbled_text:
                    # ë³µêµ¬ëœ í…ìŠ¤íŠ¸ê°€ í•œê¸€ì„ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
                    has_korean = any(0xAC00 <= ord(c) <= 0xD7A3 for c in recovered)
                    question_ratio = recovered.count('?') / max(len(recovered), 1)
                    if has_korean and question_ratio < 0.2:
                        test_logger.debug(f"Recovered text using {src_enc}->{dst_enc}: '{garbled_text[:30]}...' -> '{recovered[:30]}...'")
                        return recovered
            except Exception:
                continue
    
    return None


def _validate_and_fix_query(query: str, default_query: str) -> str:
    """
    ì§ˆì˜ ê²€ì¦ ë° ë³µêµ¬ í•¨ìˆ˜
    
    Args:
        query: ê²€ì¦í•  ì§ˆì˜
        default_query: ê¸°ë³¸ ì§ˆì˜ (ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    
    Returns:
        ê²€ì¦ëœ ì§ˆì˜ ë˜ëŠ” ê¸°ë³¸ ì§ˆì˜
    """
    if not query or not isinstance(query, str):
        return default_query
    
    query = query.strip()
    
    if not query:
        return default_query
    
    # ê¹¨ì§„ ë¬¸ì íŒ¨í„´ ê°ì§€
    garbled_chars = sum(1 for c in query if ord(c) > 0xFF and (ord(c) < 0xAC00 or ord(c) > 0xD7A3))
    garbled_ratio = garbled_chars / max(len(query), 1)
    
    # '?' ë¬¸ì ë¹„ìœ¨ í™•ì¸
    question_mark_ratio = query.count('?') / max(len(query), 1)
    
    # ê¹¨ì§„ ë¬¸ì ë¹„ìœ¨ì´ 30% ì´ìƒì´ê±°ë‚˜ '?' ë¬¸ìê°€ 20% ì´ìƒì´ë©´ ê¹¨ì§„ ê²ƒìœ¼ë¡œ ê°„ì£¼
    if garbled_ratio > 0.3 or question_mark_ratio > 0.2:
        # ë³µêµ¬ ì‹œë„
        try:
            # ì—¬ëŸ¬ ì¸ì½”ë”© ë°©ì‹ìœ¼ë¡œ ë³µêµ¬ ì‹œë„
            for encoding in ['cp949', 'euc-kr', 'latin1']:
                try:
                    # ì›ë³¸ì„ bytesë¡œ ì¸ì½”ë”© í›„ ë‹¤ì‹œ ë””ì½”ë”©
                    fixed = query.encode(encoding, errors='ignore').decode('utf-8', errors='replace')
                    # ë³µêµ¬ í›„ ê²€ì¦
                    fixed_garbled = sum(1 for c in fixed if ord(c) > 0xFF and (ord(c) < 0xAC00 or ord(c) > 0xD7A3))
                    fixed_garbled_ratio = fixed_garbled / max(len(fixed), 1)
                    fixed_question_mark_ratio = fixed.count('?') / max(len(fixed), 1)
                    
                    if len(fixed) > 0 and fixed_garbled_ratio < 0.3 and fixed_question_mark_ratio < 0.2:
                        return fixed
                except Exception:
                    continue
        except Exception:
            pass
        
        # ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆì˜ ë°˜í™˜
        return default_query
    
    # ì •ìƒì ì¸ ì§ˆì˜
    return query


async def run_single_query_test_streaming(query: str):
    """ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ë²„ì „)"""
    test_logger.info("\n" + "="*80)
    test_logger.info("LangGraph ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë°)")
    test_logger.info("="*80)
    
    try:
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.langgraph_core.workflow.workflow_service import LangGraphWorkflowService
        from lawfirm_langgraph.langgraph_core.state.state_definitions import create_initial_legal_state
        import uuid
        
        test_logger.info(f"\nğŸ“‹ ì§ˆì˜: {query}")
        test_logger.info("-" * 80)
        
        # ì„¤ì • ë¡œë“œ
        test_logger.info("\n1ï¸âƒ£  ì„¤ì • ë¡œë“œ ì¤‘...")
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False
        test_logger.info(f"   âœ… LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        test_logger.info(f"   âœ… ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš©: {config.enable_checkpoint} (í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë¹„í™œì„±í™”)")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        test_logger.info("\n2ï¸âƒ£  LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        service = LangGraphWorkflowService(config)
        test_logger.info("   âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì§ˆì˜ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)
        test_logger.info("\n3ï¸âƒ£  ì§ˆì˜ ì²˜ë¦¬ ì¤‘ (ìŠ¤íŠ¸ë¦¬ë°)...")
        test_logger.info("   (ë‹µë³€ì´ ìƒì„±ë˜ëŠ” ë™ì•ˆ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤)")
        test_logger.info("-" * 80)
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = "single_query_test"
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = create_initial_legal_state(query, session_id)
        config_dict = {"configurable": {"thread_id": session_id}}
        
        # ìŠ¤íŠ¸ë¦¬ë° ë³€ìˆ˜
        full_answer = ""
        answer_found = False
        tokens_received = 0
        event_count = 0
        llm_stream_count = 0
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        final_result = None
        
        # astream_events()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
        try:
            # ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼
            async def get_stream_events():
                """ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë˜í¼"""
                try:
                    # version="v2" ì‹œë„ (LangGraph ìµœì‹  ë²„ì „)
                    async for event in service.app.astream_events(
                        initial_state, 
                        config_dict,
                        version="v2"
                    ):
                        yield event
                except (TypeError, AttributeError):
                    # version íŒŒë¼ë¯¸í„°ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° (êµ¬ë²„ì „)
                    async for event in service.app.astream_events(
                        initial_state, 
                        config_dict
                    ):
                        yield event
            
            # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
            event_types_seen = set()  # ë³¸ ì´ë²¤íŠ¸ íƒ€ì… ì¶”ì 
            node_names_seen = set()  # ë³¸ ë…¸ë“œ ì´ë¦„ ì¶”ì 
            
            async for event in get_stream_events():
                event_count += 1
                event_type = event.get("event", "")
                event_name = event.get("name", "")
                
                # ì´ë²¤íŠ¸ íƒ€ì…ê³¼ ë…¸ë“œ ì´ë¦„ ì¶”ì 
                event_types_seen.add(event_type)
                if event_name:
                    node_names_seen.add(event_name)
                
                # ë””ë²„ê¹…: ì´ë²¤íŠ¸ íƒ€ì… ë¡œê¹… (ì²˜ìŒ 10ê°œë§Œ, DEBUG ë ˆë²¨)
                if event_count <= 10:
                    test_logger.debug(f"ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ #{event_count}: type={event_type}, name={event_name}")
                
                # LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ê°ì§€ (ë‹µë³€ ìƒì„± ë…¸ë“œì—ì„œë§Œ)
                # LangGraph/LangChain ìµœì‹  ë²„ì „ì—ì„œëŠ” on_chat_model_streamë„ ì§€ì›
                if event_type in ["on_llm_stream", "on_chat_model_stream"]:
                    llm_stream_count += 1
                    test_logger.debug(f"{event_type} ì´ë²¤íŠ¸ ë°œê²¬: name={event_name}, ì „ì²´ ì´ë²¤íŠ¸ í‚¤: {list(event.keys())}")
                    
                    # ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œì¸ì§€ í™•ì¸ (ë” ë§ì€ íŒ¨í„´ ì§€ì›)
                    # ChatGoogleGenerativeAIëŠ” LLM ëª¨ë¸ ìì²´ì´ë¯€ë¡œ í•­ìƒ ì²˜ë¦¬
                    is_answer_node = (
                        "generate_answer" in event_name.lower() or 
                        "generate_and_validate" in event_name.lower() or
                        "answer" in event_name.lower() or
                        event_name in ["generate_answer_enhanced", "generate_and_validate_answer", "direct_answer"] or
                        event_type == "on_chat_model_stream"  # on_chat_model_streamì€ í•­ìƒ ì²˜ë¦¬
                    )
                    
                    # ë””ë²„ê¹…: ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë¡œê¹… (ì²˜ìŒ 5ê°œë§Œ, DEBUG ë ˆë²¨)
                    if llm_stream_count <= 5:
                        test_logger.debug(f"{event_type} ì´ë²¤íŠ¸ #{llm_stream_count}: name={event_name}, is_answer_node={is_answer_node}")
                        # ì´ë²¤íŠ¸ êµ¬ì¡° ìƒì„¸ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
                        if llm_stream_count <= 3:
                            event_data = event.get("data", {})
                            test_logger.debug(f"  ì´ë²¤íŠ¸ êµ¬ì¡°: event_data type={type(event_data)}, event_data keys={list(event_data.keys()) if isinstance(event_data, dict) else 'N/A'}")
                            if isinstance(event_data, dict):
                                chunk_obj = event_data.get("chunk")
                                if chunk_obj is not None:
                                    test_logger.debug(f"  chunk_obj type={type(chunk_obj)}, chunk_obj={chunk_obj}")
                    
                    if is_answer_node:
                        # ì²« ë²ˆì§¸ ì´ë²¤íŠ¸ë§Œ INFO ë ˆë²¨ë¡œ ë¡œê¹…
                        if llm_stream_count == 1:
                            test_logger.info(f"âœ… ë‹µë³€ ìƒì„± ë…¸ë“œì—ì„œ {event_type} ì´ë²¤íŠ¸ ê°ì§€: {event_name}")
                        else:
                            test_logger.debug(f"âœ… ë‹µë³€ ìƒì„± ë…¸ë“œì—ì„œ {event_type} ì´ë²¤íŠ¸ ê°ì§€: {event_name}")
                    else:
                        # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹Œ ê²½ìš°ì—ë„ ë¡œê¹… (ë””ë²„ê¹…ìš©, DEBUG ë ˆë²¨)
                        if llm_stream_count <= 5:
                            test_logger.debug(f"ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹˜: {event_name} (ë¬´ì‹œ)")
                    
                    # ë…¸ë“œ ì´ë¦„ í•„í„°ë§ ì—†ì´ ëª¨ë“  on_chat_model_stream ì´ë²¤íŠ¸ì—ì„œ í† í° ì¶”ì¶œ ì‹œë„
                    # (ë…¸ë“œ ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
                    if event_type == "on_chat_model_stream":
                        # ëª¨ë“  on_chat_model_stream ì´ë²¤íŠ¸ì—ì„œ í† í° ì¶”ì¶œ ì‹œë„
                        if not is_answer_node:
                            # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹ˆì–´ë„ ì¼ë‹¨ í† í° ì¶”ì¶œ ì‹œë„ (ë””ë²„ê¹…ìš©, DEBUG ë ˆë²¨)
                            if llm_stream_count <= 3:
                                test_logger.debug(f"âš ï¸ ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹ˆì§€ë§Œ í† í° ì¶”ì¶œ ì‹œë„: {event_name}")
                    
                    if is_answer_node or (event_type == "on_chat_model_stream" and llm_stream_count <= 10):
                        # í† í° ì¶”ì¶œ
                        chunk = None
                        event_data = event.get("data", {})
                        
                        try:
                            # ê²½ìš° 1: LangChain í‘œì¤€ í˜•ì‹ - data.chunk.content
                            if isinstance(event_data, dict):
                                chunk_obj = event_data.get("chunk")
                                if chunk_obj is not None:
                                    # AIMessageChunk ê°ì²´ ì²˜ë¦¬
                                    if hasattr(chunk_obj, "content"):
                                        content = chunk_obj.content
                                        # contentê°€ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                        if isinstance(content, str):
                                            chunk = content
                                        # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (AIMessageChunkì˜ contentëŠ” ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ)
                                        elif isinstance(content, list) and len(content) > 0:
                                            # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë¬¸ìì—´ì´ë©´ ì‚¬ìš©
                                            if isinstance(content[0], str):
                                                chunk = content[0]
                                            else:
                                                chunk = str(content[0])
                                        else:
                                            chunk = str(content)
                                    elif isinstance(chunk_obj, str):
                                        chunk = chunk_obj
                                    elif hasattr(chunk_obj, "text"):
                                        chunk = chunk_obj.text
                                    # AIMessageChunk ê°ì²´ì˜ ê²½ìš° ì§ì ‘ content ì ‘ê·¼ ì‹œë„
                                    elif hasattr(chunk_obj, "__class__") and "AIMessageChunk" in str(type(chunk_obj)):
                                        try:
                                            content = getattr(chunk_obj, "content", None)
                                            if isinstance(content, str):
                                                chunk = content
                                            elif isinstance(content, list) and len(content) > 0:
                                                if isinstance(content[0], str):
                                                    chunk = content[0]
                                                else:
                                                    chunk = str(content[0])
                                            elif content is not None:
                                                chunk = str(content)
                                        except Exception:
                                            pass
                                
                                # ê²½ìš° 2: ì§ì ‘ ë¬¸ìì—´ í˜•ì‹
                                if not chunk:
                                    chunk = event_data.get("text") or event_data.get("content")
                                
                                # ê²½ìš° 3: delta í˜•ì‹ (LangGraph v2)
                                if not chunk and "delta" in event_data:
                                    delta = event_data["delta"]
                                    if isinstance(delta, dict):
                                        chunk = delta.get("content") or delta.get("text")
                                    elif isinstance(delta, str):
                                        chunk = delta
                            
                            # ê²½ìš° 4: ì´ë²¤íŠ¸ ìµœìƒìœ„ ë ˆë²¨ì— ì§ì ‘ í¬í•¨
                            if not chunk:
                                chunk = event.get("chunk") or event.get("text") or event.get("content")
                            
                            # í† í°ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¶œë ¥
                            if chunk and isinstance(chunk, str) and len(chunk) > 0:
                                # JSON ì‘ë‹µ í•„í„°ë§ (ê²€ì¦ ê²°ê³¼ ë“±)
                                if chunk.strip().startswith('{') or chunk.strip().startswith('```json'):
                                    # JSON ì‘ë‹µì€ ë¡œê¹…ë§Œ í•˜ê³  ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                                    if tokens_received <= 5:
                                        test_logger.debug(f"JSON ì‘ë‹µ í•„í„°ë§: {chunk[:100]}...")
                                    continue
                                
                                full_answer += chunk
                                tokens_received += 1
                                answer_found = True
                                # ì‹¤ì‹œê°„ ì¶œë ¥ (ë²„í¼ë§ ì—†ì´)
                                print(chunk, end='', flush=True)
                                # ë””ë²„ê¹…: í† í° ì¶”ì¶œ ì„±ê³µ ë¡œê¹… (ì²˜ìŒ 10ê°œë§Œ)
                                if tokens_received <= 10:
                                    test_logger.debug(f"âœ… í† í° ì¶”ì¶œ ì„±ê³µ #{tokens_received}: chunk='{chunk[:50]}...', length={len(chunk)}")
                            else:
                                # í† í° ì¶”ì¶œ ì‹¤íŒ¨ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ, DEBUG ë ˆë²¨)
                                if llm_stream_count <= 3:
                                    test_logger.debug(f"âš ï¸ í† í° ì¶”ì¶œ ì‹¤íŒ¨: chunk={chunk}, chunk type={type(chunk) if chunk else 'None'}")
                                    test_logger.debug(f"  event_data keys: {list(event_data.keys()) if isinstance(event_data, dict) else 'N/A'}")
                                    if isinstance(event_data, dict):
                                        chunk_obj = event_data.get("chunk")
                                        if chunk_obj is not None:
                                            test_logger.debug(f"  chunk_obj type={type(chunk_obj)}, chunk_obj={chunk_obj}")
                                
                        except (AttributeError, TypeError, KeyError) as e:
                            # ì´ë²¤íŠ¸ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ê²½ìš° ë¡œê¹…ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
                            test_logger.debug(f"í† í° ì¶”ì¶œ ì‹¤íŒ¨ (ì´ë²¤íŠ¸ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„): {e}, event_keys={list(event.keys()) if isinstance(event, dict) else 'N/A'}")
                            # ë””ë²„ê¹…: ì´ë²¤íŠ¸ êµ¬ì¡° ìƒì„¸ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
                            if llm_stream_count <= 3:
                                test_logger.debug(f"ì´ë²¤íŠ¸ êµ¬ì¡° ìƒì„¸: event_data={event_data}, event_data type={type(event_data)}")
                                if isinstance(event_data, dict):
                                    test_logger.debug(f"event_data keys: {list(event_data.keys())}")
                            continue
                
                # LLM ì™„ë£Œ ì´ë²¤íŠ¸ (on_llm_end ë˜ëŠ” on_chat_model_end)
                elif event_type in ["on_llm_end", "on_chat_model_end"]:
                    # ìµœì¢… ë‹µë³€ í™•ì¸ (ëˆ„ë½ëœ ë¶€ë¶„ì´ ìˆëŠ”ì§€ ì²´í¬)
                    try:
                        event_data = event.get("data", {})
                        if isinstance(event_data, dict):
                            output = event_data.get("output")
                            if output is not None:
                                final_answer = None
                                
                                # ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì§€ì›
                                if hasattr(output, "content"):
                                    final_answer = output.content
                                elif isinstance(output, str):
                                    final_answer = output
                                elif isinstance(output, dict):
                                    final_answer = output.get("content") or output.get("text") or str(output)
                                else:
                                    final_answer = str(output)
                                
                                # ëˆ„ë½ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì¶œë ¥
                                if final_answer and isinstance(final_answer, str):
                                    if len(final_answer) > len(full_answer):
                                        missing_part = final_answer[len(full_answer):]
                                        if missing_part:
                                            full_answer = final_answer
                                            print(missing_part, end='', flush=True)
                                            test_logger.debug(f"ëˆ„ë½ëœ ë¶€ë¶„ ì¶œë ¥: {len(missing_part)}ì")
                    except (AttributeError, TypeError, KeyError) as e:
                        test_logger.debug(f"on_llm_end ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        pass
                
                # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸ (ìµœì¢… í¬ë§·íŒ…ëœ ë‹µë³€ í™•ì¸)
                elif event_type == "on_chain_end":
                    node_name = event.get("name", "")
                    if node_name in ["generate_answer_enhanced", "generate_and_validate_answer"]:
                        try:
                            event_data = event.get("data", {})
                            if isinstance(event_data, dict):
                                output = event_data.get("output")
                                if output is not None:
                                    # answer í•„ë“œ í™•ì¸ (ë‹¤ì–‘í•œ êµ¬ì¡° ì§€ì›)
                                    final_formatted_answer = None
                                    
                                    if isinstance(output, dict):
                                        # ìµœìƒìœ„ ë ˆë²¨
                                        final_formatted_answer = output.get("answer", "")
                                        
                                        # common ê·¸ë£¹
                                        if not final_formatted_answer and "common" in output:
                                            common = output.get("common", {})
                                            if isinstance(common, dict):
                                                final_formatted_answer = common.get("answer", "")
                                        
                                        # generation ê·¸ë£¹
                                        if not final_formatted_answer and "generation" in output:
                                            generation = output.get("generation", {})
                                            if isinstance(generation, dict):
                                                final_formatted_answer = generation.get("answer", "")
                                    
                                    if final_formatted_answer and isinstance(final_formatted_answer, str) and len(final_formatted_answer) > 0:
                                        # ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ì—ˆì„ ë•Œ: ì „ì²´ ë‹µë³€ ì¶œë ¥
                                        if not answer_found:
                                            full_answer = final_formatted_answer
                                            answer_found = True
                                            print(final_formatted_answer, end='', flush=True)
                                            test_logger.info("ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì—†ìŒ, on_chain_endì—ì„œ í´ë°± ì¶œë ¥")
                                        else:
                                            # ìŠ¤íŠ¸ë¦¬ë°ì´ ìˆì—ˆì„ ë•Œ: ìµœì¢… í¬ë§·íŒ…ëœ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ë¶€ë¶„ ë³´ì™„
                                            if final_formatted_answer != full_answer:
                                                if len(final_formatted_answer) > len(full_answer):
                                                    # ìµœì¢… ë‹µë³€ì´ ë” ê¸´ ê²½ìš°: ëˆ„ë½ëœ ë¶€ë¶„ ì¶œë ¥
                                                    missing_part = final_formatted_answer[len(full_answer):]
                                                    if missing_part:
                                                        full_answer = final_formatted_answer
                                                        print(missing_part, end='', flush=True)
                                                        test_logger.info(f"ìµœì¢… í¬ë§·íŒ…ëœ ë‹µë³€ì—ì„œ ëˆ„ë½ëœ ë¶€ë¶„ ì¶œë ¥: {len(missing_part)}ì")
                                                # ìµœì¢… ê²°ê³¼ ì €ì¥ (í¬ë§·íŒ…ëœ ë‹µë³€)
                                                final_result = output
                        except (AttributeError, TypeError, KeyError) as e:
                            test_logger.debug(f"on_chain_end ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            pass
            
            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
            print()  # ì¤„ë°”ê¿ˆ
            test_logger.info(f"\nìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: ì´ {event_count}ê°œ ì´ë²¤íŠ¸, LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ {llm_stream_count}ê°œ, í† í° ìˆ˜ì‹  {tokens_received}ê°œ")
            test_logger.info(f"ë°œìƒí•œ ì´ë²¤íŠ¸ íƒ€ì…: {sorted(event_types_seen)}")
            test_logger.info(f"ë°œìƒí•œ ë…¸ë“œ ì´ë¦„ (ë‹µë³€ ìƒì„± ê´€ë ¨): {[n for n in sorted(node_names_seen) if 'answer' in n.lower() or 'generate' in n.lower()]}")
            
            # ë””ë²„ê¹…: ë°œìƒí•œ ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…ê³¼ ë…¸ë“œ ì´ë¦„ ë¡œê¹…
            if llm_stream_count == 0:
                test_logger.warning("âš ï¸ LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                test_logger.debug(f"ë°œìƒí•œ ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…: {sorted(event_types_seen)}")
                test_logger.debug(f"ë°œìƒí•œ ëª¨ë“  ë…¸ë“œ ì´ë¦„: {sorted(node_names_seen)}")
                # ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                answer_nodes_executed = [n for n in sorted(node_names_seen) if 'answer' in n.lower() or 'generate' in n.lower()]
                if answer_nodes_executed:
                    test_logger.info(f"ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œ ì‹¤í–‰ë¨: {answer_nodes_executed}")
                else:
                    test_logger.warning("ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìµœì¢… ê²°ê³¼ê°€ ì—†ìœ¼ë©´ process_query()ë¡œ í´ë°±
            if not final_result:
                test_logger.info("\nìµœì¢… ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ process_query() í˜¸ì¶œ...")
                final_result = await service.process_query(
                    query=query,
                    session_id=session_id,
                    enable_checkpoint=False
                )
            
        except Exception as stream_error:
            test_logger.warning(f"ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨, process_query()ë¡œ í´ë°±: {stream_error}")
            final_result = await service.process_query(
                query=query,
                session_id=session_id,
                enable_checkpoint=False
            )
        
        # ê²°ê³¼ ì¶œë ¥
        test_logger.info("\n4ï¸âƒ£  ê²°ê³¼:")
        test_logger.info("="*80)
        
        if final_result:
            # ë‹µë³€ì€ ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¶œë ¥í–ˆìœ¼ë¯€ë¡œ, ë‹¤ë¥¸ ì •ë³´ë§Œ ì¶œë ¥
            answer = final_result.get("answer", full_answer or "")
            
            # ì†ŒìŠ¤ ì •ë³´
            sources = final_result.get("sources", [])
            if sources:
                test_logger.info(f"\nğŸ“š ì†ŒìŠ¤ ({len(sources)}ê°œ):")
                test_logger.info("-" * 80)
                for i, source in enumerate(sources[:5], 1):
                    test_logger.info(f"   {i}. {source}")
                if len(sources) > 5:
                    test_logger.info(f"   ... (ì´ {len(sources)}ê°œ)")
            
            # ë²•ë¥  ì°¸ì¡°
            legal_references = final_result.get("legal_references", [])
            if legal_references:
                test_logger.info(f"\nâš–ï¸  ë²•ë¥  ì°¸ì¡° ({len(legal_references)}ê°œ):")
                test_logger.info("-" * 80)
                for i, ref in enumerate(legal_references[:5], 1):
                    test_logger.info(f"   {i}. {ref}")
                if len(legal_references) > 5:
                    test_logger.info(f"   ... (ì´ {len(legal_references)}ê°œ)")
            
            # ì‹ ë¢°ë„
            confidence = final_result.get("confidence", 0.0)
            if confidence:
                test_logger.info(f"\nğŸ¯ ì‹ ë¢°ë„: {confidence:.2f}")
            
            # ì²˜ë¦¬ ì‹œê°„
            processing_time = final_result.get("processing_time", 0.0)
            if processing_time:
                test_logger.info(f"\nâ±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        
        test_logger.info("\n" + "="*80)
        test_logger.info("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        test_logger.info("="*80)
        
        if log_file:
            test_logger.info(f"\nğŸ“„ ë¡œê·¸ íŒŒì¼: {log_file}")
        
        return final_result or {"answer": full_answer}
        
    except ImportError as e:
        test_logger.error(f"\nâŒ Import ì˜¤ë¥˜: {e}")
        test_logger.error("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        test_logger.error("  - lawfirm_langgraph.config.langgraph_config")
        test_logger.error("  - lawfirm_langgraph.langgraph_core.workflow.workflow_service")
        raise
        
    except Exception as e:
        test_logger.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}", exc_info=True)
        import traceback
        test_logger.error("\nìƒì„¸ ì˜¤ë¥˜:")
        test_logger.error(traceback.format_exc())
        raise


async def run_single_query_test(query: str):
    """ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    test_logger.info("\n" + "="*80)
    test_logger.info("LangGraph ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸")
    test_logger.info("="*80)
    
    try:
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.langgraph_core.workflow.workflow_service import LangGraphWorkflowService
        
        test_logger.info(f"\nğŸ“‹ ì§ˆì˜: {query}")
        test_logger.info("-" * 80)
        
        # ì„¤ì • ë¡œë“œ
        test_logger.info("\n1ï¸âƒ£  ì„¤ì • ë¡œë“œ ì¤‘...")
        config = LangGraphConfig.from_env()
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²´í¬í¬ì¸íŠ¸ ë¹„í™œì„±í™”
        config.enable_checkpoint = False
        test_logger.info(f"   âœ… LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        test_logger.info(f"   âœ… ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš©: {config.enable_checkpoint} (í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë¹„í™œì„±í™”)")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        test_logger.info("\n2ï¸âƒ£  LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        service = LangGraphWorkflowService(config)
        test_logger.info("   âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì§ˆì˜ ì²˜ë¦¬
        test_logger.info("\n3ï¸âƒ£  ì§ˆì˜ ì²˜ë¦¬ ì¤‘...")
        test_logger.info("   (ì´ ì‘ì—…ì€ ëª‡ ì´ˆì—ì„œ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        result = await service.process_query(
            query=query,
            session_id="single_query_test",
            enable_checkpoint=False  # í…ŒìŠ¤íŠ¸ì´ë¯€ë¡œ ì²´í¬í¬ì¸íŠ¸ ë¹„í™œì„±í™”
        )
        
        test_logger.info("\n4ï¸âƒ£  ê²°ê³¼:")
        test_logger.info("="*80)
        
        # ë‹µë³€ ì¶”ì¶œ
        answer = result.get("answer", "")
        answer_text = answer
        if isinstance(answer_text, dict):
            # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ ë‹µë³€ ì¶”ì¶œ ì‹œë„
            for key in ("answer", "content", "text"):
                if isinstance(answer_text, dict) and key in answer_text:
                    answer_text = answer_text[key]
            if isinstance(answer_text, dict):
                answer_text = str(answer_text)
        
        # ë‹µë³€ ì¶œë ¥ (ê°œì„ : ì „ì²´ ë‹µë³€ ì¶œë ¥)
        test_logger.info(f"\nğŸ“ ë‹µë³€ (ê¸¸ì´: {len(str(answer_text)) if answer_text else 0}ì):")
        test_logger.info("-" * 80)
        if answer_text:
            # ê°œì„ : ì „ì²´ ë‹µë³€ ì¶œë ¥ (1000ì ì œí•œ í•´ì œ)
            full_answer = str(answer_text)
            test_logger.info(full_answer)
            if len(full_answer) > 5000:
                test_logger.info(f"\n... (ì´ {len(full_answer)}ì, ì „ì²´ ì¶œë ¥ ì™„ë£Œ)")
        else:
            test_logger.warning("<ë‹µë³€ ì—†ìŒ>")
        
        # ì†ŒìŠ¤ ì •ë³´
        sources = result.get("sources", [])
        if sources:
            test_logger.info(f"\nğŸ“š ì†ŒìŠ¤ ({len(sources)}ê°œ):")
            test_logger.info("-" * 80)
            for i, source in enumerate(sources[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
                test_logger.info(f"   {i}. {source}")
            if len(sources) > 5:
                test_logger.info(f"   ... (ì´ {len(sources)}ê°œ)")
        
        # ë²•ë¥  ì°¸ì¡°
        legal_references = result.get("legal_references", [])
        if legal_references:
            test_logger.info(f"\nâš–ï¸  ë²•ë¥  ì°¸ì¡° ({len(legal_references)}ê°œ):")
            test_logger.info("-" * 80)
            for i, ref in enumerate(legal_references[:5], 1):
                test_logger.info(f"   {i}. {ref}")
            if len(legal_references) > 5:
                test_logger.info(f"   ... (ì´ {len(legal_references)}ê°œ)")
        
        # ë©”íƒ€ë°ì´í„°
        metadata = result.get("metadata", {})
        if metadata:
            test_logger.info(f"\nğŸ“Š ë©”íƒ€ë°ì´í„°:")
            test_logger.info("-" * 80)
            for key, value in list(metadata.items())[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                test_logger.info(f"   {key}: {value}")
        
        # ì‹ ë¢°ë„
        confidence = result.get("confidence", 0.0)
        if confidence:
            test_logger.info(f"\nğŸ¯ ì‹ ë¢°ë„: {confidence:.2f}")
        
        # ì²˜ë¦¬ ì‹œê°„
        processing_time = result.get("processing_time", 0.0)
        if processing_time:
            test_logger.info(f"\nâ±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        
        test_logger.info("\n" + "="*80)
        test_logger.info("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        test_logger.info("="*80)
        
        if log_file:
            test_logger.info(f"\nğŸ“„ ë¡œê·¸ íŒŒì¼: {log_file}")
        
        return result
        
    except ImportError as e:
        test_logger.error(f"\nâŒ Import ì˜¤ë¥˜: {e}")
        test_logger.error("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        test_logger.error("  - lawfirm_langgraph.config.langgraph_config")
        test_logger.error("  - lawfirm_langgraph.langgraph_core.workflow.workflow_service")
        raise
        
    except Exception as e:
        test_logger.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}", exc_info=True)
        import traceback
        test_logger.error("\nìƒì„¸ ì˜¤ë¥˜:")
        test_logger.error(traceback.format_exc())
        raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê¸°ë³¸ ì§ˆì˜ ëª©ë¡
    default_queries = [
        "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    ]
    default_query = default_queries[1]  # "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒ"ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³€ê²½
    
    # ì§ˆì˜ ì„ íƒ ë°©ë²• (ìš°ì„ ìˆœìœ„):
    # 1. í™˜ê²½ ë³€ìˆ˜ TEST_QUERY (ì¸ì½”ë”© ë¬¸ì œ íšŒí”¼ìš©)
    # 2. íŒŒì¼ì—ì„œ ì½ê¸° (-f ë˜ëŠ” --file ì˜µì…˜)
    # 3. ëª…ë ¹ì¤„ ì¸ìë¡œ ìˆ«ì (0, 1, 2 ë“±) - ê¸°ë³¸ ì§ˆì˜ ëª©ë¡ì—ì„œ ì„ íƒ
    # 4. ëª…ë ¹ì¤„ ì¸ìë¡œ ì§ì ‘ ì§ˆì˜ í…ìŠ¤íŠ¸
    # 5. ì¸ìê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê¸°ë³¸ ì§ˆì˜ ì‚¬ìš©
    
    query = None
    
    # 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ˆì˜ ì½ê¸° (ì¸ì½”ë”© ë¬¸ì œ íšŒí”¼ìš©)
    test_query_env = os.getenv('TEST_QUERY')
    if test_query_env and test_query_env.strip():
        query = test_query_env.strip()
        original_query = query
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ì€ ì§ˆì˜ëŠ” PowerShell ì¸ì½”ë”© ë¬¸ì œë¡œ ê¹¨ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
        # ë¨¼ì € ë³µêµ¬ ì‹œë„ (PowerShellì—ì„œ UTF-8ì´ CP949ë¡œ ì˜ëª» í•´ì„ëœ ê²½ìš°)
        recovered_query = _try_recover_garbled_text(query)
        if recovered_query and recovered_query != query:
            test_logger.info(f"\nğŸ’¡ í™˜ê²½ ë³€ìˆ˜ TEST_QUERYì—ì„œ ì§ˆì˜ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤ (ë³µêµ¬ë¨).")
            test_logger.debug(f"   ì›ë³¸: '{query[:50]}...'")
            test_logger.debug(f"   ë³µêµ¬: '{recovered_query[:50]}...'")
            query = recovered_query
        else:
            # ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
            query = original_query
        
        # ë³µêµ¬ í›„ ê²€ì¦
        query_validated = _validate_and_fix_query(query, default_query)
        
        # ê²€ì¦ ê²°ê³¼ê°€ ê¸°ë³¸ ì§ˆì˜ì™€ ë‹¤ë¥´ë©´ ì •ìƒì ìœ¼ë¡œ ê²€ì¦ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
        if query_validated != default_query:
            query = query_validated
            test_logger.info(f"\nğŸ’¡ í™˜ê²½ ë³€ìˆ˜ TEST_QUERYì—ì„œ ì§ˆì˜ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤: '{query}'")
            test_logger.info(f"   ì‚¬ìš©ë²•: $env:TEST_QUERY='ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?'; python run_single_query_test.py")
            test_logger.info(f"   ë˜ëŠ”: set TEST_QUERY=ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”? && python run_single_query_test.py")
        else:
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œì—ë„ ë³µêµ¬ëœ ì§ˆì˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if recovered_query and recovered_query != original_query:
                query = recovered_query
                test_logger.info(f"\nğŸ’¡ í™˜ê²½ ë³€ìˆ˜ TEST_QUERYì—ì„œ ì§ˆì˜ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤ (ë³µêµ¬ëœ ì§ˆì˜ ì‚¬ìš©): '{query}'")
            else:
                query = default_query
                test_logger.warning(f"\nâš ï¸  í™˜ê²½ ë³€ìˆ˜ TEST_QUERYì˜ ì§ˆì˜ë¥¼ ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§ˆì˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                test_logger.warning(f"   ì›ë³¸ ì§ˆì˜: {original_query[:100]}...")
                test_logger.warning(f"   ğŸ’¡ íŒ: PowerShellì—ì„œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì‹œ ì¸ì½”ë”© ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                test_logger.warning(f"   ğŸ’¡ ëŒ€ì•ˆ: íŒŒì¼ë¡œ ì§ˆì˜ë¥¼ ì €ì¥í•˜ê³  -f ì˜µì…˜ìœ¼ë¡œ ì½ê¸°: python run_single_query_test.py -f query.txt")
    
    # 2. íŒŒì¼ì—ì„œ ì§ˆì˜ ì½ê¸°
    if not query and len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        if arg in ['-f', '--file']:
            if len(sys.argv) > 2:
                file_path = sys.argv[2]
                try:
                    # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
                    for encoding in ['utf-8', 'cp949', 'euc-kr']:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                query = f.read().strip()
                            if query:
                                test_logger.info(f"\nğŸ’¡ íŒŒì¼ì—ì„œ ì§ˆì˜ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤: {file_path} (ì¸ì½”ë”©: {encoding})")
                                break
                        except (UnicodeDecodeError, FileNotFoundError):
                            continue
                    if not query:
                        test_logger.error(f"\nâŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                        return
                except Exception as e:
                    test_logger.error(f"\nâŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    return
            else:
                test_logger.error(f"\nâŒ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”: python run_single_query_test.py -f <íŒŒì¼ê²½ë¡œ>")
                return
    
    # 3. ëª…ë ¹ì¤„ ì¸ì ì²˜ë¦¬
    if not query and len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        
        # íŒŒì¼ ì˜µì…˜ì€ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
        if arg in ['-f', '--file']:
            pass  # ì´ë¯¸ ì²˜ë¦¬ë¨
        elif arg.isdigit():
            # ìˆ«ìë¡œ ì‹œì‘í•˜ë©´ ê¸°ë³¸ ì§ˆì˜ ëª©ë¡ì—ì„œ ì„ íƒ
            idx = int(arg)
            if 0 <= idx < len(default_queries):
                query = default_queries[idx]
                test_logger.info(f"\nğŸ’¡ ê¸°ë³¸ ì§ˆì˜ ëª©ë¡ì—ì„œ ì„ íƒ: [{idx}]")
            else:
                test_logger.warning(f"\nâš ï¸  ì¸ë±ìŠ¤ {idx}ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§ˆì˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                query = default_query
        else:
            # ì§ì ‘ ì§ˆì˜ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
            # PowerShell ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì—¬ëŸ¬ ì¸ìë¥¼ í•©ì¹¨
            query_parts = sys.argv[1:]
            
            # ì¸ì½”ë”© ë¬¸ì œ í•´ê²°: ì—¬ëŸ¬ ì¸ì½”ë”© ë°©ì‹ ì‹œë„
            decoded_parts = []
            for part in query_parts:
                if isinstance(part, bytes):
                    # bytesì¸ ê²½ìš° ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
                    for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin1']:
                        try:
                            decoded = part.decode(encoding)
                            decoded_parts.append(decoded)
                            break
                        except (UnicodeDecodeError, AttributeError):
                            continue
                    else:
                        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ errors='replace'ë¡œ ë””ì½”ë”©
                        decoded_parts.append(part.decode('utf-8', errors='replace'))
                else:
                    # ì´ë¯¸ ë¬¸ìì—´ì¸ ê²½ìš°
                    # Windows PowerShellì—ì„œ ê¹¨ì§„ ì¸ì½”ë”© ë³µêµ¬ ì‹œë„
                    if isinstance(part, str):
                        # ê¹¨ì§„ ë¬¸ì íŒ¨í„´ ê°ì§€
                        has_garbled = False
                        for c in part:
                            if len(c.encode('utf-8')) > 1:
                                char_code = ord(c)
                                if (char_code > 0x7F and char_code < 0xAC00) or char_code > 0xD7A3:
                                    has_garbled = True
                                    break
                        if has_garbled or '?' in part or any(ord(c) > 0xFF for c in part):
                            # ê¹¨ì§„ ë¬¸ìì—´ì¸ ê²½ìš° ë³µêµ¬ ì‹œë„
                            try:
                                # ì—¬ëŸ¬ ì¸ì½”ë”© ë°©ì‹ìœ¼ë¡œ ë³µêµ¬ ì‹œë„
                                for encoding in ['cp949', 'euc-kr', 'latin1']:
                                    try:
                                        # ì›ë³¸ì„ bytesë¡œ ì¸ì½”ë”© í›„ ë‹¤ì‹œ ë””ì½”ë”©
                                        fixed = part.encode(encoding, errors='ignore').decode('utf-8', errors='replace')
                                        if len(fixed) > 0 and not all(ord(c) < 0x20 or ord(c) > 0x7E for c in fixed[:10]):
                                            decoded_parts.append(fixed)
                                            break
                                    except Exception:
                                        continue
                                else:
                                    # ëª¨ë“  ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                                    decoded_parts.append(part)
                            except Exception:
                                decoded_parts.append(part)
                        else:
                            # ì •ìƒì ì¸ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            decoded_parts.append(part)
                    else:
                        decoded_parts.append(str(part))
            
            query = " ".join(decoded_parts)
            
            # ìµœì¢… ê²€ì¦: ì§ˆì˜ê°€ ìœ íš¨í•œì§€ í™•ì¸ (ê³µí†µ ê²€ì¦ í•¨ìˆ˜ ì‚¬ìš©)
            query = _validate_and_fix_query(query, default_query)
            
            if query == default_query:
                test_logger.warning(f"\nâš ï¸  ì§ˆì˜ê°€ ê¹¨ì§„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ê¸°ë³¸ ì§ˆì˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                test_logger.warning(f"   ê¹¨ì§„ ì§ˆì˜: {query[:100]}...")
            else:
                # ì§ˆì˜ ì •ê·œí™” (ê³µë°± ì œê±° ë“±)
                query = query.strip()
                test_logger.info(f"\nğŸ’¡ ëª…ë ¹ì¤„ì—ì„œ ì§ˆì˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")
    
    if query is None:
        query = default_query
        test_logger.info(f"\nğŸ’¡ ê¸°ë³¸ ì§ˆì˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_logger.info(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ë³¸ ì§ˆì˜: 0='{default_queries[0]}', 1='{default_queries[1]}', 2='{default_queries[2]}'")
        test_logger.info(f"\n   ë‹¤ë¥¸ ì…ë ¥ ë°©ë²•:")
        test_logger.info(f"   - í™˜ê²½ ë³€ìˆ˜: $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python run_single_query_test.py")
        test_logger.info(f"   - íŒŒì¼ ì…ë ¥: python run_single_query_test.py -f query.txt")
        test_logger.info(f"   - ìˆ«ì ì„ íƒ: python run_single_query_test.py 0")
        test_logger.info(f"   ì‚¬ìš©ë²•: python run_single_query_test.py 0  (ë˜ëŠ” ì§ì ‘ ì§ˆì˜ ì…ë ¥)")
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    try:
        # í™˜ê²½ ë³€ìˆ˜ë¡œ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì œì–´
        use_streaming = os.getenv("TEST_USE_STREAMING", "true").lower() == "true"
        
        if use_streaming:
            result = asyncio.run(run_single_query_test_streaming(query))
        else:
            result = asyncio.run(run_single_query_test(query))
        return 0
    except KeyboardInterrupt:
        test_logger.warning("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        test_logger.error(f"\n\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())


