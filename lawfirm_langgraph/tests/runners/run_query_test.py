# -*- coding: utf-8 -*-
"""
LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python lawfirm_langgraph/tests/runners/run_query_test.py "ì§ˆì˜ ë‚´ìš©"
    python lawfirm_langgraph/tests/runners/run_query_test.py  # ê¸°ë³¸ ì§ˆì˜ ì‚¬ìš©
"""

import sys
import os
import asyncio
import logging
import logging.handlers
import queue
import signal
import atexit
import time
from pathlib import Path
from datetime import datetime
from typing import Optional

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Windows í˜¸í™˜)
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.platform == 'win32':
    os.environ['PYTHONLEGACYWINDOWSSTDIO'] = 'utf-8'

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
runners_dir = script_dir.parent
tests_dir = runners_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from utils.env_loader import ensure_env_loaded
    ensure_env_loaded(project_root)
except ImportError:
    pass

# AsyncFileHandler í´ë˜ìŠ¤ ì •ì˜ (QueueHandler + QueueListener íŒ¨í„´)
class AsyncFileHandler:
    """ë¹„ë™ê¸° íŒŒì¼ í•¸ë“¤ëŸ¬ (QueueHandler + QueueListener íŒ¨í„´)
    
    ì¥ì :
    - ë©”ì¸ ìŠ¤ë ˆë“œë¥¼ ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ
    - ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ íì— ìˆëŠ” ë¡œê·¸ê°€ ì²˜ë¦¬ë¨
    - ì„±ëŠ¥ ìš°ìˆ˜
    - flush í˜¸ì¶œ ë¶ˆí•„ìš” (ìë™ ì²˜ë¦¬)
    """
    
    def __init__(self, filename, mode='a', encoding='utf-8', level=logging.INFO):
        """ë¹„ë™ê¸° íŒŒì¼ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            filename: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            mode: íŒŒì¼ ëª¨ë“œ ('a' ë˜ëŠ” 'w')
            encoding: íŒŒì¼ ì¸ì½”ë”©
            level: ë¡œê·¸ ë ˆë²¨
        """
        self.filename = filename
        self.mode = mode
        self.encoding = encoding
        self.level = level
        
        # ë¡œê·¸ í ìƒì„± (ë¬´ì œí•œ í¬ê¸°)
        self.log_queue = queue.Queue(-1)
        
        # ì‹¤ì œ íŒŒì¼ í•¸ë“¤ëŸ¬ ìƒì„± (line buffering)
        file_handler = logging.FileHandler(
            filename, 
            mode=mode, 
            encoding=encoding,
            delay=False
        )
        # line buffering ì„¤ì • (ì¤„ ë‹¨ìœ„ë¡œ ì¦‰ì‹œ ì“°ê¸°)
        if hasattr(file_handler.stream, 'reconfigure'):
            try:
                file_handler.stream.reconfigure(line_buffering=True)
            except (AttributeError, OSError, ValueError):
                pass
        
        file_handler.setLevel(level)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        
        # QueueHandler ìƒì„± (íì— ë¡œê·¸ë¥¼ ë„£ìŒ)
        self.queue_handler = logging.handlers.QueueHandler(self.log_queue)
        self.queue_handler.setLevel(level)
        
        # QueueListener ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ íë¥¼ ì½ì–´ íŒŒì¼ì— ì“°ê¸°)
        self.listener = logging.handlers.QueueListener(
            self.log_queue, 
            file_handler,
            respect_handler_level=True
        )
        self.listener.start()
    
    def get_handler(self):
        """QueueHandler ë°˜í™˜ (ë¡œê±°ì— ì¶”ê°€í•  í•¸ë“¤ëŸ¬)
        
        Returns:
            QueueHandler: ë¡œê±°ì— ì¶”ê°€í•  í•¸ë“¤ëŸ¬
        """
        return self.queue_handler
    
    def stop(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œ)
        
        íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•œ í›„ ì¢…ë£Œí•©ë‹ˆë‹¤.
        """
        if self.listener:
            try:
                self.listener.stop()
            except Exception:
                pass
    
    def flush(self):
        """ëª…ì‹œì  flush (ì„ íƒì , ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆí•„ìš”)
        
        QueueListenerê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì¼ë°˜ì ìœ¼ë¡œ í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
        """
        # QueueListenerê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”
        pass


# SafeStreamHandler í´ë˜ìŠ¤ ì •ì˜ (Windows í™˜ê²½ í˜¸í™˜)
class SafeStreamHandler(logging.StreamHandler):
    """ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, stream, original_stdout_ref=None):
        super().__init__(stream)
        self._original_stdout = original_stdout_ref
    
    def _get_safe_stream(self):
        """ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ ë°˜í™˜"""
        streams_to_try = []
        if self.stream and hasattr(self.stream, 'write'):
            streams_to_try.append(self.stream)
        if self._original_stdout is not None and hasattr(self._original_stdout, 'write'):
            streams_to_try.append(self._original_stdout)
        if sys.stdout and hasattr(sys.stdout, 'write'):
            streams_to_try.append(sys.stdout)
        if sys.stderr and hasattr(sys.stderr, 'write'):
            streams_to_try.append(sys.stderr)
        
        for stream in streams_to_try:
            try:
                if hasattr(stream, 'buffer') or hasattr(stream, 'write'):
                    return stream
            except (ValueError, AttributeError, OSError):
                continue
        return None
    
    def emit(self, record):
        """ì•ˆì „í•œ ë¡œê·¸ ì¶œë ¥ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
        try:
            msg = self.format(record) + self.terminator
            safe_stream = self._get_safe_stream()
            if safe_stream is not None:
                try:
                    if hasattr(safe_stream, 'buffer'):
                        try:
                            buffer = safe_stream.buffer
                            if buffer is None:
                                raise ValueError("Buffer is None")
                        except (ValueError, AttributeError):
                            if hasattr(safe_stream, 'write'):
                                safe_stream.write(msg)
                                return
                    else:
                        safe_stream.write(msg)
                    
                    try:
                        safe_stream.flush()
                    except (ValueError, AttributeError, OSError):
                        pass
                    return
                except (ValueError, AttributeError, OSError):
                    pass
            
            if sys.stderr and hasattr(sys.stderr, 'write'):
                try:
                    sys.stderr.write(msg)
                    try:
                        sys.stderr.flush()
                    except (ValueError, AttributeError, OSError):
                        pass
                    return
                except (ValueError, AttributeError, OSError):
                    pass
        except Exception:
            pass
    
    def flush(self):
        """ì•ˆì „í•œ flush (ì˜¤ë¥˜ ë¬´ì‹œ)"""
        try:
            safe_stream = self._get_safe_stream()
            if safe_stream is not None:
                try:
                    safe_stream.flush()
                except (ValueError, AttributeError, OSError):
                    pass
        except (ValueError, AttributeError, OSError):
            pass


# ì›ë³¸ stdout ì €ì¥
_original_stdout = sys.stdout

# ğŸ”¥ ê°œì„ : ê¸€ë¡œë²Œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì €ì¥ (signal handlerì—ì„œ ì‚¬ìš©)
_global_log_file_path = None
# ğŸ”¥ ê°œì„ : ê¸€ë¡œë²Œ AsyncFileHandler ì €ì¥ (í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ stop í˜¸ì¶œìš©)
_global_async_file_handler = None


def _signal_handler(signum, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ë¡œê·¸ ì²˜ë¦¬)"""
    try:
        # QueueListenerê°€ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ stop
        global _global_async_file_handler
        if _global_async_file_handler:
            _global_async_file_handler.stop()
        
        flush_all_log_handlers()  # StreamHandlerë§Œ flush
        if _global_log_file_path:
            print(f"\n[ì‹œê·¸ë„ ìˆ˜ì‹ ] ë¡œê·¸ íŒŒì¼: {_global_log_file_path}")
    except Exception:
        pass
    # ì›ë˜ ì‹œê·¸ë„ ë™ì‘ ìˆ˜í–‰
    if signum == signal.SIGINT:
        raise KeyboardInterrupt
    sys.exit(0)


def _atexit_handler():
    """í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ë¡œê·¸ ì²˜ë¦¬ (atexit ì‚¬ìš©)"""
    try:
        # QueueListenerê°€ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ stop
        global _global_async_file_handler
        if _global_async_file_handler:
            _global_async_file_handler.stop()
        
        flush_all_log_handlers()  # StreamHandlerë§Œ flush
    except Exception:
        pass


# ğŸ”¥ ê°œì„ : ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡ (í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ë¡œê·¸ ì €ì¥ ë³´ì¥)
if sys.platform != 'win32':
    # Unix/Linux: SIGTERM, SIGINT ì²˜ë¦¬
    signal.signal(signal.SIGTERM, _signal_handler)
    signal.signal(signal.SIGINT, _signal_handler)
else:
    # Windows: SIGINTë§Œ ì²˜ë¦¬ (SIGTERM ì—†ìŒ)
    signal.signal(signal.SIGINT, _signal_handler)

# ğŸ”¥ ê°œì„ : atexit í•¸ë“¤ëŸ¬ ë“±ë¡ (ì •ìƒ ì¢…ë£Œ ì‹œ ë¡œê·¸ ì €ì¥ ë³´ì¥)
atexit.register(_atexit_handler)


def flush_all_log_handlers():
    """ëª¨ë“  ë¡œê±°ì˜ StreamHandlerë§Œ flush (ì „ì—­ í•¨ìˆ˜)
    
    QueueHandler + QueueListener íŒ¨í„´ì—ì„œëŠ” íŒŒì¼ í•¸ë“¤ëŸ¬ì˜ flushê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ
    StreamHandler(ì½˜ì†” ì¶œë ¥)ë§Œ flushí•©ë‹ˆë‹¤.
    """
    try:
        # StreamHandlerë§Œ flush (ì½˜ì†” ì¶œë ¥ ë³´ì¥)
        root_logger = logging.getLogger()
        for handler in root_logger.handlers:
            if isinstance(handler, logging.StreamHandler):
                try:
                    if hasattr(handler, 'stream') and handler.stream:
                        handler.stream.flush()
                except (ValueError, AttributeError, OSError):
                    pass
        
        # Pythonì˜ í‘œì¤€ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ë„ flush
        try:
            sys.stdout.flush()
            sys.stderr.flush()
        except (ValueError, AttributeError, OSError):
            pass
    except Exception:
        pass


# ë¡œê¹… ì„¤ì •
def setup_logging(log_level: Optional[str] = None) -> logging.Logger:
    """ë¡œê¹… ì„¤ì •
    
    Args:
        log_level: ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ LOG_LEVEL ë˜ëŠ” INFO)
    
    Returns:
        ì„¤ì •ëœ ë¡œê±°
    """
    # ë¡œê·¸ ë ˆë²¨ ê²°ì •
    if log_level is None:
        log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    else:
        log_level = log_level.upper()
    
    log_level_map = {
        "CRITICAL": logging.CRITICAL,
        "ERROR": logging.ERROR,
        "WARNING": logging.WARNING,
        "INFO": logging.INFO,
        "DEBUG": logging.DEBUG,
    }
    log_level_value = log_level_map.get(log_level, logging.INFO)
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (í™˜ê²½ ë³€ìˆ˜ë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥)
    log_dir_env = os.getenv("TEST_LOG_DIR")
    if log_dir_env:
        log_dir = Path(log_dir_env)
    else:
        log_dir = project_root / "logs" / "langgraph"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (í™˜ê²½ ë³€ìˆ˜ë¡œ íŒŒì¼ëª… ì§€ì • ê°€ëŠ¥)
    log_file_env = os.getenv("TEST_LOG_FILE")
    if log_file_env:
        log_file = Path(log_file_env)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"test_langgraph_query_{timestamp}.log"
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level_value)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in list(root_logger.handlers):
        root_logger.removeHandler(handler)
    
    # ğŸ”¥ ê°œì„ : ë¹„ë™ê¸° íŒŒì¼ í•¸ë“¤ëŸ¬ ì‚¬ìš© (QueueHandler + QueueListener íŒ¨í„´)
    # ì¥ì : ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ì—†ìŒ, ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ íì— ìˆëŠ” ë¡œê·¸ ì²˜ë¦¬, ì„±ëŠ¥ ìš°ìˆ˜
    global _global_async_file_handler
    async_file_handler = AsyncFileHandler(
        log_file, 
        encoding='utf-8', 
        mode='w', 
        level=log_level_value
    )
    _global_async_file_handler = async_file_handler
    
    # QueueHandlerë¥¼ ë¡œê±°ì— ì¶”ê°€
    file_handler = async_file_handler.get_handler()
    root_logger.addHandler(file_handler)
    
    # í¬ë§·í„° ì„¤ì • (QueueListener ë‚´ë¶€ì˜ ì‹¤ì œ íŒŒì¼ í•¸ë“¤ëŸ¬ì— ì ìš©ë¨)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€ (SafeStreamHandler ì‚¬ìš©)
    try:
        base_handler = logging.StreamHandler(_original_stdout)
    except (ValueError, AttributeError):
        try:
            base_handler = logging.StreamHandler(sys.stdout)
        except (ValueError, AttributeError):
            base_handler = logging.StreamHandler(sys.stderr)
    
    safe_handler = SafeStreamHandler(base_handler.stream, _original_stdout)
    safe_handler.setLevel(log_level_value)
    safe_handler.setFormatter(file_formatter)
    root_logger.addHandler(safe_handler)
    
    # ğŸ”¥ ê°œì„ : ëª¨ë“  ì£¼ìš” ë¡œê±°ê°€ ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒë˜ë„ë¡ ê°•ì œ ì„¤ì •
    # ëª¨ë“  ê¸°ì¡´ ë¡œê±°ì˜ propagateë¥¼ Trueë¡œ ì„¤ì •
    for logger_name in list(logging.Logger.manager.loggerDict.keys()):
        try:
            existing_logger = logging.getLogger(logger_name)
            existing_logger.propagate = True
            existing_logger.disabled = False
        except (ValueError, AttributeError, RuntimeError):
            pass
    
    # lawfirm_langgraph ë¡œê±° ì„¤ì •
    langgraph_logger = logging.getLogger("lawfirm_langgraph")
    langgraph_logger.setLevel(log_level_value)
    langgraph_logger.propagate = True
    langgraph_logger.disabled = False
    
    # ğŸ”¥ ê°œì„ : core ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¡œê±°ë“¤ë„ ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒë˜ë„ë¡ ì„¤ì •
    core_logger = logging.getLogger("core")
    core_logger.setLevel(log_level_value)
    core_logger.propagate = True
    core_logger.disabled = False
    
    # ğŸ”¥ ê°œì„ : ì£¼ìš” ì„œë¸Œ ë¡œê±°ë“¤ ì„¤ì • (propagate=Trueë¡œ ë£¨íŠ¸ ë¡œê±°ì˜ í•¸ë“¤ëŸ¬ ì‚¬ìš©)
    # QueueHandler + QueueListener íŒ¨í„´ì—ì„œëŠ” ëª¨ë“  ë¡œê±°ê°€ ê°™ì€ íë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ
    # ì„œë¸Œ ë¡œê±°ì— ì§ì ‘ í•¸ë“¤ëŸ¬ë¥¼ ì¶”ê°€í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
    important_loggers = [
        "core.search.engines.semantic_search_engine_v2",
        "core.data.db_adapter",
        "core.workflow.workflow_service",
        "core.workflow.legal_workflow_enhanced",
    ]
    
    for logger_name in important_loggers:
        try:
            sub_logger = logging.getLogger(logger_name)
            sub_logger.setLevel(log_level_value)
            sub_logger.propagate = True  # ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒ
            sub_logger.disabled = False
        except (ValueError, AttributeError, RuntimeError):
            pass
    
    # Few-shot examples ê²½ê³  í•„í„°ë§ (ì„ íƒì )
    if os.getenv("SUPPRESS_FEW_SHOT_WARNING", "false").lower() == "true":
        few_shot_logger = logging.getLogger("lawfirm_langgraph.core.generation.formatters.answer_structure_enhancer")
        few_shot_logger.setLevel(logging.ERROR)  # WARNING ì´ìƒë§Œ í‘œì‹œ
    
    # í…ŒìŠ¤íŠ¸ ë¡œê±° (íŒŒì¼ëª…ê³¼ ì¼ì¹˜)
    logger = logging.getLogger("lawfirm_langgraph.tests.runners.run_query_test")
    logger.setLevel(log_level_value)
    logger.propagate = True
    logger.disabled = False
    
    # ğŸ”¥ ê°œì„ : ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ (íŒŒì¼ ìƒì„± í™•ì¸ìš© - í•œ ë²ˆë§Œ)
    logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file.absolute()} | ë¡œê·¸ ë ˆë²¨: {log_level}")
    
    # ğŸ”¥ ê°œì„ : ê¸€ë¡œë²Œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì €ì¥ (signal handlerì—ì„œ ì‚¬ìš©)
    global _global_log_file_path
    _global_log_file_path = str(log_file.absolute())
    
    # ğŸ”¥ ê°œì„ : ì½˜ì†”ì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥ (ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš° ëŒ€ë¹„)
    print(f"\n[ë¡œê·¸ ì„¤ì •]")
    print(f"  ë¡œê·¸ íŒŒì¼: {log_file.absolute()}")
    print(f"  ë¡œê·¸ ë ˆë²¨: {log_level}")
    print()
    
    return logger


def get_query_from_args() -> str:
    """ëª…ë ¹ì¤„ ì¸ìì—ì„œ ì§ˆì˜ ì¶”ì¶œ"""
    default_queries = [
        "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    ]
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    test_query = os.getenv('TEST_QUERY', '').strip()
    if test_query:
        return test_query
    
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸
    if len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        
        # ìˆ«ìë¡œ ê¸°ë³¸ ì§ˆì˜ ì„ íƒ
        if arg.isdigit():
            idx = int(arg)
            if 0 <= idx < len(default_queries):
                return default_queries[idx]
        
        # ì§ˆì˜ ë‚´ìš© ì§ì ‘ ì…ë ¥
        return " ".join(sys.argv[1:])
    
    # ê¸°ë³¸ ì§ˆì˜ ë°˜í™˜
    return default_queries[0]


async def test_langgraph_query(query: str, logger: logging.Logger):
    """LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    Args:
        query: í…ŒìŠ¤íŠ¸í•  ì§ˆì˜
        logger: ë¡œê±°
    """
    logger.info("=" * 80)
    logger.info("LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 80)
    logger.info(f"ì§ˆì˜: {query}")
    
    try:
        # ì´ˆê¸°í™” ì‹œê°„ ì¸¡ì • ì‹œì‘
        import time
        total_start_time = time.time()
        
        # ì„¤ì • ë¡œë“œ
        logger.info("1. ì„¤ì • ë¡œë“œ ì¤‘...")
        setup_start = time.time()
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.config.app_config import Config as AppConfig
        
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False
        setup_time = time.time() - setup_start
        logger.info(f"   LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        logger.info(f"   ì²´í¬í¬ì¸íŠ¸: {config.enable_checkpoint}")
        logger.info(f"   ì„¤ì • ë¡œë“œ ì‹œê°„: {setup_time:.3f}ì´ˆ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ê²€ìƒ‰ ì„¤ì • í™•ì¸
        logger.info("\n1.1. ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ê²€ìƒ‰ ì„¤ì • í™•ì¸...")
        db_check_start = time.time()
        app_config = AppConfig()
        
        # SQLite URL ê²€ì¦ (í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „)
        if app_config.database_url.startswith("sqlite://"):
            logger.error("   âŒ SQLiteëŠ” ë” ì´ìƒ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PostgreSQLì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            logger.error("   PostgreSQL URL ì„¤ì • ë°©ë²•:")
            logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
            logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
            raise ValueError("SQLite is no longer supported. Please configure PostgreSQL.")
        
        logger.info(f"   âœ… Database URL ì„¤ì •ë¨ (PostgreSQL)")
        logger.info(f"   VECTOR_SEARCH_METHOD: {app_config.vector_search_method}")
        if app_config.faiss_index_path:
            logger.info(f"   FAISS_INDEX_PATH: {app_config.faiss_index_path}")
        
        # DatabaseAdapter í™•ì¸
        db_adapter_start = time.time()
        try:
            from lawfirm_langgraph.core.data.db_adapter import DatabaseAdapter
            if app_config.database_url:
                db_adapter = DatabaseAdapter(app_config.database_url)
                logger.info(f"   âœ… DatabaseAdapter ì´ˆê¸°í™” ì„±ê³µ: type={db_adapter.db_type}")
                if db_adapter.db_type == 'postgresql':
                    logger.info(f"   âœ… PostgreSQL ì‚¬ìš© ì¤‘")
                else:
                    logger.error(f"   âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…: {db_adapter.db_type} (PostgreSQLë§Œ ì§€ì›)")
                    logger.error("   PostgreSQL URL ì„¤ì • ë°©ë²•:")
                    logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
                    logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
                    raise ValueError(f"Unsupported database type: {db_adapter.db_type}. Only PostgreSQL is supported.")
        except ValueError as e:
            logger.error(f"   âŒ DatabaseAdapter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        except Exception as e:
            logger.error(f"   âŒ DatabaseAdapter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error("   PostgreSQL ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            raise
        
        # VectorSearchFactory í™•ì¸
        try:
            from lawfirm_langgraph.core.search.engines.vector_search_adapter import VectorSearchFactory
            logger.info(f"   âœ… VectorSearchFactory ì‚¬ìš© ê°€ëŠ¥")
            if app_config.vector_search_method.lower() == 'pgvector':
                try:
                    import pgvector
                    logger.info(f"   âœ… pgvector ì‚¬ìš© ì¤‘ (pgvector íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨)")
                except ImportError:
                    logger.warning(f"   âš ï¸  pgvector ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    logger.warning(f"   ì„¤ì¹˜ ë°©ë²•: pip install pgvector")
            elif app_config.vector_search_method.lower() == 'faiss':
                logger.info(f"   âœ… FAISS ì‚¬ìš© ì¤‘")
            elif app_config.vector_search_method.lower() == 'hybrid':
                logger.info(f"   âœ… Hybrid (pgvector + FAISS) ì‚¬ìš© ì¤‘")
        except Exception as e:
            logger.warning(f"   âš ï¸  VectorSearchFactory ì‚¬ìš© ë¶ˆê°€: {e}")
        
        db_check_time = time.time() - db_check_start
        logger.info(f"   ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸ ì‹œê°„: {db_check_time:.3f}ì´ˆ")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("\n2. LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        service_start = time.time()
        
        # ğŸ”¥ ê°œì„ : ì´ˆê¸°í™” ì „ ë¡œê·¸ flush
        try:
            for handler in logging.getLogger().handlers:
                if isinstance(handler, logging.FileHandler):
                    handler.flush()
                    if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                        try:
                            os.fsync(handler.stream.fileno())
                        except (OSError, AttributeError):
                            pass
        except Exception:
            pass
        
        try:
            from lawfirm_langgraph.core.workflow.workflow_service import LangGraphWorkflowService
            
            service = LangGraphWorkflowService(config)
            service_time = time.time() - service_start
            logger.info(f"   ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (ì´ˆê¸°í™” ì‹œê°„: {service_time:.3f}ì´ˆ)")
            
            # ğŸ”¥ ê°œì„ : ì´ˆê¸°í™” ì§í›„ ì¦‰ì‹œ flush
            try:
                for handler in logging.getLogger().handlers:
                    if isinstance(handler, logging.FileHandler):
                        handler.flush()
                        if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                            try:
                                os.fsync(handler.stream.fileno())
                            except (OSError, AttributeError):
                                pass
            except Exception:
                pass
            
            # ì„œë¹„ìŠ¤ ë‚´ë¶€ ì»´í¬ë„ŒíŠ¸ í™•ì¸
            if hasattr(service, 'db_manager') and service.db_manager:
                if hasattr(service.db_manager, '_db_adapter') and service.db_manager._db_adapter:
                    logger.info(f"   âœ… LegalDataConnectorV2 DatabaseAdapter: type={service.db_manager._db_adapter.db_type}")
            
            if hasattr(service, 'semantic_search_engine') and service.semantic_search_engine:
                if hasattr(service.semantic_search_engine, '_db_adapter') and service.semantic_search_engine._db_adapter:
                    logger.info(f"   âœ… SemanticSearchEngineV2 DatabaseAdapter: type={service.semantic_search_engine._db_adapter.db_type}")
                if hasattr(service.semantic_search_engine, 'vector_adapter') and service.semantic_search_engine.vector_adapter:
                    adapter_type = type(service.semantic_search_engine.vector_adapter).__name__
                    logger.info(f"   âœ… SemanticSearchEngineV2 VectorAdapter: {adapter_type}")
            
            # ì´ˆê¸°í™” ì´ ì‹œê°„ ê³„ì‚°
            init_total_time = time.time() - total_start_time
            logger.info(f"\nì´ˆê¸°í™” ì™„ë£Œ (ì´ ì‹œê°„: {init_total_time:.3f}ì´ˆ)")
            
            # ğŸ”¥ ê°œì„ : ì´ˆê¸°í™” ì™„ë£Œ í›„ ì¦‰ì‹œ flush
            try:
                for handler in logging.getLogger().handlers:
                    if isinstance(handler, logging.FileHandler):
                        handler.flush()
                        if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                            try:
                                os.fsync(handler.stream.fileno())
                            except (OSError, AttributeError):
                                pass
            except Exception:
                pass
                
        except Exception as e:
            # ğŸ”¥ ê°œì„ : ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ë¡œê·¸ ê¸°ë¡
            logger.error(f"   âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {type(e).__name__}: {e}")
            logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
            
            # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ flush
            try:
                for handler in logging.getLogger().handlers:
                    if isinstance(handler, logging.FileHandler):
                        handler.flush()
                        if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                            try:
                                os.fsync(handler.stream.fileno())
                            except (OSError, AttributeError):
                                pass
            except Exception:
                pass
            
            raise
        
        # ì§ˆì˜ ì²˜ë¦¬
        logger.info("\n3. ì§ˆì˜ ì²˜ë¦¬ ì¤‘...")
        logger.info("   (ì´ ì‘ì—…ì€ ëª‡ ì´ˆì—ì„œ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        query_start_time = time.time()
        
        logger.debug("   3.1. ê²€ìƒ‰ ë‹¨ê³„ ì‹œì‘...")
        
        # ğŸ”¥ ê°œì„ : QueueHandler + QueueListener íŒ¨í„´ì—ì„œëŠ” ë°±ê·¸ë¼ìš´ë“œ flush íƒœìŠ¤í¬ ë¶ˆí•„ìš”
        # QueueListenerê°€ ìë™ìœ¼ë¡œ íì—ì„œ ë¡œê·¸ë¥¼ ì½ì–´ íŒŒì¼ì— ì“°ë¯€ë¡œ flush í˜¸ì¶œ ë¶ˆí•„ìš”
        try:
            
            # ğŸ”¥ ê°œì„ : process_query ì‹¤í–‰ (QueueHandler + QueueListenerê°€ ìë™ìœ¼ë¡œ ë¡œê·¸ ì²˜ë¦¬)
            result = None
            try:
                logger.info("   ğŸ”„ process_query ì‹¤í–‰ ì‹œì‘...")
                
                result = await service.process_query(
                    query=query,
                    session_id="test_langgraph_query",
                    enable_checkpoint=False,
                    use_astream_events=True
                )
                
                logger.info("   âœ… process_query ì‹¤í–‰ ì™„ë£Œ")
                
            except Exception as query_error:
                # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ ë¡œê·¸ ê¸°ë¡
                try:
                    logger.error(f"   âŒ ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(query_error).__name__}: {query_error}")
                    logger.error(f"   - ì˜¤ë¥˜ íƒ€ì…: {type(query_error).__name__}")
                    logger.error(f"   - ì˜¤ë¥˜ ë©”ì‹œì§€: {str(query_error)}")
                    if hasattr(query_error, '__cause__') and query_error.__cause__:
                        logger.error(f"   - ì›ì¸: {query_error.__cause__}")
                    logger.debug("   ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
                except Exception:
                    pass
                
                # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ì—ì„œ ì²˜ë¦¬
                raise
        finally:
            # QueueHandler + QueueListener íŒ¨í„´ì—ì„œëŠ” flush ë¶ˆí•„ìš”
            # QueueListenerê°€ ìë™ìœ¼ë¡œ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•¨
            pass
        
        query_end_time = time.time()
        query_elapsed_time = query_end_time - query_start_time
        total_elapsed_time = query_end_time - total_start_time
        logger.info(f"   ì§ˆì˜ ì²˜ë¦¬ ì™„ë£Œ (ì§ˆì˜ ì²˜ë¦¬ ì‹œê°„: {query_elapsed_time:.2f}ì´ˆ, ì´ ì‹œê°„: {total_elapsed_time:.2f}ì´ˆ)")
        
        # ğŸ”¥ ê°œì„ : resultê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
        if result is None:
            logger.error("   âŒ ì§ˆì˜ ì²˜ë¦¬ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            raise ValueError("Query processing returned None result")
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n4. ê²°ê³¼:")
        logger.info("=" * 80)
        
        # ë‹µë³€ ì¶”ì¶œ (ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°)
        answer = result.get("answer", "")
        if isinstance(answer, dict):
            answer = answer.get("answer", "") or answer.get("content", "") or ""
        answer = str(answer).strip() if answer else ""
        
        # answerê°€ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
        if not answer:
            # output í•„ë“œ í™•ì¸
            output = result.get("output", {})
            if isinstance(output, dict):
                answer = output.get("answer", "") or output.get("content", "")
        
        # ìµœì¢… ë¬¸ìì—´ ë³€í™˜
        answer = str(answer).strip() if answer else ""
        
        if answer:
            logger.info(f"\në‹µë³€ ({len(answer)}ì):")
            logger.info("-" * 80)
            logger.info(answer)
            # ğŸ”¥ ê°œì„ : ë‹µë³€ ì¶œë ¥ í›„ ì¦‰ì‹œ flush
            flush_all_log_handlers()
        else:
            logger.warning("\në‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤!")
            # ë””ë²„ê¹…: resultì˜ ëª¨ë“  í‚¤ ì¶œë ¥
            logger.debug(f"Result keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
            if isinstance(result, dict) and "answer" in result:
                logger.debug(f"Answer type: {type(result['answer'])}, value: {str(result['answer'])[:100]}")
            # ğŸ”¥ ê°œì„ : ê²½ê³  ì¶œë ¥ í›„ ì¦‰ì‹œ flush
            flush_all_log_handlers()
        
        # ê²€ìƒ‰ ê²°ê³¼ (í’ˆì§ˆ ì •ë³´ í¬í•¨)
        retrieved_docs = result.get("retrieved_docs", [])
        if retrieved_docs:
            logger.info(f"\nê²€ìƒ‰ëœ ì°¸ê³ ìë£Œ ({len(retrieved_docs)}ê°œ):")
            for i, doc in enumerate(retrieved_docs[:5], 1):
                if isinstance(doc, dict):
                    # ğŸ”¥ ê°œì„ : ë©”íƒ€ë°ì´í„° ë³´ê°• - ìµœìƒìœ„ í•„ë“œë¥¼ metadataì— ë³µì‚¬ (DocumentType ì¶”ë¡ ì„ ìœ„í•´)
                    metadata = doc.get("metadata", {})
                    if not isinstance(metadata, dict):
                        metadata = {}
                    
                    # ìµœìƒìœ„ í•„ë“œë¥¼ metadataì— ë³µì‚¬ (DocumentType ì¶”ë¡ ì„ ìœ„í•´)
                    for key in ["statute_name", "law_name", "article_no", "case_id", "court", "doc_id", "casenames", "precedent_id", "type", "source_type"]:
                        if key in doc and key not in metadata:
                            metadata[key] = doc[key]
                    
                    # metadataì˜ ì •ë³´ë„ ìµœìƒìœ„ í•„ë“œë¡œ ë³µì‚¬ (ì¼ê´€ì„± ìœ ì§€)
                    for key in ["statute_name", "law_name", "article_no", "case_id", "court", "doc_id", "casenames", "precedent_id", "type", "source_type"]:
                        if key in metadata and key not in doc:
                            doc[key] = metadata[key]
                    
                    doc["metadata"] = metadata
                    
                    # DocumentType Enum ì‚¬ìš©í•˜ì—¬ íƒ€ì… ì¶”ì¶œ
                    try:
                        from lawfirm_langgraph.core.workflow.constants.document_types import DocumentType
                        # ë””ë²„ê¹…: docì˜ íƒ€ì… ê´€ë ¨ í•„ë“œ í™•ì¸
                        debug_type_info = {
                            "type": doc.get("type"),
                            "source_type": doc.get("source_type"),
                            "metadata_type": metadata.get("type"),
                            "metadata_source_type": metadata.get("source_type"),
                            "has_statute_fields": any(key in doc or key in metadata for key in ["statute_name", "law_name", "article_no"]),
                            "has_case_fields": any(key in doc or key in metadata for key in ["case_id", "court", "doc_id", "casenames", "precedent_id"]),
                        }
                        logger.info(f"ğŸ” [DOC TYPE DEBUG] Doc {i} type info: {debug_type_info}")
                        
                        doc_type_enum = DocumentType.from_metadata(doc)
                        doc_type = doc_type_enum.value
                        # íƒ€ì… ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜
                        type_names = {
                            "statute_article": "ë²•ë ¹",
                            "precedent_content": "íŒë¡€",
                            "unknown": "ì•Œ ìˆ˜ ì—†ìŒ"
                        }
                        doc_type_display = type_names.get(doc_type, doc_type)
                        
                        # ë””ë²„ê¹…: ì¶”ë¡ ëœ íƒ€ì… ë¡œê¹…
                        if doc_type == "unknown":
                            logger.info(f"âš ï¸ [DOC TYPE DEBUG] Doc {i} inferred as UNKNOWN. Full doc keys: {list(doc.keys())[:20]}, metadata keys: {list(metadata.keys())[:20] if isinstance(metadata, dict) else 'N/A'}")
                    except Exception as e:
                        # ì˜ˆì™¸ ë°œìƒ ì‹œ ì§ì ‘ í•„ë“œ í™•ì¸
                        logger.debug(f"âš ï¸ [DOC TYPE ERROR] Doc {i} type inference error: {e}")
                        doc_type = doc.get("type") or doc.get("source_type") or metadata.get("type") or metadata.get("source_type", "unknown")
                        # ë ˆê±°ì‹œ í˜¸í™˜: "case" -> "precedent_content"
                        if doc_type == "case":
                            doc_type = "precedent_content"
                        type_names = {
                            "statute_article": "ë²•ë ¹",
                            "precedent_content": "íŒë¡€",
                            "unknown": "ì•Œ ìˆ˜ ì—†ìŒ"
                        }
                        doc_type_display = type_names.get(doc_type, doc_type)
                    
                    # ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œì—ì„œ ì‹œë„)
                    title = (
                        doc.get("title") or 
                        doc.get("name") or 
                        doc.get("source") or
                        (doc.get("content", "")[:100] if doc.get("content") else "") or
                        (doc.get("text", "")[:100] if doc.get("text") else "") or
                        "ì œëª© ì—†ìŒ"
                    )
                    
                    # ì ìˆ˜ ì¶”ì¶œ (ì •ê·œí™”ëœ ì ìˆ˜ ìš°ì„ )
                    score = (
                        doc.get("relevance_score") or 
                        doc.get("final_weighted_score") or
                        doc.get("score") or 
                        doc.get("similarity") or 
                        0.0
                    )
                    score_display = f"{score:.3f}" if isinstance(score, (int, float)) else str(score)
                    
                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ì²˜ë¦¬)
                    content = doc.get("content") or doc.get("text") or ""
                    if isinstance(content, dict):
                        # contentê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° text í•„ë“œ ì¶”ì¶œ
                        content = content.get("text", "") or content.get("content", "") or str(content)
                    if not isinstance(content, str):
                        content = str(content)
                    content_preview = content[:100] + "..." if len(content) > 100 else content
                    
                    logger.info(f"   {i}. [{doc_type_display}] {title}")
                    logger.info(f"       ì ìˆ˜: {score_display}, ë‚´ìš©: {content_preview}")
                    # ğŸ”¥ ê°œì„ : ê° ë¬¸ì„œ ì¶œë ¥ í›„ ì£¼ê¸°ì ìœ¼ë¡œ flush (5ê°œë§ˆë‹¤)
                    if i % 5 == 0:
                        flush_all_log_handlers()
                else:
                    logger.info(f"   {i}. {str(doc)[:100]}")
            if len(retrieved_docs) > 5:
                logger.info(f"   ... (ì´ {len(retrieved_docs)}ê°œ)")
            # ğŸ”¥ ê°œì„ : ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ ì™„ë£Œ í›„ flush
            flush_all_log_handlers()
        else:
            logger.warning("\nê²€ìƒ‰ëœ ì°¸ê³ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤!")
            # ğŸ”¥ ê°œì„ : ê²½ê³  ì¶œë ¥ í›„ ì¦‰ì‹œ flush
            flush_all_log_handlers()
        
        # ì†ŒìŠ¤
        sources = result.get("sources", [])
        if sources:
            logger.info(f"\nì†ŒìŠ¤ ({len(sources)}ê°œ):")
            for i, source in enumerate(sources[:5], 1):
                if isinstance(source, dict):
                    source_name = source.get("name") or source.get("title") or "ì œëª© ì—†ìŒ"
                    logger.info(f"   {i}. {source_name}")
                else:
                    logger.info(f"   {i}. {source}")
            if len(sources) > 5:
                logger.info(f"   ... (ì´ {len(sources)}ê°œ)")
            # ğŸ”¥ ê°œì„ : ì†ŒìŠ¤ ì¶œë ¥ ì™„ë£Œ í›„ flush
            flush_all_log_handlers()
        
        # ì²˜ë¦¬ ì‹œê°„ (ì¸¡ì •ëœ ì‹œê°„ê³¼ ê²°ê³¼ì˜ ì‹œê°„ ëª¨ë‘ í‘œì‹œ)
        processing_time = result.get("processing_time", 0.0)
        if processing_time:
            logger.info(f"\nì²˜ë¦¬ ì‹œê°„ (ê²°ê³¼): {processing_time:.2f}ì´ˆ")
        if 'query_elapsed_time' in locals():
            logger.info(f"ì²˜ë¦¬ ì‹œê°„ (ì¸¡ì •): {query_elapsed_time:.2f}ì´ˆ")
        # ğŸ”¥ ê°œì„ : ì²˜ë¦¬ ì‹œê°„ ì¶œë ¥ í›„ flush
        flush_all_log_handlers()
        
        # ì˜¤ë¥˜ í™•ì¸
        errors = result.get("errors", [])
        if errors:
            logger.warning(f"\nì˜¤ë¥˜ ë°œìƒ ({len(errors)}ê°œ):")
            for i, error in enumerate(errors[:5], 1):
                logger.warning(f"   {i}. {error}")
            if len(errors) > 5:
                logger.warning(f"   ... (ì´ {len(errors)}ê°œ)")
            # ğŸ”¥ ê°œì„ : ì˜¤ë¥˜ ì¶œë ¥ í›„ ì¦‰ì‹œ flush (ì¤‘ìš”!)
            flush_all_log_handlers()
        
        # 5. ê²°ê³¼ ìš”ì•½
        logger.info("\n5. ê²°ê³¼ ìš”ì•½:")
        logger.info("=" * 80)
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        summary = {
            "ì§ˆì˜": query,
            "ë‹µë³€ ê¸¸ì´": len(answer) if answer else 0,
            "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜": len(retrieved_docs) if retrieved_docs else 0,
            "ì†ŒìŠ¤ ìˆ˜": len(sources) if sources else 0,
            "ì²˜ë¦¬ ì‹œê°„": f"{processing_time:.2f}ì´ˆ" if processing_time else "N/A",
            "ì˜¤ë¥˜ ìˆ˜": len(errors) if errors else 0
        }
        
        logger.info("   ìš”ì•½ ì •ë³´:")
        for key, value in summary.items():
            logger.info(f"   - {key}: {value}")
        
        # ğŸ”¥ ê°œì„ : ìš”ì•½ ì •ë³´ ì¶œë ¥ í›„ flush
        flush_all_log_handlers()
        
        logger.info("\n" + "=" * 80)
        logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        logger.info("=" * 80)
        
        # ğŸ”¥ ê°œì„ : í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì§í›„ ì¦‰ì‹œ flush (ëª¨ë“  ë¡œê·¸ ì €ì¥ ë³´ì¥)
        flush_all_log_handlers()
        
        # ğŸ”¥ ê°œì„ : ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ë“±)
        try:
            # ì„œë¹„ìŠ¤ê°€ cleanup ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©´ í˜¸ì¶œ
            if hasattr(service, 'cleanup'):
                service.cleanup()
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì •ë¦¬
            if hasattr(service, 'legal_workflow') and service.legal_workflow:
                if hasattr(service.legal_workflow, 'data_connector') and service.legal_workflow.data_connector:
                    if hasattr(service.legal_workflow.data_connector, '_db_adapter') and service.legal_workflow.data_connector._db_adapter:
                        db_adapter = service.legal_workflow.data_connector._db_adapter
                        if hasattr(db_adapter, 'connection_pool') and db_adapter.connection_pool:
                            try:
                                # ì—°ê²° í’€ì˜ ëª¨ë“  ì—°ê²° ë‹«ê¸°
                                db_adapter.connection_pool.closeall()
                                logger.debug("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì •ë¦¬ ì™„ë£Œ")
                            except Exception as e:
                                logger.debug(f"ì—°ê²° í’€ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        except Exception as e:
            logger.debug(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        # ğŸ”¥ ê°œì„ : ë¡œê·¸ íŒŒì¼ì— ëª¨ë“  ë‚´ìš©ì´ ì €ì¥ë˜ë„ë¡ flush (ê°•í™”)
        # UnbufferedFileHandlerë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ë¯¸ flushë˜ì—ˆì§€ë§Œ, ìµœì¢… í™•ì¸ì„ ìœ„í•´ ë‹¤ì‹œ flush
        try:
            # ëª¨ë“  ë¡œê±°ì˜ ëª¨ë“  í•¸ë“¤ëŸ¬ flush
            loggers_to_flush = [
                logging.getLogger(),  # ë£¨íŠ¸ ë¡œê±°
                logging.getLogger("lawfirm_langgraph"),  # í•˜ìœ„ ë¡œê±°
                logging.getLogger("lawfirm_langgraph.tests.runners.run_query_test"),  # í…ŒìŠ¤íŠ¸ ë¡œê±°
            ]
            
            for logger_to_flush in loggers_to_flush:
                for handler in logger_to_flush.handlers:
                    try:
                        handler.flush()
                        # FileHandlerì˜ ê²½ìš° streamë„ ì§ì ‘ flush
                        if isinstance(handler, logging.FileHandler):
                            if hasattr(handler, 'stream') and handler.stream:
                                try:
                                    handler.stream.flush()
                                    # Windowsì—ì„œ ê°•ì œ ë™ê¸°í™”
                                    if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                                        try:
                                            os.fsync(handler.stream.fileno())
                                        except (OSError, AttributeError):
                                            pass
                                except (ValueError, AttributeError, OSError):
                                    pass
                    except Exception:
                        pass
        except Exception as e:
            logger.debug(f"ë¡œê·¸ flush ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        return result
        
    except ImportError as e:
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush
        flush_all_log_handlers()
        
        logger.error(f"\nImport ì˜¤ë¥˜: {e}")
        logger.error("í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        logger.error("   íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r requirements.txt")
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡ í›„ flush (ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
        for _ in range(5):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        raise
    except ValueError as e:
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush
        flush_all_log_handlers()
        
        logger.error(f"\nì„¤ì • ì˜¤ë¥˜: {e}")
        logger.error("í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        logger.error("   PostgreSQL URL ì„¤ì •:")
        logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
        logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡ í›„ flush (ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
        for _ in range(5):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        raise
    except KeyboardInterrupt:
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush
        flush_all_log_handlers()
        
        logger.warning("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ğŸ”¥ ê°œì„ : ì¤‘ë‹¨ ì‹œ ì¦‰ì‹œ flush (ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
        for _ in range(5):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        # ì¤‘ë‹¨ ì‹œì—ë„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œë„
        try:
            if 'service' in locals():
                if hasattr(service, 'legal_workflow') and service.legal_workflow:
                    if hasattr(service.legal_workflow, 'data_connector') and service.legal_workflow.data_connector:
                        if hasattr(service.legal_workflow.data_connector, '_db_adapter') and service.legal_workflow.data_connector._db_adapter:
                            db_adapter = service.legal_workflow.data_connector._db_adapter
                            if hasattr(db_adapter, 'connection_pool') and db_adapter.connection_pool:
                                try:
                                    db_adapter.connection_pool.closeall()
                                except Exception:
                                    pass
        except Exception:
            pass
        
        # ğŸ”¥ ê°œì„ : ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í›„ ë‹¤ì‹œ flush (ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
        for _ in range(5):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        raise
    except Exception as e:
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ
        for _ in range(3):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ ë¡œê·¸ ê¸°ë¡ ë° flush
        try:
            logger.error(f"\nì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}")
            logger.error("   ìƒì„¸ ì •ë³´:")
            logger.error(f"   - ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            logger.error(f"   - ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            if hasattr(e, '__cause__') and e.__cause__:
                logger.error(f"   - ì›ì¸: {e.__cause__}")
            logger.debug("   ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
            
            # ğŸ”¥ ê°œì„ : ê° ë¡œê·¸ ê¸°ë¡ í›„ ì¦‰ì‹œ flush
            for _ in range(3):
                flush_all_log_handlers()
                if sys.platform == 'win32':
                    time.sleep(0.01)
        except Exception:
            # ë¡œê·¸ ê¸°ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ flush ì‹œë„
            try:
                flush_all_log_handlers()
            except Exception:
                pass
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ ë° íŒŒì¼ ë™ê¸°í™”
        for _ in range(10):  # ë” ë§ì´ ë°˜ë³µ
            flush_all_log_handlers()
            # Windowsì—ì„œ íŒŒì¼ ë™ê¸°í™”
            if sys.platform == 'win32':
                try:
                    for handler in logging.getLogger().handlers:
                        if isinstance(handler, logging.FileHandler) and hasattr(handler, 'stream') and handler.stream:
                            if hasattr(handler.stream, 'fileno'):
                                try:
                                    os.fsync(handler.stream.fileno())
                                except (OSError, AttributeError):
                                    pass
                except Exception:
                    pass
            time.sleep(0.02)  # ë” ê¸´ ëŒ€ê¸°
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œë„
        try:
            if 'service' in locals():
                if hasattr(service, 'legal_workflow') and service.legal_workflow:
                    if hasattr(service.legal_workflow, 'data_connector') and service.legal_workflow.data_connector:
                        if hasattr(service.legal_workflow.data_connector, '_db_adapter') and service.legal_workflow.data_connector._db_adapter:
                            db_adapter = service.legal_workflow.data_connector._db_adapter
                            if hasattr(db_adapter, 'connection_pool') and db_adapter.connection_pool:
                                try:
                                    db_adapter.connection_pool.closeall()
                                except Exception:
                                    pass
        except Exception:
            pass
        
        # ğŸ”¥ ê°œì„ : ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í›„ ë‹¤ì‹œ flush (ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
        for _ in range(5):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    global _global_async_file_handler
    
    logger = None
    log_file_path = None
    try:
        # ë¡œê¹… ì„¤ì •
        logger = setup_logging()
        
        # ğŸ”¥ ê°œì„ : ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì €ì¥ (ì˜ˆì™¸ ë°œìƒ ì‹œ ì¶œë ¥ìš©)
        if logger:
            # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (handlerì—ì„œ)
            for handler in logging.getLogger().handlers:
                if isinstance(handler, logging.FileHandler):
                    log_file_path = handler.baseFilename
                    break
        
        # ì§ˆì˜ ê°€ì ¸ì˜¤ê¸°
        query = get_query_from_args()
        
        if not query:
            if logger:
                logger.error("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                logger.info("\nì‚¬ìš©ë²•:")
                logger.info("  python run_query_test.py \"ì§ˆì˜ ë‚´ìš©\"")
                logger.info("  python run_query_test.py 0  # ê¸°ë³¸ ì§ˆì˜ ì„ íƒ")
                logger.info("  $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python run_query_test.py")
            else:
                print("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return 1
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        try:
            # ğŸ”¥ ê°œì„ : asyncio.run í˜¸ì¶œ ì „ ë¡œê·¸ flush ë³´ì¥
            flush_all_log_handlers()
            
            # ğŸ”¥ ê°œì„ : asyncio.runì„ try-exceptë¡œ ê°ì‹¸ì„œ ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”
            try:
                asyncio.run(test_langgraph_query(query, logger))
            except KeyboardInterrupt:
                # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush
                flush_all_log_handlers()
                
                # ğŸ”¥ ê°œì„ : KeyboardInterruptëŠ” ë³„ë„ ì²˜ë¦¬ (ë¡œê·¸ ê¸°ë¡ í›„ ì¬ë°œìƒ)
                if logger:
                    logger.warning("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤ (asyncio.run ë‚´ë¶€).")
                
                # ğŸ”¥ ê°œì„ : ë¡œê·¸ ê¸°ë¡ í›„ flush (ì—¬ëŸ¬ ë²ˆ)
                for _ in range(5):
                    flush_all_log_handlers()
                    time.sleep(0.01)
                raise
            except Exception as async_error:
                # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ
                for _ in range(3):
                    flush_all_log_handlers()
                    time.sleep(0.01)
                
                # ğŸ”¥ ê°œì„ : ë¹„ë™ê¸° ì‘ì—… ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ ë¡œê·¸ ê¸°ë¡ ë° flush
                if logger:
                    try:
                        logger.error(f"\n\në¹„ë™ê¸° ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(async_error).__name__}: {async_error}")
                        logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(async_error).__name__}")
                        logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(async_error)}")
                        if hasattr(async_error, '__cause__') and async_error.__cause__:
                            logger.error(f"   ì›ì¸: {async_error.__cause__}")
                        logger.debug("   ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
                        
                        # ğŸ”¥ ê°œì„ : ê° ë¡œê·¸ ê¸°ë¡ í›„ ì¦‰ì‹œ flush
                        for _ in range(3):
                            flush_all_log_handlers()
                            time.sleep(0.01)
                    except Exception:
                        # ë¡œê·¸ ê¸°ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ flush ì‹œë„
                        try:
                            flush_all_log_handlers()
                        except Exception:
                            pass
                
                # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ flush (ì—¬ëŸ¬ ë²ˆ) ë° íŒŒì¼ ë™ê¸°í™”
                for _ in range(10):  # ë” ë§ì´ ë°˜ë³µ
                    flush_all_log_handlers()
                    # Windowsì—ì„œ íŒŒì¼ ë™ê¸°í™”
                    if sys.platform == 'win32':
                        try:
                            for handler in logging.getLogger().handlers:
                                if isinstance(handler, logging.FileHandler) and hasattr(handler, 'stream') and handler.stream:
                                    if hasattr(handler.stream, 'fileno'):
                                        try:
                                            os.fsync(handler.stream.fileno())
                                        except (OSError, AttributeError):
                                            pass
                        except Exception:
                            pass
                    time.sleep(0.02)  # ë” ê¸´ ëŒ€ê¸°
                raise
        except Exception as e:
            # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ
            for _ in range(3):
                flush_all_log_handlers()
                if sys.platform == 'win32':
                    time.sleep(0.01)
            
            # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ ë¡œê·¸ ê¸°ë¡ ë° flush
            if logger:
                try:
                    logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}")
                    logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                    logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
                    if hasattr(e, '__cause__') and e.__cause__:
                        logger.error(f"   ì›ì¸: {e.__cause__}")
                    logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
                    
                    # ğŸ”¥ ê°œì„ : ê° ë¡œê·¸ ê¸°ë¡ í›„ ì¦‰ì‹œ flush
                    for _ in range(3):
                        flush_all_log_handlers()
                        if sys.platform == 'win32':
                            time.sleep(0.01)
                except Exception:
                    # ë¡œê·¸ ê¸°ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ flush ì‹œë„
                    try:
                        flush_all_log_handlers()
                    except Exception:
                        pass
            
            # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œ ì¦‰ì‹œ flush (ì—¬ëŸ¬ ë²ˆ) ë° íŒŒì¼ ë™ê¸°í™”
            for _ in range(10):  # ë” ë§ì´ ë°˜ë³µ
                flush_all_log_handlers()
                # Windowsì—ì„œ íŒŒì¼ ë™ê¸°í™”
                if sys.platform == 'win32':
                    try:
                        for handler in logging.getLogger().handlers:
                            if isinstance(handler, logging.FileHandler) and hasattr(handler, 'stream') and handler.stream:
                                if hasattr(handler.stream, 'fileno'):
                                    try:
                                        os.fsync(handler.stream.fileno())
                                    except (OSError, AttributeError):
                                        pass
                    except Exception:
                        pass
                time.sleep(0.02)  # ë” ê¸´ ëŒ€ê¸°
            raise
        finally:
            # ğŸ”¥ ê°œì„ : ë¹„ë™ê¸° ì‘ì—… ì™„ë£Œ ì§í›„ ì¦‰ì‹œ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ
            for _ in range(5):
                flush_all_log_handlers()
                if sys.platform == 'win32':
                    time.sleep(0.01)
        
        # ğŸ”¥ ê°œì„ : í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[í…ŒìŠ¤íŠ¸ ì™„ë£Œ]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
            print(f"  ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¡´ ì—¬ë¶€ë¥¼ ê²€ì¦í•˜ì„¸ìš”.")
        
        # ğŸ”¥ ê°œì„ : ìµœì¢… flush (í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì§í›„)
        flush_all_log_handlers()
        
        # ğŸ”¥ ê°œì„ : ëª¨ë“  ë¡œê·¸ í•¸ë“¤ëŸ¬ flush ë° close (ë¡œê·¸ íŒŒì¼ ì™„ì „ ì €ì¥ ë³´ì¥) - ê°•í™”
        try:
            # ëª¨ë“  ë¡œê±°ì˜ ëª¨ë“  í•¸ë“¤ëŸ¬ flush ë° close
            loggers_to_close = [
                logging.getLogger(),  # ë£¨íŠ¸ ë¡œê±°
                logging.getLogger("lawfirm_langgraph"),  # í•˜ìœ„ ë¡œê±°
                logging.getLogger("lawfirm_langgraph.tests.runners.run_query_test"),  # í…ŒìŠ¤íŠ¸ ë¡œê±°
            ]
            
            for logger_to_close in loggers_to_close:
                for handler in logger_to_close.handlers[:]:  # ë³µì‚¬ë³¸ìœ¼ë¡œ ìˆœíšŒ (ì œê±° ì¤‘ ë³€ê²½ ë°©ì§€)
                    try:
                        # ë¨¼ì € flush
                        handler.flush()
                        
                        # FileHandlerì˜ ê²½ìš° streamë„ ì§ì ‘ flush ë° ë™ê¸°í™”
                        if isinstance(handler, logging.FileHandler):
                            if hasattr(handler, 'stream') and handler.stream:
                                try:
                                    handler.stream.flush()
                                    # Windowsì—ì„œ ê°•ì œ ë™ê¸°í™”
                                    if sys.platform == 'win32' and hasattr(handler.stream, 'fileno'):
                                        try:
                                            os.fsync(handler.stream.fileno())
                                        except (OSError, AttributeError):
                                            pass
                                except (ValueError, AttributeError, OSError):
                                    pass
                            # ê·¸ ë‹¤ìŒ close
                            handler.close()
                    except Exception:
                        pass
        except Exception as e:
            if logger:
                logger.debug(f"ë¡œê·¸ í•¸ë“¤ëŸ¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        
        return 0
        
    except KeyboardInterrupt:
        # ğŸ”¥ ê°œì„ : QueueListenerê°€ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ stop
        if _global_async_file_handler:
            try:
                _global_async_file_handler.stop()
            except Exception:
                pass
        
        if logger:
            logger.warning("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ğŸ”¥ ê°œì„ : ì¤‘ë‹¨ ì‹œì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
        
        # StreamHandlerë§Œ flush
        flush_all_log_handlers()
        
        return 1
    except Exception as e:
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì „ ê¸°ì¡´ ë¡œê·¸ flush (ì¤‘ìš”!) - ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ
        for _ in range(3):
            flush_all_log_handlers()
            if sys.platform == 'win32':
                time.sleep(0.01)
        
        if logger:
            try:
                logger.error(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
                if hasattr(e, '__cause__') and e.__cause__:
                    logger.error(f"   ì›ì¸: {e.__cause__}")
                logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
                
                # ğŸ”¥ ê°œì„ : ê° ë¡œê·¸ ê¸°ë¡ í›„ ì¦‰ì‹œ flush
                for _ in range(3):
                    flush_all_log_handlers()
                    if sys.platform == 'win32':
                        time.sleep(0.01)
            except Exception as log_error:
                # ë¡œê·¸ ê¸°ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ flush ì‹œë„
                try:
                    flush_all_log_handlers()
                except Exception:
                    pass
        else:
            print(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[ì˜¤ë¥˜ ë°œìƒ]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
            print(f"  ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
        
        # ğŸ”¥ ê°œì„ : QueueListenerê°€ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ stop
        if _global_async_file_handler:
            try:
                _global_async_file_handler.stop()
            except Exception:
                pass
        
        # StreamHandlerë§Œ flush
        flush_all_log_handlers()
        
        return 1
    finally:
        # ğŸ”¥ ê°œì„ : finally ë¸”ë¡ì—ì„œ QueueListener ì •ë¦¬ (ìµœì¢… ë³´ì¥)
        # QueueListenerê°€ íì— ë‚¨ì•„ìˆëŠ” ëª¨ë“  ë¡œê·¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ stop
        if _global_async_file_handler:
            try:
                _global_async_file_handler.stop()
            except Exception:
                pass
        
        # StreamHandlerë§Œ flush (ì½˜ì†” ì¶œë ¥ ë³´ì¥)
        flush_all_log_handlers()


if __name__ == "__main__":
    sys.exit(main())

