# -*- coding: utf-8 -*-
"""
LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python lawfirm_langgraph/tests/runners/run_query_test.py "ì§ˆì˜ ë‚´ìš©"
    python lawfirm_langgraph/tests/runners/run_query_test.py  # ê¸°ë³¸ ì§ˆì˜ ì‚¬ìš©
"""

import sys
import os
import asyncio
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Windows í˜¸í™˜)
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.platform == 'win32':
    os.environ['PYTHONLEGACYWINDOWSSTDIO'] = 'utf-8'

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
runners_dir = script_dir.parent
tests_dir = runners_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir.parent

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from utils.env_loader import ensure_env_loaded
    ensure_env_loaded(project_root)
except ImportError:
    pass

# SafeStreamHandler í´ë˜ìŠ¤ ì •ì˜ (Windows í™˜ê²½ í˜¸í™˜)
class SafeStreamHandler(logging.StreamHandler):
    """ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, stream, original_stdout_ref=None):
        super().__init__(stream)
        self._original_stdout = original_stdout_ref
    
    def _get_safe_stream(self):
        """ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ ë°˜í™˜"""
        streams_to_try = []
        if self.stream and hasattr(self.stream, 'write'):
            streams_to_try.append(self.stream)
        if self._original_stdout is not None and hasattr(self._original_stdout, 'write'):
            streams_to_try.append(self._original_stdout)
        if sys.stdout and hasattr(sys.stdout, 'write'):
            streams_to_try.append(sys.stdout)
        if sys.stderr and hasattr(sys.stderr, 'write'):
            streams_to_try.append(sys.stderr)
        
        for stream in streams_to_try:
            try:
                if hasattr(stream, 'buffer') or hasattr(stream, 'write'):
                    return stream
            except (ValueError, AttributeError, OSError):
                continue
        return None
    
    def emit(self, record):
        """ì•ˆì „í•œ ë¡œê·¸ ì¶œë ¥ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
        try:
            msg = self.format(record) + self.terminator
            safe_stream = self._get_safe_stream()
            if safe_stream is not None:
                try:
                    if hasattr(safe_stream, 'buffer'):
                        try:
                            buffer = safe_stream.buffer
                            if buffer is None:
                                raise ValueError("Buffer is None")
                        except (ValueError, AttributeError):
                            if hasattr(safe_stream, 'write'):
                                safe_stream.write(msg)
                                return
                    else:
                        safe_stream.write(msg)
                    
                    try:
                        safe_stream.flush()
                    except (ValueError, AttributeError, OSError):
                        pass
                    return
                except (ValueError, AttributeError, OSError):
                    pass
            
            if sys.stderr and hasattr(sys.stderr, 'write'):
                try:
                    sys.stderr.write(msg)
                    try:
                        sys.stderr.flush()
                    except (ValueError, AttributeError, OSError):
                        pass
                    return
                except (ValueError, AttributeError, OSError):
                    pass
        except Exception:
            pass
    
    def flush(self):
        """ì•ˆì „í•œ flush (ì˜¤ë¥˜ ë¬´ì‹œ)"""
        try:
            safe_stream = self._get_safe_stream()
            if safe_stream is not None:
                try:
                    safe_stream.flush()
                except (ValueError, AttributeError, OSError):
                    pass
        except (ValueError, AttributeError, OSError):
            pass


# ì›ë³¸ stdout ì €ì¥
_original_stdout = sys.stdout

# ë¡œê¹… ì„¤ì •
def setup_logging(log_level: Optional[str] = None) -> logging.Logger:
    """ë¡œê¹… ì„¤ì •
    
    Args:
        log_level: ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ LOG_LEVEL ë˜ëŠ” INFO)
    
    Returns:
        ì„¤ì •ëœ ë¡œê±°
    """
    # ë¡œê·¸ ë ˆë²¨ ê²°ì •
    if log_level is None:
        log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    else:
        log_level = log_level.upper()
    
    log_level_map = {
        "CRITICAL": logging.CRITICAL,
        "ERROR": logging.ERROR,
        "WARNING": logging.WARNING,
        "INFO": logging.INFO,
        "DEBUG": logging.DEBUG,
    }
    log_level_value = log_level_map.get(log_level, logging.INFO)
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„± (í™˜ê²½ ë³€ìˆ˜ë¡œ ê²½ë¡œ ì§€ì • ê°€ëŠ¥)
    log_dir_env = os.getenv("TEST_LOG_DIR")
    if log_dir_env:
        log_dir = Path(log_dir_env)
    else:
        log_dir = project_root / "logs" / "langgraph"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (í™˜ê²½ ë³€ìˆ˜ë¡œ íŒŒì¼ëª… ì§€ì • ê°€ëŠ¥)
    log_file_env = os.getenv("TEST_LOG_FILE")
    if log_file_env:
        log_file = Path(log_file_env)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"test_langgraph_query_{timestamp}.log"
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level_value)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in list(root_logger.handlers):
        root_logger.removeHandler(handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='w')
    file_handler.setLevel(log_level_value)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    root_logger.addHandler(file_handler)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€ (SafeStreamHandler ì‚¬ìš©)
    try:
        base_handler = logging.StreamHandler(_original_stdout)
    except (ValueError, AttributeError):
        try:
            base_handler = logging.StreamHandler(sys.stdout)
        except (ValueError, AttributeError):
            base_handler = logging.StreamHandler(sys.stderr)
    
    safe_handler = SafeStreamHandler(base_handler.stream, _original_stdout)
    safe_handler.setLevel(log_level_value)
    safe_handler.setFormatter(file_formatter)
    root_logger.addHandler(safe_handler)
    
    # lawfirm_langgraph ë¡œê±° ì„¤ì •
    langgraph_logger = logging.getLogger("lawfirm_langgraph")
    langgraph_logger.setLevel(log_level_value)
    langgraph_logger.propagate = True
    
    # Few-shot examples ê²½ê³  í•„í„°ë§ (ì„ íƒì )
    if os.getenv("SUPPRESS_FEW_SHOT_WARNING", "false").lower() == "true":
        few_shot_logger = logging.getLogger("lawfirm_langgraph.core.generation.formatters.answer_structure_enhancer")
        few_shot_logger.setLevel(logging.ERROR)  # WARNING ì´ìƒë§Œ í‘œì‹œ
    
    # í…ŒìŠ¤íŠ¸ ë¡œê±° (íŒŒì¼ëª…ê³¼ ì¼ì¹˜)
    logger = logging.getLogger("lawfirm_langgraph.tests.runners.run_query_test")
    logger.setLevel(log_level_value)
    
    # ğŸ”¥ ê°œì„ : ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶œë ¥ (íŒŒì¼ ìƒì„± í™•ì¸ìš©)
    logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    logger.info(f"ë¡œê·¸ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ: {log_file.absolute()}")
    logger.info(f"ë¡œê·¸ ë ˆë²¨: {log_level}")
    
    # ğŸ”¥ ê°œì„ : ì½˜ì†”ì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥ (ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš° ëŒ€ë¹„)
    print(f"\n[ë¡œê·¸ ì„¤ì •]")
    print(f"  ë¡œê·¸ íŒŒì¼: {log_file.absolute()}")
    print(f"  ë¡œê·¸ ë ˆë²¨: {log_level}")
    print()
    
    return logger


def get_query_from_args() -> str:
    """ëª…ë ¹ì¤„ ì¸ìì—ì„œ ì§ˆì˜ ì¶”ì¶œ"""
    default_queries = [
        "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    ]
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    test_query = os.getenv('TEST_QUERY', '').strip()
    if test_query:
        return test_query
    
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸
    if len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        
        # ìˆ«ìë¡œ ê¸°ë³¸ ì§ˆì˜ ì„ íƒ
        if arg.isdigit():
            idx = int(arg)
            if 0 <= idx < len(default_queries):
                return default_queries[idx]
        
        # ì§ˆì˜ ë‚´ìš© ì§ì ‘ ì…ë ¥
        return " ".join(sys.argv[1:])
    
    # ê¸°ë³¸ ì§ˆì˜ ë°˜í™˜
    return default_queries[0]


async def test_langgraph_query(query: str, logger: logging.Logger):
    """LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    Args:
        query: í…ŒìŠ¤íŠ¸í•  ì§ˆì˜
        logger: ë¡œê±°
    """
    logger.info("=" * 80)
    logger.info("LangGraph ì§ˆì˜ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 80)
    logger.info(f"\nì§ˆì˜: {query}\n")
    
    try:
        # ì„¤ì • ë¡œë“œ
        logger.info("1. ì„¤ì • ë¡œë“œ ì¤‘...")
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.config.app_config import Config as AppConfig
        
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False
        logger.info(f"   LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        logger.info(f"   ì²´í¬í¬ì¸íŠ¸: {config.enable_checkpoint}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ê²€ìƒ‰ ì„¤ì • í™•ì¸
        logger.info("\n1.1. ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ê²€ìƒ‰ ì„¤ì • í™•ì¸...")
        app_config = AppConfig()
        
        # SQLite URL ê²€ì¦ (í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „)
        if app_config.database_url.startswith("sqlite://"):
            logger.error("   âŒ SQLiteëŠ” ë” ì´ìƒ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PostgreSQLì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            logger.error("   PostgreSQL URL ì„¤ì • ë°©ë²•:")
            logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
            logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
            raise ValueError("SQLite is no longer supported. Please configure PostgreSQL.")
        
        logger.info(f"   âœ… Database URL ì„¤ì •ë¨ (PostgreSQL)")
        logger.info(f"   VECTOR_SEARCH_METHOD: {app_config.vector_search_method}")
        if app_config.faiss_index_path:
            logger.info(f"   FAISS_INDEX_PATH: {app_config.faiss_index_path}")
        
        # DatabaseAdapter í™•ì¸
        try:
            from lawfirm_langgraph.core.data.db_adapter import DatabaseAdapter
            if app_config.database_url:
                db_adapter = DatabaseAdapter(app_config.database_url)
                logger.info(f"   âœ… DatabaseAdapter ì´ˆê¸°í™” ì„±ê³µ: type={db_adapter.db_type}")
                if db_adapter.db_type == 'postgresql':
                    logger.info(f"   âœ… PostgreSQL ì‚¬ìš© ì¤‘")
                else:
                    logger.error(f"   âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…: {db_adapter.db_type} (PostgreSQLë§Œ ì§€ì›)")
                    logger.error("   PostgreSQL URL ì„¤ì • ë°©ë²•:")
                    logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
                    logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
                    raise ValueError(f"Unsupported database type: {db_adapter.db_type}. Only PostgreSQL is supported.")
        except ValueError as e:
            logger.error(f"   âŒ DatabaseAdapter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        except Exception as e:
            logger.error(f"   âŒ DatabaseAdapter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error("   PostgreSQL ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            raise
        
        # VectorSearchFactory í™•ì¸
        try:
            from lawfirm_langgraph.core.search.engines.vector_search_adapter import VectorSearchFactory
            logger.info(f"   âœ… VectorSearchFactory ì‚¬ìš© ê°€ëŠ¥")
            if app_config.vector_search_method.lower() == 'pgvector':
                try:
                    import pgvector
                    logger.info(f"   âœ… pgvector ì‚¬ìš© ì¤‘ (pgvector íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨)")
                except ImportError:
                    logger.warning(f"   âš ï¸  pgvector ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    logger.warning(f"   ì„¤ì¹˜ ë°©ë²•: pip install pgvector")
            elif app_config.vector_search_method.lower() == 'faiss':
                logger.info(f"   âœ… FAISS ì‚¬ìš© ì¤‘")
            elif app_config.vector_search_method.lower() == 'hybrid':
                logger.info(f"   âœ… Hybrid (pgvector + FAISS) ì‚¬ìš© ì¤‘")
        except Exception as e:
            logger.warning(f"   âš ï¸  VectorSearchFactory ì‚¬ìš© ë¶ˆê°€: {e}")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("\n2. LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        from lawfirm_langgraph.core.workflow.workflow_service import LangGraphWorkflowService
        
        service = LangGraphWorkflowService(config)
        logger.info("   ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì„œë¹„ìŠ¤ ë‚´ë¶€ ì»´í¬ë„ŒíŠ¸ í™•ì¸
        if hasattr(service, 'db_manager') and service.db_manager:
            if hasattr(service.db_manager, '_db_adapter') and service.db_manager._db_adapter:
                logger.info(f"   âœ… LegalDataConnectorV2 DatabaseAdapter: type={service.db_manager._db_adapter.db_type}")
        
        if hasattr(service, 'semantic_search_engine') and service.semantic_search_engine:
            if hasattr(service.semantic_search_engine, '_db_adapter') and service.semantic_search_engine._db_adapter:
                logger.info(f"   âœ… SemanticSearchEngineV2 DatabaseAdapter: type={service.semantic_search_engine._db_adapter.db_type}")
            if hasattr(service.semantic_search_engine, 'vector_adapter') and service.semantic_search_engine.vector_adapter:
                adapter_type = type(service.semantic_search_engine.vector_adapter).__name__
                logger.info(f"   âœ… SemanticSearchEngineV2 VectorAdapter: {adapter_type}")
        
        # ì§ˆì˜ ì²˜ë¦¬
        logger.info("\n3. ì§ˆì˜ ì²˜ë¦¬ ì¤‘...")
        logger.info("   (ì´ ì‘ì—…ì€ ëª‡ ì´ˆì—ì„œ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        import time
        start_time = time.time()
        
        logger.debug("   3.1. ê²€ìƒ‰ ë‹¨ê³„ ì‹œì‘...")
        result = await service.process_query(
            query=query,
            session_id="test_langgraph_query",
            enable_checkpoint=False,
            use_astream_events=True
        )
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        logger.debug(f"   3.2. ì§ˆì˜ ì²˜ë¦¬ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n4. ê²°ê³¼:")
        logger.info("=" * 80)
        
        # ë‹µë³€ ì¶”ì¶œ (ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°)
        answer = result.get("answer", "")
        if isinstance(answer, dict):
            answer = answer.get("answer", "") or answer.get("content", "") or ""
        answer = str(answer).strip() if answer else ""
        
        # answerê°€ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°
        if not answer:
            # output í•„ë“œ í™•ì¸
            output = result.get("output", {})
            if isinstance(output, dict):
                answer = output.get("answer", "") or output.get("content", "")
        
        # ìµœì¢… ë¬¸ìì—´ ë³€í™˜
        answer = str(answer).strip() if answer else ""
        
        if answer:
            logger.info(f"\në‹µë³€ ({len(answer)}ì):")
            logger.info("-" * 80)
            logger.info(answer)
        else:
            logger.warning("\në‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤!")
            # ë””ë²„ê¹…: resultì˜ ëª¨ë“  í‚¤ ì¶œë ¥
            logger.debug(f"Result keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
            if isinstance(result, dict) and "answer" in result:
                logger.debug(f"Answer type: {type(result['answer'])}, value: {str(result['answer'])[:100]}")
        
        # ê²€ìƒ‰ ê²°ê³¼ (í’ˆì§ˆ ì •ë³´ í¬í•¨)
        retrieved_docs = result.get("retrieved_docs", [])
        if retrieved_docs:
            logger.info(f"\nê²€ìƒ‰ëœ ì°¸ê³ ìë£Œ ({len(retrieved_docs)}ê°œ):")
            for i, doc in enumerate(retrieved_docs[:5], 1):
                if isinstance(doc, dict):
                    # ğŸ”¥ ê°œì„ : ë©”íƒ€ë°ì´í„° ë³´ê°• - ìµœìƒìœ„ í•„ë“œë¥¼ metadataì— ë³µì‚¬ (DocumentType ì¶”ë¡ ì„ ìœ„í•´)
                    metadata = doc.get("metadata", {})
                    if not isinstance(metadata, dict):
                        metadata = {}
                    
                    # ìµœìƒìœ„ í•„ë“œë¥¼ metadataì— ë³µì‚¬ (DocumentType ì¶”ë¡ ì„ ìœ„í•´)
                    for key in ["statute_name", "law_name", "article_no", "case_id", "court", "doc_id", "casenames", "precedent_id", "type", "source_type"]:
                        if key in doc and key not in metadata:
                            metadata[key] = doc[key]
                    
                    # metadataì˜ ì •ë³´ë„ ìµœìƒìœ„ í•„ë“œë¡œ ë³µì‚¬ (ì¼ê´€ì„± ìœ ì§€)
                    for key in ["statute_name", "law_name", "article_no", "case_id", "court", "doc_id", "casenames", "precedent_id", "type", "source_type"]:
                        if key in metadata and key not in doc:
                            doc[key] = metadata[key]
                    
                    doc["metadata"] = metadata
                    
                    # DocumentType Enum ì‚¬ìš©í•˜ì—¬ íƒ€ì… ì¶”ì¶œ
                    try:
                        from lawfirm_langgraph.core.workflow.constants.document_types import DocumentType
                        # ë””ë²„ê¹…: docì˜ íƒ€ì… ê´€ë ¨ í•„ë“œ í™•ì¸
                        debug_type_info = {
                            "type": doc.get("type"),
                            "source_type": doc.get("source_type"),
                            "metadata_type": metadata.get("type"),
                            "metadata_source_type": metadata.get("source_type"),
                            "has_statute_fields": any(key in doc or key in metadata for key in ["statute_name", "law_name", "article_no"]),
                            "has_case_fields": any(key in doc or key in metadata for key in ["case_id", "court", "doc_id", "casenames", "precedent_id"]),
                        }
                        logger.info(f"ğŸ” [DOC TYPE DEBUG] Doc {i} type info: {debug_type_info}")
                        
                        doc_type_enum = DocumentType.from_metadata(doc)
                        doc_type = doc_type_enum.value
                        # íƒ€ì… ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜
                        type_names = {
                            "statute_article": "ë²•ë ¹",
                            "precedent_content": "íŒë¡€",
                            "unknown": "ì•Œ ìˆ˜ ì—†ìŒ"
                        }
                        doc_type_display = type_names.get(doc_type, doc_type)
                        
                        # ë””ë²„ê¹…: ì¶”ë¡ ëœ íƒ€ì… ë¡œê¹…
                        if doc_type == "unknown":
                            logger.info(f"âš ï¸ [DOC TYPE DEBUG] Doc {i} inferred as UNKNOWN. Full doc keys: {list(doc.keys())[:20]}, metadata keys: {list(metadata.keys())[:20] if isinstance(metadata, dict) else 'N/A'}")
                    except Exception as e:
                        # ì˜ˆì™¸ ë°œìƒ ì‹œ ì§ì ‘ í•„ë“œ í™•ì¸
                        logger.debug(f"âš ï¸ [DOC TYPE ERROR] Doc {i} type inference error: {e}")
                        doc_type = doc.get("type") or doc.get("source_type") or metadata.get("type") or metadata.get("source_type", "unknown")
                        # ë ˆê±°ì‹œ í˜¸í™˜: "case" -> "precedent_content"
                        if doc_type == "case":
                            doc_type = "precedent_content"
                        type_names = {
                            "statute_article": "ë²•ë ¹",
                            "precedent_content": "íŒë¡€",
                            "unknown": "ì•Œ ìˆ˜ ì—†ìŒ"
                        }
                        doc_type_display = type_names.get(doc_type, doc_type)
                    
                    # ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œì—ì„œ ì‹œë„)
                    title = (
                        doc.get("title") or 
                        doc.get("name") or 
                        doc.get("source") or
                        (doc.get("content", "")[:100] if doc.get("content") else "") or
                        (doc.get("text", "")[:100] if doc.get("text") else "") or
                        "ì œëª© ì—†ìŒ"
                    )
                    
                    # ì ìˆ˜ ì¶”ì¶œ (ì •ê·œí™”ëœ ì ìˆ˜ ìš°ì„ )
                    score = (
                        doc.get("relevance_score") or 
                        doc.get("final_weighted_score") or
                        doc.get("score") or 
                        doc.get("similarity") or 
                        0.0
                    )
                    score_display = f"{score:.3f}" if isinstance(score, (int, float)) else str(score)
                    
                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ì²˜ë¦¬)
                    content = doc.get("content") or doc.get("text") or ""
                    if isinstance(content, dict):
                        # contentê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° text í•„ë“œ ì¶”ì¶œ
                        content = content.get("text", "") or content.get("content", "") or str(content)
                    if not isinstance(content, str):
                        content = str(content)
                    content_preview = content[:100] + "..." if len(content) > 100 else content
                    
                    logger.info(f"   {i}. [{doc_type_display}] {title}")
                    logger.info(f"       ì ìˆ˜: {score_display}, ë‚´ìš©: {content_preview}")
                else:
                    logger.info(f"   {i}. {str(doc)[:100]}")
            if len(retrieved_docs) > 5:
                logger.info(f"   ... (ì´ {len(retrieved_docs)}ê°œ)")
        else:
            logger.warning("\nê²€ìƒ‰ëœ ì°¸ê³ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        # ì†ŒìŠ¤
        sources = result.get("sources", [])
        if sources:
            logger.info(f"\nì†ŒìŠ¤ ({len(sources)}ê°œ):")
            for i, source in enumerate(sources[:5], 1):
                if isinstance(source, dict):
                    source_name = source.get("name") or source.get("title") or "ì œëª© ì—†ìŒ"
                    logger.info(f"   {i}. {source_name}")
                else:
                    logger.info(f"   {i}. {source}")
            if len(sources) > 5:
                logger.info(f"   ... (ì´ {len(sources)}ê°œ)")
        
        # ì²˜ë¦¬ ì‹œê°„ (ì¸¡ì •ëœ ì‹œê°„ê³¼ ê²°ê³¼ì˜ ì‹œê°„ ëª¨ë‘ í‘œì‹œ)
        processing_time = result.get("processing_time", 0.0)
        if processing_time:
            logger.info(f"\nì²˜ë¦¬ ì‹œê°„ (ê²°ê³¼): {processing_time:.2f}ì´ˆ")
        if 'elapsed_time' in locals():
            logger.info(f"ì²˜ë¦¬ ì‹œê°„ (ì¸¡ì •): {elapsed_time:.2f}ì´ˆ")
        
        # ì˜¤ë¥˜ í™•ì¸
        errors = result.get("errors", [])
        if errors:
            logger.warning(f"\nì˜¤ë¥˜ ë°œìƒ ({len(errors)}ê°œ):")
            for i, error in enumerate(errors[:5], 1):
                logger.warning(f"   {i}. {error}")
            if len(errors) > 5:
                logger.warning(f"   ... (ì´ {len(errors)}ê°œ)")
        
        # 5. ê²°ê³¼ ìš”ì•½
        logger.info("\n5. ê²°ê³¼ ìš”ì•½:")
        logger.info("=" * 80)
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        summary = {
            "ì§ˆì˜": query,
            "ë‹µë³€ ê¸¸ì´": len(answer) if answer else 0,
            "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜": len(retrieved_docs) if retrieved_docs else 0,
            "ì†ŒìŠ¤ ìˆ˜": len(sources) if sources else 0,
            "ì²˜ë¦¬ ì‹œê°„": f"{processing_time:.2f}ì´ˆ" if processing_time else "N/A",
            "ì˜¤ë¥˜ ìˆ˜": len(errors) if errors else 0
        }
        
        logger.info("   ìš”ì•½ ì •ë³´:")
        for key, value in summary.items():
            logger.info(f"   - {key}: {value}")
        
        logger.info("\n" + "=" * 80)
        logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        logger.info("=" * 80)
        
        return result
        
    except ImportError as e:
        logger.error(f"\nImport ì˜¤ë¥˜: {e}")
        logger.error("í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        logger.error(f"   íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r requirements.txt")
        raise
    except ValueError as e:
        logger.error(f"\nì„¤ì • ì˜¤ë¥˜: {e}")
        logger.error("í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        logger.error("   PostgreSQL URL ì„¤ì •:")
        logger.error("   - DATABASE_URL=postgresql://user:password@host:port/database")
        logger.error("   - ë˜ëŠ” POSTGRES_HOST, POSTGRES_PORT, POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
        raise
    except Exception as e:
        logger.error(f"\nì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}")
        logger.error(f"   ìƒì„¸ ì •ë³´:")
        logger.error(f"   - ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        logger.error(f"   - ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
        if hasattr(e, '__cause__') and e.__cause__:
            logger.error(f"   - ì›ì¸: {e.__cause__}")
        logger.debug("   ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
        raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger = None
    log_file_path = None
    try:
        # ë¡œê¹… ì„¤ì •
        logger = setup_logging()
        
        # ğŸ”¥ ê°œì„ : ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì €ì¥ (ì˜ˆì™¸ ë°œìƒ ì‹œ ì¶œë ¥ìš©)
        if logger:
            # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (handlerì—ì„œ)
            for handler in logging.getLogger().handlers:
                if isinstance(handler, logging.FileHandler):
                    log_file_path = handler.baseFilename
                    break
        
        # ì§ˆì˜ ê°€ì ¸ì˜¤ê¸°
        query = get_query_from_args()
        
        if not query:
            if logger:
                logger.error("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                logger.info("\nì‚¬ìš©ë²•:")
                logger.info("  python run_query_test.py \"ì§ˆì˜ ë‚´ìš©\"")
                logger.info("  python run_query_test.py 0  # ê¸°ë³¸ ì§ˆì˜ ì„ íƒ")
                logger.info("  $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python run_query_test.py")
            else:
                print("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return 1
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        asyncio.run(test_langgraph_query(query, logger))
        
        # ğŸ”¥ ê°œì„ : í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[í…ŒìŠ¤íŠ¸ ì™„ë£Œ]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
            print(f"  ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¡´ ì—¬ë¶€ë¥¼ ê²€ì¦í•˜ì„¸ìš”.")
        
        return 0
        
    except KeyboardInterrupt:
        if logger:
            logger.warning("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ğŸ”¥ ê°œì„ : ì¤‘ë‹¨ ì‹œì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
        
        return 1
    except Exception as e:
        if logger:
            logger.error(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
        else:
            print(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        # ğŸ”¥ ê°œì„ : ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        if log_file_path:
            print(f"\n[ì˜¤ë¥˜ ë°œìƒ]")
            print(f"  ë¡œê·¸ íŒŒì¼: {log_file_path}")
            print(f"  ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
        
        return 1


if __name__ == "__main__":
    sys.exit(main())

