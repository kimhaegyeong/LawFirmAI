# -*- coding: utf-8 -*-
"""
astream_eventsì—ì„œ type ì •ë³´ ë³´ì¡´ í…ŒìŠ¤íŠ¸

Usage:
    python lawfirm_langgraph/tests/runners/test_astream_events_type_preservation.py "ì§ˆì˜ ë‚´ìš©"
"""

import sys
import os
import asyncio
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Windows í˜¸í™˜)
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.platform == 'win32':
    os.environ['PYTHONLEGACYWINDOWSSTDIO'] = 'utf-8'

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent
runners_dir = script_dir.parent
tests_dir = runners_dir.parent
lawfirm_langgraph_dir = tests_dir.parent
project_root = lawfirm_langgraph_dir

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(lawfirm_langgraph_dir) not in sys.path:
    sys.path.insert(0, str(lawfirm_langgraph_dir))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from utils.env_loader import ensure_env_loaded
    ensure_env_loaded(project_root)
except ImportError:
    pass


class SafeStreamHandler(logging.StreamHandler):
    """ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
    
    def emit(self, record):
        """ì•ˆì „í•œ ë¡œê·¸ ì¶œë ¥ (ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë°©ì§€)"""
        try:
            msg = self.format(record) + self.terminator
            stream = self.stream
            if stream and hasattr(stream, 'write'):
                try:
                    stream.write(msg)
                    if hasattr(stream, 'flush'):
                        stream.flush()
                except (ValueError, AttributeError, OSError):
                    # ë²„í¼ ë¶„ë¦¬ ì˜¤ë¥˜ ë“±ì€ ë¬´ì‹œ
                    pass
        except Exception:
            # ëª¨ë“  ì˜ˆì™¸ëŠ” ë¬´ì‹œ (ë¡œê¹… ì‹¤íŒ¨ê°€ í”„ë¡œê·¸ë¨ ì‹¤íŒ¨ë¡œ ì´ì–´ì§€ì§€ ì•Šë„ë¡)
            self.handleError(record)
    
    def flush(self):
        """ì•ˆì „í•œ flush (ì˜¤ë¥˜ ë¬´ì‹œ)"""
        try:
            if self.stream and hasattr(self.stream, 'flush'):
                self.stream.flush()
        except (ValueError, AttributeError, OSError):
            pass


def setup_logging(log_level: Optional[str] = None) -> logging.Logger:
    """ë¡œê¹… ì„¤ì •"""
    if log_level is None:
        log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    log_level_map = {
        "CRITICAL": logging.CRITICAL,
        "ERROR": logging.ERROR,
        "WARNING": logging.WARNING,
        "INFO": logging.INFO,
        "DEBUG": logging.DEBUG,
    }
    log_level_value = log_level_map.get(log_level, logging.INFO)
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir_env = os.getenv("TEST_LOG_DIR")
    if log_dir_env:
        log_dir = Path(log_dir_env)
    else:
        log_dir = project_root / "logs" / "test"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    log_file_env = os.getenv("TEST_LOG_FILE")
    if log_file_env:
        log_file = Path(log_file_env)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"test_astream_events_type_{timestamp}.log"
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level_value)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in list(root_logger.handlers):
        try:
            handler.close()
        except Exception:
            pass
        root_logger.removeHandler(handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(log_level_value)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    root_logger.addHandler(file_handler)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬ (ì•ˆì „í•œ í•¸ë“¤ëŸ¬ ì‚¬ìš©)
    console_handler = SafeStreamHandler(sys.stdout)
    console_handler.setLevel(log_level_value)
    console_handler.setFormatter(file_formatter)
    root_logger.addHandler(console_handler)
    
    # ğŸ”¥ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ë¡œê¹… ë¹„í™œì„±í™” (langsmith ë“±)
    try:
        langsmith_logger = logging.getLogger("langsmith")
        langsmith_logger.setLevel(logging.ERROR)  # ERROR ì´ìƒë§Œ í‘œì‹œ
        langsmith_logger.propagate = False  # ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒí•˜ì§€ ì•ŠìŒ
    except Exception:
        pass
    
    logger = logging.getLogger("test_astream_events_type")
    logger.setLevel(log_level_value)
    
    logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file.absolute()}")
    
    return logger


def check_document_type(doc: Dict[str, Any], doc_index: int) -> Dict[str, Any]:
    """ë¬¸ì„œì˜ type ì •ë³´ í™•ì¸"""
    result = {
        "index": doc_index,
        "has_type": False,
        "type": None,
        "has_source_type": False,
        "source_type": None,
        "has_metadata_type": False,
        "metadata_type": None,
        "type_hints": {}
    }
    
    if not isinstance(doc, dict):
        return result
    
    # ìµœìƒìœ„ ë ˆë²¨ type í™•ì¸
    if "type" in doc and doc["type"]:
        result["has_type"] = True
        result["type"] = doc["type"]
    
    # source_type í™•ì¸
    if "source_type" in doc and doc["source_type"]:
        result["has_source_type"] = True
        result["source_type"] = doc["source_type"]
    
    # metadata type í™•ì¸
    metadata = doc.get("metadata", {})
    if isinstance(metadata, dict):
        if "type" in metadata and metadata["type"]:
            result["has_metadata_type"] = True
            result["metadata_type"] = metadata["type"]
    
    # type hint í•„ë“œ í™•ì¸
    type_hint_fields = [
        "statute_name", "law_name", "article_no", "case_id", "court",
        "doc_id", "casenames", "precedent_id"
    ]
    for field in type_hint_fields:
        if field in doc and doc[field]:
            result["type_hints"][field] = doc[field]
        elif isinstance(metadata, dict) and field in metadata and metadata[field]:
            result["type_hints"][field] = metadata[field]
    
    return result


async def test_astream_events_type_preservation(query: str, logger: logging.Logger):
    """astream_eventsì—ì„œ type ì •ë³´ ë³´ì¡´ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 80)
    logger.info("astream_events Type ì •ë³´ ë³´ì¡´ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 80)
    logger.info(f"ì§ˆì˜: {query}")
    
    try:
        # ì„¤ì • ë¡œë“œ
        logger.info("1. ì„¤ì • ë¡œë“œ ì¤‘...")
        from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
        from lawfirm_langgraph.config.app_config import Config as AppConfig
        
        config = LangGraphConfig.from_env()
        config.enable_checkpoint = False
        
        app_config = AppConfig()
        logger.info(f"   LangGraph í™œì„±í™”: {config.langgraph_enabled}")
        logger.info(f"   ì²´í¬í¬ì¸íŠ¸: {config.enable_checkpoint}")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        logger.info("\n2. LangGraphWorkflowService ì´ˆê¸°í™” ì¤‘...")
        from lawfirm_langgraph.core.workflow.workflow_service import LangGraphWorkflowService
        
        service = LangGraphWorkflowService(config)
        logger.info("   ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì§ˆì˜ ì²˜ë¦¬ (astream_events ì‚¬ìš©)
        logger.info("\n3. ì§ˆì˜ ì²˜ë¦¬ ì¤‘ (astream_events)...")
        logger.info("   (ì´ ì‘ì—…ì€ ëª‡ ì´ˆì—ì„œ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        result = await service.process_query(
            query=query,
            session_id="test_astream_events_type",
            enable_checkpoint=False,
            use_astream_events=True  # ğŸ”¥ CRITICAL: astream_events ì‚¬ìš©
        )
        
        logger.info("   ì§ˆì˜ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ê²°ê³¼ ê²€ì¦
        logger.info("\n4. Type ì •ë³´ ê²€ì¦:")
        logger.info("=" * 80)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        retrieved_docs = result.get("retrieved_docs", [])
        if not retrieved_docs:
            # search ê·¸ë£¹ì—ì„œ í™•ì¸
            search_group = result.get("search", {})
            if isinstance(search_group, dict):
                retrieved_docs = search_group.get("retrieved_docs", [])
        
        if not retrieved_docs:
            logger.error("   âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        logger.info(f"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}ê°œ")
        
        # ê° ë¬¸ì„œì˜ type ì •ë³´ í™•ì¸
        type_check_results = []
        type_missing_count = 0
        type_present_count = 0
        
        for i, doc in enumerate(retrieved_docs):
            check_result = check_document_type(doc, i + 1)
            type_check_results.append(check_result)
            
            if check_result["has_type"] or check_result["has_source_type"] or check_result["has_metadata_type"]:
                type_present_count += 1
                logger.info(f"   âœ… ë¬¸ì„œ {i+1}: type={check_result['type'] or check_result['source_type'] or check_result['metadata_type']}")
            else:
                type_missing_count += 1
                logger.warning(f"   âŒ ë¬¸ì„œ {i+1}: type ì •ë³´ ì—†ìŒ")
                logger.warning(f"      - type_hints: {check_result['type_hints']}")
        
        # í†µê³„ ì¶œë ¥
        logger.info("\n5. Type ì •ë³´ í†µê³„:")
        logger.info("=" * 80)
        logger.info(f"   ì´ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}ê°œ")
        logger.info(f"   Type ì •ë³´ ìˆìŒ: {type_present_count}ê°œ ({type_present_count/len(retrieved_docs)*100:.1f}%)")
        logger.info(f"   Type ì •ë³´ ì—†ìŒ: {type_missing_count}ê°œ ({type_missing_count/len(retrieved_docs)*100:.1f}%)")
        
        # Type ë¶„í¬
        type_distribution = {}
        for check_result in type_check_results:
            doc_type = check_result["type"] or check_result["source_type"] or check_result["metadata_type"]
            if doc_type:
                type_distribution[doc_type] = type_distribution.get(doc_type, 0) + 1
        
        if type_distribution:
            logger.info(f"\n   Type ë¶„í¬:")
            for doc_type, count in sorted(type_distribution.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"      - {doc_type}: {count}ê°œ")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒì •
        success_rate = type_present_count / len(retrieved_docs) if retrieved_docs else 0
        threshold = 0.8  # 80% ì´ìƒì´ë©´ ì„±ê³µ
        
        logger.info("\n6. í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        logger.info("=" * 80)
        if success_rate >= threshold:
            logger.info(f"   âœ… í…ŒìŠ¤íŠ¸ í†µê³¼: {success_rate*100:.1f}% ë¬¸ì„œì— type ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold*100:.0f}%)")
            return True
        else:
            logger.error(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {success_rate*100:.1f}% ë¬¸ì„œì—ë§Œ type ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤ (ì„ê³„ê°’: {threshold*100:.0f}%)")
            return False
        
    except Exception as e:
        logger.error(f"\nì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}")
        logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
        return False


def get_query_from_args() -> str:
    """ëª…ë ¹ì¤„ ì¸ìì—ì„œ ì§ˆì˜ ì¶”ì¶œ"""
    default_queries = [
        "ì†í•´ë°°ìƒì˜ ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ê²°ì •ë˜ë‚˜ìš”?",
        "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜í•  ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¯¼ë²• ì œ750ì¡° ì†í•´ë°°ìƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    ]
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    test_query = os.getenv('TEST_QUERY', '').strip()
    if test_query:
        return test_query
    
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸
    if len(sys.argv) > 1:
        arg = sys.argv[1].strip()
        
        # ìˆ«ìë¡œ ê¸°ë³¸ ì§ˆì˜ ì„ íƒ
        if arg.isdigit():
            idx = int(arg)
            if 0 <= idx < len(default_queries):
                return default_queries[idx]
        
        # ì§ˆì˜ ë‚´ìš© ì§ì ‘ ì…ë ¥
        return " ".join(sys.argv[1:])
    
    # ê¸°ë³¸ ì§ˆì˜ ë°˜í™˜
    return default_queries[0]


def cleanup_logging():
    """ë¡œê±° ì •ë¦¬ (í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì „)"""
    try:
        root_logger = logging.getLogger()
        for handler in list(root_logger.handlers):
            try:
                handler.flush()
                handler.close()
            except Exception:
                pass
            root_logger.removeHandler(handler)
        
        # ëª¨ë“  ë¡œê±°ì˜ í•¸ë“¤ëŸ¬ ì •ë¦¬
        for logger_name in list(logging.Logger.manager.loggerDict.keys()):
            try:
                logger = logging.getLogger(logger_name)
                for handler in list(logger.handlers):
                    try:
                        handler.flush()
                        handler.close()
                    except Exception:
                        pass
                    logger.removeHandler(handler)
            except Exception:
                pass
    except Exception:
        pass


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger = None
    
    try:
        # ë¡œê¹… ì„¤ì •
        logger = setup_logging()
        
        # ì§ˆì˜ ê°€ì ¸ì˜¤ê¸°
        query = get_query_from_args()
        
        if not query:
            if logger:
                logger.error("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                logger.info("\nì‚¬ìš©ë²•:")
                logger.info("  python test_astream_events_type_preservation.py \"ì§ˆì˜ ë‚´ìš©\"")
                logger.info("  python test_astream_events_type_preservation.py 0  # ê¸°ë³¸ ì§ˆì˜ ì„ íƒ")
                logger.info("  $env:TEST_QUERY='ì§ˆì˜ë‚´ìš©'; python test_astream_events_type_preservation.py")
            return 1
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        success = asyncio.run(test_astream_events_type_preservation(query, logger))
        
        if success:
            try:
                logger.info("\n" + "=" * 80)
                logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ: âœ… í†µê³¼")
                logger.info("=" * 80)
            except Exception:
                # ë¡œê¹… ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
                print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ: âœ… í†µê³¼")
            return 0
        else:
            try:
                logger.error("\n" + "=" * 80)
                logger.error("í…ŒìŠ¤íŠ¸ ì™„ë£Œ: âŒ ì‹¤íŒ¨")
                logger.error("=" * 80)
            except Exception:
                # ë¡œê¹… ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
                print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ: âŒ ì‹¤íŒ¨")
            return 1
        
    except KeyboardInterrupt:
        try:
            if logger:
                logger.warning("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception:
            print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        try:
            if logger:
                logger.error(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                logger.debug("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:", exc_info=True)
            else:
                print(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
        except Exception:
            print(f"\n\ní…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        return 1
    finally:
        # ğŸ”¥ CRITICAL: í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì „ ë¡œê±° ì •ë¦¬
        cleanup_logging()


if __name__ == "__main__":
    sys.exit(main())

