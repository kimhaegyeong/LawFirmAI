# -*- coding: utf-8 -*-
"""
Classification Mixin
ë¶„ë¥˜ ê´€ë ¨ ë…¸ë“œ ë° ë©”ì„œë“œë“¤ì„ ì œê³µí•˜ëŠ” Mixin í´ë˜ìŠ¤
"""

import time
from typing import Any, Dict, Tuple

try:
    from lawfirm_langgraph.core.workflow.state.state_definitions import LegalWorkflowState
except ImportError:
    from core.workflow.state.state_definitions import LegalWorkflowState
try:
    from lawfirm_langgraph.core.workflow.state.workflow_types import QueryComplexity
except ImportError:
    from core.workflow.state.workflow_types import QueryComplexity
try:
    from lawfirm_langgraph.core.shared.wrappers.node_wrappers import with_state_optimization
except ImportError:
    from core.shared.wrappers.node_wrappers import with_state_optimization
try:
    from lawfirm_langgraph.core.workflow.utils.ethical_checker import EthicalChecker
except ImportError:
    from core.workflow.utils.ethical_checker import EthicalChecker

# Mock observe decorator (Langfuse ì œê±°ë¨)
def observe(**kwargs):
    def decorator(func):
        return func
    return decorator


class ClassificationMixin:
    """ë¶„ë¥˜ ê´€ë ¨ ë…¸ë“œ ë° ë©”ì„œë“œë“¤ì„ ì œê³µí•˜ëŠ” Mixin í´ë˜ìŠ¤"""
    
    # ============================================================================
    # Classification í—¬í¼ ë©”ì„œë“œë“¤
    # ============================================================================
    
    def _restore_and_validate_query(self, state: LegalWorkflowState) -> str:
        """Query ë³µì› ë° ê²€ì¦ (ì¤‘ë³µ ì½”ë“œ ì œê±°)"""
        self._ensure_input_group(state)
        
        current_query = state["input"].get("query", "")
        if not current_query:
            query_from_top = state.get("query", "")
            session_id_from_top = state.get("session_id", "")
            if query_from_top:
                state["input"]["query"] = query_from_top
                if session_id_from_top:
                    state["input"]["session_id"] = session_id_from_top
        
        query_value = self._get_state_value(state, "query", "")
        if not query_value or not str(query_value).strip():
            if "input" in state and isinstance(state.get("input"), dict):
                query_value = state["input"].get("query", "")
            elif isinstance(state, dict) and "query" in state:
                query_value = state["query"]
            else:
                if "input" not in state:
                    state["input"] = {}
                state["input"]["query"] = ""
        else:
            if "input" not in state:
                state["input"] = {}
            state["input"]["query"] = query_value
        
        return self._get_state_value(state, "query", "")
    
    def _execute_classification(
        self,
        query: str
    ) -> Tuple[Any, float, QueryComplexity, bool]:
        """ë¶„ë¥˜ ì‹¤í–‰ (LLM ê¸°ë°˜ ë˜ëŠ” í´ë°±) (ì¤‘ë³µ ì½”ë“œ ì œê±°)"""
        if not query:
            classified_type, confidence = self._fallback_classification("")
            complexity = QueryComplexity.MODERATE
            needs_search = True
        else:
            if self.config.use_llm_for_complexity:
                try:
                    classified_type, confidence, complexity, needs_search = self._classify_query_with_chain(query)
                    self.logger.info(
                        f"âœ… [UNIFIED CLASSIFICATION] "
                        f"QuestionType={classified_type.value}, complexity={complexity.value}, "
                        f"needs_search={needs_search}, confidence={confidence:.2f}"
                    )
                except Exception as e:
                    self.logger.warning(f"ì²´ì¸ LLM ë¶„ë¥˜ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
                    classified_type, confidence = self._fallback_classification(query)
                    complexity, needs_search = self._fallback_complexity_classification(query)
            else:
                classified_type, confidence = self._fallback_classification(query)
                complexity, needs_search = self._fallback_complexity_classification(query)
        
        return (classified_type, confidence, complexity, needs_search)
    
    def _save_classification_results(
        self,
        state: LegalWorkflowState,
        query_type_str: str,
        confidence: float,
        legal_field: str
    ) -> None:
        """ë¶„ë¥˜ ê²°ê³¼ë¥¼ Stateì— ì €ì¥ (ì¤‘ë³µ ì½”ë“œ ì œê±° - ê°œì„ : ì—¬ëŸ¬ ìœ„ì¹˜ ë° global cacheì— ì €ì¥)"""
        self._set_state_value(state, "query_type", query_type_str)
        self._set_state_value(state, "confidence", confidence)
        self._set_state_value(state, "legal_field", legal_field)
        self._set_state_value(state, "legal_domain", self._map_to_legal_domain(legal_field))
        
        if "classification" not in state:
            state["classification"] = {}
        state["classification"]["query_type"] = query_type_str
        state["classification"]["confidence"] = confidence
        state["classification"]["legal_field"] = legal_field
        
        if "common" not in state:
            state["common"] = {}
        if "classification" not in state["common"]:
            state["common"]["classification"] = {}
        state["common"]["classification"]["query_type"] = query_type_str
        state["common"]["classification"]["confidence"] = confidence
        state["common"]["classification"]["legal_field"] = legal_field
        # common ìµœìƒìœ„ì—ë„ ì €ì¥
        state["common"]["query_type"] = query_type_str
        
        if "metadata" not in state:
            state["metadata"] = {}
        state["metadata"]["query_type"] = query_type_str
        state["metadata"]["confidence"] = confidence
        state["metadata"]["legal_field"] = legal_field
        
        # Global cacheì—ë„ ì €ì¥ (ë³µêµ¬ë¥¼ ìœ„í•´)
        try:
            from core.shared.wrappers.node_wrappers import _global_search_results_cache
            if not _global_search_results_cache:
                _global_search_results_cache = {}
            _global_search_results_cache["query_type"] = query_type_str
            _global_search_results_cache["confidence"] = confidence
            _global_search_results_cache["legal_field"] = legal_field
            if "common" not in _global_search_results_cache:
                _global_search_results_cache["common"] = {}
            if "classification" not in _global_search_results_cache["common"]:
                _global_search_results_cache["common"]["classification"] = {}
            _global_search_results_cache["common"]["classification"]["query_type"] = query_type_str
            _global_search_results_cache["common"]["classification"]["confidence"] = confidence
            if "metadata" not in _global_search_results_cache:
                _global_search_results_cache["metadata"] = {}
            _global_search_results_cache["metadata"]["query_type"] = query_type_str
            self.logger.debug(f"âœ… [CLASSIFICATION] Saved query_type to global cache: {query_type_str}")
        except (ImportError, AttributeError, TypeError) as e:
            self.logger.debug(f"Could not save to global cache: {e}")
        
        if "metadata" not in state["common"]:
            state["common"]["metadata"] = {}
        state["common"]["metadata"]["query_type"] = query_type_str
        state["common"]["metadata"]["confidence"] = confidence
        
        try:
            from core.shared.wrappers.node_wrappers import _global_search_results_cache
            import core.shared.wrappers.node_wrappers as node_wrappers_module
            if node_wrappers_module._global_search_results_cache is None:
                node_wrappers_module._global_search_results_cache = {}
            
            # None ì²´í¬ ì¶”ê°€: _global_search_results_cacheê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹Œ ê²½ìš° ì´ˆê¸°í™”
            if _global_search_results_cache is None or not isinstance(_global_search_results_cache, dict):
                _global_search_results_cache = {}
                node_wrappers_module._global_search_results_cache = _global_search_results_cache
            
            if "common" not in _global_search_results_cache:
                _global_search_results_cache["common"] = {}
            if "classification" not in _global_search_results_cache["common"]:
                _global_search_results_cache["common"]["classification"] = {}
            _global_search_results_cache["common"]["classification"]["query_type"] = query_type_str
            _global_search_results_cache["common"]["classification"]["confidence"] = confidence
            
            if "metadata" not in _global_search_results_cache:
                _global_search_results_cache["metadata"] = {}
            _global_search_results_cache["metadata"]["query_type"] = query_type_str
            _global_search_results_cache["metadata"]["confidence"] = confidence
            
            _global_search_results_cache["query_type"] = query_type_str
            _global_search_results_cache["confidence"] = confidence
            
            saved_query_type = (
                _global_search_results_cache.get("common", {}).get("classification", {}).get("query_type") or
                _global_search_results_cache.get("metadata", {}).get("query_type") or
                _global_search_results_cache.get("query_type")
            )
            if saved_query_type == query_type_str:
                self.logger.info(f"âœ… [QUERY_TYPE] Saved to global cache and verified: {query_type_str}")
            else:
                self.logger.warning(f"âš ï¸ [QUERY_TYPE] Global cache save verification failed: expected {query_type_str}, got {saved_query_type}")
        except (ImportError, AttributeError, TypeError) as e:
            self.logger.debug(f"Could not save to global cache: {e}")
    
    def _save_complexity_results(
        self,
        state: LegalWorkflowState,
        complexity: QueryComplexity,
        needs_search: bool
    ) -> None:
        """ë³µì¡ë„ ê²°ê³¼ë¥¼ Stateì— ì €ì¥ (ì¤‘ë³µ ì½”ë“œ ì œê±°)"""
        self._set_state_value(state, "query_complexity", complexity.value)
        self._set_state_value(state, "needs_search", needs_search)
        
        if "classification" not in state:
            state["classification"] = {}
        state["classification"]["query_complexity"] = complexity.value
        state["classification"]["needs_search"] = needs_search
        state["query_complexity"] = complexity.value
        state["needs_search"] = needs_search
        
        if "common" not in state:
            state["common"] = {}
        state["common"]["query_complexity"] = complexity.value
        state["common"]["needs_search"] = needs_search
        
        if "metadata" not in state:
            state["metadata"] = {}
        elif not isinstance(state.get("metadata"), dict):
            state["metadata"] = {}
        state["metadata"]["query_complexity"] = complexity.value
        state["metadata"]["needs_search"] = needs_search
        
        try:
            # ì—¬ëŸ¬ import ë°©ë²• ì‹œë„ (ëª¨ë“ˆ ê²½ë¡œ ì˜¤ë¥˜ ë°©ì§€)
            try:
                from lawfirm_langgraph.core.agents import node_wrappers
            except ImportError:
                try:
                    from core.agents import node_wrappers
                except ImportError:
                    import sys
                    from pathlib import Path
                    # ìƒëŒ€ ê²½ë¡œë¡œ ì§ì ‘ import
                    agents_dir = Path(__file__).parent.parent.parent / "agents"
                    if str(agents_dir.parent) not in sys.path:
                        sys.path.insert(0, str(agents_dir.parent))
                    from core.agents import node_wrappers
            if not hasattr(node_wrappers, '_global_search_results_cache') or node_wrappers._global_search_results_cache is None:
                node_wrappers._global_search_results_cache = {}
            node_wrappers._global_search_results_cache["query_complexity"] = complexity.value
            node_wrappers._global_search_results_cache["needs_search"] = needs_search
            self.logger.debug(f"âœ… Global cache ì €ì¥ ì™„ë£Œ: query_complexity={complexity.value}, needs_search={needs_search}")
        except Exception as e:
            # Global cache ì €ì¥ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê²½ê³ ë§Œ ì¶œë ¥
            self.logger.debug(f"âš ï¸ Global cache ì €ì¥ ì‹¤íŒ¨ (ë¹„ì¹˜ëª…ì ): {e}")
            # ëª¨ë“ˆ ê²½ë¡œ ì˜¤ë¥˜ì¸ ê²½ìš° ë” ëª…í™•í•œ ë©”ì‹œì§€
            if "modular_states" in str(e) or "No module named" in str(e):
                self.logger.debug(f"   â†’ ëª¨ë“ˆ ê²½ë¡œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ê¸°ëŠ¥ì—ëŠ” ì˜í–¥ ì—†ìŠµë‹ˆë‹¤.")
    
    # ============================================================================
    # Classification ë…¸ë“œë“¤
    # ============================================================================
    
    @observe(name="classify_query")
    @with_state_optimization("classify_query", enable_reduction=True)
    def classify_query(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì§ˆë¬¸ ë¶„ë¥˜ (LLM ê¸°ë°˜)"""
        self._ensure_input_group(state)
        
        query_value, session_id_value = self._restore_query_from_state(state)
        if query_value:
            state["input"]["query"] = query_value
            if session_id_value:
                state["input"]["session_id"] = session_id_value
        else:
            query_value = self._get_state_value(state, "query", "")
            if query_value:
                state["input"]["query"] = query_value

        try:
            start_time = time.time()

            query = self._get_state_value(state, "query", "")
            classified_type, confidence = self._classify_with_llm(query)

            query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
            legal_field = self._extract_legal_field(query_type_str, query)
            
            # ê°œì„ : _save_classification_results í˜¸ì¶œí•˜ì—¬ ì—¬ëŸ¬ ìœ„ì¹˜ì— ì €ì¥
            self._save_classification_results(state, query_type_str, confidence, legal_field)

            self.logger.info(
                f"âœ… [QUESTION CLASSIFICATION] "
                f"QuestionType={classified_type.name if hasattr(classified_type, 'name') else classified_type} "
                f"(confidence: {confidence:.2f})"
            )

            processing_time = self._update_processing_time(state, start_time)
            self._add_step(state, "ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ",
                         f"ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ: {query_type_str}, ë²•ë¥ ë¶„ì•¼: {legal_field} (ì‹œê°„: {processing_time:.3f}s)")

            self.logger.info(f"LLM classified query as {query_type_str} with confidence {confidence}, field: {legal_field}")

            self._ensure_input_group(state)
            query_value, session_id_value = self._restore_query_from_state(state)
            state["input"]["query"] = query_value or state.get("input", {}).get("query", "")
            state["input"]["session_id"] = session_id_value or state.get("input", {}).get("session_id", "")

            if not state["input"]["query"]:
                self.logger.warning(f"classify_query: query is empty after ensuring input group!")
            else:
                self.logger.debug(f"Ensured input group in state after classify_query: query length={len(state['input']['query'])}")

        except Exception as e:
            self._handle_error(state, str(e), "LLM ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            query = self._get_state_value(state, "query", "")
            classified_type, confidence = self._fallback_classification(query)
            query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
            self._set_state_value(state, "query_type", query_type_str)
            self._set_state_value(state, "confidence", confidence)

            legal_field = self._extract_legal_field(query_type_str, query)
            self._set_state_value(state, "legal_field", legal_field)
            self._set_state_value(state, "legal_domain", self._map_to_legal_domain(legal_field))

            self._add_step(state, "í´ë°± í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‚¬ìš©", "í´ë°± í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ì‚¬ìš©")

            self._ensure_input_group(state)
            query_value, session_id_value = self._restore_query_from_state(state)
            state["input"]["query"] = query_value or state.get("input", {}).get("query", "")
            state["input"]["session_id"] = session_id_value or state.get("input", {}).get("session_id", "")

            if not state["input"]["query"]:
                self.logger.warning(f"classify_query (fallback): query is empty after ensuring input group!")
            else:
                self.logger.debug(f"Ensured input group in state after classify_query (fallback): query length={len(state['input']['query'])}")

        self._ensure_input_group(state)
        query_value, session_id_value = self._restore_query_from_state(state)
        if query_value:
            state["input"]["query"] = query_value
            if session_id_value:
                state["input"]["session_id"] = session_id_value
        else:
            self.logger.error(f"classify_query: query not found, state keys: {list(state.keys()) if isinstance(state, dict) else 'N/A'}")

        return state

    @observe(name="classify_query_and_complexity")
    @with_state_optimization("classify_query_and_complexity", enable_reduction=False)
    def classify_query_and_complexity(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í†µí•©ëœ ì§ˆë¬¸ ë¶„ë¥˜ ë° ë³µì¡ë„ íŒë‹¨ (classify_query + classify_complexity)"""
        try:
            overall_start_time = time.time()
            query_start_time = time.time()

            query = self._restore_and_validate_query(state)
            
            # ìœ¤ë¦¬ì  ê²€ì‚¬ ìˆ˜í–‰
            ethical_checker = EthicalChecker(logger_instance=self.logger)
            is_problematic, rejection_reason, severity = ethical_checker.check_query(query)
            
            if is_problematic:
                # ìœ¤ë¦¬ì  ë¬¸ì œ ê°ì§€ ì‹œ í”Œë˜ê·¸ ì„¤ì • ë° ê±°ë¶€ ì‚¬ìœ  ì €ì¥
                self._set_state_value(state, "is_ethically_problematic", True)
                self._set_state_value(state, "ethical_rejection_reason", rejection_reason)
                
                # ë©”íƒ€ë°ì´í„°ì— ìœ¤ë¦¬ ê²€ì‚¬ ê²°ê³¼ ì €ì¥
                metadata = self._get_state_value(state, "metadata", {})
                if not isinstance(metadata, dict):
                    metadata = {}
                metadata["ethical_check"] = {
                    "rejected": True,
                    "reason": rejection_reason,
                    "severity": severity
                }
                self._set_state_value(state, "metadata", metadata)
                
                # ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ëŠ” ì„¤ì •í•˜ë˜, ìœ¤ë¦¬ì  ë¬¸ì œ í”Œë˜ê·¸ë¡œ ë¼ìš°íŒ…ì—ì„œ ì²˜ë¦¬
                self._set_state_value(state, "query_type", "ethical_rejection")
                self._set_state_value(state, "query_complexity", QueryComplexity.SIMPLE.value)
                self._set_state_value(state, "needs_search", False)
                
                self.logger.warning(
                    f"ìœ¤ë¦¬ì  ë¬¸ì œ ê°ì§€: {rejection_reason} (ì‹¬ê°ë„: {severity})"
                )
                
                self._preserve_metadata_and_common_state(state)
                return state
            
            classified_type, confidence, complexity, needs_search = self._execute_classification(query)

            query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
            legal_field = self._extract_legal_field(query_type_str, query)

            self._save_classification_results(state, query_type_str, confidence, legal_field)

            self._update_processing_time(state, query_start_time)
            self._add_step(state, "ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ",
                         f"ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ: {query_type_str}, ë²•ë¥ ë¶„ì•¼: {legal_field}")

            self._preserve_metadata_and_common_state(state)

            self._save_complexity_results(state, complexity, needs_search)

            self._add_step(
                state,
                "ë³µì¡ë„ ë¶„ë¥˜",
                f"ì§ˆë¬¸ ë³µì¡ë„: {complexity.value}, ê²€ìƒ‰ í•„ìš”: {needs_search}"
            )

            self._update_processing_time(state, overall_start_time)

        except Exception as e:
            self._handle_error(state, str(e), "ì§ˆë¬¸ ë¶„ë¥˜ ë° ë³µì¡ë„ íŒë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            try:
                query = self._get_state_value(state, "query", "")
                classified_type, confidence = self._fallback_classification(query)
                query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
                legal_field = self._extract_legal_field(query_type_str, query)
                self._set_state_value(state, "query_type", query_type_str)
                self._set_state_value(state, "confidence", confidence)
                self._set_state_value(state, "legal_field", legal_field)
                self._set_state_value(state, "legal_domain", self._map_to_legal_domain(legal_field))
            except Exception:
                self._set_state_value(state, "query_type", "general_question")
                self._set_state_value(state, "confidence", 0.5)
                self._set_state_value(state, "legal_field", "general")
                self._set_state_value(state, "legal_domain", "general")

            self._set_state_value(state, "query_complexity", QueryComplexity.MODERATE.value)
            self._set_state_value(state, "needs_search", True)

        self._preserve_metadata_and_common_state(state)

        return state
    
    @with_state_optimization("classify_query_simple", enable_reduction=False)
    def classify_query_simple(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì§ˆì˜ íƒ€ì…ë§Œ ë¹ ë¥´ê²Œ ë¶„ë¥˜ (ê²€ìƒ‰ í•„í„°ë§ì— í•„ìˆ˜)"""
        try:
            start_time = time.time()
            query = self._restore_and_validate_query(state)
            
            # ìœ¤ë¦¬ì  ê²€ì‚¬ ìˆ˜í–‰
            ethical_checker = EthicalChecker(logger_instance=self.logger)
            is_problematic, rejection_reason, severity = ethical_checker.check_query(query)
            
            if is_problematic:
                # ìœ¤ë¦¬ì  ë¬¸ì œ ê°ì§€ ì‹œ í”Œë˜ê·¸ ì„¤ì • ë° ê±°ë¶€ ì‚¬ìœ  ì €ì¥
                self._set_state_value(state, "is_ethically_problematic", True)
                self._set_state_value(state, "ethical_rejection_reason", rejection_reason)
                
                # ë©”íƒ€ë°ì´í„°ì— ìœ¤ë¦¬ ê²€ì‚¬ ê²°ê³¼ ì €ì¥
                metadata = self._get_state_value(state, "metadata", {})
                if not isinstance(metadata, dict):
                    metadata = {}
                metadata["ethical_check"] = {
                    "rejected": True,
                    "reason": rejection_reason,
                    "severity": severity
                }
                self._set_state_value(state, "metadata", metadata)
                
                # ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ëŠ” ì„¤ì •í•˜ë˜, ìœ¤ë¦¬ì  ë¬¸ì œ í”Œë˜ê·¸ë¡œ ë¼ìš°íŒ…ì—ì„œ ì²˜ë¦¬
                self._set_state_value(state, "query_type", "ethical_rejection")
                self._set_state_value(state, "query_complexity", QueryComplexity.SIMPLE.value)
                self._set_state_value(state, "needs_search", False)
                
                self.logger.warning(
                    f"ìœ¤ë¦¬ì  ë¬¸ì œ ê°ì§€: {rejection_reason} (ì‹¬ê°ë„: {severity})"
                )
                
                self._preserve_metadata_and_common_state(state)
                return state
            
            # ì§ˆì˜ íƒ€ì…ë§Œ ë¹ ë¥´ê²Œ ë¶„ë¥˜
            if self.classification_handler:
                try:
                    classified_type, confidence = self.classification_handler.classify_with_llm(query)
                    self.logger.info(
                        f"âœ… [QUERY TYPE CLASSIFICATION] "
                        f"QuestionType={classified_type.value}, confidence={confidence:.2f}"
                    )
                except Exception as e:
                    self.logger.warning(f"LLM ì§ˆì˜ íƒ€ì… ë¶„ë¥˜ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
                    classified_type, confidence = self._fallback_classification(query)
            else:
                classified_type, confidence = self._fallback_classification(query)
            
            query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
            legal_field = self._extract_legal_field(query_type_str, query)
            
            self._save_classification_results(state, query_type_str, confidence, legal_field)
            
            # ì´ˆê¸° complexityëŠ” ê¸°ë³¸ê°’ ì„¤ì • (ë‚˜ì¤‘ì— ì¬í‰ê°€)
            initial_complexity = QueryComplexity.MODERATE
            self._save_complexity_results(state, initial_complexity, True)
            
            self._update_processing_time(state, start_time)
            self._add_step(state, "ì§ˆì˜ íƒ€ì… ë¶„ë¥˜ ì™„ë£Œ",
                         f"ì§ˆì˜ íƒ€ì…: {query_type_str}, ë²•ë¥ ë¶„ì•¼: {legal_field}, ì‹ ë¢°ë„: {confidence:.2f}")
            
            self._preserve_metadata_and_common_state(state)
            
        except Exception as e:
            self._handle_error(state, str(e), "ì§ˆì˜ íƒ€ì… ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            try:
                query = self._get_state_value(state, "query", "")
                classified_type, confidence = self._fallback_classification(query)
                query_type_str = classified_type.value if hasattr(classified_type, 'value') else str(classified_type)
                legal_field = self._extract_legal_field(query_type_str, query)
                self._set_state_value(state, "query_type", query_type_str)
                self._set_state_value(state, "confidence", confidence)
                self._set_state_value(state, "legal_field", legal_field)
                self._set_state_value(state, "legal_domain", self._map_to_legal_domain(legal_field))
            except Exception:
                self._set_state_value(state, "query_type", "general_question")
                self._set_state_value(state, "confidence", 0.5)
                self._set_state_value(state, "legal_field", "general")
                self._set_state_value(state, "legal_domain", "general")
            
            self._set_state_value(state, "query_complexity", QueryComplexity.MODERATE.value)
            self._set_state_value(state, "needs_search", True)
        
        self._preserve_metadata_and_common_state(state)
        return state
    
    @with_state_optimization("classify_complexity_after_keywords", enable_reduction=False)
    def classify_complexity_after_keywords(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """í‚¤ì›Œë“œ í™•ì¥ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ë³µì¡ë„ ì¬í‰ê°€"""
        try:
            start_time = time.time()
            query = self._get_state_value(state, "query", "")
            # ğŸ”¥ ìˆ˜ì •: expanded_keywords ëŒ€ì‹  extracted_keywords ì‚¬ìš© (expand_keywords ë…¸ë“œì—ì„œ ì €ì¥í•˜ëŠ” í•„ë“œëª…)
            expanded_keywords = self._get_state_value(state, "extracted_keywords", [])
            # expanded_keywordsë„ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„±)
            if not expanded_keywords:
                expanded_keywords = self._get_state_value(state, "expanded_keywords", [])
            query_type = self._get_state_value(state, "query_type", "")
            query_type_confidence = self._get_state_value(state, "confidence", 0.0)
            
            if not query:
                self.logger.warning("âš ï¸ [COMPLEXITY RE-EVAL] Query is empty, using default complexity")
                self._set_state_value(state, "query_complexity", QueryComplexity.MODERATE.value)
                self._set_state_value(state, "needs_search", True)
                return state
            
            # í‚¤ì›Œë“œ í™•ì¥ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ë³µì¡ë„ í‰ê°€
            if self.classification_handler:
                try:
                    # query_typeì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    query_type_str = query_type
                    if hasattr(query_type, 'value'):
                        query_type_str = query_type.value
                    elif not isinstance(query_type, str):
                        query_type_str = str(query_type)
                    
                    # ë³µì¡ë„ë§Œ ì¬í‰ê°€
                    complexity, needs_search = self.classification_handler.classify_complexity_with_llm(
                        query, query_type_str
                    )
                    
                    # í‚¤ì›Œë“œ í™•ì¥ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ë³µì¡ë„ ì¡°ì •
                    if expanded_keywords and isinstance(expanded_keywords, list):
                        keyword_count = len(expanded_keywords)
                        # í‚¤ì›Œë“œê°€ ë§ìœ¼ë©´ ë³µì¡ë„ ìƒí–¥ ì¡°ì •
                        if keyword_count > 10 and complexity == QueryComplexity.SIMPLE:
                            complexity = QueryComplexity.MODERATE
                            self.logger.debug(
                                f"ğŸ” [COMPLEXITY RE-EVAL] í‚¤ì›Œë“œ ìˆ˜({keyword_count})ì— ë”°ë¼ ë³µì¡ë„ ìƒí–¥ ì¡°ì •: "
                                f"SIMPLE â†’ MODERATE"
                            )
                        elif keyword_count > 15 and complexity == QueryComplexity.MODERATE:
                            complexity = QueryComplexity.COMPLEX
                            self.logger.debug(
                                f"ğŸ” [COMPLEXITY RE-EVAL] í‚¤ì›Œë“œ ìˆ˜({keyword_count})ì— ë”°ë¼ ë³µì¡ë„ ìƒí–¥ ì¡°ì •: "
                                f"MODERATE â†’ COMPLEX"
                            )
                    
                    self.logger.info(
                        f"âœ… [COMPLEXITY RE-EVAL] "
                        f"complexity={complexity.value}, needs_search={needs_search}, "
                        f"keywords={len(expanded_keywords) if expanded_keywords else 0}"
                    )
                except Exception as e:
                    self.logger.warning(f"LLM ë³µì¡ë„ ì¬í‰ê°€ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
                    complexity, needs_search = self._fallback_complexity_classification(query)
            else:
                complexity, needs_search = self._fallback_complexity_classification(query)
            
            # query_type ì¬í‰ê°€ (ì‹ ë¢°ë„ ë‚®ì„ ë•Œë§Œ)
            if query_type_confidence < 0.7 and expanded_keywords:
                try:
                    if self.classification_handler:
                        new_classified_type, new_confidence = self.classification_handler.classify_with_llm(query)
                        if new_confidence > query_type_confidence:
                            query_type_str = new_classified_type.value if hasattr(new_classified_type, 'value') else str(new_classified_type)
                            legal_field = self._extract_legal_field(query_type_str, query)
                            self._save_classification_results(state, query_type_str, new_confidence, legal_field)
                            self.logger.info(
                                f"âœ… [QUERY TYPE RE-EVAL] "
                                f"QuestionType={query_type_str}, confidence={new_confidence:.2f} "
                                f"(ì´ì „: {query_type_confidence:.2f})"
                            )
                except Exception as e:
                    self.logger.debug(f"query_type ì¬í‰ê°€ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
            # ë³µì¡ë„ ê²°ê³¼ ì €ì¥
            self._save_complexity_results(state, complexity, needs_search)
            
            self._update_processing_time(state, start_time)
            self._add_step(
                state,
                "ë³µì¡ë„ ì¬í‰ê°€",
                f"ì§ˆë¬¸ ë³µì¡ë„: {complexity.value}, ê²€ìƒ‰ í•„ìš”: {needs_search}, "
                f"í‚¤ì›Œë“œ ìˆ˜: {len(expanded_keywords) if expanded_keywords else 0}"
            )
            
            self._preserve_metadata_and_common_state(state)
            
        except Exception as e:
            self._handle_error(state, str(e), "ë³µì¡ë„ ì¬í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            # í´ë°±: ê¸°ë³¸ ë³µì¡ë„ ì„¤ì •
            self._set_state_value(state, "query_complexity", QueryComplexity.MODERATE.value)
            self._set_state_value(state, "needs_search", True)
        
        self._preserve_metadata_and_common_state(state)
        return state

