"""
ë‹µë³€ ìƒíƒœ ê´€ë¦¬ í—¬í¼ í•¨ìˆ˜

StructuredAnswerì™€ AnswerState ê°„ì˜ ë³€í™˜ ë° ê´€ë¦¬
"""

import re
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from .answer_models import (
    StructuredAnswer,
    DocumentUsageInfo,
    CoverageMetrics,
)

logger = logging.getLogger(__name__)


def create_structured_answer_from_state(
    answer_text: str,
    retrieved_docs: Optional[List[Dict[str, Any]]] = None,
    validation_result: Optional[Dict[str, Any]] = None,
    sources: Optional[List[str]] = None,
    structure_confidence: float = 0.0,
    query_type: Optional[str] = None
) -> StructuredAnswer:
    """
    ë‹µë³€ ìƒì„± ê²°ê³¼ë¡œë¶€í„° StructuredAnswer ìƒì„±
    
    Args:
        answer_text: ë‹µë³€ ë³¸ë¬¸
        retrieved_docs: ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡
        validation_result: ê²€ì¦ ê²°ê³¼ (coverage ì •ë³´ í¬í•¨)
        sources: ì°¸ê³  ì¶œì²˜ ëª©ë¡
        structure_confidence: êµ¬ì¡° ì‹ ë¢°ë„
        query_type: ì§ˆë¬¸ ìœ í˜•
    
    Returns:
        StructuredAnswer ê°ì²´
    """
    # ë¬¸ì„œ ì‚¬ìš© ì •ë³´ ìƒì„±
    document_usage: List[DocumentUsageInfo] = []
    
    if retrieved_docs:
        # ë‹µë³€ì—ì„œ ì¸ìš© ì¶”ì¶œ
        import re
        citation_pattern = r'\[ë¬¸ì„œ\s*(\d+)\]'
        citations_in_answer = re.findall(citation_pattern, answer_text)
        citation_counts = {}
        for cit in citations_in_answer:
            doc_num = int(cit)
            citation_counts[doc_num] = citation_counts.get(doc_num, 0) + 1
        
        # ì¸ìš© ìœ„ì¹˜ ì°¾ê¸°
        citation_positions: Dict[int, List[int]] = {}
        for match in re.finditer(citation_pattern, answer_text):
            doc_num = int(match.group(1))
            if doc_num not in citation_positions:
                citation_positions[doc_num] = []
            citation_positions[doc_num].append(match.start())
        
        # ê° ë¬¸ì„œì— ëŒ€í•œ ì‚¬ìš© ì •ë³´ ìƒì„±
        for idx, doc in enumerate(retrieved_docs, start=1):
            doc_num = idx
            used_in_answer = doc_num in citation_counts
            
            # ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
            source = doc.get("source", doc.get("name", f"ë¬¸ì„œ {doc_num}"))
            source_type = doc.get("type", doc.get("source_type", "unknown"))
            doc_id = doc.get("doc_id") or doc.get("id") or doc.get("chunk_id")
            
            # ê´€ë ¨ì„± ì ìˆ˜
            relevance_score = doc.get("relevance_score") or doc.get("similarity") or doc.get("score")
            semantic_similarity = doc.get("semantic_similarity") or doc.get("cross_encoder_score")
            
            document_usage.append(
                DocumentUsageInfo(
                    document_number=doc_num,
                    document_id=str(doc_id) if doc_id else None,
                    source=str(source),
                    source_type=str(source_type),
                    used_in_answer=used_in_answer,
                    citation_count=citation_counts.get(doc_num, 0),
                    citation_positions=citation_positions.get(doc_num, []),
                    relevance_score=float(relevance_score) if relevance_score is not None else None,
                    semantic_similarity=float(semantic_similarity) if semantic_similarity is not None else None,
                    key_content=doc.get("content", doc.get("text", ""))[:200] if doc.get("content") or doc.get("text") else None
                )
            )
    
    # ì»¤ë²„ë¦¬ì§€ ë©”íŠ¸ë¦­ ìƒì„±
    coverage = CoverageMetrics()
    
    if validation_result:
        # í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€
        coverage.keyword_coverage = validation_result.get("keyword_coverage", 0.0)
        coverage.keyword_total = validation_result.get("keyword_total", 0)
        coverage.keyword_matched = validation_result.get("keyword_matched", 0)
        
        # ì¸ìš© ì»¤ë²„ë¦¬ì§€
        coverage.citation_coverage = validation_result.get("citation_coverage", 0.0)
        coverage.citation_count = validation_result.get("citation_count", 0)
        coverage.citation_expected = validation_result.get("citations_expected", 0)
        
        # ë¬¸ì„œ í™œìš©ë„
        coverage.document_usage_rate = validation_result.get("document_usage_rate", 0.0)
        coverage.documents_used = validation_result.get("used_doc_count", 0)
        coverage.documents_total = validation_result.get("total_doc_count", 0)
        coverage.documents_min_required = validation_result.get("min_required_citations", 0)
        
        # ë²•ë¥  ì°¸ì¡° ì»¤ë²„ë¦¬ì§€
        coverage.legal_reference_coverage = validation_result.get("legal_reference_coverage")
        coverage.legal_references_found = validation_result.get("legal_references_found", 0)
        
        # ì „ì²´ ì»¤ë²„ë¦¬ì§€
        coverage.overall_coverage = validation_result.get("coverage_score", 0.0)
        
        # ì»¤ë²„ë¦¬ì§€ ì„¸ë¶€ ì •ë³´
        coverage.coverage_breakdown = {
            "keyword": coverage.keyword_coverage,
            "citation": coverage.citation_coverage,
            "document_usage": coverage.document_usage_rate,
        }
        if coverage.legal_reference_coverage is not None:
            coverage.coverage_breakdown["legal_reference"] = coverage.legal_reference_coverage
    
    return StructuredAnswer(
        answer_text=answer_text,
        document_usage=document_usage,
        coverage=coverage,
        sources=sources or [],
        structure_confidence=structure_confidence,
        query_type=query_type
    )


def parse_answer_with_metadata(answer_text: str) -> Tuple[str, Optional[Dict[str, Any]]]:
    """
    ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ë¶„ë¦¬
    
    Args:
        answer_text: LLMì´ ìƒì„±í•œ ë‹µë³€ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„° í¬í•¨ ê°€ëŠ¥)
    
    Returns:
        (ë‹µë³€ ë³¸ë¬¸, ë©”íƒ€ë°ì´í„° dict ë˜ëŠ” None)
    """
    if not answer_text:
        return answer_text, None
    
    # ğŸ”¥ ê°œì„ : ìƒˆë¡œìš´ í˜•ì‹ ì§€ì› - [END] + [metadata] ì„¹ì…˜
    # íŒ¨í„´ 0: [END] ë§ˆì»¤ì™€ [metadata] ì„¹ì…˜ í˜•ì‹
    # í˜•ì‹: [ë‹µë³€ ë³¸ë¬¸]\n\n[END]\n\n[metadata]\n{...}
    end_marker_pattern = r'\[END\]'
    metadata_section_pattern = r'\[metadata\]\s*(\{.*?\})'
    
    end_match = re.search(end_marker_pattern, answer_text, re.IGNORECASE)
    if end_match:
        # [END] ë§ˆì»¤ ì´í›„ì—ì„œ [metadata] ì„¹ì…˜ ì°¾ê¸°
        after_end = answer_text[end_match.end():]
        metadata_match = re.search(metadata_section_pattern, after_end, re.DOTALL | re.IGNORECASE)
        
        if metadata_match:
            try:
                metadata_json = metadata_match.group(1)
                metadata = json.loads(metadata_json)
                
                # [END] ë§ˆì»¤ ì´ì „ê¹Œì§€ê°€ ë‹µë³€ ë³¸ë¬¸
                answer_body = answer_text[:end_match.start()].rstrip()
                
                logger.debug(f"âœ… [METADATA PARSE] Successfully parsed [END] + [metadata] format")
                return answer_body.strip(), metadata
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ [METADATA PARSE] Failed to parse JSON metadata from [metadata] section: {e}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ [END] ì´ì „ê¹Œì§€ë§Œ ë°˜í™˜
                answer_body = answer_text[:end_match.start()].rstrip()
                return answer_body.strip(), None
            except Exception as e:
                logger.warning(f"âš ï¸ [METADATA PARSE] Unexpected error parsing [metadata] section: {e}")
                answer_body = answer_text[:end_match.start()].rstrip()
                return answer_body.strip(), None
        else:
            # [END] ë§ˆì»¤ëŠ” ìˆì§€ë§Œ [metadata] ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš°
            answer_body = answer_text[:end_match.start()].rstrip()
            logger.debug(f"âœ… [METADATA PARSE] Found [END] marker but no [metadata] section")
            return answer_body.strip(), None
    
    # ğŸ”¥ ê°œì„ : ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ metadata ì¶”ì¶œ ì‹œë„
    # íŒ¨í„´ 1: <metadata> íƒœê·¸ë¡œ ê°ì‹¸ì§„ JSON
    metadata_pattern = r'<metadata>\s*(\{.*?\})\s*</metadata>'
    match = re.search(metadata_pattern, answer_text, re.DOTALL | re.IGNORECASE)
    
    if match:
        try:
            metadata_json = match.group(1)
            # JSON íŒŒì‹±
            metadata = json.loads(metadata_json)
            
            # ë©”íƒ€ë°ì´í„° ë¶€ë¶„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ ë‹µë³€ ë³¸ë¬¸ë§Œ ì¶”ì¶œ
            answer_body = answer_text[:match.start()].rstrip()
            # "---" êµ¬ë¶„ì„  ì œê±°
            answer_body = re.sub(r'\n*---\s*\n*$', '', answer_body, flags=re.MULTILINE)
            
            # ğŸ”¥ ê°œì„ : </metadata> íƒœê·¸ ì´í›„ì˜ ëª¨ë“  ë‚´ìš© ì œê±° (ì¶”ê°€ ì„¹ì…˜ í¬í•¨)
            metadata_end = match.end()
            # </metadata> ì´í›„ì˜ ëª¨ë“  ë‚´ìš© ì œê±°
            answer_body = answer_text[:match.start()].rstrip()
            
            logger.debug(f"âœ… [METADATA PARSE] Successfully parsed metadata from answer")
            return answer_body.strip(), metadata
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ [METADATA PARSE] Failed to parse JSON metadata: {e}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë©”íƒ€ë°ì´í„° ë¶€ë¶„ë§Œ ì œê±°
            answer_body = answer_text[:match.start()].rstrip()
            answer_body = re.sub(r'\n*---\s*\n*$', '', answer_body, flags=re.MULTILINE)
            # </metadata> ì´í›„ì˜ ëª¨ë“  ë‚´ìš© ì œê±°
            return answer_body.strip(), None
        except Exception as e:
            logger.warning(f"âš ï¸ [METADATA PARSE] Unexpected error parsing metadata: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ </metadata> ì´í›„ ë‚´ìš© ì œê±° ì‹œë„
            if match:
                answer_body = answer_text[:match.start()].rstrip()
                return answer_body.strip(), None
            return answer_text, None
    
    # ğŸ”¥ ê°œì„ : íŒ¨í„´ 2: ë‹µë³€ ë³¸ë¬¸ì— í¬í•¨ëœ JSON í˜•ì‹ì˜ metadata ì œê±° (íƒœê·¸ ì—†ì´)
    # JSON ê°ì²´ íŒ¨í„´ ì°¾ê¸° (document_usage, coverage ë“±ì´ í¬í•¨ëœ ê²½ìš°)
    # ì¤‘ì²©ëœ ì¤‘ê´„í˜¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë” ì •êµí•œ íŒ¨í„´ ì‚¬ìš©
    json_metadata_pattern = r'(\{[^{}]*"document_usage"[^{}]*(?:\{[^{}]*\}[^{}]*)*"coverage"[^{}]*(?:\{[^{}]*\}[^{}]*)*\})'
    json_match = re.search(json_metadata_pattern, answer_text, re.DOTALL | re.IGNORECASE)
    
    if json_match:
        try:
            # JSONì´ ë‹µë³€ ëë¶€ë¶„ì— ìˆëŠ”ì§€ í™•ì¸
            json_start = json_match.start()
            # ë‹µë³€ì˜ ë§ˆì§€ë§‰ 30% ì´ë‚´ì— ìˆìœ¼ë©´ metadataë¡œ ê°„ì£¼
            if json_start > len(answer_text) * 0.7:
                # ì¤‘ê´„í˜¸ ë§¤ì¹­ì„ ìœ„í•´ ë” ì •í™•í•œ ì¶”ì¶œ ì‹œë„
                # ì‹œì‘ ìœ„ì¹˜ë¶€í„° ëê¹Œì§€ ì°¾ì•„ì„œ ì™„ì „í•œ JSON ê°ì²´ ì¶”ì¶œ
                brace_count = 0
                json_end = json_start
                for i in range(json_start, len(answer_text)):
                    if answer_text[i] == '{':
                        brace_count += 1
                    elif answer_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
                
                if json_end > json_start:
                    metadata_json = answer_text[json_start:json_end]
                    metadata = json.loads(metadata_json)
                    # JSON ë¶€ë¶„ ì œê±°
                    answer_body = answer_text[:json_start].rstrip()
                    logger.debug(f"âœ… [METADATA PARSE] Successfully parsed JSON metadata from answer body (position: {json_start}-{json_end})")
                    return answer_body.strip(), metadata
        except (json.JSONDecodeError, Exception) as e:
            logger.debug(f"âš ï¸ [METADATA PARSE] JSON pattern found but failed to parse: {e}")
            # íŒŒì‹± ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    # ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜
    return answer_text, None


def create_structured_answer_from_llm_response(
    answer_text: str,
    retrieved_docs: Optional[List[Dict[str, Any]]] = None,
    validation_result: Optional[Dict[str, Any]] = None,
    sources: Optional[List[str]] = None,
    structure_confidence: float = 0.0,
    query_type: Optional[str] = None
) -> StructuredAnswer:
    """
    LLM ì‘ë‹µì—ì„œ StructuredAnswer ìƒì„± (ë©”íƒ€ë°ì´í„° íŒŒì‹± í¬í•¨)
    
    Args:
        answer_text: LLMì´ ìƒì„±í•œ ë‹µë³€ (ë©”íƒ€ë°ì´í„° í¬í•¨ ê°€ëŠ¥)
        retrieved_docs: ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡
        validation_result: ê²€ì¦ ê²°ê³¼ (coverage ì •ë³´ í¬í•¨)
        sources: ì°¸ê³  ì¶œì²˜ ëª©ë¡
        structure_confidence: êµ¬ì¡° ì‹ ë¢°ë„
        query_type: ì§ˆë¬¸ ìœ í˜•
    
    Returns:
        StructuredAnswer ê°ì²´
    """
    # ë©”íƒ€ë°ì´í„° íŒŒì‹±
    answer_body, metadata = parse_answer_with_metadata(answer_text)
    
    # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
    if metadata:
        try:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ document_usage ì¶”ì¶œ
            document_usage: List[DocumentUsageInfo] = []
            if metadata.get("document_usage"):
                for doc_dict in metadata["document_usage"]:
                    try:
                        document_usage.append(DocumentUsageInfo(**doc_dict))
                    except Exception as e:
                        logger.warning(f"âš ï¸ [METADATA PARSE] Failed to parse document_usage item: {e}")
                        continue
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ coverage ì¶”ì¶œ
            coverage = CoverageMetrics()
            if metadata.get("coverage"):
                try:
                    coverage = CoverageMetrics(**metadata["coverage"])
                except Exception as e:
                    logger.warning(f"âš ï¸ [METADATA PARSE] Failed to parse coverage: {e}")
                    # ê²€ì¦ ê²°ê³¼ë¡œ ëŒ€ì²´
                    coverage = CoverageMetrics()
                    if validation_result:
                        coverage.overall_coverage = validation_result.get("coverage_score", 0.0)
            
            # ë©”íƒ€ë°ì´í„°ê°€ ë¶ˆì™„ì „í•œ ê²½ìš° ê²€ì¦ ê²°ê³¼ë¡œ ë³´ì™„
            if not document_usage and retrieved_docs:
                logger.debug("âš ï¸ [METADATA PARSE] document_usage not found in metadata, using fallback")
                return create_structured_answer_from_state(
                    answer_text=answer_body,
                    retrieved_docs=retrieved_docs,
                    validation_result=validation_result,
                    sources=sources,
                    structure_confidence=structure_confidence,
                    query_type=query_type
                )
            
            logger.info(f"âœ… [METADATA PARSE] Created StructuredAnswer from LLM metadata: {len(document_usage)} documents")
            return StructuredAnswer(
                answer_text=answer_body,
                document_usage=document_usage,
                coverage=coverage,
                sources=sources or [],
                structure_confidence=structure_confidence,
                query_type=query_type
            )
        except Exception as e:
            logger.warning(f"âš ï¸ [METADATA PARSE] Failed to create StructuredAnswer from metadata: {e}, using fallback")
            # ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            return create_structured_answer_from_state(
                answer_text=answer_body,
                retrieved_docs=retrieved_docs,
                validation_result=validation_result,
                sources=sources,
                structure_confidence=structure_confidence,
                query_type=query_type
            )
    else:
        # ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        return create_structured_answer_from_state(
            answer_text=answer_body,
            retrieved_docs=retrieved_docs,
            validation_result=validation_result,
            sources=sources,
            structure_confidence=structure_confidence,
            query_type=query_type
        )


def update_answer_state_with_structured(
    answer_state: Dict[str, Any],
    structured_answer: StructuredAnswer
) -> Dict[str, Any]:
    """
    AnswerStateì— StructuredAnswer ì •ë³´ ì—…ë°ì´íŠ¸
    
    Args:
        answer_state: ê¸°ì¡´ AnswerState dict
        structured_answer: StructuredAnswer ê°ì²´
    
    Returns:
        ì—…ë°ì´íŠ¸ëœ AnswerState dict
    """
    answer_state["answer"] = structured_answer.answer_text
    answer_state["sources"] = structured_answer.sources
    answer_state["structure_confidence"] = structured_answer.structure_confidence
    
    # êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ê°€
    if structured_answer.document_usage:
        answer_state["document_usage"] = [doc.model_dump() for doc in structured_answer.document_usage]
    if structured_answer.coverage:
        answer_state["coverage"] = structured_answer.coverage.model_dump()
    
    return answer_state

