# -*- coding: utf-8 -*-
"""
Document Summary Tasks
ë¬¸ì„œ ìš”ì•½ ê´€ë ¨ Task ì •ì˜ (ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸)
í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ ë¶„í•  ì²˜ë¦¬ í¬í•¨
"""

import re
import logging
from typing import Any, Dict, List, Optional, Tuple
from enum import Enum

try:
    from lawfirm_langgraph.core.utils.logger import get_logger
except ImportError:
    from core.utils.logger import get_logger

logger = get_logger(__name__)


class SummaryStrategy(Enum):
    """ìš”ì•½ ì „ëµ"""
    BATCH = "batch"  # ë°°ì¹˜ ìš”ì•½ (ê¶Œì¥)
    INDIVIDUAL = "individual"  # ê°œë³„ ìš”ì•½
    HYBRID = "hybrid"  # ì¡°ê±´ë¶€ í•˜ì´ë¸Œë¦¬ë“œ
    RULE_BASED = "rule_based"  # ê·œì¹™ ê¸°ë°˜


class DocumentSummaryTask:
    """ë¬¸ì„œ ìš”ì•½ Task (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” + í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ ê³ ë ¤)"""
    
    def __init__(
        self,
        llm_fast: Optional[Any] = None,
        logger_instance: Optional[logging.Logger] = None,
        strategy: SummaryStrategy = SummaryStrategy.BATCH,
        batch_size: int = 5,
        max_summary_length: int = 500,
        max_prompt_length: int = 8000,  # í”„ë¡¬í”„íŠ¸ ìµœëŒ€ ê¸¸ì´ (ë¬¸ì ìˆ˜)
        max_prompt_tokens: Optional[int] = None  # í”„ë¡¬í”„íŠ¸ ìµœëŒ€ í† í° ìˆ˜ (ì„ íƒì )
    ):
        """
        DocumentSummaryTask ì´ˆê¸°í™”
        
        Args:
            llm_fast: ë¹ ë¥¸ LLM ì¸ìŠ¤í„´ìŠ¤
            logger_instance: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
            strategy: ìš”ì•½ ì „ëµ
            batch_size: ë°°ì¹˜ í¬ê¸°
            max_summary_length: ìµœëŒ€ ìš”ì•½ ê¸¸ì´
            max_prompt_length: í”„ë¡¬í”„íŠ¸ ìµœëŒ€ ê¸¸ì´ (ë¬¸ì ìˆ˜)
            max_prompt_tokens: í”„ë¡¬í”„íŠ¸ ìµœëŒ€ í† í° ìˆ˜ (Noneì´ë©´ ë¬¸ì ìˆ˜ ê¸°ì¤€)
        """
        self.llm_fast = llm_fast
        self.logger = logger_instance or logger
        self.strategy = strategy
        self.batch_size = batch_size
        self.max_summary_length = max_summary_length
        self.max_prompt_length = max_prompt_length
        self.max_prompt_tokens = max_prompt_tokens
        
        # ì„ê³„ê°’ ì„¤ì •
        self.SUMMARY_THRESHOLD_LAW = 1000
        self.SUMMARY_THRESHOLD_CASE = 600
        self.SUMMARY_THRESHOLD_COMMENTARY = 400
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê¸¸ì´ (ê³ ì • ë¶€ë¶„)
        self._estimate_base_prompt_length(query="", doc_count=0)
    
    def _estimate_base_prompt_length(self, query: str, doc_count: int) -> int:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¶”ì •"""
        base_template = f"""ë‹¤ìŒ {doc_count}ê°œì˜ ë²•ë¥  ë¬¸ì„œë¥¼ ê°ê° ìš”ì•½í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ìš”êµ¬ì‚¬í•­:
- ê° ë¬¸ì„œë¥¼ {self.max_summary_length}ì ì´ë‚´ë¡œ ìš”ì•½
- í•µì‹¬ ìŸì  3ê°œ ì´ìƒ í¬í•¨
- ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„± ëª…ì‹œ

ì‘ë‹µ í˜•ì‹ (ê° ë¬¸ì„œë§ˆë‹¤ ë°˜ë³µ):
[ë¬¸ì„œ 1]
ìš”ì•½: [ìš”ì•½ í…ìŠ¤íŠ¸]
í•µì‹¬ ìŸì :
1. [ìŸì  1]
2. [ìŸì  2]
3. [ìŸì  3]
ì—°ê´€ì„±: [ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„±]

[ë¬¸ì„œ 2]
...
"""
        return len(base_template)
    
    def execute(
        self,
        docs: List[Dict[str, Any]],
        query: str,
        use_llm: bool = True
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Task ì‹¤í–‰
        
        Args:
            docs: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            query: ì‚¬ìš©ì ì§ˆë¬¸
            use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            (summaries, metadata) íŠœí”Œ
            - summaries: ìš”ì•½ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            - metadata: ì‹¤í–‰ ë©”íƒ€ë°ì´í„° (ì„±ê³µ ì—¬ë¶€, ì „ëµ, ì‹œê°„ ë“±)
        """
        import time
        start_time = time.time()
        
        try:
            if self.strategy == SummaryStrategy.BATCH:
                summaries, metadata = self._execute_batch(docs, query, use_llm)
            elif self.strategy == SummaryStrategy.INDIVIDUAL:
                summaries, metadata = self._execute_individual(docs, query, use_llm)
            elif self.strategy == SummaryStrategy.HYBRID:
                summaries, metadata = self._execute_hybrid(docs, query, use_llm)
            else:  # RULE_BASED
                summaries, metadata = self._execute_rule_based(docs, query)
            
            elapsed_time = time.time() - start_time
            metadata['execution_time'] = elapsed_time
            metadata['success'] = True
            
            self.logger.info(
                f"[DocumentSummaryTask] ìš”ì•½ ì™„ë£Œ: "
                f"ì „ëµ={self.strategy.value}, ë¬¸ì„œ={len(docs)}, "
                f"ì‹œê°„={elapsed_time:.2f}ì´ˆ, LLM í˜¸ì¶œ={metadata.get('llm_calls', 0)}"
            )
            
            return summaries, metadata
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            self.logger.error(f"[DocumentSummaryTask] ìš”ì•½ ì‹¤íŒ¨: {e}")
            
            # í´ë°±: ê·œì¹™ ê¸°ë°˜ ìš”ì•½
            summaries, metadata = self._execute_rule_based(docs, query)
            metadata['execution_time'] = elapsed_time
            metadata['success'] = False
            metadata['error'] = str(e)
            metadata['fallback_used'] = True
            
            return summaries, metadata
    
    def _execute_batch(
        self,
        docs: List[Dict[str, Any]],
        query: str,
        use_llm: bool
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """ë°°ì¹˜ ìš”ì•½ ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ ê³ ë ¤)"""
        if not use_llm or not self.llm_fast:
            return self._execute_rule_based(docs, query)
        
        self.logger.info(
            f"[DocumentSummaryTask] ë°°ì¹˜ ìš”ì•½ ì‹œì‘: "
            f"ë¬¸ì„œ ìˆ˜={len(docs)}, ë°°ì¹˜ í¬ê¸°={self.batch_size}"
        )
        
        # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ë°°ì¹˜ ë¶„í• 
        batches = self._split_docs_into_batches(docs, query)
        
        all_summaries = []
        total_llm_calls = 0
        global_doc_start = 1  # ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ì‹œì‘
        
        for batch_idx, batch_docs in enumerate(batches, 1):
            self.logger.info(
                f"[DocumentSummaryTask] ë°°ì¹˜ {batch_idx}/{len(batches)} ì²˜ë¦¬ ì¤‘: "
                f"ë¬¸ì„œ ìˆ˜={len(batch_docs)}, ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ì‹œì‘={global_doc_start}"
            )
            
            try:
                # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
                batch_prompt = self._build_batch_prompt(batch_docs, query, batch_idx, len(batches), global_doc_start)
                
                # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í™•ì¸
                prompt_length = len(batch_prompt)
                self.logger.debug(
                    f"[DocumentSummaryTask] ë°°ì¹˜ {batch_idx} í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {prompt_length}ì"
                )
                
                # í•œ ë²ˆì˜ LLM í˜¸ì¶œ
                response = self.llm_fast.invoke(batch_prompt)
                response_text = response.content if hasattr(response, 'content') else str(response)
                total_llm_calls += 1
                
                # ë°°ì¹˜ ì‘ë‹µ íŒŒì‹± (ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ì‹œì‘ ì „ë‹¬)
                batch_summaries = self._parse_batch_response(
                    response_text, 
                    batch_docs, 
                    batch_idx,
                    len(batches),
                    global_doc_start
                )
                all_summaries.extend(batch_summaries)
                
                # ë‹¤ìŒ ë°°ì¹˜ì˜ ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ì‹œì‘ ì—…ë°ì´íŠ¸
                global_doc_start += len(batch_docs)
                
            except Exception as e:
                self.logger.warning(
                    f"[DocumentSummaryTask] ë°°ì¹˜ {batch_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}, "
                    f"ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±"
                )
                # í´ë°±: ê·œì¹™ ê¸°ë°˜ ìš”ì•½
                for doc in batch_docs:
                    summary = self._summarize_with_rules(doc, query)
                    all_summaries.append(summary)
        
        metadata = {
            'strategy': 'batch',
            'llm_calls': total_llm_calls,
            'total_docs': len(docs),
            'batches': len(batches),
            'batch_sizes': [len(batch) for batch in batches]
        }
        
        return all_summaries, metadata
    
    def _split_docs_into_batches(
        self,
        docs: List[Dict[str, Any]],
        query: str
    ) -> List[List[Dict[str, Any]]]:
        """
        ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ë°°ì¹˜ë¡œ ë¶„í• 
        
        Args:
            docs: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            query: ì‚¬ìš©ì ì§ˆë¬¸
        
        Returns:
            ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
        """
        if not docs:
            return []
        
        batches = []
        current_batch = []
        current_batch_length = 0
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¶”ì • (ì§ˆë¬¸ í¬í•¨)
        base_length = self._estimate_base_prompt_length(query, 1)
        available_length = self.max_prompt_length - base_length
        
        for doc in docs:
            # ë¬¸ì„œ ë‚´ìš© ê¸¸ì´ ì¶”ì • (ìµœëŒ€ 2000ìë¡œ ì œí•œ)
            doc_content = doc.get("content", "")[:2000]
            doc_title = self._get_document_title(doc)
            doc_type = self._get_document_type(doc)
            
            # ë¬¸ì„œ ì„¹ì…˜ ê¸¸ì´ ì¶”ì •
            doc_section_length = len(f"""
[ë¬¸ì„œ X]
ì œëª©: {doc_title}
ìœ í˜•: {doc_type}
ë‚´ìš©:
{doc_content}
""")
            
            # í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€ ê°€ëŠ¥í•œì§€ í™•ì¸
            if current_batch and (current_batch_length + doc_section_length) > available_length:
                # í˜„ì¬ ë°°ì¹˜ ì €ì¥í•˜ê³  ìƒˆ ë°°ì¹˜ ì‹œì‘
                batches.append(current_batch)
                current_batch = [doc]
                current_batch_length = doc_section_length
                self.logger.debug(
                    f"[DocumentSummaryTask] ë°°ì¹˜ ë¶„í• : "
                    f"ì´ì „ ë°°ì¹˜={len(batches[-1])}ê°œ ë¬¸ì„œ, "
                    f"ìƒˆ ë°°ì¹˜ ì‹œì‘"
                )
            else:
                # í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€
                current_batch.append(doc)
                current_batch_length += doc_section_length
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì¶”ê°€
        if current_batch:
            batches.append(current_batch)
        
        self.logger.info(
            f"[DocumentSummaryTask] ë°°ì¹˜ ë¶„í•  ì™„ë£Œ: "
            f"ì´ {len(docs)}ê°œ ë¬¸ì„œ â†’ {len(batches)}ê°œ ë°°ì¹˜, "
            f"ë°°ì¹˜ í¬ê¸°={[len(batch) for batch in batches]}"
        )
        
        return batches
    
    def _build_batch_prompt(
        self,
        docs: List[Dict[str, Any]],
        query: str,
        batch_idx: int = 1,
        total_batches: int = 1,
        global_doc_start: int = 1
    ) -> str:
        """ë°°ì¹˜ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        doc_sections = []
        for i, doc in enumerate(docs, 1):
            doc_type = self._get_document_type(doc)
            doc_title = self._get_document_title(doc)
            content = doc.get("content", "")[:2000]  # ê° ë¬¸ì„œ ìµœëŒ€ 2000ì
            
            # ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ê³„ì‚°
            global_doc_num = global_doc_start + i - 1
            
            doc_sections.append(f"""
[ë¬¸ì„œ {global_doc_num}]
ì œëª©: {doc_title}
ìœ í˜•: {doc_type}
ë‚´ìš©:
{content}
""")
        
        batch_info = ""
        if total_batches > 1:
            batch_info = f"\n(ì°¸ê³ : ì´ ë°°ì¹˜ëŠ” ì „ì²´ {total_batches}ê°œ ë°°ì¹˜ ì¤‘ {batch_idx}ë²ˆì§¸ì…ë‹ˆë‹¤.)\n"
        
        # ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ ìƒì„±
        response_examples = []
        for i in range(len(docs)):
            doc_num = global_doc_start + i
            response_examples.append(f"[ë¬¸ì„œ {doc_num}]\nìš”ì•½: [ìš”ì•½ í…ìŠ¤íŠ¸]\ní•µì‹¬ ìŸì :\n1. [ìŸì  1]\n2. [ìŸì  2]\n3. [ìŸì  3]\nì—°ê´€ì„±: [ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„±]")
        
        return f"""ë‹¤ìŒ {len(docs)}ê°œì˜ ë²•ë¥  ë¬¸ì„œë¥¼ ê°ê° ìš”ì•½í•´ì£¼ì„¸ìš”.{batch_info}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

{''.join(doc_sections)}

ìš”êµ¬ì‚¬í•­:
- ê° ë¬¸ì„œë¥¼ {self.max_summary_length}ì ì´ë‚´ë¡œ ìš”ì•½
- í•µì‹¬ ìŸì  3ê°œ ì´ìƒ í¬í•¨
- ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„± ëª…ì‹œ

ì‘ë‹µ í˜•ì‹ (ê° ë¬¸ì„œë§ˆë‹¤ ë°˜ë³µ):
{chr(10).join(response_examples)}
"""
    
    def _parse_batch_response(
        self,
        response_text: str,
        docs: List[Dict[str, Any]],
        batch_idx: int = 1,
        total_batches: int = 1,
        global_doc_start: int = 1
    ) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ìš”ì•½ ì‘ë‹µ íŒŒì‹± (ê°œì„ : ë‹¤ì–‘í•œ ì‘ë‹µ í˜•ì‹ ì§€ì›)"""
        summaries = []
        
        for i, doc in enumerate(docs, 1):
            doc_type = self._get_document_type(doc)
            
            # ì „ì—­ ë¬¸ì„œ ë²ˆí˜¸ ê³„ì‚°
            global_doc_num = global_doc_start + i - 1
            
            # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ë¬¸ì„œ ì„¹ì…˜ ì¶”ì¶œ ì‹œë„ (ë” ê²¬ê³ í•œ íŒ¨í„´)
            patterns = [
                rf'\[ë¬¸ì„œ\s*{global_doc_num}\](.+?)(?=\[ë¬¸ì„œ\s*\d+\]|$)',
                rf'ë¬¸ì„œ\s*{global_doc_num}[:\s]+(.+?)(?=ë¬¸ì„œ\s*\d+|$)',
                rf'\[{global_doc_num}\](.+?)(?=\[\d+\]|$)',
                rf'ë¬¸ì„œ\s*{i}[:\s]+(.+?)(?=ë¬¸ì„œ\s*\d+|$)',  # ë°°ì¹˜ ë‚´ ì¸ë±ìŠ¤
                rf'\[ë¬¸ì„œ\s*{i}\](.+?)(?=\[ë¬¸ì„œ\s*\d+\]|$)',  # ë°°ì¹˜ ë‚´ ì¸ë±ìŠ¤
            ]
            
            doc_response = None
            for pattern in patterns:
                match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)
                if match:
                    doc_response = match.group(1).strip()
                    if len(doc_response) > 20:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                        break
            
            # ğŸ”¥ ê°œì„ : íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë°°ì¹˜ ì‘ë‹µì„ ë¬¸ì„œ ìˆ˜ë¡œ ë‚˜ëˆ„ì–´ í• ë‹¹
            if not doc_response and len(docs) > 1:
                # ë°°ì¹˜ ì‘ë‹µì„ ë¬¸ì„œ ìˆ˜ë¡œ ë‚˜ëˆ„ê¸°
                response_lines = response_text.split('\n')
                total_lines = len(response_lines)
                lines_per_doc = max(1, total_lines // len(docs))
                start_line = (i - 1) * lines_per_doc
                end_line = i * lines_per_doc if i < len(docs) else total_lines
                doc_response = '\n'.join(response_lines[start_line:end_line]).strip()
                if doc_response:
                    self.logger.debug(
                        f"[DocumentSummaryTask] ë¬¸ì„œ {global_doc_num} íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨, "
                        f"ë¼ì¸ ë¶„í• ë¡œ í´ë°± (ë¼ì¸ {start_line}-{end_line})"
                    )
            
            if doc_response:
                # ìš”ì•½ ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
                summary_patterns = [
                    r'ìš”ì•½[:\s]*(.+?)(?=í•µì‹¬|ìŸì |ì—°ê´€ì„±|$)',
                    r'Summary[:\s]*(.+?)(?=Key|Points|Relevance|$)',
                    r'(.+?)(?=í•µì‹¬|ìŸì |ì—°ê´€ì„±|$)',
                ]
                
                summary = None
                for pattern in summary_patterns:
                    match = re.search(pattern, doc_response, re.DOTALL | re.IGNORECASE)
                    if match:
                        summary = match.group(1).strip()
                        if len(summary) > 50:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                            break
                
                if not summary:
                    summary = doc_response[:self.max_summary_length]
                
                # í•µì‹¬ ìŸì  ì¶”ì¶œ
                key_points_patterns = [
                    r'í•µì‹¬\s*ìŸì [:\s]*(.+?)(?=ì—°ê´€ì„±|$)',
                    r'Key\s*Points[:\s]*(.+?)(?=Relevance|$)',
                    r'\d+\.\s*(.+?)(?=\d+\.|ì—°ê´€ì„±|Relevance|$)',
                ]
                
                key_points = []
                for pattern in key_points_patterns:
                    matches = re.findall(pattern, doc_response, re.DOTALL | re.IGNORECASE)
                    if matches:
                        if isinstance(matches[0], str):
                            # ë‹¨ì¼ ë¬¸ìì—´ì¸ ê²½ìš° ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬
                            lines = matches[0].split('\n')
                            key_points = [line.strip() for line in lines if line.strip() and re.match(r'^\d+\.', line.strip())]
                            if key_points:
                                # ë²ˆí˜¸ ì œê±°
                                key_points = [re.sub(r'^\d+\.\s*', '', p).strip() for p in key_points[:5]]
                        else:
                            key_points = [m.strip() for m in matches[:5]]
                        if key_points:
                            break
                
                # ì—°ê´€ì„± ì¶”ì¶œ
                relevance_patterns = [
                    r'ì—°ê´€ì„±[:\s]*(.+?)$',
                    r'Relevance[:\s]*(.+?)$',
                ]
                
                relevance = 'ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©'
                for pattern in relevance_patterns:
                    match = re.search(pattern, doc_response, re.DOTALL | re.IGNORECASE)
                    if match:
                        relevance = match.group(1).strip()
                        break
                
                summaries.append({
                    'summary': summary[:self.max_summary_length],
                    'key_points': key_points[:5],
                    'relevance_notes': relevance,
                    'document_type': doc_type,
                    'original_length': len(doc.get("content", "")),
                    'summary_length': len(summary)
                })
            else:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
                self.logger.warning(
                    f"[DocumentSummaryTask] ë¬¸ì„œ {global_doc_num} (ë°°ì¹˜ {batch_idx}, ì¸ë±ìŠ¤ {i}) "
                    f"íŒŒì‹± ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±. ì‘ë‹µ ê¸¸ì´: {len(response_text)}ì"
                )
                # ë””ë²„ê¹…: ì‘ë‹µ í…ìŠ¤íŠ¸ ì¼ë¶€ ë¡œê¹…
                if self.logger.level <= logging.DEBUG:
                    self.logger.debug(
                        f"[DocumentSummaryTask] ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒ˜í”Œ (ì²˜ìŒ 500ì): "
                        f"{response_text[:500]}"
                    )
                summaries.append(self._summarize_with_rules(doc, ""))
        
        return summaries
    
    def _execute_individual(
        self,
        docs: List[Dict[str, Any]],
        query: str,
        use_llm: bool
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """ê°œë³„ ìš”ì•½ ì‹¤í–‰ (ê° ë¬¸ì„œë§ˆë‹¤ LLM í˜¸ì¶œ)"""
        if not use_llm or not self.llm_fast:
            return self._execute_rule_based(docs, query)
        
        self.logger.info(
            f"[DocumentSummaryTask] ê°œë³„ ìš”ì•½ ì‹œì‘: ë¬¸ì„œ ìˆ˜={len(docs)}"
        )
        
        summaries = []
        for i, doc in enumerate(docs, 1):
            try:
                summary = self._summarize_single_doc(doc, query, i)
                summaries.append(summary)
            except Exception as e:
                self.logger.warning(f"ë¬¸ì„œ {i} ìš”ì•½ ì‹¤íŒ¨: {e}")
                # í´ë°±: ê·œì¹™ ê¸°ë°˜
                summary = self._summarize_with_rules(doc, query)
                summaries.append(summary)
        
        metadata = {
            'strategy': 'individual',
            'llm_calls': len(docs),
            'total_docs': len(docs)
        }
        
        return summaries, metadata
    
    def _execute_hybrid(
        self,
        docs: List[Dict[str, Any]],
        query: str,
        use_llm: bool
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ìš”ì•½ (ì¡°ê±´ë¶€ ë°°ì¹˜/ê°œë³„)"""
        # ê¸´ ë¬¸ì„œëŠ” LLM, ì§§ì€ ë¬¸ì„œëŠ” ê·œì¹™ ê¸°ë°˜
        docs_for_llm = []
        docs_for_rules = []
        doc_indices = []
        
        for i, doc in enumerate(docs):
            content = doc.get("content", "")
            doc_type = self._get_document_type(doc)
            threshold = self._get_summary_threshold(doc_type)
            
            if len(content) > threshold and use_llm and self.llm_fast:
                docs_for_llm.append((i, doc))
            else:
                docs_for_rules.append((i, doc))
        
        summaries = [None] * len(docs)
        llm_calls = 0
        
        # LLM ìš”ì•½ (ë°°ì¹˜)
        if docs_for_llm:
            llm_docs = [doc for _, doc in docs_for_llm]
            llm_summaries, batch_metadata = self._execute_batch(llm_docs, query, use_llm=True)
            llm_calls = batch_metadata.get('llm_calls', 0)
            
            for (idx, _), summary in zip(docs_for_llm, llm_summaries):
                summaries[idx] = summary
        
        # ê·œì¹™ ê¸°ë°˜ ìš”ì•½
        for idx, doc in docs_for_rules:
            summaries[idx] = self._summarize_with_rules(doc, query)
        
        metadata = {
            'strategy': 'hybrid',
            'llm_calls': llm_calls,
            'rule_based_count': len(docs_for_rules),
            'llm_count': len(docs_for_llm)
        }
        
        return summaries, metadata
    
    def _execute_rule_based(
        self,
        docs: List[Dict[str, Any]],
        query: str
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """ê·œì¹™ ê¸°ë°˜ ìš”ì•½ (LLM ì—†ì´)"""
        summaries = [
            self._summarize_with_rules(doc, query)
            for doc in docs
        ]
        
        metadata = {
            'strategy': 'rule_based',
            'llm_calls': 0,
            'total_docs': len(docs)
        }
        
        return summaries, metadata
    
    def _summarize_single_doc(
        self,
        doc: Dict[str, Any],
        query: str,
        doc_index: int
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ë¬¸ì„œ ìš”ì•½ (ê°œë³„ LLM í˜¸ì¶œ)"""
        doc_type = self._get_document_type(doc)
        doc_title = self._get_document_title(doc)
        content = doc.get("content", "")[:2000]
        
        prompt = f"""ë‹¤ìŒ ë²•ë¥  ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ì œëª©: {doc_title}
ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë¬¸ì„œ ë‚´ìš©:
{content}

ìš”ì•½ ìš”êµ¬ì‚¬í•­:
- {self.max_summary_length}ì ì´ë‚´ë¡œ ìš”ì•½
- í•µì‹¬ ìŸì  3ê°œ ì´ìƒ í¬í•¨
- ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„± ëª…ì‹œ

ì‘ë‹µ í˜•ì‹:
ìš”ì•½: [ìš”ì•½ í…ìŠ¤íŠ¸]
í•µì‹¬ ìŸì :
1. [ìŸì  1]
2. [ìŸì  2]
3. [ìŸì  3]
ì—°ê´€ì„±: [ì§ˆë¬¸ê³¼ì˜ ì—°ê´€ì„±]"""
        
        response = self.llm_fast.invoke(prompt)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # íŒŒì‹±
        summary_match = re.search(r'ìš”ì•½:\s*(.+?)(?=í•µì‹¬|$)', response_text, re.DOTALL)
        summary = summary_match.group(1).strip() if summary_match else response_text[:self.max_summary_length]
        
        key_points_match = re.findall(r'\d+\.\s*(.+?)(?=\d+\.|ì—°ê´€ì„±|$)', response_text, re.DOTALL)
        key_points = [p.strip() for p in key_points_match[:5]]
        
        relevance_match = re.search(r'ì—°ê´€ì„±:\s*(.+?)$', response_text, re.DOTALL)
        relevance = relevance_match.group(1).strip() if relevance_match else 'ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©'
        
        return {
            'summary': summary[:self.max_summary_length],
            'key_points': key_points,
            'relevance_notes': relevance,
            'document_type': doc_type,
            'original_length': len(doc.get("content", "")),
            'summary_length': len(summary)
        }
    
    def _summarize_with_rules(
        self,
        doc: Dict[str, Any],
        query: str
    ) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ ìš”ì•½ (LLM ì—†ì´)"""
        content = doc.get("content", "")
        summary = content[:self.max_summary_length] if len(content) > self.max_summary_length else content
        
        return {
            'summary': summary,
            'key_points': [],
            'relevance_notes': 'ê·œì¹™ ê¸°ë°˜ ìš”ì•½',
            'document_type': self._get_document_type(doc),
            'original_length': len(content),
            'summary_length': len(summary)
        }
    
    def _get_document_type(self, doc: Dict[str, Any]) -> str:
        """ë¬¸ì„œ ìœ í˜• íŒë‹¨"""
        if doc.get("law_name") and doc.get("article_no"):
            return 'law'
        elif doc.get("court") or doc.get("case_name"):
            return 'case'
        elif doc.get("type") == "commentary":
            return 'commentary'
        else:
            return 'general'
    
    def _get_document_title(self, doc: Dict[str, Any]) -> str:
        """ë¬¸ì„œ ì œëª© ì¶”ì¶œ"""
        law_name = doc.get("law_name", "")
        article_no = doc.get("article_no", "")
        case_name = doc.get("case_name", "")
        court = doc.get("court", "")
        title = doc.get("title", "")
        
        if law_name and article_no:
            return f"{law_name} ì œ{article_no}ì¡°"
        elif court and case_name:
            return f"{court} {case_name}"
        elif case_name:
            return case_name
        elif title:
            return title
        else:
            return "ë¬¸ì„œ"
    
    def _get_summary_threshold(self, doc_type: str) -> int:
        """ë¬¸ì„œ ìœ í˜•ë³„ ìš”ì•½ ì„ê³„ê°’"""
        thresholds = {
            'law': self.SUMMARY_THRESHOLD_LAW,
            'case': self.SUMMARY_THRESHOLD_CASE,
            'commentary': self.SUMMARY_THRESHOLD_COMMENTARY,
            'general': 500
        }
        return thresholds.get(doc_type, 500)

