# -*- coding: utf-8 -*-
"""
Search Routes
ê²€ìƒ‰ ê´€ë ¨ ë¼ìš°íŒ… í•¨ìˆ˜ë“¤
"""

import logging
try:
    from lawfirm_langgraph.core.utils.logger import get_logger
except ImportError:
    from core.utils.logger import get_logger
from typing import Optional

try:
    from lawfirm_langgraph.core.agents.state_definitions import LegalWorkflowState
except ImportError:
    from core.agents.state_definitions import LegalWorkflowState
try:
    from lawfirm_langgraph.core.workflow.utils.workflow_utils import WorkflowUtils
except ImportError:
    from core.workflow.utils.workflow_utils import WorkflowUtils


logger = get_logger(__name__)


class QueryComplexity:
    """ì§ˆë¬¸ ë³µì¡ë„ Enum ëŒ€ì²´ í´ë˜ìŠ¤"""
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"


class SearchRoutes:
    """ê²€ìƒ‰ ê´€ë ¨ ë¼ìš°íŒ… í´ë˜ìŠ¤"""
    
    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        """
        SearchRoutes ì´ˆê¸°í™”
        
        Args:
            logger_instance: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
        """
        self.logger = logger_instance or logger
    
    def should_analyze_document(self, state: LegalWorkflowState) -> str:
        """
        ë¬¸ì„œ ë¶„ì„ í•„ìš” ì—¬ë¶€ ê²°ì •
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
        Returns:
            "analyze" ë˜ëŠ” "skip"
        """
        if state.get("uploaded_document"):
            return "analyze"
        return "skip"
    
    def should_skip_search_adaptive(self, state: LegalWorkflowState) -> str:
        """
        Adaptive RAG: ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ ìŠ¤í‚µ ê²°ì •
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
        Returns:
            "skip" ë˜ëŠ” "continue"
        """
        # ìºì‹œ íˆíŠ¸ ì²´í¬
        cache_hit = WorkflowUtils.get_state_value(state, "search_cache_hit", False)
        if cache_hit:
            return "skip"
        
        # ë³µì¡ë„ ê¸°ë°˜ ìŠ¤í‚µ ê²°ì •
        needs_search = WorkflowUtils.get_state_value(state, "needs_search", True)
        complexity = WorkflowUtils.get_state_value(state, "query_complexity", QueryComplexity.MODERATE)
        
        # Enumì¸ ê²½ìš° ê°’ìœ¼ë¡œ ë³€í™˜
        if hasattr(complexity, 'value'):
            complexity = complexity.value
        
        if not needs_search or complexity == QueryComplexity.SIMPLE or complexity == "simple":
            self.logger.info(f"â­ï¸ ê²€ìƒ‰ ìŠ¤í‚µ: ê°„ë‹¨í•œ ì§ˆë¬¸ (ë³µì¡ë„: {complexity})")
            return "skip"
        
        return "continue"
    
    def should_expand_keywords_ai(
        self,
        state: LegalWorkflowState,
        ai_keyword_generator=None
    ) -> str:
        """
        AI í‚¤ì›Œë“œ í™•ì¥ ì—¬ë¶€ ê²°ì •
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
            ai_keyword_generator: AI í‚¤ì›Œë“œ ìƒì„±ê¸° (ì„ íƒì )
        
        Returns:
            "expand" ë˜ëŠ” "skip"
        """
        if not ai_keyword_generator:
            return "skip"
        
        keywords = WorkflowUtils.get_state_value(state, "extracted_keywords", [])
        if len(keywords) < 3:
            return "skip"
        
        # ë³µì¡í•œ ì§ˆë¬¸ì¸ ê²½ìš° í™•ì¥
        query_type = WorkflowUtils.get_state_value(state, "query_type", "")
        complex_types = ["precedent_search", "law_inquiry", "legal_advice"]
        
        if query_type in complex_types:
            return "expand"
        
        return "skip"
    
    def should_use_multi_query_agent(self, state: LegalWorkflowState) -> str:
        """
        ë©€í‹° ì§ˆì˜ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
        
        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        
        Returns:
            "multi_query_agent" ë˜ëŠ” "standard_search"
        """
        query = WorkflowUtils.get_state_value(state, "query", "")
        complexity = WorkflowUtils.get_state_value(state, "query_complexity", QueryComplexity.MODERATE)
        needs_search = WorkflowUtils.get_state_value(state, "needs_search", True)
        
        # Enumì¸ ê²½ìš° ê°’ìœ¼ë¡œ ë³€í™˜
        if hasattr(complexity, 'value'):
            complexity = complexity.value
        
        # ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ í‘œì¤€ ê²€ìƒ‰ìœ¼ë¡œ
        if not needs_search:
            return "standard_search"
        
        # ë³µì¡í•œ ì§ˆë¬¸ì¸ ê²½ìš° ë©€í‹° ì§ˆì˜ ì—ì´ì „íŠ¸ ì‚¬ìš©
        if complexity == QueryComplexity.COMPLEX or complexity == "complex":
            self.logger.info(f"ğŸ” [ROUTING] Using multi-query agent for complex query: '{query[:50]}...'")
            return "multi_query_agent"
        
        # ì§ˆë¬¸ ê¸¸ì´ê°€ ê¸¸ê±°ë‚˜ ì—¬ëŸ¬ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
        if query and (len(query) > 25 or len(query.split()) > 4):
            self.logger.info(f"ğŸ” [ROUTING] Using multi-query agent for long/multi-keyword query: '{query[:50]}...' (length={len(query)}, words={len(query.split())})")
            return "multi_query_agent"
        
        # ì§ˆë¬¸ì— ì—¬ëŸ¬ ë²•ë¥  ê°œë…ì´ í¬í•¨ëœ ê²½ìš° (ì˜ˆ: "ì‚¬ìœ ", "ì ˆì°¨", "íš¨ê³¼", "ìš”ê±´" ë“±)
        legal_concepts = ["ì‚¬ìœ ", "ì ˆì°¨", "íš¨ê³¼", "ìš”ê±´", "ì¡°ê±´", "ë°©ë²•", "ì ˆì°¨", "ê¸°ê°„", "íš¨ë ¥", "ë¬´íš¨", "ì·¨ì†Œ"]
        if query and sum(1 for concept in legal_concepts if concept in query) >= 2:
            self.logger.info(f"ğŸ” [ROUTING] Using multi-query agent for multi-concept query: '{query[:50]}...'")
            return "multi_query_agent"
        
        # ê¸°ë³¸ê°’: í‘œì¤€ ê²€ìƒ‰
        self.logger.debug(f"ğŸ” [ROUTING] Using standard search for query: '{query[:50]}...' (complexity={complexity}, length={len(query) if query else 0})")
        return "standard_search"

