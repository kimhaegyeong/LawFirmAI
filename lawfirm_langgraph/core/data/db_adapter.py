# -*- coding: utf-8 -*-
"""
Database Adapter
ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì— ë…ë¦½ì ì¸ ì–´ëŒ‘í„°
PostgreSQLë§Œ ì§€ì›
"""

import os
import time
import threading
from abc import ABC, abstractmethod
from contextlib import contextmanager
from typing import Optional, Any, Dict, List, Tuple
from urllib.parse import urlparse

try:
    from lawfirm_langgraph.core.utils.logger import get_logger
except ImportError:
    from core.utils.logger import get_logger

from .sql_adapter import SQLAdapter

logger = get_logger(__name__)

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ (database_urlë³„ë¡œ ê´€ë¦¬)
_database_adapter_cache: Dict[str, 'DatabaseAdapter'] = {}


# PostgreSQL ì§€ì›
try:
    import psycopg2
    from psycopg2.extras import RealDictCursor, RealDictRow
    from psycopg2.pool import ThreadedConnectionPool
    POSTGRESQL_AVAILABLE = True
except ImportError:
    POSTGRESQL_AVAILABLE = False
    logger.warning("PostgreSQL (psycopg2) not available. Install with: pip install psycopg2-binary")


class DatabaseConnection(ABC):
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def cursor(self, *args, **kwargs):
        """ì»¤ì„œ ìƒì„±"""
        pass
    
    @abstractmethod
    def commit(self):
        """íŠ¸ëœì­ì…˜ ì»¤ë°‹"""
        pass
    
    @abstractmethod
    def rollback(self):
        """íŠ¸ëœì­ì…˜ ë¡¤ë°±"""
        pass
    
    @abstractmethod
    def close(self):
        """ì—°ê²° ë‹«ê¸°"""
        pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.rollback()
        else:
            self.commit()
        self.close()
        return False


class PostgreSQLConnection(DatabaseConnection):
    """PostgreSQL ì—°ê²° ë˜í¼"""
    
    def __init__(self, conn):
        self.conn = conn
    
    def _is_closed(self) -> bool:
        """ì—°ê²°ì´ ë‹«í˜€ìˆëŠ”ì§€ í™•ì¸"""
        if not self.conn:
            return True
        # psycopg2 ì—°ê²°ì˜ closed ì†ì„± í™•ì¸ (psycopg2 2.0.0+)
        if hasattr(self.conn, 'closed'):
            return self.conn.closed != 0  # closedëŠ” ì •ìˆ˜ (0=ì—´ë¦¼, 1=ë‹«í˜)
        # closed ì†ì„±ì´ ì—†ëŠ” ê²½ìš° (êµ¬ë²„ì „), ìƒíƒœ í™•ì¸ ì‹œë„
        try:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸ (ìµœí›„ì˜ ìˆ˜ë‹¨)
            cursor = self.conn.cursor()
            cursor.execute("SELECT 1")
            cursor.close()
            return False
        except (psycopg2.InterfaceError, psycopg2.OperationalError, AttributeError):
            return True
    
    def cursor(self, *args, **kwargs):
        # ì—°ê²°ì´ ë‹«í˜€ìˆëŠ”ì§€ í™•ì¸
        if self._is_closed():
            # ì—°ê²°ì´ ë‹«í˜€ìˆìœ¼ë©´ ìƒˆ ì—°ê²°ì„ ê°€ì ¸ì˜¤ë ¤ê³  ì‹œë„ (ì—°ê²° í’€ì—ì„œ)
            # í•˜ì§€ë§Œ ì´ëŠ” ì—°ê²° í’€ ê´€ë¦¬ ë¬¸ì œì´ë¯€ë¡œ, ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ
            raise psycopg2.InterfaceError(
                "Connection is closed. This may indicate a connection pool issue. "
                "Please check if the connection was properly returned to the pool."
            )
        # RealDictCursor ì‚¬ìš©í•˜ì—¬ dict-like ì ‘ê·¼ ê°€ëŠ¥
        try:
            return self.conn.cursor(cursor_factory=RealDictCursor)
        except psycopg2.InterfaceError as e:
            if "connection already closed" in str(e).lower():
                raise psycopg2.InterfaceError(
                    "Connection was closed during cursor creation. "
                    "This may indicate a connection pool issue."
                ) from e
            raise
    
    def commit(self):
        if self._is_closed():
            logger.warning("Attempted to commit on closed connection, skipping")
            return
        try:
            self.conn.commit()
        except psycopg2.InterfaceError as e:
            if "connection already closed" in str(e).lower():
                logger.warning(f"Connection already closed during commit: {e}")
            else:
                raise
    
    def rollback(self):
        if self._is_closed():
            logger.warning("Attempted to rollback on closed connection, skipping")
            return
        try:
            self.conn.rollback()
        except psycopg2.InterfaceError as e:
            if "connection already closed" in str(e).lower():
                logger.warning(f"Connection already closed during rollback: {e}")
            else:
                raise
    
    def close(self):
        if not self._is_closed():
            self.conn.close()


class DatabaseAdapter:
    """ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì…ì— ë…ë¦½ì ì¸ ì–´ëŒ‘í„° (PostgreSQLë§Œ ì§€ì›)"""
    
    def __init__(self, database_url: str, minconn: Optional[int] = None, maxconn: Optional[int] = None, force_new: bool = False):
        """
        ì´ˆê¸°í™”
        
        Args:
            database_url: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL
                - PostgreSQL: postgresql://user:password@host:port/database
            minconn: ì—°ê²° í’€ ìµœì†Œ í¬ê¸° (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ DB_POOL_MIN_SIZE ë˜ëŠ” 5)
            maxconn: ì—°ê²° í’€ ìµœëŒ€ í¬ê¸° (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ DB_POOL_MAX_SIZE ë˜ëŠ” 50)
            force_new: Trueì´ë©´ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ê¸°ë³¸ê°’: False, ì‹±ê¸€í†¤ ì‚¬ìš©)
        """
        # ì‹±ê¸€í†¤ íŒ¨í„´: ë™ì¼í•œ database_urlì— ëŒ€í•´ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
        global _database_adapter_cache
        if not force_new and database_url in _database_adapter_cache:
            existing = _database_adapter_cache[database_url]
            # ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ì˜ ì†ì„± ë³µì‚¬
            self.database_url = existing.database_url
            self.db_type = existing.db_type
            self.connection_pool = existing.connection_pool
            # ìºì‹œ ì¬ì‚¬ìš© ì‹œ DEBUG ë ˆë²¨ë¡œ ë³€ê²½ (ì´ë¯¸ INFO ë ˆë²¨ë¡œ ë¡œê·¸ê°€ ì¶œë ¥ë˜ì—ˆìœ¼ë¯€ë¡œ)
            logger.debug(f"DatabaseAdapter reused from cache: type={self.db_type}, url={self._mask_url(database_url)}")
            return
        
        self.database_url = database_url
        self.db_type = self._detect_db_type(database_url)
        self.connection_pool = None
        # ì—°ê²° í’€ í†µê³„ ì¶”ì 
        self._pool_stats = {
            'total_connections': 0,
            'active_connections': 0,
            'failed_connections': 0,
            'returned_connections': 0
        }
        self._pool_stats_lock = threading.Lock()
        
        # ì´ˆê¸°í™” ì‹œê°„ ì¸¡ì •
        init_start = time.time()
        self._initialize_connection_pool(minconn=minconn, maxconn=maxconn)
        init_time = time.time() - init_start
        
        # ì¤‘ë³µ ë¡œê·¸ ë°©ì§€: force_newê°€ Falseì´ê³  ìºì‹œì— ì´ë¯¸ ìˆìœ¼ë©´ ë¡œê·¸ ì¶œë ¥ ì•ˆ í•¨
        if force_new or database_url not in _database_adapter_cache:
            logger.info(f"DatabaseAdapter initialized: type={self.db_type}, url={self._mask_url(database_url)} (ì´ˆê¸°í™” ì‹œê°„: {init_time:.3f}ì´ˆ)")
        
        # ì‹±ê¸€í†¤ ìºì‹œì— ì €ì¥ (force_newê°€ Trueì—¬ë„ ìºì‹œì— ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•¨)
        _database_adapter_cache[database_url] = self
    
    @classmethod
    def get_instance(cls, database_url: str, minconn: Optional[int] = None, maxconn: Optional[int] = None) -> 'DatabaseAdapter':
        """
        ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            database_url: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL
            minconn: ì—°ê²° í’€ ìµœì†Œ í¬ê¸°
            maxconn: ì—°ê²° í’€ ìµœëŒ€ í¬ê¸°
            
        Returns:
            DatabaseAdapter ì¸ìŠ¤í„´ìŠ¤
        """
        global _database_adapter_cache
        if database_url not in _database_adapter_cache:
            # force_new=Falseë¡œ ìƒì„±í•˜ì—¬ ìºì‹œì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•¨
            _database_adapter_cache[database_url] = cls(database_url, minconn=minconn, maxconn=maxconn, force_new=False)
        return _database_adapter_cache[database_url]
    
    def _mask_url(self, url: str) -> str:
        """URLì—ì„œ ë¹„ë°€ë²ˆí˜¸ ë§ˆìŠ¤í‚¹"""
        try:
            parsed = urlparse(url)
            if parsed.password:
                return url.replace(parsed.password, "***")
        except Exception:
            pass
        return url
    
    def _detect_db_type(self, database_url: str) -> str:
        """
        ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì… ìë™ ê°ì§€ (PostgreSQLë§Œ ì§€ì›)
        
        Args:
            database_url: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL
        
        Returns:
            'postgresql'
        """
        if database_url.startswith('postgresql://') or database_url.startswith('postgres://'):
            return 'postgresql'
        else:
            raise ValueError(f"Unsupported database URL format: {database_url[:50]}... Only PostgreSQL is supported.")
    
    def _initialize_connection_pool(self, minconn: Optional[int] = None, maxconn: Optional[int] = None):
        """ì—°ê²° í’€ ì´ˆê¸°í™”"""
        if self.db_type == 'postgresql':
            if not POSTGRESQL_AVAILABLE:
                raise ImportError("psycopg2 is required for PostgreSQL support. Install with: pip install psycopg2-binary")
            
            # í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì—°ê²° í’€ í¬ê¸° ì„¤ì •
            # ê¸°ë³¸ê°’ ì¦ê°€: ë™ì‹œ ê²€ìƒ‰ ìš”ì²­ì´ ë§ì„ ë•Œ ì—°ê²° í’€ ê³ ê°ˆ ë°©ì§€
            min_size = minconn if minconn is not None else int(os.getenv("DB_POOL_MIN_SIZE", "5"))
            max_size = maxconn if maxconn is not None else int(os.getenv("DB_POOL_MAX_SIZE", "50"))
            
            # PostgreSQL ì—°ê²° í’€ ìƒì„±
            self.connection_pool = ThreadedConnectionPool(
                minconn=min_size,
                maxconn=max_size,
                dsn=self.database_url
            )
            # ì—°ê²° í’€ ì´ˆê¸°í™” ë¡œê·¸ëŠ” DatabaseAdapter ì´ˆê¸°í™” ë¡œê·¸ì— í¬í•¨ë˜ë¯€ë¡œ ë³„ë„ ì¶œë ¥ ì•ˆ í•¨
            # (ì¤‘ë³µ ë°©ì§€)
        else:
            raise ValueError(f"Unsupported database type: {self.db_type}. Only PostgreSQL is supported.")
    
    def get_connection(self) -> DatabaseConnection:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°€ì ¸ì˜¤ê¸° (PostgreSQLë§Œ ì§€ì›)
        
        Returns:
            DatabaseConnection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        """
        if self.db_type == 'postgresql':
            if not self.connection_pool:
                raise RuntimeError("PostgreSQL connection pool not initialized")
            conn = self.connection_pool.getconn()
            with self._pool_stats_lock:
                self._pool_stats['total_connections'] += 1
                self._pool_stats['active_connections'] += 1
            return PostgreSQLConnection(conn)
        else:
            raise ValueError(f"Unsupported database type: {self.db_type}. Only PostgreSQL is supported.")
    
    def _get_connection_with_timeout(self, timeout: Optional[int] = None) -> DatabaseConnection:
        """
        íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” ì—°ê²° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            timeout: íƒ€ì„ì•„ì›ƒ ì‹œê°„ (ì´ˆ), Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
            
        Returns:
            DatabaseConnection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
            
        Raises:
            TimeoutError: íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ
            RuntimeError: ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ
        """
        if timeout is None:
            timeout = int(os.getenv("DB_CONNECTION_TIMEOUT", "30"))  # ê¸°ë³¸ 30ì´ˆ
        
        start_time = time.time()
        retry_count = 0
        max_retries = 3
        
        while True:
            try:
                if self.db_type == 'postgresql':
                    if not self.connection_pool:
                        raise RuntimeError("PostgreSQL connection pool not initialized")
                    
                    # ì—°ê²° í’€ ìƒíƒœ í™•ì¸ (ì—ëŸ¬ ë°œìƒí•´ë„ ì—°ê²° ê°€ì ¸ì˜¤ê¸° ê³„ì†)
                    try:
                        stats = self.get_pool_status()
                        available = stats.get("available_connections", 0)
                        if available <= 0:
                            elapsed = time.time() - start_time
                            if elapsed >= timeout:
                                raise TimeoutError(
                                    f"Connection timeout after {timeout}s: "
                                    f"pool exhausted (active: {stats.get('active_connections')}/{stats.get('maxconn')})"
                                )
                            logger.debug(f"Connection pool exhausted, waiting... (elapsed: {elapsed:.1f}s)")
                            time.sleep(0.1)  # ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            continue
                    except Exception as status_error:
                        # ìƒíƒœ í™•ì¸ ì‹¤íŒ¨í•´ë„ ì—°ê²° ê°€ì ¸ì˜¤ê¸° ê³„ì† (ì—ëŸ¬ë§Œ ë¡œê¹…)
                        logger.debug(f"Failed to get pool status (continuing anyway): {status_error}")
                        # ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ ì‹œ ë°”ë¡œ ì—°ê²° ì‹œë„
                    
                    conn = self.connection_pool.getconn()
                    # í†µê³„ ì—…ë°ì´íŠ¸ (ì—ëŸ¬ ë°œìƒí•´ë„ ì—°ê²°ì€ ë°˜í™˜)
                    try:
                        if hasattr(self, '_pool_stats_lock') and hasattr(self, '_pool_stats'):
                            with self._pool_stats_lock:
                                self._pool_stats['total_connections'] += 1
                                self._pool_stats['active_connections'] += 1
                        else:
                            # ì†ì„±ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)
                            if not hasattr(self, '_pool_stats_lock'):
                                self._pool_stats_lock = threading.Lock()
                            if not hasattr(self, '_pool_stats'):
                                self._pool_stats = {
                                    'total_connections': 0,
                                    'active_connections': 0,
                                    'failed_connections': 0,
                                    'returned_connections': 0
                                }
                            with self._pool_stats_lock:
                                self._pool_stats['total_connections'] += 1
                                self._pool_stats['active_connections'] += 1
                    except Exception as stats_error:
                        logger.debug(f"Failed to update pool stats (connection still returned): {stats_error}")
                    return PostgreSQLConnection(conn)
                else:
                    raise ValueError(f"Unsupported database type: {self.db_type}")
                    
            except psycopg2.pool.PoolError as e:
                elapsed = time.time() - start_time
                if elapsed >= timeout:
                    with self._pool_stats_lock:
                        self._pool_stats['failed_connections'] += 1
                    raise TimeoutError(f"Connection timeout after {timeout}s: {e}")
                
                retry_count += 1
                if retry_count >= max_retries:
                    with self._pool_stats_lock:
                        self._pool_stats['failed_connections'] += 1
                    raise RuntimeError(f"Failed to get connection after {max_retries} retries: {e}")
                
                wait_time = min(0.5 * retry_count, 2.0)  # ì§€ìˆ˜ ë°±ì˜¤í”„ (ìµœëŒ€ 2ì´ˆ)
                logger.debug(f"Retrying connection ({retry_count}/{max_retries}) after {wait_time:.1f}s...")
                time.sleep(wait_time)
    
    def _validate_connection(self, conn: DatabaseConnection):
        """ì—°ê²° ìƒíƒœ ê²€ì¦"""
        if hasattr(conn, '_is_closed') and conn._is_closed():
            raise psycopg2.InterfaceError("Connection is closed")
        
        # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
        try:
            if hasattr(conn, 'conn'):
                cursor = conn.conn.cursor()
                cursor.execute("SELECT 1")
                cursor.close()
        except Exception as e:
            raise psycopg2.InterfaceError(f"Connection validation failed: {e}") from e
    
    def _safe_return_connection(self, conn_wrapper: DatabaseConnection):
        """ì•ˆì „í•˜ê²Œ ì—°ê²° ë°˜í™˜ (ì—ëŸ¬ ë°œìƒí•´ë„ ì—°ê²°ì€ ë°˜í™˜)"""
        if not conn_wrapper:
            return
        
        if self.db_type == 'postgresql' and self.connection_pool:
            if hasattr(conn_wrapper, 'conn'):
                try:
                    # ì—°ê²° ìƒíƒœ í™•ì¸
                    if hasattr(conn_wrapper, '_is_closed') and not conn_wrapper._is_closed():
                        # ì—°ê²°ì´ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ í’€ì— ë°˜í™˜
                        self.connection_pool.putconn(conn_wrapper.conn)
                        # í†µê³„ ì—…ë°ì´íŠ¸ (ì—ëŸ¬ ë°œìƒí•´ë„ ì—°ê²°ì€ ì´ë¯¸ ë°˜í™˜ë¨)
                        try:
                            if hasattr(self, '_pool_stats_lock') and hasattr(self, '_pool_stats'):
                                with self._pool_stats_lock:
                                    self._pool_stats['active_connections'] = max(0, self._pool_stats['active_connections'] - 1)
                                    self._pool_stats['returned_connections'] += 1
                            else:
                                # ì†ì„±ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)
                                if not hasattr(self, '_pool_stats_lock'):
                                    self._pool_stats_lock = threading.Lock()
                                if not hasattr(self, '_pool_stats'):
                                    self._pool_stats = {
                                        'total_connections': 0,
                                        'active_connections': 0,
                                        'failed_connections': 0,
                                        'returned_connections': 0
                                    }
                                with self._pool_stats_lock:
                                    self._pool_stats['active_connections'] = max(0, self._pool_stats['active_connections'] - 1)
                                    self._pool_stats['returned_connections'] += 1
                        except Exception as stats_error:
                            logger.debug(f"Failed to update pool stats (connection already returned): {stats_error}")
                        logger.debug("Connection returned to pool successfully")
                    else:
                        # ì—°ê²°ì´ ì´ë¯¸ ë‹«í˜€ìˆìœ¼ë©´ í’€ì—ì„œ ì œê±°ë¨
                        try:
                            if hasattr(self, '_pool_stats_lock') and hasattr(self, '_pool_stats'):
                                with self._pool_stats_lock:
                                    self._pool_stats['active_connections'] = max(0, self._pool_stats['active_connections'] - 1)
                        except Exception:
                            pass
                        logger.debug("Connection already closed, not returning to pool")
                except Exception as e:
                    logger.warning(f"Error returning connection to pool: {e}")
                    # ì—°ê²°ì´ ì†ìƒëœ ê²½ìš° ë‹«ê¸° ì‹œë„
                    try:
                        if hasattr(conn_wrapper, 'conn'):
                            conn_wrapper.conn.close()
                    except Exception:
                        pass
                    # í†µê³„ ì—…ë°ì´íŠ¸ ì‹œë„ (ì—ëŸ¬ ë°œìƒí•´ë„ ì‹œë„)
                    try:
                        if hasattr(self, '_pool_stats_lock') and hasattr(self, '_pool_stats'):
                            with self._pool_stats_lock:
                                self._pool_stats['active_connections'] = max(0, self._pool_stats['active_connections'] - 1)
                    except Exception:
                        pass
    
    @contextmanager
    def get_connection_context(self, timeout: Optional[int] = None):
        """
        ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°
        
        íŠ¹ì§•:
        - í•­ìƒ ì—°ê²° ë°˜í™˜ ë³´ì¥ (ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„)
        - íƒ€ì„ì•„ì›ƒ ì§€ì›
        - ìë™ ì¬ì—°ê²°
        - ì—°ê²° ìƒíƒœ ê²€ì¦
        - ì‹¤í–‰ ì‹œê°„ ëª¨ë‹ˆí„°ë§
        - ì¿¼ë¦¬ë³„ ì‹¤í–‰ ì‹œê°„ ë¡œê¹… (ëŠë¦° ì¿¼ë¦¬ ìë™ ê°ì§€)
        
        ì‚¬ìš© ì˜ˆ:
            with adapter.get_connection_context() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT ...")
        
        Args:
            timeout: ì—°ê²° íƒ€ì„ì•„ì›ƒ (ì´ˆ), Noneì´ë©´ í™˜ê²½ ë³€ìˆ˜ DB_CONNECTION_TIMEOUT ì‚¬ìš© (ê¸°ë³¸ 30ì´ˆ)
        """
        conn_wrapper = None
        start_time = time.time()
        query_times = []  # ì¿¼ë¦¬ë³„ ì‹¤í–‰ ì‹œê°„ ì €ì¥
        query_count = 0
        
        try:
            # íƒ€ì„ì•„ì›ƒì´ ì„¤ì •ëœ ê²½ìš° ì—°ê²° ëŒ€ê¸° ì‹œê°„ ì œí•œ
            conn_wrapper = self._get_connection_with_timeout(timeout)
            
            # ì—°ê²° ìƒíƒœ ê²€ì¦
            self._validate_connection(conn_wrapper)
            
            # ì¿¼ë¦¬ ì‹¤í–‰ ì¶”ì ì„ ìœ„í•œ cursor ë˜í¼ ì¶”ê°€
            if isinstance(conn_wrapper, PostgreSQLConnection):
                original_cursor = conn_wrapper.cursor
                
                def tracked_cursor(*args, **kwargs):
                    cursor = original_cursor(*args, **kwargs)
                    original_execute = cursor.execute
                    
                    def tracked_execute(query, *args, **kwargs):
                        nonlocal query_count
                        query_start_time = time.time()
                        query_count += 1
                        
                        # ì¿¼ë¦¬ ì •ë¦¬ (ë¡œê¹…ìš©)
                        query_str = query[:200] if isinstance(query, str) else str(query)[:200]
                        
                        try:
                            result = original_execute(query, *args, **kwargs)
                            query_elapsed = time.time() - query_start_time
                            query_times.append(query_elapsed)
                            
                            # ëŠë¦° ì¿¼ë¦¬ ê°ì§€ (0.5ì´ˆ ì´ìƒ)
                            slow_query_threshold = float(os.getenv("DB_SLOW_QUERY_THRESHOLD", "0.5"))
                            if query_elapsed > slow_query_threshold:
                                logger.warning(
                                    f"ğŸŒ Slow query detected ({query_elapsed:.3f}s): {query_str}..."
                                )
                            elif query_elapsed > 0.1:  # 0.1ì´ˆ ì´ìƒì€ DEBUG ë ˆë²¨ë¡œ ë¡œê¹…
                                logger.debug(
                                    f"â±ï¸  Query executed ({query_elapsed:.3f}s): {query_str}..."
                                )
                            
                            return result
                        except Exception as e:
                            query_elapsed = time.time() - query_start_time
                            query_times.append(query_elapsed)
                            logger.error(
                                f"âŒ Query failed after {query_elapsed:.3f}s: {query_str}... Error: {e}"
                            )
                            raise
                    
                    cursor.execute = tracked_execute
                    return cursor
                
                # cursor ë©”ì„œë“œë¥¼ ë˜í•‘ëœ ë²„ì „ìœ¼ë¡œ êµì²´
                conn_wrapper.cursor = tracked_cursor
            
            yield conn_wrapper
            
            # ì •ìƒ ì¢…ë£Œ ì‹œ commit (íŠ¸ëœì­ì…˜ì´ ìˆëŠ” ê²½ìš°)
            try:
                if hasattr(conn_wrapper, '_is_closed') and not conn_wrapper._is_closed():
                    conn_wrapper.commit()
            except (psycopg2.InterfaceError, AttributeError) as commit_error:
                logger.debug(f"Commit skipped (connection may be closed): {commit_error}")
                
        except psycopg2.pool.PoolError as e:
            # ì—°ê²° í’€ ê³ ê°ˆ ì‹œ ì¬ì‹œë„
            logger.warning(f"Connection pool exhausted, retrying with timeout={timeout}...")
            try:
                conn_wrapper = self._get_connection_with_timeout(timeout)
                self._validate_connection(conn_wrapper)
                yield conn_wrapper
                # ì •ìƒ ì¢…ë£Œ ì‹œ commit
                try:
                    if hasattr(conn_wrapper, '_is_closed') and not conn_wrapper._is_closed():
                        conn_wrapper.commit()
                except (psycopg2.InterfaceError, AttributeError):
                    pass
            except Exception as retry_error:
                # ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì›ë˜ ì˜ˆì™¸ ë°œìƒ
                raise e from retry_error
                
        except Exception as e:
            # rollback ì‹œë„ (ì—°ê²°ì´ ë‹«í˜€ìˆìœ¼ë©´ ë¬´ì‹œ)
            if conn_wrapper:
                try:
                    if hasattr(conn_wrapper, '_is_closed') and not conn_wrapper._is_closed():
                        conn_wrapper.rollback()
                except (psycopg2.InterfaceError, AttributeError) as rollback_error:
                    logger.debug(f"Rollback skipped (connection may be closed): {rollback_error}")
            
            # ì˜ˆì™¸ ì •ë³´ë¥¼ ìƒì„¸íˆ ë¡œê¹…
            import traceback
            error_type = type(e).__name__
            error_message = str(e) if e else "Unknown error"
            error_repr = repr(e) if e else "Unknown error"
            
            # ì˜ˆì™¸ ê°ì²´ê°€ ë¹„ì •ìƒì ì¸ ê²½ìš°ë¥¼ ê°ì§€
            if not error_message or error_message == "0" or error_repr == "0":
                logger.error(
                    f"Database error in connection context: {error_type} - "
                    f"message='{error_message}', repr='{error_repr}'\n"
                    f"Traceback:\n{traceback.format_exc()}"
                )
            else:
                logger.error(
                    f"Database error in connection context: {error_type}: {error_message}"
                )
            raise
            
        finally:
            # í•­ìƒ ì—°ê²° ë°˜í™˜ (ì˜ˆì™¸ ë°œìƒ ì—¬ë¶€ì™€ ë¬´ê´€)
            if conn_wrapper:
                self._safe_return_connection(conn_wrapper)
            
            # ì‹¤í–‰ ì‹œê°„ ë¡œê¹…
            elapsed = time.time() - start_time
            
            # ì¿¼ë¦¬ í†µê³„ ê³„ì‚°
            if query_count > 0:
                avg_query_time = sum(query_times) / len(query_times) if query_times else 0
                max_query_time = max(query_times) if query_times else 0
                total_query_time = sum(query_times)
                
                # ì—°ê²° ìœ ì§€ ì‹œê°„ì´ 1ì´ˆ ì´ìƒì´ê±°ë‚˜ ì¿¼ë¦¬ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ìƒì„¸ ë¡œê¹…
                if elapsed > 1.0 or query_count > 1:
                    logger.warning(
                        f"ğŸ”— Connection held for {elapsed:.2f}s "
                        f"(queries: {query_count}, "
                        f"total query time: {total_query_time:.3f}s, "
                        f"avg: {avg_query_time:.3f}s, "
                        f"max: {max_query_time:.3f}s)"
                    )
                elif elapsed > 0.5:  # 0.5ì´ˆ ì´ìƒì€ DEBUG ë ˆë²¨
                    logger.debug(
                        f"Connection held for {elapsed:.2f}s (queries: {query_count})"
                    )
            elif elapsed > 1.0:  # ì¿¼ë¦¬ ì—†ì´ 1ì´ˆ ì´ìƒ ìœ ì§€
                logger.warning(f"Connection held for {elapsed:.2f}s without queries (longer than expected)")
    
    def execute_query(
        self,
        query: str,
        params: Optional[Tuple] = None,
        fetch: bool = True
    ) -> Optional[List[Dict[str, Any]]]:
        """
        ì¿¼ë¦¬ ì‹¤í–‰ (ìë™ ë³€í™˜)
        
        Args:
            query: SQL ì¿¼ë¦¬
            params: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            fetch: ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ì§€ ì—¬ë¶€
        
        Returns:
            ì¿¼ë¦¬ ê²°ê³¼ (fetch=Trueì¸ ê²½ìš°)
        """
        # SQL ë³€í™˜
        converted_query = SQLAdapter.convert_sql(query, self.db_type)
        
        # íŒŒë¼ë¯¸í„° ë³€í™˜ (í•„ìš”ì‹œ)
        if params:
            # PostgreSQLì˜ ê²½ìš° %s ì‚¬ìš©, SQLiteëŠ” ? ì‚¬ìš©
            # SQLAdapterì—ì„œ ì´ë¯¸ ë³€í™˜í–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            pass
        
        with self.get_connection_context() as conn:
            cursor = conn.cursor()
            try:
                cursor.execute(converted_query, params)
                
                if fetch:
                    rows = cursor.fetchall()
                    # Row ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
                    return [SQLAdapter.convert_row_to_dict(row) for row in rows]
                else:
                    return None
            except Exception as e:
                logger.error(f"Query execution error: {e}")
                logger.error(f"Query: {converted_query[:200]}...")
                logger.error(f"Params: {params}")
                raise
    
    def analyze_query_performance(
        self, 
        query: str, 
        params: Optional[Tuple] = None
    ) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ (EXPLAIN ANALYZE ì‹¤í–‰)
        
        Args:
            query: ë¶„ì„í•  ì¿¼ë¦¬
            params: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            
        Returns:
            ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        explain_query = f"EXPLAIN (ANALYZE, BUFFERS, VERBOSE) {query}"
        
        with self.get_connection_context() as conn:
            cursor = conn.cursor()
            start_time = time.time()
            try:
                cursor.execute(explain_query, params)
                explain_result = cursor.fetchall()
                elapsed = time.time() - start_time
                
                # ê²°ê³¼ íŒŒì‹±
                explain_plan = '\n'.join([
                    str(row) if not hasattr(row, 'keys') else 
                    row.get('QUERY PLAN', str(row))
                    for row in explain_result
                ])
                
                return {
                    'query': query,
                    'params': params,
                    'execution_time': elapsed,
                    'explain_plan': explain_plan,
                    'raw_result': explain_result
                }
            except Exception as e:
                logger.error(f"Query performance analysis failed: {e}")
                logger.error(f"Query: {query[:200]}...")
                raise
    
    def convert_sql(self, sql: str) -> str:
        """
        SQLì„ PostgreSQL SQLë¡œ ë³€í™˜
        
        Args:
            sql: SQL ì¿¼ë¦¬
        
        Returns:
            ë³€í™˜ëœ SQL ì¿¼ë¦¬
        """
        return SQLAdapter.convert_sql(sql, self.db_type)
    
    def table_exists(self, table_name: str) -> bool:
        """
        í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        
        Args:
            table_name: í…Œì´ë¸”ëª…
        
        Returns:
            í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€
        """
        query, params = SQLAdapter.convert_table_check_query(table_name, self.db_type)
        
        with self.get_connection_context() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            result = cursor.fetchone()
            return result is not None
    
    def get_pool_status(self) -> Dict[str, Any]:
        """
        ì—°ê²° í’€ ìƒíƒœ ì¡°íšŒ
        
        Returns:
            ì—°ê²° í’€ ìƒíƒœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not self.connection_pool:
            return {"status": "not_initialized"}
        
        try:
            # _pool_stats_lockì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)
            if not hasattr(self, '_pool_stats_lock'):
                self._pool_stats_lock = threading.Lock()
            if not hasattr(self, '_pool_stats'):
                self._pool_stats = {
                    'total_connections': 0,
                    'active_connections': 0,
                    'failed_connections': 0,
                    'returned_connections': 0
                }
            
            with self._pool_stats_lock:
                stats = self._pool_stats.copy()
            
            # ThreadedConnectionPoolì˜ ê¸°ë³¸ ì •ë³´
            minconn = self.connection_pool.minconn
            maxconn = self.connection_pool.maxconn
            active = stats.get('active_connections', 0)
            available = maxconn - active
            
            utilization = active / maxconn if maxconn > 0 else 0
            
            return {
                "status": "active",
                "minconn": minconn,
                "maxconn": maxconn,
                "active_connections": active,
                "available_connections": available,
                "utilization": utilization,
                "total_connections": stats.get('total_connections', 0),
                "returned_connections": stats.get('returned_connections', 0),
                "failed_connections": stats.get('failed_connections', 0)
            }
        except Exception as e:
            logger.debug(f"Failed to get pool status: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì—°ê²° ê°€ì ¸ì˜¤ê¸°ëŠ” ê³„ì† ê°€ëŠ¥í•˜ë„ë¡)
            try:
                minconn = self.connection_pool.minconn if self.connection_pool else 0
                maxconn = self.connection_pool.maxconn if self.connection_pool else 0
                return {
                    "status": "error",
                    "error": str(e),
                    "minconn": minconn,
                    "maxconn": maxconn,
                    "available_connections": maxconn  # ìµœì•…ì˜ ê²½ìš° ì „ì²´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ê³  ê°€ì •
                }
            except Exception:
                return {"status": "error", "error": str(e), "available_connections": 50}  # ê¸°ë³¸ê°’
    
    def close(self):
        """ì—°ê²° í’€ ë‹«ê¸°"""
        if self.db_type == 'postgresql' and self.connection_pool:
            self.connection_pool.closeall()
            logger.info("PostgreSQL connection pool closed")

