# -*- coding: utf-8 -*-
"""
í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ (HuggingFace + LLM)
Multi-Query ìƒì„±ë§Œ LLM ì‚¬ìš©, ë‚˜ë¨¸ì§€ëŠ” HuggingFace ëª¨ë¸ ì‚¬ìš©
"""

import logging
from typing import Any, Dict, List, Optional, Tuple

from core.search.optimizers.legal_query_analyzer import LegalQueryAnalyzer
from core.search.optimizers.legal_keyword_expander import LegalKeywordExpander
from core.search.optimizers.legal_query_optimizer import LegalQueryOptimizer
from core.search.optimizers.legal_query_validator import LegalQueryValidator

logger = logging.getLogger(__name__)


class HybridQueryProcessor:
    """í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ (HuggingFace + LLM)"""
    
    def __init__(
        self,
        keyword_extractor: Optional[Any] = None,
        term_integrator: Optional[Any] = None,
        llm: Optional[Any] = None,
        embedding_model_name: Optional[str] = None,
        logger: Optional[logging.Logger] = None
    ):
        """
        HybridQueryProcessor ì´ˆê¸°í™”
        
        Args:
            keyword_extractor: í‚¤ì›Œë“œ ì¶”ì¶œê¸°
            term_integrator: ë²•ë¥  ìš©ì–´ í†µí•©ê¸°
            llm: LLM ì¸ìŠ¤í„´ìŠ¤ (Multi-Query ìƒì„±ìš©ë§Œ)
            embedding_model_name: ì„ë² ë”© ëª¨ë¸ëª…
            logger: ë¡œê±°
        """
        self.logger = logger or logging.getLogger(__name__)
        self.llm = llm
        
        # HuggingFace ëª¨ë¸ ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.query_analyzer = LegalQueryAnalyzer(
            keyword_extractor=keyword_extractor,
            embedding_model_name=embedding_model_name,
            logger=self.logger
        )
        
        self.keyword_expander = LegalKeywordExpander(
            term_integrator=term_integrator,
            embedding_model_name=embedding_model_name,
            logger=self.logger
        )
        
        self.query_optimizer = LegalQueryOptimizer(
            embedding_model_name=embedding_model_name,
            logger=self.logger
        )
        
        self.query_validator = LegalQueryValidator(
            embedding_model_name=embedding_model_name,
            logger=self.logger
        )
        
        self.logger.info("âœ… [HYBRID PROCESSOR] HybridQueryProcessor initialized")
    
    def process_query_hybrid(
        self,
        query: str,
        search_query: str,
        query_type: str,
        extracted_keywords: List[str],
        legal_field: str,
        complexity: str,
        is_retry: bool = False
    ) -> Tuple[Dict[str, Any], bool]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            search_query: ê²€ìƒ‰ìš© ì¿¼ë¦¬
            query_type: ì§ˆë¬¸ ìœ í˜•
            extracted_keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
            legal_field: ë²•ë¥  ë¶„ì•¼
            complexity: ë³µì¡ë„ (simple, moderate, complex)
            is_retry: ì¬ì‹œë„ ì—¬ë¶€
            
        Returns:
            (optimized_queries, cache_hit)
        """
        # Step 1: ì¿¼ë¦¬ ë¶„ì„ (HuggingFace)
        self.logger.info(f"ğŸ” [HYBRID] Step 1: Query analysis (HuggingFace)")
        analysis_result = self.query_analyzer.analyze_query(
            query, query_type, legal_field
        )
        core_keywords = analysis_result.get("core_keywords", extracted_keywords)
        
        # Step 2: í‚¤ì›Œë“œ í™•ì¥ (HuggingFace)
        self.logger.info(f"ğŸ” [HYBRID] Step 2: Keyword expansion (HuggingFace)")
        expansion_result = self.keyword_expander.expand_keywords(
            query,
            core_keywords,
            extracted_keywords,
            legal_field
        )
        
        # Step 3: ì¿¼ë¦¬ ìµœì í™” (HuggingFace)
        self.logger.info(f"ğŸ” [HYBRID] Step 3: Query optimization (HuggingFace)")
        optimization_result = self.query_optimizer.optimize_query(
            query,
            core_keywords,
            expansion_result["expanded_keywords"],
            query_type
        )
        
        # Step 4: ê²€ì¦ (HuggingFace, ì„ íƒì )
        if complexity in ["moderate", "complex"]:
            self.logger.info(f"ğŸ” [HYBRID] Step 4: Query validation (HuggingFace)")
            validation_result = self.query_validator.validate_query(
                optimization_result, query
            )
            
            if not validation_result["is_valid"] and validation_result["improvements"]:
                self.logger.info(f"âš ï¸ [HYBRID] Validation failed, applying improvements")
                optimization_result = self._apply_improvements(
                    optimization_result, validation_result["improvements"]
                )
        
        # Step 5: Multi-Query ìƒì„± (LLMë§Œ ì‚¬ìš©)
        multi_queries = None
        if self.llm:
            self.logger.info(f"ğŸ” [HYBRID] Step 5: Multi-query generation (LLM)")
            try:
                max_queries = self._get_max_queries_by_complexity(complexity)
                multi_queries = self._generate_multi_queries_with_llm(
                    search_query, query_type, max_queries
                )
            except Exception as e:
                self.logger.warning(f"âš ï¸ [HYBRID] Multi-query generation failed: {e}")
                multi_queries = [search_query]
        else:
            self.logger.warning("âš ï¸ [HYBRID] LLM not available, skipping multi-query generation")
            multi_queries = [search_query]
        
        # ê²°ê³¼ í†µí•©
        optimized_queries = {
            "semantic_query": optimization_result["semantic_query"],
            "keyword_queries": optimization_result["keyword_queries"],
            "expanded_keywords": expansion_result["expanded_keywords"],
            "synonyms": expansion_result.get("synonyms", []),
            "legal_references": expansion_result.get("legal_references", []),
            "multi_queries": multi_queries,
            "llm_enhanced": False,  # Multi-Queryë§Œ LLM ì‚¬ìš©
            "hf_models_used": True,
            "quality_score": optimization_result.get("quality_score", 0.7)
        }
        
        # Multi-Queryê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ë¥¼ semantic_queryë¡œ ì‚¬ìš©
        if multi_queries and len(multi_queries) > 1:
            optimized_queries["semantic_query"] = multi_queries[0]
        
        self.logger.info(
            f"âœ… [HYBRID] Query processing completed: "
            f"semantic_query='{optimized_queries['semantic_query'][:50]}...', "
            f"keyword_queries={len(optimized_queries['keyword_queries'])}, "
            f"multi_queries={len(multi_queries) if multi_queries else 0}"
        )
        
        return optimized_queries, False  # ìºì‹œ íˆíŠ¸ëŠ” ë³„ë„ ì²˜ë¦¬
    
    def _generate_multi_queries_with_llm(
        self,
        query: str,
        query_type: str,
        max_queries: int = 3
    ) -> List[str]:
        """Multi-Query ìƒì„± (LLMë§Œ ì‚¬ìš©)"""
        if not self.llm or not query:
            return [query] if query else []
        
        try:
            # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ ì‚¬ìš©
            if not hasattr(self.__class__, '_multi_query_cache'):
                self.__class__._multi_query_cache = {}
            
            cache_key = f"multi_query:{query}:{query_type}:{max_queries}"
            
            # ìºì‹œ í™•ì¸
            if cache_key in self.__class__._multi_query_cache:
                self.logger.info(f"âœ… [MULTI-QUERY] Cache hit for query: '{query[:50]}...'")
                return self.__class__._multi_query_cache[cache_key]
            
            # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ (ë²•ë¥  ì „ë¬¸ ì§ˆì˜ ì¬ì‘ì„±)
            num_variations = max_queries - 1  # ì›ë³¸ ì œì™¸í•œ ë³€í˜• ê°œìˆ˜
            
            prompt = f"""ë‹¹ì‹ ì€ ë²•ë¥  ë¶„ì•¼ ì „ë¬¸ ì§ˆì˜ ì¬ì‘ì„±(Multi-Query) ìƒì„±ê¸°ì…ë‹ˆë‹¤.  

ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì„ **ì„œë¡œ ë‹¤ë¥¸ ê´€ì Â·ë²•ë¥  ìš©ì–´Â·ìŸì  í‘œí˜„Â·ì¡°ë¬¸ ë°©ì‹**ìœ¼ë¡œ ë‹¤ì–‘í•˜ê²Œ ë³€í˜•í•´ ìƒì„±í•˜ì„¸ìš”.

ì•„ë˜ ê·œì¹™ì„ ë”°ë¥´ì‹­ì‹œì˜¤:

[ìƒì„± ê·œì¹™]

1. ì›ë¬¸ì˜ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜, ì„œë¡œ ë‹¤ë¥¸ ë°©ì‹(ìš©ì–´Â·ë¬¸ì¥êµ¬ì¡°Â·ë²•ë¥  ê°œë…)ìœ¼ë¡œ í‘œí˜„í•  ê²ƒ

2. ë²•ë¥  ìš©ì–´(ì¡°ë¬¸, ë²•ë¥ ëª…, ë²•ì  í‘œí˜„ ë“±)ë¥¼ í¬í•¨í•œ ë³€í˜• 1ê°œ ì´ìƒ ìƒì„±

3. ì‹¤ë¬´ì—ì„œ ìì£¼ ì“°ëŠ” ì§ˆë¬¸ í˜•íƒœë¡œ ë³€í˜• 1ê°œ ì´ìƒ ìƒì„±

4. ë„ˆë¬´ í¬ê´„ì ì´ê±°ë‚˜ ë„ˆë¬´ ì¢ì€ ì˜ë¯¸ë¡œ ë³€í˜•í•˜ì§€ ë§ ê²ƒ

5. í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥í•  ê²ƒ

6. ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ê³  ì„¤ëª…ì€ ê¸ˆì§€

[ì›ë³¸ ì§ˆë¬¸]
{query}

[ì¶œë ¥ í˜•íƒœ]
ì¬ì‘ì„±:
- ì§ˆë¬¸1
- ì§ˆë¬¸2
- ì§ˆë¬¸3
{'- ì§ˆë¬¸4' if num_variations >= 4 else ''}{'- ì§ˆë¬¸5' if num_variations >= 5 else ''}

ì´ {num_variations}ê°œì˜ ë³€í˜•ëœ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”."""
            
            # LLM í˜¸ì¶œ
            if hasattr(self.llm, 'invoke'):
                response = self.llm.invoke(prompt)
            elif hasattr(self.llm, '__call__'):
                response = self.llm(prompt)
            else:
                response = str(self.llm)
            
            if isinstance(response, str):
                llm_output = response
            elif hasattr(response, 'content'):
                llm_output = response.content
            else:
                llm_output = str(response)
            
            # ì‘ë‹µ íŒŒì‹± (ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ê²Œ)
            queries = []
            skip_patterns = [
                "ì¬ì‘ì„±:", "ì¬ì‘ì„±", "ê° ì¤„ì—", "í•˜ë‚˜ì”©", "ì§ˆë¬¸:", "ìœ í˜•:", "ì›ë³¸ ì§ˆë¬¸:",
                "ìš”êµ¬ì‚¬í•­:", "ë‹¤ìŒ ì§ˆë¬¸ì„", "ë‹¤ìŒ ë²•ë¥  ì§ˆë¬¸ì„", "ì¶œë ¥ í˜•íƒœ", "ìƒì„± ê·œì¹™",
                "ë‹¹ì‹ ì€", "ë²•ë¥  ë¶„ì•¼", "ì§€ê¸ˆë¶€í„°", "ì•„ë˜ ê·œì¹™", "ì›ë³¸ ì§ˆë¬¸", "ì´", "ê°œì˜ ë³€í˜•"
            ]
            
            in_reformatted_section = False
            for line in llm_output.split('\n'):
                line = line.strip()
                if not line:
                    continue
                
                # "ì¬ì‘ì„±:" ì„¹ì…˜ ì‹œì‘ í™•ì¸
                if "ì¬ì‘ì„±" in line and ":" in line:
                    in_reformatted_section = True
                    continue
                
                # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ìŠ¤í‚µ
                if any(pattern in line for pattern in skip_patterns):
                    continue
                
                # "- ì§ˆë¬¸" í˜•ì‹ ë˜ëŠ” ë²ˆí˜¸ íŒ¨í„´ ì œê±°
                if line.startswith('-'):
                    line = line[1:].strip()
                line = line.lstrip('0123456789.-) ')
                
                if line and not line.startswith('#') and len(line) > 5:
                    queries.append(line)
            
            # ì›ë³¸ ì§ˆë¬¸ì„ ì²« ë²ˆì§¸ë¡œ í¬í•¨
            result_queries = [query] + queries[:max_queries - 1]
            result_queries = result_queries[:max_queries]
            
            if not result_queries:
                result_queries = [query]
            
            # ìºì‹œ ì €ì¥
            if len(self.__class__._multi_query_cache) >= 200:
                oldest_key = next(iter(self.__class__._multi_query_cache))
                del self.__class__._multi_query_cache[oldest_key]
            self.__class__._multi_query_cache[cache_key] = result_queries
            
            self.logger.info(
                f"âœ… [MULTI-QUERY] Generated {len(result_queries)} queries "
                f"(original + {len(result_queries) - 1} variations)"
            )
            
            return result_queries
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ [MULTI-QUERY] LLM generation failed: {e}, using original query")
            return [query]
    
    def _get_max_queries_by_complexity(self, complexity: str) -> int:
        """ë³µì¡ë„ì— ë”°ë¥¸ ìµœëŒ€ ì¿¼ë¦¬ ìˆ˜"""
        complexity_map = {
            "simple": 2,
            "moderate": 3,
            "complex": 4
        }
        return complexity_map.get(complexity, 3)
    
    def _apply_improvements(
        self,
        optimization_result: Dict[str, Any],
        improvements: List[str]
    ) -> Dict[str, Any]:
        """ê°œì„  ì œì•ˆ ì ìš©"""
        # ê°„ë‹¨í•œ ê°œì„  ì ìš© (ê·œì¹™ ê¸°ë°˜)
        semantic_query = optimization_result.get("semantic_query", "")
        
        # ë²•ë¥  ì „ë¬¸ ìš©ì–´ ì¶”ê°€ ì œì•ˆì´ ìˆìœ¼ë©´
        if any("ë²•ë¥  ì „ë¬¸" in imp or "ìš©ì–´" in imp for imp in improvements):
            # ë²•ë¥  ìš©ì–´ íŒ¨í„´ ì¶”ê°€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            legal_terms = ["ë²•ë¥ ", "ì¡°ë¬¸", "ê·œì •"]
            for term in legal_terms:
                if term not in semantic_query:
                    semantic_query = f"{semantic_query} {term}"
                    break
        
        optimization_result["semantic_query"] = semantic_query
        return optimization_result

