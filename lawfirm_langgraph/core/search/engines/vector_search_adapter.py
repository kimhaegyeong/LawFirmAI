# -*- coding: utf-8 -*-
"""
Vector Search Adapter
ë²¡í„° ê²€ìƒ‰ ì¶”ìƒí™” ë ˆì´ì–´
pgvectorì™€ FAISSë¥¼ í†µí•© ì¸í„°í˜ì´ìŠ¤ë¡œ ì œê³µ
"""

import os
import sys
import threading
from abc import ABC, abstractmethod
from typing import List, Tuple, Optional, Dict, Any
from pathlib import Path

import numpy as np

try:
    from lawfirm_langgraph.core.utils.logger import get_logger
except ImportError:
    from core.utils.logger import get_logger

logger = get_logger(__name__)

# FAISS ì§€ì› í™•ì¸
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    logger.warning("FAISS not available. Install with: pip install faiss-cpu")

# pgvector ì§€ì› í™•ì¸
try:
    from pgvector.psycopg2 import register_vector
    PGVECTOR_AVAILABLE = True
except ImportError:
    PGVECTOR_AVAILABLE = False
    logger.warning("pgvector not available. Install with: pip install pgvector")


class VectorSearchAdapter(ABC):
    """ë²¡í„° ê²€ìƒ‰ ì–´ëŒ‘í„° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def search(
        self,
        query_vector: np.ndarray,
        limit: int,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[int, float]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
        
        Args:
            query_vector: ì¿¼ë¦¬ ë²¡í„° (1D numpy array)
            limit: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            filters: í•„í„° ì¡°ê±´ (ì˜ˆ: {'article_id': [1, 2, 3]})
        
        Returns:
            [(id, distance), ...] ë¦¬ìŠ¤íŠ¸ (distanceëŠ” ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨)
        """
        pass
    
    @abstractmethod
    def add_vectors(
        self,
        vectors: np.ndarray,
        ids: List[int],
        metadata: Optional[List[Dict[str, Any]]] = None
    ):
        """
        ë²¡í„° ì¶”ê°€
        
        Args:
            vectors: ë²¡í„° ë°°ì—´ (N x D)
            ids: ë²¡í„° ID ë¦¬ìŠ¤íŠ¸
            metadata: ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì„ íƒì )
        """
        pass
    
    @abstractmethod
    def get_vector(self, vector_id: int) -> Optional[np.ndarray]:
        """
        ë²¡í„° ì¡°íšŒ
        
        Args:
            vector_id: ë²¡í„° ID
        
        Returns:
            ë²¡í„° (ì—†ìœ¼ë©´ None)
        """
        pass


# ğŸ”¥ ê°œì„ : ì—°ê²°ë³„ ë“±ë¡ ìƒíƒœ ì¶”ì  (í´ë˜ìŠ¤ ë ˆë²¨, ìŠ¤ë ˆë“œ ì•ˆì „)
_registered_connections = set()
_connection_lock = threading.Lock()


class PgVectorAdapter(VectorSearchAdapter):
    """pgvector ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰"""
    
    def __init__(
        self,
        connection,
        table_name: str = 'statute_embeddings',
        id_column: str = 'article_id',
        vector_column: str = 'embedding_vector'
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            connection: PostgreSQL ì—°ê²° ê°ì²´
            table_name: ì„ë² ë”© í…Œì´ë¸”ëª…
            id_column: ID ì»¬ëŸ¼ëª…
            vector_column: ë²¡í„° ì»¬ëŸ¼ëª…
        """
        if not PGVECTOR_AVAILABLE:
            raise ImportError("pgvector is required. Install with: pip install pgvector")
        
        self.connection = connection
        self.table_name = table_name
        self.id_column = id_column
        self.vector_column = vector_column
        
        # ğŸ”¥ ê°œì„ : ì—°ê²° ID ìƒì„± (ì—°ê²° ê°ì²´ì˜ ê³ ìœ  ì‹ë³„ì)
        connection_id = id(connection)
        
        # pgvector ë“±ë¡ (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        try:
            # ì—°ê²°ì´ ë‹«í˜”ëŠ”ì§€ í™•ì¸
            if hasattr(connection, 'closed') and connection.closed:
                raise RuntimeError("Connection is closed")
            
            # pgvector í™•ì¥ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            cursor = connection.cursor()
            cursor.execute("SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname = 'vector')")
            row = cursor.fetchone()
            has_extension = row[0] if isinstance(row, tuple) else (row.get('exists', False) if isinstance(row, dict) else False)
            
            if not has_extension:
                raise RuntimeError("pgvector extension is not installed in the database. Run: CREATE EXTENSION IF NOT EXISTS vector;")
            
            # ğŸ”¥ ê°œì„ : ì´ë¯¸ ë“±ë¡ëœ ì—°ê²°ì¸ì§€ í™•ì¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
            with _connection_lock:
                is_registered = connection_id in _registered_connections
            
            if is_registered:
                logger.debug(f"pgvector already registered for connection {connection_id}")
            else:
                # register_vector í˜¸ì¶œ (ì´ë¯¸ ë“±ë¡ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬)
                try:
                    register_vector(connection)
                    # ë“±ë¡ ì„±ê³µ ì‹œ ì¶”ì ì— ì¶”ê°€
                    with _connection_lock:
                        _registered_connections.add(connection_id)
                    logger.info(f"âœ… PgVectorAdapter initialized: table={table_name}")
                except Exception as reg_error:
                    # ì´ë¯¸ ë“±ë¡ë˜ì—ˆê±°ë‚˜ ë‹¤ë¥¸ ì˜¤ë¥˜ì¸ ê²½ìš°
                    error_str = str(reg_error).lower()
                    if "already" in error_str or "registered" in error_str:
                        # ì´ë¯¸ ë“±ë¡ëœ ê²½ìš° ì¶”ì ì— ì¶”ê°€
                        with _connection_lock:
                            _registered_connections.add(connection_id)
                        logger.debug(f"pgvector already registered: {reg_error}")
                    elif "vector type not found" in error_str:
                        # ğŸ”¥ ê°œì„ : vector íƒ€ì…ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° - í™•ì¥ì€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ íƒ€ì… ì¸ì‹ ì‹¤íŒ¨
                        # ì‹¤ì œë¡œëŠ” ì‘ë™í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë””ë²„ê·¸ ë ˆë²¨ë¡œ ì²˜ë¦¬
                        with _connection_lock:
                            _registered_connections.add(connection_id)
                        logger.debug(
                            f"pgvector type not found (extension installed, may work anyway): {reg_error}. "
                            f"Continuing as pgvector extension is installed."
                        )
                    else:
                        # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                        logger.warning(f"âš ï¸ pgvector registration warning: {reg_error}, continuing anyway")
        except Exception as e:
            error_msg = str(e).lower()
            if "closed" in error_msg or "extension" in error_msg:
                logger.error(f"âŒ Failed to register pgvector: {e}")
                raise
            # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
            logger.warning(f"âš ï¸ pgvector registration warning: {e}, continuing anyway")
    
    def search(
        self,
        query_vector: np.ndarray,
        limit: int,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[int, float]]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ê±°ë¦¬)"""
        # ì¿¼ë¦¬ ë²¡í„°ë¥¼ 1Dë¡œ ë³€í™˜
        if query_vector.ndim > 1:
            query_vector = query_vector.flatten()
        
        # í•„í„° ì¡°ê±´ êµ¬ì„±
        where_clauses = []
        params = []
        
        # embedding_vector IS NOT NULL ì¡°ê±´ ì¶”ê°€ (precedent_chunksìš©)
        where_clauses.append(f"{self.vector_column} IS NOT NULL")
        
        if filters:
            for key, values in filters.items():
                if isinstance(values, list):
                    if len(values) > 0:
                        # PostgreSQL ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ANY ì ˆ ì‚¬ìš©
                        where_clauses.append(f"{key} = ANY(%s::int[])")
                        params.append(values)
                else:
                    where_clauses.append(f"{key} = %s")
                    params.append(values)
        
        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)
        
        # ì½”ì‚¬ì¸ ê±°ë¦¬ ì‚¬ìš© (<=> ì—°ì‚°ì)
        # pgvectorì˜ <=> ì—°ì‚°ìëŠ” ì½”ì‚¬ì¸ ê±°ë¦¬ë¥¼ ë°˜í™˜ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
        query = f"""
            SELECT {self.id_column}, 
                   {self.vector_column} <=> %s::vector AS distance
            FROM {self.table_name}
            {where_clause}
            ORDER BY distance
            LIMIT %s
        """
        
        # íŒŒë¼ë¯¸í„° ìˆœì„œ: query_vector, filters..., limit
        params = [query_vector.tolist()] + params + [limit]
        
        cursor = self.connection.cursor()
        try:
            cursor.execute(query, params)
            results = []
            for row in cursor.fetchall():
                # rowê°€ dictì¸ ê²½ìš°ì™€ tupleì¸ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                if isinstance(row, dict):
                    vector_id = row[self.id_column]
                    distance = float(row['distance'])
                else:
                    # tupleì¸ ê²½ìš° ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ
                    vector_id = row[0]
                    distance = float(row[1])
                results.append((vector_id, distance))
            return results
        except Exception as e:
            logger.error(f"PgVector search error: {e}")
            raise
    
    def add_vectors(
        self,
        vectors: np.ndarray,
        ids: List[int],
        metadata: Optional[List[Dict[str, Any]]] = None
    ):
        """ë²¡í„° ì¶”ê°€"""
        if vectors.ndim != 2:
            raise ValueError("vectors must be 2D array (N x D)")
        
        if len(vectors) != len(ids):
            raise ValueError("vectors and ids must have the same length")
        
        cursor = self.connection.cursor()
        try:
            for i, (vector, vector_id) in enumerate(zip(vectors, ids)):
                meta = metadata[i] if metadata else {}
                
                # ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                vector_list = vector.tolist()
                
                query = f"""
                    INSERT INTO {self.table_name} ({self.id_column}, {self.vector_column}, metadata)
                    VALUES (%s, %s, %s)
                    ON CONFLICT ({self.id_column}) DO UPDATE
                    SET {self.vector_column} = EXCLUDED.{self.vector_column},
                        metadata = EXCLUDED.metadata
                """
                
                import json
                cursor.execute(query, (vector_id, vector_list, json.dumps(meta)))
            
            self.connection.commit()
            logger.info(f"Added {len(vectors)} vectors to {self.table_name}")
        except Exception as e:
            self.connection.rollback()
            logger.error(f"Failed to add vectors: {e}")
            raise
    
    def get_vector(self, vector_id: int) -> Optional[np.ndarray]:
        """ë²¡í„° ì¡°íšŒ"""
        query = f"""
            SELECT {self.vector_column}
            FROM {self.table_name}
            WHERE {self.id_column} = %s
        """
        
        cursor = self.connection.cursor()
        try:
            cursor.execute(query, (vector_id,))
            row = cursor.fetchone()
            if row:
                vector = row[self.vector_column]
                if isinstance(vector, list):
                    return np.array(vector, dtype=np.float32)
                return vector
            return None
        except Exception as e:
            logger.error(f"Failed to get vector: {e}")
            return None


class FaissAdapter(VectorSearchAdapter):
    """FAISS ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰"""
    
    def __init__(
        self,
        index_path: str,
        vector_loader: Optional[callable] = None,
        dimension: Optional[int] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            index_path: FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
            vector_loader: ë²¡í„° ë¡œë” í•¨ìˆ˜ (í•„ìš”ì‹œ)
            dimension: ë²¡í„° ì°¨ì› (ì¸ë±ìŠ¤ê°€ ì—†ì„ ë•Œ ìƒì„±ìš©)
        """
        if not FAISS_AVAILABLE:
            raise ImportError("FAISS is required. Install with: pip install faiss-cpu")
        
        self.index_path = Path(index_path)
        self.vector_loader = vector_loader
        self.dimension = dimension
        self.index = None
        self._load_index()
        
        logger.info(f"FaissAdapter initialized: index_path={index_path}")
    
    def _load_index(self):
        """FAISS ì¸ë±ìŠ¤ ë¡œë“œ"""
        if self.index_path.exists():
            try:
                self.index = faiss.read_index(str(self.index_path))
                logger.info(f"Loaded FAISS index: {self.index_path}")
            except Exception as e:
                logger.error(f"Failed to load FAISS index: {e}")
                raise
        else:
            # ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
            if self.dimension is None:
                raise ValueError("dimension is required when creating new index")
            
            # ê¸°ë³¸ ì¸ë±ìŠ¤ ìƒì„± (L2 ê±°ë¦¬)
            self.index = faiss.IndexFlatL2(self.dimension)
            logger.info(f"Created new FAISS index: dimension={self.dimension}")
    
    def search(
        self,
        query_vector: np.ndarray,
        limit: int,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[int, float]]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (L2 ê±°ë¦¬)"""
        if self.index is None:
            raise RuntimeError("FAISS index not loaded")
        
        # ì¿¼ë¦¬ ë²¡í„°ë¥¼ 2Dë¡œ ë³€í™˜ (1 x D)
        if query_vector.ndim == 1:
            query_vector = query_vector.reshape(1, -1)
        
        # float32ë¡œ ë³€í™˜
        query_vector = query_vector.astype('float32')
        
        # ê²€ìƒ‰
        distances, indices = self.index.search(query_vector, limit)
        
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            if idx != -1:  # FAISSì˜ -1ì€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²°ê³¼
                results.append((int(idx), float(dist)))
        
        # í•„í„° ì ìš© (í•„ìš”ì‹œ)
        if filters:
            results = self._apply_filters(results, filters)
        
        return results
    
    def _apply_filters(
        self,
        results: List[Tuple[int, float]],
        filters: Dict[str, Any]
    ) -> List[Tuple[int, float]]:
        """í•„í„° ì ìš© (FAISSëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ì´ë¯€ë¡œ ì‚¬í›„ í•„í„°ë§)"""
        # FAISSëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ì´ë¯€ë¡œ í•„í„°ë§ì´ ì œí•œì 
        # í•„ìš”ì‹œ vector_loaderë¥¼ í†µí•´ ë©”íƒ€ë°ì´í„° í™•ì¸
        if self.vector_loader:
            filtered_results = []
            for vector_id, distance in results:
                # vector_loaderë¥¼ í†µí•´ ë©”íƒ€ë°ì´í„° í™•ì¸
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ IDë§Œ í™•ì¸
                if 'id' in filters:
                    if vector_id in filters['id']:
                        filtered_results.append((vector_id, distance))
                else:
                    filtered_results.append((vector_id, distance))
            return filtered_results
        return results
    
    def add_vectors(
        self,
        vectors: np.ndarray,
        ids: List[int],
        metadata: Optional[List[Dict[str, Any]]] = None
    ):
        """ë²¡í„° ì¶”ê°€"""
        if self.index is None:
            raise RuntimeError("FAISS index not loaded")
        
        if vectors.ndim != 2:
            raise ValueError("vectors must be 2D array (N x D)")
        
        # float32ë¡œ ë³€í™˜
        vectors = vectors.astype('float32')
        
        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(vectors)
        
        # ì¸ë±ìŠ¤ ì €ì¥
        faiss.write_index(self.index, str(self.index_path))
        
        logger.info(f"Added {len(vectors)} vectors to FAISS index")
    
    def get_vector(self, vector_id: int) -> Optional[np.ndarray]:
        """ë²¡í„° ì¡°íšŒ (FAISSëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ì´ë¯€ë¡œ vector_loader í•„ìš”)"""
        if self.vector_loader:
            return self.vector_loader(vector_id)
        else:
            logger.warning("vector_loader not set, cannot get vector by ID")
            return None


class VectorSearchFactory:
    """ë²¡í„° ê²€ìƒ‰ ì–´ëŒ‘í„° íŒ©í† ë¦¬"""
    
    @staticmethod
    def create(
        method: str,
        connection=None,
        table_name: str = 'statute_embeddings',
        index_path: str = None,
        vector_loader: Optional[callable] = None,
        dimension: Optional[int] = None,
        **kwargs
    ) -> VectorSearchAdapter:
        """
        ë²¡í„° ê²€ìƒ‰ ì–´ëŒ‘í„° ìƒì„±
        
        Args:
            method: 'pgvector' ë˜ëŠ” 'faiss'
            connection: PostgreSQL ì—°ê²° (pgvectorìš©)
            table_name: í…Œì´ë¸”ëª… (pgvectorìš©)
            index_path: FAISS ì¸ë±ìŠ¤ ê²½ë¡œ (faissìš©)
            vector_loader: ë²¡í„° ë¡œë” í•¨ìˆ˜ (faissìš©)
            dimension: ë²¡í„° ì°¨ì› (faissìš©, ì¸ë±ìŠ¤ ìƒì„± ì‹œ)
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
            VectorSearchAdapter ì¸ìŠ¤í„´ìŠ¤
        """
        method = method.lower()
        
        if method == 'pgvector':
            if connection is None:
                raise ValueError("connection is required for pgvector")
            return PgVectorAdapter(
                connection=connection,
                table_name=table_name,
                **kwargs
            )
        
        elif method == 'faiss':
            if index_path is None:
                raise ValueError("index_path is required for faiss")
            return FaissAdapter(
                index_path=index_path,
                vector_loader=vector_loader,
                dimension=dimension
            )
        
        else:
            raise ValueError(f"Unknown vector search method: {method}. Use 'pgvector' or 'faiss'")

