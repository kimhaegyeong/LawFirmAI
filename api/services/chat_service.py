"""
ì±„íŒ… ì„œë¹„ìŠ¤ (lawfirm_langgraph ë˜í¼)
"""
import sys
import re
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, AsyncGenerator

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# lawfirm_langgraph ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€ (core ëª¨ë“ˆ importë¥¼ ìœ„í•´)
lawfirm_langgraph_path = project_root / "lawfirm_langgraph"
if lawfirm_langgraph_path.exists():
    sys.path.insert(0, str(lawfirm_langgraph_path))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ChatService ì´ˆê¸°í™” ì „ì— ë°˜ë“œì‹œ ë¡œë“œ)
try:
    from dotenv import load_dotenv
    
    # 1. lawfirm_langgraph/.env ë¡œë“œ (LangGraphConfigê°€ ì‚¬ìš©)
    langgraph_env = lawfirm_langgraph_path / ".env"
    if langgraph_env.exists():
        load_dotenv(dotenv_path=str(langgraph_env), override=False)
        logging.info(f"âœ… [ChatService] Loaded environment from: {langgraph_env}")
    else:
        logging.warning(f"âš ï¸  [ChatService] Environment file not found: {langgraph_env}")
    
    # 2. í”„ë¡œì íŠ¸ ë£¨íŠ¸ .env ë¡œë“œ (ê³µí†µ ì„¤ì •)
    root_env = project_root / ".env"
    if root_env.exists():
        load_dotenv(dotenv_path=str(root_env), override=False)
        logging.info(f"âœ… [ChatService] Loaded environment from: {root_env}")
    
    # 3. api/.env ë¡œë“œ (API ì„œë²„ ì „ìš© ì„¤ì •, ìµœìš°ì„ )
    api_env = Path(__file__).parent.parent / ".env"
    if api_env.exists():
        load_dotenv(dotenv_path=str(api_env), override=True)
        logging.info(f"âœ… [ChatService] Loaded environment from: {api_env}")
        
except ImportError:
    logging.warning("âš ï¸  python-dotenv not installed. Environment variables from .env files will not be loaded.")
except Exception as e:
    logging.warning(f"âš ï¸  Failed to load environment variables: {e}")

try:
    from lawfirm_langgraph.langgraph_core.workflow.workflow_service import LangGraphWorkflowService
    from lawfirm_langgraph.config.langgraph_config import LangGraphConfig
    LANGGRAPH_AVAILABLE = True
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    logging.warning(f"LangGraph not available: {e}")

logger = logging.getLogger(__name__)

# ë¡œê±° ë ˆë²¨ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • (ë£¨íŠ¸ ë¡œê±° ë ˆë²¨ê³¼ ë™ê¸°í™”)
# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œê·¸ ë ˆë²¨ ì½ê¸°
import os
log_level_str = os.getenv("LOG_LEVEL", "info").upper()
log_level_map = {
    "CRITICAL": logging.CRITICAL,
    "ERROR": logging.ERROR,
    "WARNING": logging.WARNING,
    "INFO": logging.INFO,
    "DEBUG": logging.DEBUG,
}
log_level = log_level_map.get(log_level_str, logging.INFO)
logger.setLevel(log_level)
logger.disabled = False  # ëª…ì‹œì ìœ¼ë¡œ í™œì„±í™”
logger.propagate = True  # ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒ

# ë¡œê¹…ì´ ë¹„í™œì„±í™”ë˜ì§€ ì•Šë„ë¡ ë³´í˜¸
logging.disable(logging.NOTSET)  # ëª¨ë“  ë¡œê¹… í™œì„±í™”

# ë£¨íŠ¸ ë¡œê±°ì— í•¸ë“¤ëŸ¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€ (ëª¨ë“ˆ import ì‹œì ì— ë¡œê¹…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ)
root_logger = logging.getLogger()
if not root_logger.handlers:
    handler = logging.StreamHandler()
    handler.setLevel(log_level)
    handler.setFormatter(
        logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    )
    root_logger.addHandler(handler)
    root_logger.setLevel(log_level)
    root_logger.disabled = False

# í…ŒìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥ (ëª¨ë“ˆ import ì‹œì )
logger.info("âœ… ChatService logger initialized and enabled")
logger.debug("âœ… ChatService logger debug level enabled")


class ChatService:
    """ì±„íŒ… ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ChatService.__init__() called - Initializing ChatService...")
        self.workflow_service: Optional[LangGraphWorkflowService] = None
        self._initialize_workflow()
        logger.info("âœ… ChatService.__init__() completed")
    
    def _initialize_workflow(self):
        """ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”"""
        if not LANGGRAPH_AVAILABLE:
            logger.warning("LangGraph is not available. Service will continue without LangGraph features.")
            return
        
        try:
            import os
            # í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ë¯¼ê° ì •ë³´ëŠ” ë¡œê·¸ì— ë…¸ì¶œí•˜ì§€ ì•ŠìŒ)
            google_api_key = os.getenv("GOOGLE_API_KEY", "")
            if not google_api_key:
                logger.warning("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                logger.warning("LangGraphëŠ” Google API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                logger.info("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            logger.info("Loading LangGraphConfig from environment...")
            
            config = LangGraphConfig.from_env()
            logger.info(f"LangGraph Config loaded: langgraph_enabled={config.langgraph_enabled}, llm_provider={config.llm_provider}")
            
            if not config.langgraph_enabled:
                logger.warning("LangGraph is disabled in configuration")
                return
            
            logger.info("Initializing LangGraphWorkflowService...")
            
            self.workflow_service = LangGraphWorkflowService(config)
            logger.info("âœ… ChatService initialized successfully with LangGraph workflow")
        except ImportError as e:
            logger.error(f"Import error during workflow initialization: {e}", exc_info=True)
            self.workflow_service = None
        except Exception as e:
            logger.error(f"Failed to initialize workflow service: {e}", exc_info=True)
            import traceback
            tb = traceback.format_exc()
            logger.error(f"Traceback:\n{tb}")
            self.workflow_service = None
    
    async def process_message(
        self,
        message: str,
        session_id: Optional[str] = None,
        enable_checkpoint: bool = True
    ) -> Dict[str, Any]:
        """
        ë©”ì‹œì§€ ì²˜ë¦¬
        
        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            session_id: ì„¸ì…˜ ID
            enable_checkpoint: ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.workflow_service:
            import os
            error_details = []
            
            # ì›ì¸ ë¶„ì„
            if not LANGGRAPH_AVAILABLE:
                error_details.append("LangGraph ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                google_api_key = os.getenv("GOOGLE_API_KEY", "")
                if not google_api_key:
                    error_details.append("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    error_details.append("ì›Œí¬í”Œë¡œìš° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            error_msg = f"Workflow service unavailable. Details: {', '.join(error_details)}"
            logger.error(error_msg)
            
            return {
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\nì›ì¸:\n" + "\n".join(f"- {detail}" for detail in error_details) + "\n\nAPI ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
                "sources": [],
                "confidence": 0.0,
                "legal_references": [],
                "processing_steps": ["ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨"],
                "session_id": session_id or "error",
                "processing_time": 0.0,
                "query_type": "error",
                "metadata": {"error_details": error_details},
                "errors": error_details
            }
        
        try:
            result = await self.workflow_service.process_query(
                query=message,
                session_id=session_id,
                enable_checkpoint=enable_checkpoint
            )
            return result
        except Exception as e:
            logger.error(f"Error processing message: {e}", exc_info=True)
            import os
            debug_mode = os.getenv("DEBUG", "false").lower() == "true"
            error_detail = str(e) if debug_mode else "ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "confidence": 0.0,
                "legal_references": [],
                "processing_steps": [f"ì˜¤ë¥˜: {error_detail}"],
                "session_id": session_id or "error",
                "processing_time": 0.0,
                "query_type": "error",
                "metadata": {"error": error_detail} if debug_mode else {"error": True},
                "errors": [error_detail]
            }
    
    async def stream_message(
        self,
        message: str,
        session_id: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì²˜ë¦¬ (Server-Sent Events)
        ì‹¤ì œ LLM í† í° ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•©ë‹ˆë‹¤.
        
        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            session_id: ì„¸ì…˜ ID
            
        Yields:
            ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬ (í† í° ë‹¨ìœ„)
        """
        # ë””ë²„ê·¸ ëª¨ë“œ í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´) - í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì •ì˜
        import os
        DEBUG_STREAM = os.getenv("DEBUG_STREAM", "false").lower() == "true"
        
        has_yielded = False  # ìµœì†Œí•œ í•˜ë‚˜ì˜ yieldê°€ ìˆì—ˆëŠ”ì§€ ì¶”ì 
        
        if not self.workflow_service:
            error_event = {
                "type": "final",
                "content": "[ì˜¤ë¥˜] ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "metadata": {"error": True},
                "timestamp": datetime.now().isoformat()
            }
            yield json.dumps(error_event, ensure_ascii=False) + "\n"
            has_yielded = True
            return
        
        try:
            import uuid
            
            # ì„¸ì…˜ ID ìƒì„±
            if not session_id:
                session_id = str(uuid.uuid4())
            
            # ì›Œí¬í”Œë¡œìš° ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            from lawfirm_langgraph.langgraph_core.state.state_definitions import create_initial_legal_state
            
            # ë¡œê¹…: message ê°’ í™•ì¸
            logger.info(f"stream_message: ë°›ì€ message='{message[:100] if message else 'EMPTY'}...', length={len(message) if message else 0}")
            
            # messageë¥¼ queryë¡œ ì‚¬ìš© (create_initial_legal_stateì˜ ì²« ë²ˆì§¸ íŒŒë¼ë¯¸í„°ëŠ” query)
            initial_state = create_initial_legal_state(message, session_id)
            
            # ì¤‘ìš”: initial_stateì— queryê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ë„ë¡ ê°•ì œ
            # LangGraphì— ì „ë‹¬í•˜ê¸° ì „ì— input ê·¸ë£¹ì— queryê°€ ìˆì–´ì•¼ í•¨
            if "input" not in initial_state:
                initial_state["input"] = {}
            if not initial_state["input"].get("query"):
                initial_state["input"]["query"] = message
                logger.debug(f"stream_message: input.queryì— message ì„¤ì •: '{message[:50]}...'")
            if not initial_state["input"].get("session_id"):
                initial_state["input"]["session_id"] = session_id
            
            # ìµœìƒìœ„ ë ˆë²¨ì—ë„ query í¬í•¨ (ì´ì¤‘ ë³´ì¥)
            if not initial_state.get("query"):
                initial_state["query"] = message
                logger.debug(f"stream_message: ìµœìƒìœ„ queryì— message ì„¤ì •: '{message[:50]}...'")
            if not initial_state.get("session_id"):
                initial_state["session_id"] = session_id
            
            # ì´ˆê¸° state ê²€ì¦
            initial_query = initial_state.get("input", {}).get("query", "") if initial_state.get("input") else initial_state.get("query", "")
            logger.info(f"stream_message: initial_state query length={len(initial_query)}, query='{initial_query[:100] if initial_query else 'EMPTY'}...'")
            logger.debug(f"stream_message: initial_state input.query='{initial_state.get('input', {}).get('query', 'NOT_FOUND')[:50] if initial_state.get('input', {}).get('query') else 'NOT_FOUND'}...'")
            logger.debug(f"stream_message: initial_state ìµœìƒìœ„ query='{initial_state.get('query', 'NOT_FOUND')[:50] if initial_state.get('query') else 'NOT_FOUND'}...'")
            
            if not initial_query or not str(initial_query).strip():
                logger.error(f"Initial state query is empty! Input message was: '{message[:50]}...'")
                logger.debug(f"stream_message: ERROR - initial_state query is empty!")
                logger.debug(f"stream_message: initial_state keys: {list(initial_state.keys())}")
                error_event = {
                    "type": "final",
                    "content": "[ì˜¤ë¥˜] ì§ˆë¬¸ì´ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "metadata": {"error": True},
                    "timestamp": datetime.now().isoformat()
                }
                yield json.dumps(error_event, ensure_ascii=False) + "\n"
                return
            
            config = {"configurable": {"thread_id": session_id}}
            
            # ì‹¤ì œ í† í° ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ë³€ìˆ˜
            full_answer = ""
            answer_found = False
            tokens_received = 0
            last_node_name = None
            executed_nodes = set()  # ì‹¤í–‰ëœ ë…¸ë“œ ì¶”ì 
            answer_generation_started = False  # ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘ í”Œë˜ê·¸
            json_output_detected = False  # JSON ì¶œë ¥ ê°ì§€ í”Œë˜ê·¸
            
            # ë…¸ë“œ ì´ë¦„ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë©”ì‹œì§€ë¡œ ë§¤í•‘
            node_name_mapping = {
                "classify_query_and_complexity": "ì§ˆë¬¸ ë¶„ì„ ì¤‘...",
                "classification_parallel": "ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘...",
                "route_expert": "ì „ë¬¸ê°€ ë¼ìš°íŒ… ì¤‘...",
                "expand_keywords": "í‚¤ì›Œë“œ í™•ì¥ ì¤‘...",
                "prepare_search_query": "ê²€ìƒ‰ ì¿¼ë¦¬ ì¤€ë¹„ ì¤‘...",
                "execute_searches_parallel": "ê´€ë ¨ ë²•ë¥  ê²€ìƒ‰ ì¤‘...",
                "process_search_results_combined": "ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ì¤‘...",
                "prepare_documents_and_terms": "ë¬¸ì„œ ì¤€ë¹„ ì¤‘...",
                "generate_answer_enhanced": "ë‹µë³€ ìƒì„± ì¤‘...",
                "generate_and_validate_answer": "ë‹µë³€ ìƒì„± ì¤‘...",
                "validate_answer_quality": "ë‹µë³€ ê²€ì¦ ì¤‘...",
                "prepare_final_response": "ìµœì¢… ë‹µë³€ ì¤€ë¹„ ì¤‘..."
            }
            
            # astream_events()ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM í† í° ìŠ¤íŠ¸ë¦¬ë° ê°ì§€
            # 
            # ìŠ¤íŠ¸ë¦¬ë° íë¦„:
            # 1. LangGraphì˜ astream_events()ê°€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°
            # 2. LLM í˜¸ì¶œ ì‹œ on_llm_stream ë˜ëŠ” on_chat_model_stream ì´ë²¤íŠ¸ ë°œìƒ
            # 3. LangChainì˜ ChatGoogleGenerativeAI/OllamaëŠ” invoke() í˜¸ì¶œ ì‹œì—ë„
            #    ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ë¯€ë¡œ astream_events()ê°€ ì´ë¥¼ ìº¡ì²˜ ê°€ëŠ¥
            # 4. ë‹µë³€ ìƒì„± ë…¸ë“œ(generate_answer_enhanced)ì—ì„œ ë°œìƒí•œ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
            # 5. ê° í† í°ì„ JSONL í˜•ì‹ìœ¼ë¡œ yieldí•˜ì—¬ HTTP ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ë‹¬
            try:
                # ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
                # LangGraph ë²„ì „ë³„ í˜¸í™˜ì„±: version íŒŒë¼ë¯¸í„°ê°€ ì—†ì„ ìˆ˜ë„ ìˆìŒ
                # wrapper í•¨ìˆ˜ë¡œ ë²„ì „ í˜¸í™˜ì„± ì²˜ë¦¬
                async def get_stream_events():
                    """ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë˜í¼
                    
                    LangGraphì˜ astream_events()ëŠ” ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ëª¨ë“  ì´ë²¤íŠ¸ë¥¼
                    ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤. LLM í˜¸ì¶œ ì‹œ on_llm_stream ë˜ëŠ” 
                    on_chat_model_stream ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ë©°, LangChainì˜ LLMì€ 
                    invoke() í˜¸ì¶œ ì‹œì—ë„ ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ë¯€ë¡œ 
                    ì´ ì´ë²¤íŠ¸ë“¤ì„ í†µí•´ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    """
                    try:
                        # version="v2" ì‹œë„ (LangGraph ìµœì‹  ë²„ì „)
                        # include_namesë¡œ generate_and_validate_answer ë…¸ë“œì˜ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§ ì‹œë„
                        if DEBUG_STREAM:
                            logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: astream_events(version='v2') ì‚¬ìš©")
                        try:
                            # include_names íŒŒë¼ë¯¸í„°ë¡œ íŠ¹ì • ë…¸ë“œë§Œ í•„í„°ë§ ì‹œë„
                            try:
                                async for event in self.workflow_service.app.astream_events(
                                    initial_state, 
                                    config,
                                    version="v2",
                                    include_names=["generate_and_validate_answer", "generate_answer_enhanced"]
                                ):
                                    yield event
                            except (TypeError, AttributeError):
                                # include_namesê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° exclude_names ì‹œë„
                                try:
                                    async for event in self.workflow_service.app.astream_events(
                                        initial_state, 
                                        config,
                                        version="v2",
                                        exclude_names=["classify_query_and_complexity", "classification_parallel", 
                                                      "expand_keywords", "validate_answer_quality", "prepare_search_query",
                                                      "execute_searches_parallel", "process_search_results_combined",
                                                      "prepare_documents_and_terms", "prepare_final_response"]
                                    ):
                                        yield event
                                except (TypeError, AttributeError):
                                    # exclude_namesë„ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬
                                    async for event in self.workflow_service.app.astream_events(
                                        initial_state, 
                                        config,
                                        version="v2"
                                    ):
                                        yield event
                        except (TypeError, AttributeError):
                            # include_namesê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬
                            async for event in self.workflow_service.app.astream_events(
                                initial_state, 
                                config,
                                version="v2"
                            ):
                                yield event
                    except (TypeError, AttributeError) as ve:
                        # version íŒŒë¼ë¯¸í„°ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° (êµ¬ë²„ì „)
                        logger.debug(f"astream_eventsì—ì„œ version íŒŒë¼ë¯¸í„° ë¯¸ì§€ì›: {ve}, ê¸°ë³¸ ë²„ì „ ì‚¬ìš©")
                        if DEBUG_STREAM:
                            logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: astream_events() ì‚¬ìš© (ê¸°ë³¸ ë²„ì „)")
                        async for event in self.workflow_service.app.astream_events(
                            initial_state, 
                            config
                        ):
                            yield event
                
                # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
                event_count = 0
                llm_stream_count = 0
                event_types_seen = set()  # ë³¸ ì´ë²¤íŠ¸ íƒ€ì… ì¶”ì 
                node_names_seen = set()  # ë³¸ ë…¸ë“œ ì´ë¦„ ì¶”ì 
                
                async for event in get_stream_events():
                    event_count += 1
                    # ì´ë²¤íŠ¸ íƒ€ì… í™•ì¸
                    event_type = event.get("event", "")
                    event_name = event.get("name", "")
                    
                    # ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì… ì¶”ì  (ë””ë²„ê¹…ìš©)
                    event_types_seen.add(event_type)
                    if event_name:
                        node_names_seen.add(event_name)
                    
                    # ë””ë²„ê¹…: ì²˜ìŒ 100ê°œ ì´ë²¤íŠ¸ëŠ” í•­ìƒ ë¡œê¹… (ë¬¸ì œ ì§„ë‹¨ìš©)
                    if event_count <= 100:
                        logger.info(f"ì´ë²¤íŠ¸ #{event_count}: type={event_type}, name={event_name}")
                    
                    # ê´€ë ¨ ì—†ëŠ” ì´ë²¤íŠ¸ëŠ” ì¦‰ì‹œ ê±´ë„ˆë›°ê¸° (ì„±ëŠ¥ ìµœì í™”)
                    # on_chat_model_endë„ ì¶”ê°€ (Google GeminiëŠ” on_chat_model_stream ì‚¬ìš©)
                    # on_chain_streamë„ ì¶”ê°€ (LangGraphì—ì„œ ì²´ì¸ ë ˆë²¨ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸)
                    if event_type not in ["on_llm_stream", "on_chat_model_stream", "on_chain_stream", "on_chain_start", "on_chain_end", "on_llm_end", "on_chat_model_end"]:
                        continue
                    
                    # ë””ë²„ê¹…: ì²˜ë¦¬í•  ì´ë²¤íŠ¸ ë¡œê¹… (ì²˜ìŒ 20ê°œë§Œ)
                    if DEBUG_STREAM and event_count <= 20:
                        logger.debug(f"ì²˜ë¦¬í•  ì´ë²¤íŠ¸ #{event_count}: type={event_type}, name={event_name}")
                    
                    # LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ê°ì§€ (ë‹µë³€ ìƒì„± ë…¸ë“œì—ì„œë§Œ)
                    # 
                    # ì¤‘ìš”: LangChainì˜ ChatGoogleGenerativeAIì™€ OllamaëŠ”
                    # invoke() í˜¸ì¶œ ì‹œì—ë„ ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    # ë”°ë¼ì„œ astream_events()ê°€ on_llm_stream ë˜ëŠ” on_chat_model_stream
                    # ì´ë²¤íŠ¸ë¥¼ ë°œìƒì‹œì¼œ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                    # 
                    # LangGraph/LangChain ìµœì‹  ë²„ì „ì—ì„œëŠ” on_chat_model_streamë„ ì§€ì›
                    # on_chain_streamì€ ì²´ì¸ ë ˆë²¨ì˜ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ë¡œ, ì²´ì¸ ì „ì²´ì˜ ì¶œë ¥ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    if event_type in ["on_llm_stream", "on_chat_model_stream", "on_chain_stream"]:
                        # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì¡°ê¸° ì¢…ë£Œ ìµœì í™”)
                        if not answer_generation_started:
                            # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ëª¨ë“  LLM ì¶œë ¥ ë¬´ì‹œ
                            llm_stream_count += 1
                            if DEBUG_STREAM and llm_stream_count <= 5:
                                logger.debug(f"ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ: {event_name} (ëª¨ë“  ì¶œë ¥ ë¬´ì‹œ)")
                            # JSON ì¶œë ¥ì´ë“  ì•„ë‹ˆë“  ëª¨ë‘ ë¬´ì‹œ
                            continue
                        
                        llm_stream_count += 1
                        if DEBUG_STREAM:
                            logger.debug(f"{event_type} ì´ë²¤íŠ¸ ë°œê²¬: name={event_name}, ì „ì²´ ì´ë²¤íŠ¸ í‚¤: {list(event.keys())}")
                        
                        # ì´ë²¤íŠ¸ì˜ ìƒìœ„ ë…¸ë“œ ì •ë³´ í™•ì¸
                        event_tags = event.get("tags", [])
                        event_metadata = event.get("metadata", {})
                        event_parent = event.get("parent", {})
                        
                        # ìƒìœ„ ë…¸ë“œ ì´ë¦„ í™•ì¸
                        parent_node_name = None
                        if isinstance(event_parent, dict):
                            parent_node_name = event_parent.get("name", "")
                        elif isinstance(event_tags, list):
                            # tagsì—ì„œ ë…¸ë“œ ì´ë¦„ ì°¾ê¸°
                            for tag in event_tags:
                                if isinstance(tag, str) and ("generate_answer" in tag.lower() or "generate_and_validate" in tag.lower()):
                                    parent_node_name = tag
                                    break
                        
                        # ë‹µë³€ ìƒì„± ë…¸ë“œ ë‚´ë¶€ì˜ LLM í˜¸ì¶œì¸ì§€ í™•ì¸
                        is_answer_node = False
                        
                        # ë°©ë²• 1: ì´ë²¤íŠ¸ ì´ë¦„ìœ¼ë¡œ ì§ì ‘ íŒë‹¨
                        if "generate_answer" in event_name.lower() or \
                           "generate_and_validate" in event_name.lower() or \
                           event_name in ["generate_answer_enhanced", "generate_and_validate_answer", "direct_answer"]:
                            is_answer_node = True
                        
                        # ë°©ë²• 2: ìƒìœ„ ë…¸ë“œê°€ ë‹µë³€ ìƒì„± ë…¸ë“œì¸ì§€ í™•ì¸
                        elif parent_node_name and (
                            "generate_answer" in parent_node_name.lower() or 
                            "generate_and_validate" in parent_node_name.lower() or
                            parent_node_name in ["generate_answer_enhanced", "generate_and_validate_answer"]
                        ):
                            is_answer_node = True
                        
                        # ë°©ë²• 3: ChatGoogleGenerativeAIì¸ ê²½ìš°, ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹¤í–‰ëœ ë…¸ë“œê°€ ë‹µë³€ ìƒì„± ë…¸ë“œì¸ì§€ í™•ì¸
                        elif event_name == "ChatGoogleGenerativeAI" and answer_generation_started:
                            # last_node_nameì´ ì •í™•íˆ generate_and_validate_answerì¸ì§€ í™•ì¸
                            if last_node_name == "generate_and_validate_answer":
                                is_answer_node = True
                            # generate_answer_enhancedë„ í—ˆìš© (generate_and_validate_answer ë‚´ë¶€ì—ì„œ í˜¸ì¶œ)
                            elif last_node_name == "generate_answer_enhanced":
                                # generate_and_validate_answer ë…¸ë“œê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                                if "generate_and_validate_answer" in executed_nodes:
                                    is_answer_node = True
                            else:
                                # ë‹¤ë¥¸ ë…¸ë“œëŠ” ë¬´ì‹œ
                                is_answer_node = False
                        
                        # ë””ë²„ê¹…: ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë¡œê¹… (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ, ì²˜ìŒ 10ê°œë§Œ)
                        if DEBUG_STREAM and llm_stream_count <= 10:
                            logger.debug(
                                f"{event_type} ì´ë²¤íŠ¸ #{llm_stream_count}: "
                                f"name={event_name}, parent={parent_node_name}, "
                                f"is_answer_node={is_answer_node}, "
                                f"answer_generation_started={answer_generation_started}, "
                                f"last_node={last_node_name}, "
                                f"tags={event_tags}, metadata={event_metadata}"
                            )
                        
                        if not is_answer_node:
                            # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹ˆë©´ ë¬´ì‹œ
                            if DEBUG_STREAM and llm_stream_count <= 5:
                                logger.debug(f"ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì•„ë‹˜: {event_name}, parent={parent_node_name} (ë¬´ì‹œ)")
                            continue
                        
                        if DEBUG_STREAM:
                            logger.debug(f"âœ… ë‹µë³€ ìƒì„± ë…¸ë“œì—ì„œ {event_type} ì´ë²¤íŠ¸ ê°ì§€: {event_name}, parent={parent_node_name}")
                        
                        if is_answer_node:
                            if DEBUG_STREAM:
                                logger.debug(f"LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ê°ì§€: {event_name} (ì´ {llm_stream_count}ê°œ)")
                            # í† í° ì¶”ì¶œ (ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ êµ¬ì¡° ì§€ì›)
                            chunk = None
                            event_data = event.get("data", {})
                            
                            try:
                                # on_chain_stream ì´ë²¤íŠ¸ì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                                if event_type == "on_chain_stream":
                                    # on_chain_streamì€ ì²´ì¸ ë ˆë²¨ì˜ ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸
                                    # data í•„ë“œì— ì²´ì¸ì˜ ì¶œë ¥ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ
                                    # ì£¼ì˜: on_chain_streamì€ ì²´ì¸ ì „ì²´ì˜ ì¶œë ¥ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
                                    # ì´ì „ì— ë°›ì€ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì•¼ í•¨
                                    
                                    # 1. ì´ë²¤íŠ¸ êµ¬ì¡° í™•ì¸ ë° ë¡œê¹… ê°•í™”
                                    if DEBUG_STREAM:
                                        logger.debug(f"on_chain_stream ì´ë²¤íŠ¸ ìˆ˜ì‹ : event_name={event_name}")
                                        logger.debug(f"on_chain_stream ì´ë²¤íŠ¸ êµ¬ì¡°: event_data type={type(event_data)}")
                                        if isinstance(event_data, dict):
                                            logger.debug(f"on_chain_stream event_data keys: {list(event_data.keys())}")
                                            # event_dataì˜ ì£¼ìš” í‚¤ ê°’ ë¡œê¹… (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ)
                                            for key in list(event_data.keys())[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                                                value = event_data.get(key)
                                                if isinstance(value, str):
                                                    logger.debug(f"on_chain_stream event_data['{key}'] (str, {len(value)}ì): {value[:100]}...")
                                                elif isinstance(value, dict):
                                                    logger.debug(f"on_chain_stream event_data['{key}'] (dict): keys={list(value.keys())[:10]}")
                                                else:
                                                    logger.debug(f"on_chain_stream event_data['{key}']: {type(value)}")
                                    
                                    try:
                                        if isinstance(event_data, dict):
                                            # ì²´ì¸ ì¶œë ¥ì—ì„œ answer í•„ë“œ ì¶”ì¶œ ì‹œë„
                                            chain_output = event_data.get("chunk") or event_data.get("output")
                                            
                                            # ë¡œê¹…: chain_output êµ¬ì¡° í™•ì¸
                                            if DEBUG_STREAM:
                                                logger.debug(f"on_chain_stream: chain_output type={type(chain_output)}")
                                                if chain_output:
                                                    if isinstance(chain_output, str):
                                                        logger.debug(f"on_chain_stream: chain_output (str, {len(chain_output)}ì): {chain_output[:100]}...")
                                                    elif isinstance(chain_output, dict):
                                                        logger.debug(f"on_chain_stream: chain_output (dict): keys={list(chain_output.keys())[:10]}")
                                            
                                            if chain_output is not None:
                                                # chain_outputì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° answer í•„ë“œ í™•ì¸
                                                if isinstance(chain_output, dict):
                                                    # answer ê·¸ë£¹ì—ì„œ ì¶”ì¶œ
                                                    answer_group = chain_output.get("answer", {})
                                                    if isinstance(answer_group, dict):
                                                        full_answer_from_event = answer_group.get("answer", "") or answer_group.get("content", "")
                                                    elif isinstance(answer_group, str):
                                                        full_answer_from_event = answer_group
                                                    else:
                                                        full_answer_from_event = ""
                                                    
                                                    # ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì§ì ‘ ì¶”ì¶œ
                                                    if not full_answer_from_event:
                                                        full_answer_from_event = chain_output.get("answer", "") or chain_output.get("content", "")
                                                    
                                                    # ì´ì „ì— ë°›ì€ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                                                    if full_answer_from_event and isinstance(full_answer_from_event, str):
                                                        if len(full_answer_from_event) > len(full_answer):
                                                            # ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                                                            new_part = full_answer_from_event[len(full_answer):]
                                                            
                                                            # í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì „ã…‡
                                                            # ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                            # ê³µë°±, êµ¬ë‘ì , í•œê¸€/ì˜ë¬¸/ìˆ«ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                            tokens = re.findall(r'\S+|\s+', new_part)
                                                            for token in tokens:
                                                                # ì¤„ë°”ê¿ˆì„ í¬í•¨í•œ ëª¨ë“  í† í° ì „ì†¡ (strip() ì²´í¬ ì œê±°)
                                                                if token:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ì „ì†¡ (ì¤„ë°”ê¿ˆ í¬í•¨)
                                                                    try:
                                                                        # type: "stream"ìœ¼ë¡œ ì „ì†¡
                                                                        stream_event = {
                                                                            "type": "stream",
                                                                            "content": token,
                                                                            "timestamp": datetime.now().isoformat()
                                                                        }
                                                                        event_json = json.dumps(stream_event, ensure_ascii=False)
                                                                        yield event_json + "\n"
                                                                        full_answer += token
                                                                        tokens_received += 1
                                                                        answer_found = True
                                                                        if DEBUG_STREAM:
                                                                            logger.debug(f"on_chain_stream: í† í° ì „ì†¡ ({len(token)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                                    except (TypeError, ValueError) as json_error:
                                                                        # JSON ì§ë ¬í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
                                                                        if DEBUG_STREAM:
                                                                            logger.warning(f"í† í° JSON ì§ë ¬í™” ì‹¤íŒ¨: {json_error}, token={repr(token[:50])}")
                                                                        continue
                                                            # full_answer ì—…ë°ì´íŠ¸
                                                            full_answer = full_answer_from_event
                                                            chunk = None  # ì´ë¯¸ í† í° ë‹¨ìœ„ë¡œ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                        else:
                                                            # ì´ë¯¸ ë°›ì€ ë‚´ìš©ì´ë©´ ìŠ¤í‚µ
                                                            chunk = None
                                                # chain_outputì´ ë¬¸ìì—´ì¸ ê²½ìš°
                                                elif isinstance(chain_output, str):
                                                    # ì´ì „ì— ë°›ì€ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                                                    if len(chain_output) > len(full_answer):
                                                        new_part = chain_output[len(full_answer):]
                                                        
                                                        # í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                        # ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                        tokens = re.findall(r'\S+|\s+', new_part)
                                                        for token in tokens:
                                                            # ì¤„ë°”ê¿ˆì„ í¬í•¨í•œ ëª¨ë“  í† í° ì „ì†¡
                                                            if token:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ì „ì†¡ (ì¤„ë°”ê¿ˆ í¬í•¨)
                                                                # type: "stream"ìœ¼ë¡œ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                                stream_event = {
                                                                    "type": "stream",
                                                                    "content": token,
                                                                    "timestamp": datetime.now().isoformat()
                                                                }
                                                                yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                                full_answer += token
                                                                tokens_received += 1
                                                                answer_found = True
                                                                if DEBUG_STREAM:
                                                                    logger.debug(f"on_chain_stream: í† í° ì „ì†¡ ({len(token)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                        # full_answer ì—…ë°ì´íŠ¸
                                                        full_answer = chain_output
                                                        chunk = None  # ì´ë¯¸ í† í° ë‹¨ìœ„ë¡œ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                    else:
                                                        chunk = None
                                                # chain_outputì´ ê°ì²´ì¸ ê²½ìš° content ì†ì„± í™•ì¸
                                                elif hasattr(chain_output, "content"):
                                                    content = chain_output.content
                                                    if isinstance(content, str):
                                                        if len(content) > len(full_answer):
                                                            new_part = content[len(full_answer):]
                                                            
                                                            # í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                            # ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                            tokens = re.findall(r'\S+|\s+', new_part)
                                                            for token in tokens:
                                                                if token:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì „ì†¡
                                                                    # type: "stream"ìœ¼ë¡œ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                                    stream_event = {
                                                                        "type": "stream",
                                                                        "content": token,
                                                                        "timestamp": datetime.now().isoformat()
                                                                    }
                                                                    yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                                    full_answer += token
                                                                    tokens_received += 1
                                                                    answer_found = True
                                                                    if DEBUG_STREAM:
                                                                        logger.debug(f"on_chain_stream: í† í° ì „ì†¡ ({len(token)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                            # full_answer ì—…ë°ì´íŠ¸
                                                            full_answer = content
                                                            chunk = None  # ì´ë¯¸ í† í° ë‹¨ìœ„ë¡œ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                        else:
                                                            chunk = None
                                                    elif isinstance(content, dict):
                                                        answer_text = content.get("answer", "") or content.get("content", "")
                                                        if answer_text and isinstance(answer_text, str):
                                                            if len(answer_text) > len(full_answer):
                                                                new_part = answer_text[len(full_answer):]
                                                                
                                                                # í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                                # ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                                tokens = re.findall(r'\S+|\s+', new_part)
                                                                for token in tokens:
                                                                    if token:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì „ì†¡
                                                                        # type: "stream"ìœ¼ë¡œ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                                        stream_event = {
                                                                            "type": "stream",
                                                                            "content": token,
                                                                            "timestamp": datetime.now().isoformat()
                                                                        }
                                                                        yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                                        full_answer += token
                                                                        tokens_received += 1
                                                                        answer_found = True
                                                                        if DEBUG_STREAM:
                                                                            logger.debug(f"on_chain_stream: í† í° ì „ì†¡ ({len(token)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                                # full_answer ì—…ë°ì´íŠ¸
                                                                full_answer = answer_text
                                                                chunk = None  # ì´ë¯¸ í† í° ë‹¨ìœ„ë¡œ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                            else:
                                                                chunk = None
                                                        else:
                                                            chunk = None
                                                    else:
                                                        chunk = None
                                            
                                            # 2. chunk ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²½ë¡œ ì¶”ê°€
                                            if not chunk:
                                                # ëŒ€ì²´ ê²½ë¡œ 1: event_dataì—ì„œ ì§ì ‘ ì¶”ì¶œ
                                                text_content = event_data.get("text") or event_data.get("content")
                                                if text_content and isinstance(text_content, str):
                                                    if len(text_content) > len(full_answer):
                                                        new_part = text_content[len(full_answer):]
                                                        
                                                        # í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                        # ê³µë°±ê³¼ êµ¬ë‘ì ì„ ê¸°ì¤€ìœ¼ë¡œ í† í° ë¶„í• 
                                                        tokens = re.findall(r'\S+|\s+', new_part)
                                                        for token in tokens:
                                                            # ì¤„ë°”ê¿ˆì„ í¬í•¨í•œ ëª¨ë“  í† í° ì „ì†¡
                                                            if token:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ì „ì†¡ (ì¤„ë°”ê¿ˆ í¬í•¨)
                                                                # type: "stream"ìœ¼ë¡œ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•´ ê°œë³„ ì „ì†¡)
                                                                stream_event = {
                                                                    "type": "stream",
                                                                    "content": token,
                                                                    "timestamp": datetime.now().isoformat()
                                                                }
                                                                yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                                full_answer += token
                                                                tokens_received += 1
                                                                answer_found = True
                                                                if DEBUG_STREAM:
                                                                    logger.debug(f"on_chain_stream: ëŒ€ì²´ ê²½ë¡œì—ì„œ í† í° ì „ì†¡ ({len(token)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                        # full_answer ì—…ë°ì´íŠ¸
                                                        full_answer = text_content
                                                        chunk = None  # ì´ë¯¸ í† í° ë‹¨ìœ„ë¡œ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                
                                                # ëŒ€ì²´ ê²½ë¡œ 2: event ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì¶”ì¶œ
                                                if not chunk:
                                                    top_level_content = event.get("chunk") or event.get("output") or event.get("text") or event.get("content")
                                                    if top_level_content and isinstance(top_level_content, str):
                                                        if len(top_level_content) > len(full_answer):
                                                            new_part = top_level_content[len(full_answer):]
                                                            
                                                            # 3. ì „ì²´ ë‹µë³€ì´ í¬í•¨ëœ ê²½ìš° ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì „ì†¡
                                                            if len(new_part) > 200:  # 200ì ì´ìƒì´ë©´ ë¶„í• 
                                                                chunk_size = 100  # 100ìì”© ë¶„í• 
                                                                for i in range(0, len(new_part), chunk_size):
                                                                    chunk = new_part[i:i + chunk_size]
                                                                    if chunk:
                                                                        # type: "stream"ìœ¼ë¡œ ì „ì†¡
                                                                        stream_event = {
                                                                            "type": "stream",
                                                                            "content": chunk,
                                                                            "timestamp": datetime.now().isoformat()
                                                                        }
                                                                        yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                                        full_answer += chunk
                                                                        tokens_received += 1
                                                                        answer_found = True
                                                                        if DEBUG_STREAM:
                                                                            logger.debug(f"on_chain_stream: ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ë¶„í•  ì²­í¬ ì „ì†¡ ({len(chunk)}ì, ëˆ„ì  {len(full_answer)}ì)")
                                                                chunk = None  # ì´ë¯¸ ì „ì†¡í–ˆìœ¼ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                                                            else:
                                                                # ì‘ì€ ì²­í¬ëŠ” ê·¸ëŒ€ë¡œ ì „ì†¡
                                                                chunk = new_part
                                                                # full_answer ì—…ë°ì´íŠ¸ëŠ” ì•„ë˜ì—ì„œ ì²˜ë¦¬
                                                                full_answer = top_level_content
                                                
                                                # ëŒ€ì²´ ê²½ë¡œ 3: ë¡œê¹… ë° ê²½ê³ 
                                                if not chunk and DEBUG_STREAM:
                                                    logger.warning(f"on_chain_stream: chunk ì¶”ì¶œ ì‹¤íŒ¨ - event_data keys: {list(event_data.keys()) if isinstance(event_data, dict) else 'N/A'}, event keys: {list(event.keys())[:10]}")
                                        else:
                                            # event_dataê°€ dictê°€ ì•„ë‹Œ ê²½ìš°
                                            if DEBUG_STREAM:
                                                logger.warning(f"on_chain_stream: event_dataê°€ dictê°€ ì•„ë‹˜ - type={type(event_data)}, value={str(event_data)[:200]}")
                                    except Exception as chain_stream_error:
                                        # on_chain_stream ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê¹…í•˜ê³  ê³„ì† ì§„í–‰
                                        logger.error(f"on_chain_stream ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {chain_stream_error}", exc_info=True)
                                        if DEBUG_STREAM:
                                            logger.debug(f"on_chain_stream ì˜¤ë¥˜ ìƒì„¸: event_data={str(event_data)[:200] if event_data else 'None'}, event keys={list(event.keys())[:10] if isinstance(event, dict) else 'N/A'}")
                                        chunk = None
                                
                                # ê²½ìš° 1: LangChain í‘œì¤€ í˜•ì‹ - data.chunk.content
                                if not chunk and isinstance(event_data, dict):
                                    chunk_obj = event_data.get("chunk")
                                    if chunk_obj is not None:
                                        # AIMessageChunk ê°ì²´ ì²˜ë¦¬
                                        if hasattr(chunk_obj, "content"):
                                            content = chunk_obj.content
                                            # contentê°€ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                            if isinstance(content, str):
                                                chunk = content
                                            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (AIMessageChunkì˜ contentëŠ” ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ)
                                            elif isinstance(content, list) and len(content) > 0:
                                                # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë¬¸ìì—´ì´ë©´ ì‚¬ìš©
                                                if isinstance(content[0], str):
                                                    chunk = content[0]
                                                else:
                                                    chunk = str(content[0])
                                            else:
                                                chunk = str(content)
                                        elif isinstance(chunk_obj, str):
                                            chunk = chunk_obj
                                        elif hasattr(chunk_obj, "text"):
                                            chunk = chunk_obj.text
                                        # AIMessageChunk ê°ì²´ì˜ ê²½ìš° ì§ì ‘ content ì ‘ê·¼ ì‹œë„
                                        elif hasattr(chunk_obj, "__class__") and "AIMessageChunk" in str(type(chunk_obj)):
                                            try:
                                                content = getattr(chunk_obj, "content", None)
                                                if isinstance(content, str):
                                                    chunk = content
                                                elif isinstance(content, list) and len(content) > 0:
                                                    if isinstance(content[0], str):
                                                        chunk = content[0]
                                                    else:
                                                        chunk = str(content[0])
                                                elif content is not None:
                                                    chunk = str(content)
                                            except Exception:
                                                pass
                                    
                                    # ê²½ìš° 2: ì§ì ‘ ë¬¸ìì—´ í˜•ì‹
                                    if not chunk:
                                        chunk = event_data.get("text") or event_data.get("content")
                                    
                                    # ê²½ìš° 3: delta í˜•ì‹ (LangGraph v2)
                                    if not chunk and "delta" in event_data:
                                        delta = event_data["delta"]
                                        if isinstance(delta, dict):
                                            chunk = delta.get("content") or delta.get("text")
                                        elif isinstance(delta, str):
                                            chunk = delta
                                
                                # ê²½ìš° 4: ì´ë²¤íŠ¸ ìµœìƒìœ„ ë ˆë²¨ì— ì§ì ‘ í¬í•¨
                                if not chunk:
                                    chunk = event.get("chunk") or event.get("text") or event.get("content")
                                
                                # í† í°ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì „ì†¡
                                if chunk and isinstance(chunk, str):
                                    # JSON í˜•ì‹ ì¶œë ¥ ê°ì§€ ë° í•„í„°ë§ (ì¤‘ê°„ ë…¸ë“œì˜ JSON ì¶œë ¥ ì œê±°)
                                    chunk_stripped = chunk.strip()
                                    
                                    # ì´ì „ì— JSON ì¶œë ¥ì´ ê°ì§€ë˜ì—ˆìœ¼ë©´ ê³„ì† ë¬´ì‹œ
                                    if json_output_detected:
                                        if DEBUG_STREAM:
                                            logger.debug(f"ì´ì „ì— JSON ì¶œë ¥ì´ ê°ì§€ë˜ì–´ ê³„ì† ë¬´ì‹œ: {chunk_stripped[:50]}...")
                                        continue
                                    
                                    # JSON í˜•ì‹ ì‹œì‘ íŒ¨í„´ ê°ì§€
                                    is_json_output = False
                                    
                                    # ë°©ë²• 1: ì²­í¬ ì‹œì‘ ë¶€ë¶„ì´ JSON í˜•ì‹ì¸ì§€ í™•ì¸ (ê°€ì¥ ê°•ë ¥í•œ í•„í„°)
                                    # {ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì²­í¬ëŠ” JSONìœ¼ë¡œ ê°„ì£¼
                                    if chunk_stripped.startswith("{") or chunk.startswith("{"):
                                        is_json_output = True
                                        json_output_detected = True
                                    elif chunk_stripped.startswith("```json") or chunk.startswith("```json"):
                                        is_json_output = True
                                        json_output_detected = True
                                    elif chunk_stripped.startswith("```") and "json" in chunk_stripped[:20].lower():
                                        is_json_output = True
                                        json_output_detected = True
                                    # ```ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°ë„ JSONì¼ ê°€ëŠ¥ì„± ë†’ìŒ (ì½”ë“œ ë¸”ë¡)
                                    elif chunk_stripped.startswith("```") or chunk.startswith("```"):
                                        is_json_output = True
                                        json_output_detected = True
                                    # ì²­í¬ ìì²´ì— ```jsonì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ JSON
                                    elif "```json" in chunk or "``` json" in chunk:
                                        is_json_output = True
                                        json_output_detected = True
                                    
                                    # ë°©ë²• 2: ëˆ„ì ëœ ë‹µë³€ê³¼ í˜„ì¬ ì²­í¬ë¥¼ í•©ì³ì„œ JSON í˜•ì‹ì¸ì§€ í™•ì¸
                                    if not is_json_output:
                                        # full_answerê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ëˆ„ì  í…ìŠ¤íŠ¸ í™•ì¸
                                        if full_answer:
                                            combined_text = (full_answer + chunk).strip()
                                            # {ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” JSONìœ¼ë¡œ ê°„ì£¼
                                            if combined_text.startswith("{") or combined_text.startswith("```json"):
                                                is_json_output = True
                                                json_output_detected = True
                                            elif combined_text.startswith("```") and "json" in combined_text[:20].lower():
                                                is_json_output = True
                                                json_output_detected = True
                                            elif combined_text.startswith("```"):
                                                is_json_output = True
                                                json_output_detected = True
                                            elif "```json" in combined_text or "``` json" in combined_text:
                                                is_json_output = True
                                                json_output_detected = True
                                        # full_answerê°€ ë¹„ì–´ìˆê³  í˜„ì¬ ì²­í¬ê°€ { ë˜ëŠ” ```ë¡œ ì‹œì‘í•˜ë©´ JSON
                                        elif chunk_stripped.startswith("{") or chunk.startswith("{") or chunk_stripped.startswith("```") or chunk.startswith("```"):
                                            is_json_output = True
                                            json_output_detected = True
                                    
                                    # ë°©ë²• 3: JSON í‚¤ì›Œë“œ íŒ¨í„´ ê°ì§€ (ì¤‘ê°„ ë…¸ë“œì˜ JSON ì¶œë ¥ íŠ¹ì§•)
                                    if not is_json_output:
                                        json_keywords = ['"complexity"', '"confidence"', '"reasoning"', '"core_keywords"', 
                                                         '"query_intent"', '"is_valid"', '"quality_score"', '"final_score"',
                                                         '"score"', '"issues"', '"strengths"', '"recommendations"',
                                                         '"needs_improvement"', '"improvement_instructions"', '"preserve_content"',
                                                         '"focus_areas"', '"meets_quality_threshold"', '"summary"']
                                        # ì²­í¬ ìì²´ì— í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, ëˆ„ì  í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                                        if any(keyword in chunk for keyword in json_keywords):
                                            is_json_output = True
                                            json_output_detected = True
                                        elif full_answer:
                                            combined_text = full_answer + chunk
                                            if any(keyword in combined_text for keyword in json_keywords):
                                                is_json_output = True
                                                json_output_detected = True
                                    
                                    # ë°©ë²• 4: JSON êµ¬ì¡° íŒ¨í„´ ê°ì§€ (í°ë”°ì˜´í‘œë¡œ ì‹œì‘í•˜ëŠ” í‚¤-ê°’ ìŒ)
                                    if not is_json_output:
                                        # "key": í˜•íƒœì˜ íŒ¨í„´ì´ ìˆìœ¼ë©´ JSONì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                                        # re ëª¨ë“ˆì€ íŒŒì¼ ìƒë‹¨ì—ì„œ importë¨
                                        json_pattern = r'^\s*"[^"]+"\s*:\s*'
                                        if re.match(json_pattern, chunk_stripped) or re.match(json_pattern, chunk):
                                            is_json_output = True
                                            json_output_detected = True
                                    
                                    # JSON í˜•ì‹ì´ë©´ ë¬´ì‹œ (ì¤‘ê°„ ë…¸ë“œì˜ JSON ì¶œë ¥)
                                    if is_json_output:
                                        if DEBUG_STREAM:
                                            logger.debug(f"JSON í˜•ì‹ ì¶œë ¥ ê°ì§€ ë° ë¬´ì‹œ: {chunk_stripped[:100]}...")
                                        # JSON ì¶œë ¥ì€ full_answerì— ëˆ„ì í•˜ì§€ ì•ŠìŒ
                                        continue
                                    
                                    # JSON ì¶œë ¥ì´ ì•„ë‹Œ ì‹¤ì œ ë‹µë³€ì´ ì‹œì‘ë˜ë©´ JSON ì¶œë ¥ í”Œë˜ê·¸ ë¦¬ì…‹
                                    if not is_json_output and json_output_detected and len(chunk_stripped) > 0:
                                        # ì‹¤ì œ ë‹µë³€ì´ ì‹œì‘ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (JSONì´ ì•„ë‹Œ í…ìŠ¤íŠ¸)
                                        if not any(keyword in chunk for keyword in ['"complexity"', '"confidence"', '"reasoning"']):
                                            json_output_detected = False
                                            if DEBUG_STREAM:
                                                logger.debug("ì‹¤ì œ ë‹µë³€ì´ ì‹œì‘ë˜ì–´ JSON ì¶œë ¥ í”Œë˜ê·¸ ë¦¬ì…‹")
                                    
                                    # ê³µë°± í† í°ë„ í¬í•¨ (ì‹¤ì œ í† í° ìŠ¤íŠ¸ë¦¬ë°)
                                    # ë‹¨, ì™„ì „íˆ ë¹ˆ ë¬¸ìì—´ì€ ì œì™¸
                                    if len(chunk) > 0:
                                        full_answer += chunk
                                        tokens_received += 1
                                        answer_found = True
                                        # ìŠ¤íŠ¸ë¦¼ ì²­í¬ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                        stream_event = {
                                            "type": "stream",
                                            "content": chunk,
                                            "timestamp": datetime.now().isoformat()
                                        }
                                        yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                        
                            except (AttributeError, TypeError, KeyError) as e:
                                # ì´ë²¤íŠ¸ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ê²½ìš° ë¡œê¹…ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
                                logger.debug(f"í† í° ì¶”ì¶œ ì‹¤íŒ¨ (ì´ë²¤íŠ¸ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„): {e}, event_keys={list(event.keys()) if isinstance(event, dict) else 'N/A'}")
                                # ë””ë²„ê¹…: ì´ë²¤íŠ¸ êµ¬ì¡° ìƒì„¸ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
                                if llm_stream_count <= 3:
                                    logger.debug(f"ì´ë²¤íŠ¸ êµ¬ì¡° ìƒì„¸: event_data={event_data}, event_data type={type(event_data)}")
                                    if isinstance(event_data, dict):
                                        logger.debug(f"event_data keys: {list(event_data.keys())}")
                                continue
                    
                    # LLM ì™„ë£Œ ì´ë²¤íŠ¸ (on_llm_end ë˜ëŠ” on_chat_model_end)
                    elif event_type in ["on_llm_end", "on_chat_model_end"]:
                        # ìµœì¢… ë‹µë³€ í™•ì¸ (ëˆ„ë½ëœ ë¶€ë¶„ì´ ìˆëŠ”ì§€ ì²´í¬)
                        try:
                            event_data = event.get("data", {})
                            if isinstance(event_data, dict):
                                output = event_data.get("output")
                                if output is not None:
                                    final_answer = None
                                    
                                    # ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì§€ì›
                                    if hasattr(output, "content"):
                                        final_answer = output.content
                                    elif isinstance(output, str):
                                        final_answer = output
                                    elif isinstance(output, dict):
                                        final_answer = output.get("content") or output.get("text") or str(output)
                                    else:
                                        final_answer = str(output)
                                    
                                    # ëˆ„ë½ëœ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì „ì†¡ (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì¼ë¶€ í† í°ì´ ëˆ„ë½ëœ ê²½ìš°)
                                    if final_answer and isinstance(final_answer, str):
                                        if len(final_answer) > len(full_answer):
                                            missing_part = final_answer[len(full_answer):]
                                            if missing_part:
                                                full_answer = final_answer
                                                # ìŠ¤íŠ¸ë¦¼ ì²­í¬ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                                stream_event = {
                                                    "type": "stream",
                                                    "content": missing_part,
                                                    "timestamp": datetime.now().isoformat()
                                                }
                                                yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                logger.debug(f"ëˆ„ë½ëœ ë¶€ë¶„ ì „ì†¡: {len(missing_part)}ì")
                        except (AttributeError, TypeError, KeyError) as e:
                            logger.debug(f"on_llm_end ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            pass
                    
                    # ë…¸ë“œ ì‹¤í–‰ ì´ë²¤íŠ¸ (ì§„í–‰ ìƒí™© í‘œì‹œ)
                    elif event_type == "on_chain_start":
                        node_name = event.get("name", "")
                        
                        # ì£¼ìš” ë…¸ë“œì˜ ì§„í–‰ ìƒí™© í‘œì‹œ
                        if node_name in node_name_mapping:
                            if node_name not in executed_nodes:
                                progress_message = node_name_mapping.get(node_name, f"[{node_name} ì‹¤í–‰ ì¤‘...]")
                                # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                step_number = len(executed_nodes) + 1
                                progress_event = {
                                    "type": "progress",
                                    "step": step_number,
                                    "message": progress_message,
                                    "node_name": node_name,
                                    "timestamp": datetime.now().isoformat()
                                }
                                yield json.dumps(progress_event, ensure_ascii=False) + "\n"
                                executed_nodes.add(node_name)
                                if DEBUG_STREAM:
                                    logger.debug(f"ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì „ì†¡: {progress_message}")
                        
                        # ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘ ì‹œ í”Œë˜ê·¸ ì„¤ì •
                        if node_name in ["generate_answer_enhanced", "generate_and_validate_answer"]:
                            answer_generation_started = True
                            json_output_detected = False  # ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘ ì‹œ JSON ì¶œë ¥ í”Œë˜ê·¸ ë¦¬ì…‹
                            if not answer_found:
                                # ë‹µë³€ ìƒì„± ì‹œì‘ì„ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                step_number = len(executed_nodes) + 1
                                progress_event = {
                                    "type": "progress",
                                    "step": step_number,
                                    "message": "ë‹µë³€ ìƒì„± ì¤‘...",
                                    "node_name": node_name,
                                    "timestamp": datetime.now().isoformat()
                                }
                                yield json.dumps(progress_event, ensure_ascii=False) + "\n"
                                last_node_name = node_name
                                if DEBUG_STREAM:
                                    logger.debug(f"ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘: {node_name}, answer_generation_started=True, json_output_detected=False")
                    
                    # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸ (generate_and_validate_answer ë…¸ë“œì˜ answer í•„ë“œë§Œ í™•ì¸)
                    elif event_type == "on_chain_end":
                        node_name = event.get("name", "")
                        if node_name == "generate_and_validate_answer":
                            # ë‹µë³€ ìƒì„± ë…¸ë“œê°€ ì™„ë£Œë˜ë©´ í”Œë˜ê·¸ í•´ì œ
                            answer_generation_started = False
                            if DEBUG_STREAM:
                                logger.debug(f"ë‹µë³€ ìƒì„± ë…¸ë“œ ì™„ë£Œ: {node_name}, answer_generation_started=False")
                            
                            # generate_and_validate_answer ë…¸ë“œì˜ outputì—ì„œ answer í•„ë“œë§Œ ì¶”ì¶œ
                            try:
                                event_data = event.get("data", {})
                                if isinstance(event_data, dict):
                                    output = event_data.get("output")
                                    if output is not None:
                                        # answer í•„ë“œ ì¶”ì¶œ (ë‹¤ì–‘í•œ êµ¬ì¡° ì§€ì›)
                                        answer_text = None
                                        
                                        if isinstance(output, dict):
                                            # ìµœìƒìœ„ ë ˆë²¨
                                            answer_text = output.get("answer", "")
                                            
                                            # answer ê·¸ë£¹ (dictì¸ ê²½ìš°)
                                            if not answer_text and "answer" in output:
                                                answer_group = output.get("answer", {})
                                                if isinstance(answer_group, dict):
                                                    answer_text = answer_group.get("answer", "")
                                                elif isinstance(answer_group, str):
                                                    answer_text = answer_group
                                            
                                            # common ê·¸ë£¹
                                            if not answer_text and "common" in output:
                                                common = output.get("common", {})
                                                if isinstance(common, dict):
                                                    answer_text = common.get("answer", "")
                                        
                                        # answer í•„ë“œê°€ ìˆê³ , JSON í˜•ì‹ì´ ì•„ë‹ˆë©´ í™•ì¸
                                        if answer_text and isinstance(answer_text, str) and len(answer_text) > 0:
                                            # JSON í˜•ì‹ í•„í„°ë§
                                            answer_stripped = answer_text.strip()
                                            is_json_answer = (
                                                answer_stripped.startswith("{") or 
                                                answer_stripped.startswith("```json") or
                                                (answer_stripped.startswith("```") and "json" in answer_stripped[:20].lower())
                                            )
                                            
                                            if not is_json_answer:
                                                # ìŠ¤íŠ¸ë¦¬ë°ëœ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ë¶€ë¶„ë§Œ ì „ì†¡
                                                if len(answer_text) > len(full_answer):
                                                    missing_part = answer_text[len(full_answer):]
                                                    if missing_part:
                                                        if DEBUG_STREAM:
                                                            logger.debug(f"ëˆ„ë½ëœ ë¶€ë¶„ ì „ì†¡: {len(missing_part)}ì")
                                                        # ìŠ¤íŠ¸ë¦¼ ì²­í¬ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                                        stream_event = {
                                                            "type": "stream",
                                                            "content": missing_part,
                                                            "timestamp": datetime.now().isoformat()
                                                        }
                                                        yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                        full_answer = answer_text
                                                        answer_found = True
                                                elif not answer_found:
                                                    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ì—ˆë˜ ê²½ìš° ì „ì²´ ë‹µë³€ ì „ì†¡
                                                    if DEBUG_STREAM:
                                                        logger.debug(f"ì „ì²´ ë‹µë³€ ì „ì†¡ (ìŠ¤íŠ¸ë¦¬ë° ì—†ìŒ): {len(answer_text)}ì")
                                                    stream_event = {
                                                        "type": "stream",
                                                        "content": answer_text,
                                                        "timestamp": datetime.now().isoformat()
                                                    }
                                                    yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                                    full_answer = answer_text
                                                    answer_found = True
                                                else:
                                                    if DEBUG_STREAM:
                                                        logger.debug("ìŠ¤íŠ¸ë¦¬ë°ëœ ë‹µë³€ì´ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤.")
                                            else:
                                                if DEBUG_STREAM:
                                                    logger.debug("answer í•„ë“œê°€ JSON í˜•ì‹ì´ë¯€ë¡œ ë¬´ì‹œí•©ë‹ˆë‹¤.")
                                        else:
                                            if DEBUG_STREAM:
                                                logger.debug("answer í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                            except (AttributeError, TypeError, KeyError) as e:
                                if DEBUG_STREAM:
                                    logger.debug(f"on_chain_endì—ì„œ answer ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                            
                            if not answer_found:
                                # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ê°€ ì „í˜€ ë°œìƒí•˜ì§€ ì•Šì€ ê²½ìš°
                                if DEBUG_STREAM:
                                    logger.warning("ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                error_event = {
                                    "type": "final",
                                    "content": "[ì˜¤ë¥˜] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                                    "metadata": {"error": True},
                                    "timestamp": datetime.now().isoformat()
                                }
                                yield json.dumps(error_event, ensure_ascii=False) + "\n"
                                answer_found = True
                        elif node_name == "generate_answer_enhanced":
                            # generate_answer_enhanced ë…¸ë“œëŠ” generate_and_validate_answer ë‚´ë¶€ì—ì„œ í˜¸ì¶œë˜ë¯€ë¡œ
                            # ì—¬ê¸°ì„œëŠ” í”Œë˜ê·¸ë§Œ í™•ì¸í•˜ê³  answerëŠ” generate_and_validate_answerì—ì„œ ì²˜ë¦¬
                            if DEBUG_STREAM:
                                logger.debug(f"generate_answer_enhanced ë…¸ë“œ ì™„ë£Œ: {node_name}")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… í™•ì¸ (DEBUG_STREAMì´ trueì¼ ë•Œë§Œ)
                if DEBUG_STREAM:
                    logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: ì´ {event_count}ê°œ ì´ë²¤íŠ¸, LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ {llm_stream_count}ê°œ, í† í° ìˆ˜ì‹  {tokens_received}ê°œ")
                    logger.info(f"ë°œìƒí•œ ì´ë²¤íŠ¸ íƒ€ì…: {sorted(event_types_seen)}")
                    logger.info(f"ë°œìƒí•œ ë…¸ë“œ ì´ë¦„ (ë‹µë³€ ìƒì„± ê´€ë ¨): {[n for n in sorted(node_names_seen) if 'answer' in n.lower() or 'generate' in n.lower()]}")
                
                # ë””ë²„ê¹…: ë°œìƒí•œ ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…ê³¼ ë…¸ë“œ ì´ë¦„ ë¡œê¹… (DEBUG_STREAMì´ trueì¼ ë•Œë§Œ)
                if llm_stream_count == 0:
                    if DEBUG_STREAM:
                        logger.warning("âš ï¸ LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        logger.debug(f"ë°œìƒí•œ ëª¨ë“  ì´ë²¤íŠ¸ íƒ€ì…: {sorted(event_types_seen)}")
                        logger.debug(f"ë°œìƒí•œ ëª¨ë“  ë…¸ë“œ ì´ë¦„: {sorted(node_names_seen)}")
                    # ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    answer_nodes_executed = [n for n in sorted(node_names_seen) if 'answer' in n.lower() or 'generate' in n.lower()]
                    if answer_nodes_executed:
                        if DEBUG_STREAM:
                            logger.info(f"ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œ ì‹¤í–‰ë¨: {answer_nodes_executed}")
                    else:
                        if DEBUG_STREAM:
                            logger.warning("ë‹µë³€ ìƒì„± ê´€ë ¨ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                if not answer_found:
                    # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ì—ì„œ ë‹µë³€ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                    # process_messageë¥¼ í˜¸ì¶œí•˜ë©´ ì¤‘ë³µ ì‹¤í–‰ì´ë¯€ë¡œ, ìµœì¢… ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ëŠ” ë°©ë²• ì‚¬ìš©
                    if DEBUG_STREAM:
                        logger.warning(f"LLM ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ì—ì„œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì´ë²¤íŠ¸ ìˆ˜: {event_count}, LLM ìŠ¤íŠ¸ë¦¬ë°: {llm_stream_count})")
                        logger.info("ìµœì¢… ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
                    # ìµœì¢… ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
                    try:
                        result = await self.process_message(message, session_id)
                        final_answer = result.get("answer", "")
                        if final_answer and len(final_answer) > len(full_answer):
                            # ëˆ„ë½ëœ ë¶€ë¶„ë§Œ ì „ì†¡
                            missing_part = final_answer[len(full_answer):]
                            if missing_part:
                                full_answer = final_answer
                                # ìŠ¤íŠ¸ë¦¼ ì²­í¬ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                stream_event = {
                                    "type": "stream",
                                    "content": missing_part,
                                    "timestamp": datetime.now().isoformat()
                                }
                                yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                answer_found = True
                                if DEBUG_STREAM:
                                    logger.info(f"ìµœì¢… ë‹µë³€ì—ì„œ ëˆ„ë½ëœ ë¶€ë¶„ ì „ì†¡: {len(missing_part)}ì")
                        elif final_answer:
                            # ì „ì²´ ë‹µë³€ ì „ì†¡ (full_answerê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°)
                            full_answer = final_answer
                            stream_event = {
                                "type": "stream",
                                "content": final_answer,
                                "timestamp": datetime.now().isoformat()
                            }
                            yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                            answer_found = True
                            if DEBUG_STREAM:
                                logger.info(f"ì „ì²´ ë‹µë³€ ì „ì†¡: {len(final_answer)}ì")
                    except Exception as e:
                        if DEBUG_STREAM:
                            logger.error(f"ìµœì¢… ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}", exc_info=True)
                        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ìµœì†Œí•œ ì—ëŸ¬ ë©”ì‹œì§€ yield (ìŠ¤íŠ¸ë¦¼ì´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡)
                        if not answer_found:
                            error_event = {
                                "type": "final",
                                "content": f"[ì˜¤ë¥˜] ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}",
                                "metadata": {"error": True},
                                "timestamp": datetime.now().isoformat()
                            }
                            yield json.dumps(error_event, ensure_ascii=False) + "\n"
                            answer_found = True
            
            except Exception as stream_error:
                # astream_events ì‹¤íŒ¨ ì‹œ astreamìœ¼ë¡œ í´ë°±
                if DEBUG_STREAM:
                    logger.warning(f"astream_events ì‹¤íŒ¨, astreamìœ¼ë¡œ í´ë°±: {stream_error}")
                # stream_mode="updates" ì‚¬ìš© ì‹œ ë³€ê²½ëœ í•„ë“œë§Œ í¬í•¨ë˜ë¯€ë¡œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥
                async for event in self.workflow_service.app.astream(initial_state, config, stream_mode="updates"):
                    for node_name, node_state in event.items():
                        if isinstance(node_state, dict):
                            answer = None
                            # answer ê·¸ë£¹ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                            if "answer" in node_state:
                                answer = node_state.get("answer", "")
                            # common ê·¸ë£¹ì—ì„œ answer í™•ì¸ (ë³€ê²½ëœ ê²½ìš°ì—ë§Œ í¬í•¨)
                            elif "common" in node_state and isinstance(node_state["common"], dict):
                                common = node_state["common"]
                                if "answer" in common:
                                    answer = common.get("answer", "")
                            
                            if answer and isinstance(answer, str) and len(answer) > len(full_answer):
                                new_part = answer[len(full_answer):]
                                if new_part:
                                    full_answer = answer
                                    # ìŠ¤íŠ¸ë¦¼ ì²­í¬ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                                    stream_event = {
                                        "type": "stream",
                                        "content": new_part,
                                        "timestamp": datetime.now().isoformat()
                                    }
                                    yield json.dumps(stream_event, ensure_ascii=False) + "\n"
                                    answer_found = True
            
            # ì™„ë£Œ ë©”íƒ€ë°ì´í„° (ë‹µë³€ì´ ì—†ì–´ë„ ì™„ë£Œ ì‹ í˜¸ ì „ì†¡)
            if full_answer:
                if DEBUG_STREAM:
                    logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {len(full_answer)}ì, {tokens_received}ê°œ í† í° ìˆ˜ì‹ ")
                has_yielded = True
                # ìµœì¢… ì™„ë£Œ ì´ë²¤íŠ¸ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
                final_event = {
                    "type": "final",
                    "content": full_answer,
                    "metadata": {
                        "tokens_received": tokens_received,
                        "length": len(full_answer),
                        "answer_found": answer_found
                    },
                    "timestamp": datetime.now().isoformat()
                }
                yield json.dumps(final_event, ensure_ascii=False) + "\n"
            else:
                if DEBUG_STREAM:
                    logger.warning("ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                # ë‹µë³€ì´ ì—†ì–´ë„ ìµœì†Œí•œ ë¹ˆ ì‘ë‹µì„ yieldí•˜ì—¬ ìŠ¤íŠ¸ë¦¼ì´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡ ë³´ì¥
                if not answer_found:
                    error_event = {
                        "type": "final",
                        "content": "[ì˜¤ë¥˜] ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "metadata": {
                            "error": True,
                            "tokens_received": tokens_received
                        },
                        "timestamp": datetime.now().isoformat()
                    }
                    yield json.dumps(error_event, ensure_ascii=False) + "\n"
                    has_yielded = True
            
        except Exception as e:
            logger.error(f"Error in stream_message: {e}", exc_info=True)
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì „ì†¡
            try:
                error_event = {
                    "type": "final",
                    "content": f"[ì˜¤ë¥˜] ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "metadata": {
                        "error": True,
                        "error_type": type(e).__name__
                    },
                    "timestamp": datetime.now().isoformat()
                }
                yield json.dumps(error_event, ensure_ascii=False) + "\n"
                has_yielded = True
            except Exception as yield_error:
                logger.error(f"Error yielding error message: {yield_error}")
                # yield ìì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ìµœì†Œí•œ ë¹ˆ ë¬¸ìì—´ì´ë¼ë„ yield ì‹œë„
                try:
                    fallback_event = {
                        "type": "final",
                        "content": "[ì˜¤ë¥˜] ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                        "metadata": {"error": True},
                        "timestamp": datetime.now().isoformat()
                    }
                    yield json.dumps(fallback_event, ensure_ascii=False) + "\n"
                    # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ ì¶”ê°€ ë¹ˆ ì¤„ yield
                    yield "\n"
                    has_yielded = True
                except Exception:
                    pass
            finally:
                # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ìŠ¤íŠ¸ë¦¼ì´ ì œëŒ€ë¡œ ì¢…ë£Œë˜ë„ë¡ ë³´ì¥
                # (ì´ë¯¸ ìœ„ì—ì„œ yieldí–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”)
                # í•˜ì§€ë§Œ ìŠ¤íŠ¸ë¦¼ì´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡ ë³´ì¥
                if not has_yielded:
                    try:
                        fallback_event = {
                            "type": "final",
                            "content": "[ì˜¤ë¥˜] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                            "metadata": {"error": True},
                            "timestamp": datetime.now().isoformat()
                        }
                        yield json.dumps(fallback_event, ensure_ascii=False) + "\n"
                        has_yielded = True
                    except Exception as e:
                        logger.error(f"Error yielding fallback message in finally: {e}")
                
                # HTTP chunked encodingì´ ì œëŒ€ë¡œ ì¢…ë£Œë˜ë„ë¡ ë³´ì¥
                # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹ í˜¸: ë¹ˆ ì¤„ 2ê°œ yield
                # ì´ëŠ” ERR_INCOMPLETE_CHUNKED_ENCODING ì˜¤ë¥˜ë¥¼ ë°©ì§€
                try:
                    yield "\n\n"  # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹ í˜¸ (ë¹ˆ ì¤„ 2ê°œ)
                except Exception:
                    pass
        
        # ìµœì†Œí•œ í•˜ë‚˜ì˜ yieldê°€ ì—†ì—ˆìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì „ì†¡ (ìŠ¤íŠ¸ë¦¼ì´ ë¹„ì–´ìˆì§€ ì•Šë„ë¡ ë³´ì¥)
        # (finally ë¸”ë¡ì—ì„œ ì´ë¯¸ ì²˜ë¦¬í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€)
        if not has_yielded:
            try:
                fallback_event = {
                    "type": "final",
                    "content": "[ì˜¤ë¥˜] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "metadata": {"error": True},
                    "timestamp": datetime.now().isoformat()
                }
                yield json.dumps(fallback_event, ensure_ascii=False) + "\n"
            except Exception as e:
                logger.error(f"Error yielding fallback message: {e}")
    
    def is_available(self) -> bool:
        """ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.workflow_service is not None


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì§€ì—° ì´ˆê¸°í™”)
chat_service: Optional[ChatService] = None

def get_chat_service() -> ChatService:
    """ChatService ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global chat_service
    if chat_service is None:
        try:
            logger.info("Initializing ChatService...")
            chat_service = ChatService()
            if chat_service.is_available():
                logger.info("âœ… ChatService initialized successfully with workflow service")
            else:
                logger.warning("âš ï¸  ChatService initialized but workflow service is not available")
                logger.warning("   Check API server logs for initialization errors")
        except Exception as e:
            logger.error(f"Failed to initialize ChatService: {e}", exc_info=True)
            import traceback
            tb = traceback.format_exc()
            logger.error(f"Traceback:\n{tb}")
            # ì‹¤íŒ¨í•´ë„ ChatService ì¸ìŠ¤í„´ìŠ¤ëŠ” ìƒì„± (workflow_serviceê°€ Noneì¼ ìˆ˜ ìˆìŒ)
            chat_service = ChatService()
    return chat_service

# ëª¨ë“ˆ import ì‹œì ì—ëŠ” ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ (ì§€ì—° ì´ˆê¸°í™”)
# ì²« ìš”ì²­ ì‹œ get_chat_service()ë¥¼ í†µí•´ ì´ˆê¸°í™”
# ì´ë ‡ê²Œ í•˜ë©´ api/main.pyì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¨¼ì € ë¡œë“œí•œ í›„ ì´ˆê¸°í™” ê°€ëŠ¥
logger.info("ChatService module loaded. Will initialize on first request via get_chat_service().")

