# -*- coding: utf-8 -*-
"""
ì›Œí¬í”Œë¡œìš° ë¼ìš°íŒ… ëª¨ë“ˆ
LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë¡œì§ì„ ë…ë¦½ ëª¨ë“ˆë¡œ ë¶„ë¦¬
"""

import logging
from typing import Any, Dict, Optional

from core.agents.state_definitions import LegalWorkflowState
from core.agents.workflow_constants import (
    QualityThresholds,
    RetryConfig,
    WorkflowConstants,
)
from core.agents.workflow_utils import WorkflowUtils


class QueryComplexity:
    """ì§ˆë¬¸ ë³µì¡ë„ Enum ëŒ€ì²´ í´ë˜ìŠ¤"""
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    MULTI_HOP = "multi_hop"


class WorkflowRoutes:
    """
    ì›Œí¬í”Œë¡œìš° ë¼ìš°íŒ… í´ë˜ìŠ¤

    LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        retry_manager: Any,
        answer_generator: Any = None,
        ai_keyword_generator: Any = None,
        logger: Optional[logging.Logger] = None
    ):
        """
        WorkflowRoutes ì´ˆê¸°í™”

        Args:
            retry_manager: RetryCounterManager ì¸ìŠ¤í„´ìŠ¤
            answer_generator: AnswerGenerator ì¸ìŠ¤í„´ìŠ¤ (fallback ë‹µë³€ ìƒì„±ìš©)
            ai_keyword_generator: AIKeywordGenerator ì¸ìŠ¤í„´ìŠ¤ (í‚¤ì›Œë“œ í™•ì¥ìš©)
            logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        """
        self.retry_manager = retry_manager
        self.answer_generator = answer_generator
        self.ai_keyword_generator = ai_keyword_generator
        self.logger = logger or logging.getLogger(__name__)

    def route_by_complexity(self, state: LegalWorkflowState) -> str:
        """ë³µì¡ë„ì— ë”°ë¼ ë¼ìš°íŒ…"""
        # ë””ë²„ê¹…: state êµ¬ì¡° í™•ì¸
        state_keys = list(state.keys()) if isinstance(state, dict) else []
        print(f"[DEBUG] _route_by_complexity: state keys={state_keys[:15]}")
        print(f"[DEBUG] _route_by_complexity: state type={type(state).__name__}")

        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ complexity í™•ì¸ (ìš°ì„ ìˆœìœ„: ìµœìƒìœ„ > classification ê·¸ë£¹ > _get_state_value)
        complexity = None

        # 1. ìµœìƒìœ„ ë ˆë²¨ ì§ì ‘ í™•ì¸ (ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•¨)
        if isinstance(state, dict) and "query_complexity" in state:
            complexity = state["query_complexity"]
            print(f"[DEBUG] _route_by_complexity: [1] via top-level direct={complexity}")

        # 2. common ê·¸ë£¹ í™•ì¸ (reducerê°€ ë³´ì¡´í•˜ëŠ” ê·¸ë£¹)
        if not complexity and isinstance(state, dict) and "common" in state:
            if isinstance(state["common"], dict):
                complexity = state["common"].get("query_complexity")
                print(f"[DEBUG] _route_by_complexity: [2] via common group={complexity}")

        # 3. metadata í™•ì¸ (reducerê°€ ë³´ì¡´í•˜ëŠ” ê·¸ë£¹)
        if not complexity and isinstance(state, dict) and "metadata" in state:
            if isinstance(state["metadata"], dict):
                complexity = state["metadata"].get("query_complexity")
                print(f"[DEBUG] _route_by_complexity: [3] via metadata={complexity}")

        # 4. classification ê·¸ë£¹ í™•ì¸
        if not complexity and isinstance(state, dict) and "classification" in state:
            if isinstance(state["classification"], dict):
                complexity = state["classification"].get("query_complexity")
                print(f"[DEBUG] _route_by_complexity: [4] via classification group={complexity}")

        # 5. _get_state_value ì‚¬ìš© (ë§ˆì§€ë§‰ ì‹œë„)
        if not complexity:
            complexity = WorkflowUtils.get_state_value(state, "query_complexity", None)
            print(f"[DEBUG] _route_by_complexity: [5] via _get_state_value={complexity}")

        # ê¸°ë³¸ê°’ (ë¬¸ìì—´ë¡œ ì €ì¥ë¨)
        if not complexity:
            complexity = QueryComplexity.MODERATE
            print(f"[DEBUG] _route_by_complexity: [4] using default={complexity}")

        # Enumì¸ ê²½ìš° ê°’ìœ¼ë¡œ ë³€í™˜
        if hasattr(complexity, 'value'):
            complexity = complexity.value

        # ë””ë²„ê¹… ë¡œê·¸
        self.logger.info(f"ğŸ”€ [ROUTE] ë³µì¡ë„: {complexity}, ë¼ìš°íŒ… ê²°ì • ì¤‘...")
        print(f"[DEBUG] _route_by_complexity: FINAL complexity={complexity}")

        # ë¬¸ìì—´ ë¹„êµ (stateì— ì €ì¥ëœ ê°’ì€ ë¬¸ìì—´)
        if complexity == QueryComplexity.SIMPLE or complexity == "simple":
            self.logger.info(f"âœ… [ROUTE] ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ direct_answer")
            print(f"[DEBUG] _route_by_complexity: âœ… returning 'simple'")
            return "simple"
        elif complexity == QueryComplexity.MODERATE or complexity == "moderate":
            self.logger.info(f"ğŸ”„ [ROUTE] ì¤‘ê°„ ì§ˆë¬¸ â†’ classification_parallel")
            print(f"[DEBUG] _route_by_complexity: ğŸ”„ returning 'moderate'")
            return "moderate"
        else:
            self.logger.info(f"ğŸ”€ [ROUTE] ë³µì¡í•œ ì§ˆë¬¸ â†’ classification_parallel")
            print(f"[DEBUG] _route_by_complexity: ğŸ”€ returning 'complex'")
            return "complex"

    def route_expert(self, state: LegalWorkflowState) -> LegalWorkflowState:
        """ì „ë¬¸ê°€ ì„œë¸Œê·¸ë˜í”„ë¡œ ë¼ìš°íŒ…"""
        try:
            # ë³µì¡ë„ í‰ê°€
            complexity = self.assess_complexity(state)
            state["complexity_level"] = complexity

            # ì „ë¬¸ê°€ ë¼ìš°íŒ… í•„ìš” ì—¬ë¶€
            requires_expert = (
                complexity == "complex" and
                state.get("legal_field") in ["family", "corporate", "intellectual_property"]
            )
            state["requires_expert"] = requires_expert

            if requires_expert:
                # ì „ë¬¸ê°€ ì„œë¸Œê·¸ë˜í”„ ê²°ì •
                expert_map = {
                    "family": "family_law_expert",
                    "corporate": "corporate_law_expert",
                    "intellectual_property": "ip_law_expert"
                }
                state["expert_subgraph"] = expert_map.get(state.get("legal_field"))
                self.logger.info(f"Routing to expert: {state['expert_subgraph']}")
            else:
                state["expert_subgraph"] = None

            return state

        except Exception as e:
            self.logger.error(f"ì „ë¬¸ê°€ ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜: {e}")
            state["complexity_level"] = "simple"
            state["requires_expert"] = False
            state["expert_subgraph"] = None
            return state

    def assess_complexity(self, state: LegalWorkflowState) -> str:
        """ì§ˆë¬¸ ë³µì¡ë„ í‰ê°€"""
        # ë³µì¡ë„ ì§€í‘œë“¤
        query = WorkflowUtils.get_state_value(state, "query", "")
        extracted_keywords = WorkflowUtils.get_state_value(state, "extracted_keywords", [])
        indicators = {
            "query_length": len(query),
            "num_keywords": len(extracted_keywords),
            "has_document": bool(WorkflowUtils.get_state_value(state, "uploaded_document")),
            "high_urgency": state.get("urgency_level") in ["high", "critical"],
            "multiple_legal_issues": len(state.get("potential_issues", [])) > 2
        }

        complexity_score = 0

        # ì ìˆ˜ ê³„ì‚°
        if indicators["query_length"] > 200:
            complexity_score += 2
        if indicators["num_keywords"] > 10:
            complexity_score += 2
        if indicators["has_document"]:
            complexity_score += 3
        if indicators["high_urgency"]:
            complexity_score += 1
        if indicators["multiple_legal_issues"]:
            complexity_score += 2

        # ë³µì¡ë„ íŒì •
        if complexity_score >= 7:
            return "complex"
        elif complexity_score >= 4:
            return "medium"
        else:
            return "simple"

    def should_analyze_document(self, state: LegalWorkflowState) -> str:
        """ë¬¸ì„œ ë¶„ì„ í•„ìš” ì—¬ë¶€ ê²°ì •"""
        if state.get("uploaded_document"):
            return "analyze"
        return "skip"

    def should_skip_search(self, state: LegalWorkflowState) -> str:
        """ê²€ìƒ‰ ì‹¤í–‰ ê±´ë„ˆë›°ê¸° ì—¬ë¶€ ê²°ì • (ìºì‹œ íˆíŠ¸)"""
        cache_hit = WorkflowUtils.get_state_value(state, "search_cache_hit", False)
        if cache_hit:
            return "skip"
        return "continue"

    def should_skip_search_adaptive(self, state: LegalWorkflowState) -> str:
        """Adaptive RAG: ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ ìŠ¤í‚µ ê²°ì •"""
        # ìºì‹œ íˆíŠ¸ ì²´í¬ (ê¸°ì¡´ ë¡œì§)
        cache_hit = WorkflowUtils.get_state_value(state, "search_cache_hit", False)
        if cache_hit:
            return "skip"

        # ë³µì¡ë„ ê¸°ë°˜ ìŠ¤í‚µ ê²°ì •
        needs_search = WorkflowUtils.get_state_value(state, "needs_search", True)
        complexity = WorkflowUtils.get_state_value(state, "query_complexity", QueryComplexity.MODERATE)

        # Enumì¸ ê²½ìš° ê°’ìœ¼ë¡œ ë³€í™˜
        if hasattr(complexity, 'value'):
            complexity = complexity.value

        if not needs_search or complexity == QueryComplexity.SIMPLE or complexity == "simple":
            self.logger.info(f"â­ï¸ ê²€ìƒ‰ ìŠ¤í‚µ: ê°„ë‹¨í•œ ì§ˆë¬¸ (ë³µì¡ë„: {complexity})")
            return "skip"

        return "continue"

    def should_expand_keywords_ai(self, state: LegalWorkflowState) -> str:
        """AI í‚¤ì›Œë“œ í™•ì¥ ì—¬ë¶€ ê²°ì •"""
        # AI í™•ì¥ ì¡°ê±´:
        # 1. AI í‚¤ì›Œë“œ ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ê°€
        # 2. ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì¶©ë¶„íˆ ìˆëŠ”ê°€
        # 3. ì§ˆë¬¸ ë³µì¡ë„ê°€ ì¶©ë¶„íˆ ë†’ì€ê°€

        if not self.ai_keyword_generator:
            return "skip"

        keywords = WorkflowUtils.get_state_value(state, "extracted_keywords", [])
        if len(keywords) < 3:
            return "skip"

        # ë³µì¡í•œ ì§ˆë¬¸ì¸ ê²½ìš° í™•ì¥
        query_type = WorkflowUtils.get_state_value(state, "query_type", "")
        complex_types = ["precedent_search", "law_inquiry", "legal_advice"]

        if query_type in complex_types:
            return "expand"

        return "skip"

    def should_retry_generation(self, state: LegalWorkflowState) -> str:
        """
        1ë‹¨ê³„: ë‹µë³€ ìƒì„± í›„ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •

        ì¤‘ìš”: ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ëŠ” ìƒíƒœë¥¼ ìˆ˜ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
        ì¹´ìš´í„° ì¦ê°€ëŠ” prepare_search_query ë…¸ë“œì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        ì—¬ê¸°ì„œëŠ” ì¬ì‹œë„ ì—¬ë¶€ë§Œ íŒë‹¨í•©ë‹ˆë‹¤.

        ì¬ì‹œë„ ì „ëµ:
        - ìµœëŒ€ 2íšŒ ì¬ì‹œë„
        - ì—ëŸ¬ê°€ ìˆê±°ë‚˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬¸ì„œ ê²€ìƒ‰ë¶€í„° ì¬ì‹œë„
        - ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ í¬ë§·íŒ…ìœ¼ë¡œ ì§„í–‰

        Returns:
            "validate": ì •ìƒ ì§„í–‰
            "retry_search": ê²€ìƒ‰ë¶€í„° ì¬ì‹œë„
            "format": í¬ë§·íŒ…ìœ¼ë¡œ ì§„í–‰
        """
        # ì¬ì‹œë„ ì¹´ìš´í„° ì¡°íšŒ (í†µí•© í—¬í¼ ì‚¬ìš©)
        retry_counts = self.retry_manager.get_retry_counts(state)
        generation_retry_count = retry_counts["generation"]
        total_retry_count = retry_counts["total"]

        # ì „ì—­ ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬
        if total_retry_count >= RetryConfig.MAX_TOTAL_RETRIES:
            self.logger.warning(
                f"Maximum total retry count ({RetryConfig.MAX_TOTAL_RETRIES}) reached. "
                "Proceeding to formatting."
            )
            return "format"

        # ìƒì„± ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬
        if generation_retry_count >= RetryConfig.MAX_GENERATION_RETRIES:
            self.logger.warning(
                f"Maximum generation retry count ({RetryConfig.MAX_GENERATION_RETRIES}) reached. "
                "Proceeding to formatting."
            )
            return "format"

        # ì´ë¯¸ ì¬ì‹œë„í•œ ê²½ìš° ì¦‰ì‹œ ì¢…ë£Œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        if generation_retry_count > 0:
            self.logger.info(
                f"âœ… [RETRY LIMIT] Already retried {generation_retry_count}/{RetryConfig.MAX_GENERATION_RETRIES} times. "
                "Proceeding to formatting to prevent infinite loop."
            )
            return "format"

        # ë‹µë³€ ë° ì—ëŸ¬ í™•ì¸
        answer = WorkflowUtils.normalize_answer(WorkflowUtils.get_state_value(state, "answer", ""))
        errors = WorkflowUtils.get_state_value(state, "errors", [])

        answer_len = len(answer)
        has_errors = len(errors) > 0
        is_short_answer = answer_len < WorkflowConstants.MIN_ANSWER_LENGTH_GENERATION

        # ì¬ì‹œë„ í•„ìš” ì—¬ë¶€ íŒë‹¨
        if has_errors or is_short_answer:
            retry_reasons = []
            if has_errors:
                retry_reasons.append(f"errors={len(errors)}")
            if is_short_answer:
                retry_reasons.append(f"answer_len={answer_len} < {WorkflowConstants.MIN_ANSWER_LENGTH_GENERATION}")

            # ë‹µë³€ ë‚´ìš© ìƒì„¸ ë¡œê¹… (ì¬ì‹œë„ ì›ì¸ íŒŒì•…ìš©)
            self.logger.warning(
                f"âš ï¸ [SHORT ANSWER DETECTED] Answer length: {answer_len} characters\n"
                f"   Full answer content: '{answer}'\n"
                f"   Answer type: {type(answer).__name__}\n"
                f"   Answer repr: {repr(answer)}\n"
                f"   Error count: {len(errors)}"
            )

            # ë‹µë³€ ë¯¸ë¦¬ë³´ê¸° ë¡œê¹… (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            if isinstance(answer, str):
                answer_preview = (answer[:100] + "...") if len(answer) > 100 else answer
            else:
                answer_str = str(answer)
                answer_preview = (answer_str[:100] + "...") if len(answer_str) > 100 else answer_str
            self.logger.info(
                f"ğŸ”„ [RETRY DECISION] Retry needed ({', '.join(retry_reasons)}). "
                f"Will retry from document retrieval. [Preview: '{answer_preview}']"
            )
            return "retry_search"  # ê²€ìƒ‰ë¶€í„° ì¬ì‹œë„ (ì¹´ìš´í„°ëŠ” prepare_search_queryì—ì„œ ì¦ê°€)

        # ì •ìƒì ì¸ ê²½ìš° ê²€ì¦ìœ¼ë¡œ ì§„í–‰
        return "validate"

    def should_retry_validation(
        self,
        state: LegalWorkflowState,
        answer_generator: Any = None
    ) -> str:
        """
        2ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦ í›„ ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •

        ì¬ì‹œë„ ì „ëµ:
        - ìµœëŒ€ 1íšŒ ì¬ì‹œë„
        - ë²•ë ¹ ê²€ì¦ ì‹¤íŒ¨ â†’ ê²€ìƒ‰ ì¬ì‹œë„
        - ë‹µë³€ì´ ì§§ìŒ â†’ ë‹µë³€ ìƒì„± ì¬ì‹œë„
        - ê·¸ ì™¸ â†’ êµ¬ì¡° ê°•í™”ë§Œ ì‹œë„ ë˜ëŠ” ìˆ˜ë½

        Args:
            state: ì›Œí¬í”Œë¡œìš° ìƒíƒœ
            answer_generator: AnswerGenerator ì¸ìŠ¤í„´ìŠ¤ (fallback ë‹µë³€ ìƒì„±ìš©)

        Returns:
            "accept": í†µê³¼ ë˜ëŠ” ì¬ì‹œë„ ë¶ˆí•„ìš”
            "retry_generate": ë‹µë³€ ìƒì„± ì¬ì‹œë„
            "retry_search": ê²€ìƒ‰ë¶€í„° ì¬ì‹œë„
        """
        # answer_generatorê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ self.answer_generator ì‚¬ìš©
        if answer_generator is None:
            answer_generator = self.answer_generator

        # í’ˆì§ˆ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (í†µí•© í—¬í¼ ì‚¬ìš©)
        quality_meta = WorkflowUtils.get_quality_metadata(state)
        quality_check_passed = quality_meta["quality_check_passed"]
        quality_score = quality_meta["quality_score"]

        # í’ˆì§ˆ ë©”íƒ€ë°ì´í„° ìƒì„¸ ë¡œê¹… (ë””ë²„ê¹…ìš©)
        self.logger.debug(
            f"ğŸ” [QUALITY METADATA READ] From _should_retry_validation:\n"
            f"   quality_check_passed: {quality_check_passed}\n"
            f"   quality_score: {quality_score:.2f}\n"
            f"   quality_meta dict: {quality_meta}"
        )

        # ì¬ì‹œë„ ì¹´ìš´í„° ì¡°íšŒ (í†µí•© í—¬í¼ ì‚¬ìš©)
        retry_counts = self.retry_manager.get_retry_counts(state)
        validation_retry_count = retry_counts["validation"]
        total_retry_count = retry_counts["total"]

        # ì „ì—­ ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬
        if total_retry_count >= RetryConfig.MAX_TOTAL_RETRIES:
            self.logger.warning(
                f"Maximum total retry count ({RetryConfig.MAX_TOTAL_RETRIES}) reached. "
                "Accepting answer despite quality issues."
            )
            return "accept"

        # í’ˆì§ˆ ê²€ì¦ í†µê³¼ ì‹œ ì¦‰ì‹œ accept (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        if quality_check_passed:
            self.logger.info(
                f"âœ… [QUALITY PASS] Quality check passed (score={quality_score:.2f}). "
                "Accepting answer without retry."
            )
            return "accept"

        # ë¬´í•œ ë£¨í”„ ë°©ì§€: ì´ë¯¸ ì¬ì‹œë„í•œ ê²½ìš° accept
        if validation_retry_count > 0:
            self.logger.warning(
                f"â›” [HARD STOP] Validation retry already attempted ({validation_retry_count}/{RetryConfig.MAX_VALIDATION_RETRIES}). "
                "Accepting answer to prevent infinite loop."
            )
            return "accept"

        # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ í´ë°± ì²˜ë¦¬
        if validation_retry_count >= RetryConfig.MAX_VALIDATION_RETRIES:
            answer = WorkflowUtils.normalize_answer(WorkflowUtils.get_state_value(state, "answer", ""))
            answer_len = len(answer)

            if not answer or answer_len < 20:
                if answer_generator:
                    fallback_answer = answer_generator.generate_fallback_answer(state)
                    WorkflowUtils.set_state_value(state, "answer", fallback_answer)
                    self.logger.warning(
                        f"Maximum validation retry count ({RetryConfig.MAX_VALIDATION_RETRIES}) reached. "
                        f"Generated fallback answer (length: {len(fallback_answer)})"
                    )
                else:
                    self.logger.warning(
                        f"Maximum validation retry count ({RetryConfig.MAX_VALIDATION_RETRIES}) reached. "
                        "AnswerGenerator not available, cannot generate fallback answer."
                    )
            else:
                self.logger.warning(
                    f"Maximum validation retry count ({RetryConfig.MAX_VALIDATION_RETRIES}) reached. "
                    f"Accepting existing answer (length: {answer_len})"
                )
            return "accept"

        # ì¬ì‹œë„ ì „ëµ: ë¬¸ì œ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì¬ì‹œë„ ë°©ë²• ì„ íƒ
        answer = WorkflowUtils.normalize_answer(WorkflowUtils.get_state_value(state, "answer", ""))
        answer_len = len(answer)
        legal_validity = WorkflowUtils.get_state_value(state, "legal_validity_check", True)

        # ë©”íƒ€ë°ì´í„°ì—ì„œ í’ˆì§ˆ ì²´í¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        metadata = WorkflowUtils.get_state_value(state, "metadata", {})
        quality_metadata = metadata.get("quality_metadata", {}) if isinstance(metadata, dict) else {}
        quality_checks = quality_metadata.get("quality_checks", {})

        # ê°œì„  ê°€ëŠ¥ì„± í‰ê°€ (AnswerGenerator ì‚¬ìš©)
        improvement_potential = None
        if answer_generator:
            improvement_potential = answer_generator.assess_improvement_potential(
                quality_score,
                quality_checks,
                state
            )
            # í˜¸í™˜ì„±ì„ ìœ„í•´ ë°˜í™˜ í˜•ì‹ ë³€í™˜
            improvement_potential = {
                "should_retry": improvement_potential.get("potential", 0.0) >= 0.3,
                "confidence": improvement_potential.get("potential", 0.0),
                "best_strategy": improvement_potential.get("strategy") or "retry_generate",
                "reasons": improvement_potential.get("reasons", [])
            }

        # quality_score ê¸°ë°˜ ë™ì  ì„ê³„ê°’ ì„¤ì •
        if quality_score >= QualityThresholds.HIGH_QUALITY_THRESHOLD:
            min_length = QualityThresholds.HIGH_QUALITY_MIN_LENGTH
        elif quality_score >= QualityThresholds.MEDIUM_QUALITY_THRESHOLD:
            min_length = QualityThresholds.MEDIUM_QUALITY_MIN_LENGTH
        else:
            min_length = QualityThresholds.LOW_QUALITY_MIN_LENGTH

        # ì¬ì‹œë„ í•„ìš”ì„± ë¶„ë¥˜
        retry_reasons = []
        if not legal_validity:
            retry_reasons.append("legal_validity_failed")
        if answer_len < min_length:
            retry_reasons.append(f"answer_too_short({answer_len} < {min_length})")
        if quality_score < QualityThresholds.MEDIUM_QUALITY_THRESHOLD:
            retry_reasons.append(f"low_quality_score({quality_score:.2f} < {QualityThresholds.MEDIUM_QUALITY_THRESHOLD})")

        # ì¬ì‹œë„ ê²°ì • (ê°œì„  ê°€ëŠ¥ì„± ê¸°ë°˜)
        if retry_reasons and validation_retry_count < RetryConfig.MAX_VALIDATION_RETRIES:
            # ê°œì„  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©´ ì¬ì‹œë„
            if improvement_potential and improvement_potential.get("should_retry"):
                retry_strategy = improvement_potential.get("best_strategy")

                # í”¼ë“œë°± ì €ì¥ (ë‹¤ìŒ ë…¸ë“œì—ì„œ ì‚¬ìš©)
                if not isinstance(metadata, dict):
                    metadata = {}
                metadata["retry_feedback"] = {
                    "previous_score": quality_score,
                    "failed_checks": [k for k, v in quality_checks.items() if not v],
                    "improvement_potential": improvement_potential,
                    "retry_strategy": retry_strategy
                }
                WorkflowUtils.set_state_value(state, "metadata", metadata)

                # ë‹µë³€ ë‚´ìš© ìƒì„¸ ë¡œê¹…
                answer_preview = ""
                if isinstance(answer, str):
                    answer_preview = answer[:200]
                elif isinstance(answer, (dict, list)):
                    answer_preview = str(answer)[:200]
                else:
                    answer_preview = str(answer)[:200] if answer else ""

                self.logger.warning(
                    f"âš ï¸ [VALIDATION RETRY] Answer analysis:\n"
                    f"   Answer length: {answer_len} characters (min required: {min_length})\n"
                    f"   Quality score: {quality_score:.2f} (threshold: {QualityThresholds.MEDIUM_QUALITY_THRESHOLD})\n"
                    f"   Legal validity: {legal_validity}\n"
                    f"   Answer preview: {answer_preview}\n"
                    f"   Improvement potential: {improvement_potential.get('confidence', 0.0):.2f}\n"
                    f"   Best strategy: {retry_strategy}\n"
                    f"   Reasons: {improvement_potential.get('reasons', [])}\n"
                    f"   Full answer content: '{answer}'\n"
                    f"   Answer type: {type(answer).__name__}"
                )

                # ì ‘ì§€/ì¸ìš© ë¶€ì¡± ì‹œ ê²€ìƒ‰ ì¬ì‹œë„ë¥¼ ìš°ì„  ì ìš©
                try:
                    has_sources = bool(WorkflowUtils.get_state_value(state, "sources", [])) or bool(WorkflowUtils.get_state_value(state, "retrieved_docs", []))
                except Exception:
                    has_sources = True

                if not legal_validity or not has_sources or retry_strategy == "retry_search":
                    # ë²•ë ¹ ê²€ì¦ ì‹¤íŒ¨ â†’ ê²€ìƒ‰ ì¬ì‹œë„
                    self.logger.info(
                        f"ğŸ”„ [RETRY] Reasons: {', '.join(retry_reasons)}. "
                        f"Will retry search (count: {validation_retry_count}/{RetryConfig.MAX_VALIDATION_RETRIES})"
                    )
                    return "retry_search"
                elif answer_len < min_length or quality_score < QualityThresholds.MEDIUM_QUALITY_THRESHOLD:
                    # ë‹µë³€ì´ ì§§ê±°ë‚˜ í’ˆì§ˆì´ ë‚®ìŒ â†’ ë‹µë³€ ìƒì„± ì¬ì‹œë„
                    self.logger.info(
                        f"ğŸ”„ [RETRY] Reasons: {', '.join(retry_reasons)}. "
                        f"Will retry generation (count: {validation_retry_count}/{RetryConfig.MAX_VALIDATION_RETRIES})"
                    )
                    return "retry_generate"
            else:
                # ê°œì„  ê°€ëŠ¥ì„±ì´ ë‚®ìœ¼ë©´ ìˆ˜ë½
                if improvement_potential:
                    self.logger.info(
                        f"âš ï¸ [NO IMPROVEMENT POTENTIAL] Quality improvement unlikely. "
                        f"Score: {quality_score:.2f}, Potential: {improvement_potential.get('confidence', 0.0):.2f}, "
                        f"Reasons: {improvement_potential.get('reasons', [])}"
                    )
                return "accept"

        # ì¬ì‹œë„ í•„ìš” ì—†ìŒ
        self.logger.info(
            f"Quality check failed but no retry needed "
            f"(validation_retry_count: {validation_retry_count}/{RetryConfig.MAX_VALIDATION_RETRIES}, "
            f"quality_score: {quality_score:.2f}, answer_len: {answer_len}). "
            "Proceeding with enhancement."
        )
        return "accept"
