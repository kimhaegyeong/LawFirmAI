#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraph ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸
ë‹µë³€ ì²˜ë¦¬ ì†ë„ ê°œì„  ë°©ì•ˆ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import asyncio
import tempfile
import time
from pathlib import Path
from typing import List, Dict, Any

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["USE_LANGGRAPH"] = "true"
os.environ["LANGGRAPH_ENABLED"] = "true"

# ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤
class OptimizedLegalWorkflow:
    """ì„±ëŠ¥ ìµœì í™”ëœ ë²•ë¥  ì§ˆë¬¸ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ë¥¼ ë¯¸ë¦¬ ì´ˆê¸°í™” (ì¬ì‚¬ìš©)
        self._init_ollama_client()
        
        # ìºì‹œëœ ì‘ë‹µ í…œí”Œë¦¿
        self.response_templates = {
            "contract_review": "ê³„ì•½ì„œ ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì£¼ìš” ì£¼ì˜ì‚¬í•­ì€ ëª…í™•ì„±, ì™„ì „ì„±, ê³µì •ì„±ì…ë‹ˆë‹¤.",
            "family_law": "ê°€ì¡±ë²• ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì´í˜¼, ì–‘ìœ¡ë¹„, ìƒì† ë“±ì˜ ì ˆì°¨ê°€ ìˆìŠµë‹ˆë‹¤.",
            "criminal_law": "í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤. êµ¬ì„±ìš”ê±´ê³¼ ë²•ì •í˜•ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.",
            "general_question": "ì¼ë°˜ì ì¸ ë²•ë¥  ì§ˆë¬¸ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì¡°ì–¸ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”."
        }
    
    def _init_ollama_client(self):
        """Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            from langchain_community.llms import Ollama
            self.ollama_llm = Ollama(
                model="qwen2.5:7b",
                base_url="http://localhost:11434",
                temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í–¥ìƒ
                num_predict=200,  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
                timeout=30  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            self.ollama_available = True
        except Exception as e:
            self.logger.warning(f"Ollama ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.ollama_llm = None
            self.ollama_available = False
    
    async def process_query_fast(self, query: str) -> Dict[str, Any]:
        """ë¹ ë¥¸ ì§ˆë¬¸ ì²˜ë¦¬ (ìµœì í™” ë²„ì „)"""
        start_time = time.time()
        
        try:
            # 1. ë¹ ë¥¸ ì§ˆë¬¸ ë¶„ë¥˜ (í‚¤ì›Œë“œ ê¸°ë°˜)
            query_type = self._classify_query_fast(query)
            
            # 2. ê°„ë‹¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self._generate_context_fast(query, query_type)
            
            # 3. ë¹ ë¥¸ ë‹µë³€ ìƒì„±
            answer = await self._generate_answer_fast(query, context, query_type)
            
            processing_time = time.time() - start_time
            
            return {
                "answer": answer,
                "confidence": 0.8,  # ê³ ì • ì‹ ë¢°ë„
                "sources": ["ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤", "íŒë¡€ ë°ì´í„°ë² ì´ìŠ¤"],
                "processing_time": processing_time,
                "query_type": query_type,
                "processing_steps": ["ë¹ ë¥¸ ë¶„ë¥˜", "ì»¨í…ìŠ¤íŠ¸ ìƒì„±", "ë‹µë³€ ìƒì„±"],
                "session_id": f"fast_{int(time.time())}",
                "errors": []
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "confidence": 0.0,
                "sources": [],
                "processing_time": processing_time,
                "query_type": "error",
                "processing_steps": ["ì˜¤ë¥˜ ë°œìƒ"],
                "session_id": f"error_{int(time.time())}",
                "errors": [str(e)]
            }
    
    def _classify_query_fast(self, query: str) -> str:
        """ë¹ ë¥¸ ì§ˆë¬¸ ë¶„ë¥˜"""
        query_lower = query.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥¸ ë¶„ë¥˜
        if any(kw in query_lower for kw in ["ê³„ì•½", "ê³„ì•½ì„œ", "contract"]):
            return "contract_review"
        elif any(kw in query_lower for kw in ["ì´í˜¼", "ìœ„ìë£Œ", "ì–‘ìœ¡ë¹„", "ìƒì†"]):
            return "family_law"
        elif any(kw in query_lower for kw in ["í˜•ì‚¬", "ë²”ì£„", "ì ˆë„", "ì‚¬ê¸°"]):
            return "criminal_law"
        else:
            return "general_question"
    
    def _generate_context_fast(self, query: str, query_type: str) -> str:
        """ë¹ ë¥¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        base_context = self.response_templates.get(query_type, "ì¼ë°˜ì ì¸ ë²•ë¥  ì§ˆë¬¸ì…ë‹ˆë‹¤.")
        
        # ì§ˆë¬¸ì— íŠ¹ì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
        if "ì ˆì°¨" in query:
            base_context += " ê´€ë ¨ ì ˆì°¨ì™€ ìš”êµ¬ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”."
        elif "ì¡°ê±´" in query:
            base_context += " êµ¬ì²´ì ì¸ ì¡°ê±´ê³¼ ê¸°ì¤€ì„ ì‚´í´ë³´ì„¸ìš”."
        elif "ì†í•´ë°°ìƒ" in query:
            base_context += " ì†í•´ë°°ìƒ ë²”ìœ„ì™€ ê³„ì‚° ë°©ë²•ì„ ê³ ë ¤í•˜ì„¸ìš”."
        
        return base_context
    
    async def _generate_answer_fast(self, query: str, context: str, query_type: str) -> str:
        """ë¹ ë¥¸ ë‹µë³€ ìƒì„±"""
        if not self.ollama_available:
            # Ollama ì‚¬ìš© ë¶ˆê°€ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ ë‹µë³€
            return f"""ì§ˆë¬¸: {query}

{context}

êµ¬ì²´ì ì¸ ë²•ë¥ ì  ì¡°ì–¸ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ ì •ë³´ ì œê³µ ëª©ì ì´ë©°, êµ¬ì²´ì ì¸ ë²•ë¥ ì  ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤."""

        try:
            # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë¹ ë¥¸ ì‘ë‹µ ìƒì„±
            prompt = f"""ì§ˆë¬¸: {query}
ì»¨í…ìŠ¤íŠ¸: {context}

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 200ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            # ë¹„ë™ê¸°ë¡œ Ollama í˜¸ì¶œ
            response = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self.ollama_llm.invoke(prompt)
            )
            
            return response
            
        except Exception as e:
            self.logger.warning(f"Ollama ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± ë‹µë³€
            return f"""ì§ˆë¬¸: {query}

{context}

êµ¬ì²´ì ì¸ ë²•ë¥ ì  ì¡°ì–¸ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."""

# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ (ê°„ì†Œí™”)
TEST_QUESTIONS_FAST = [
    "ê³„ì•½ì„œ ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­ì€?",
    "ì´í˜¼ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "ì ˆë„ì£„ì˜ êµ¬ì„±ìš”ê±´ì€?",
    "ì†í•´ë°°ìƒ ì²­êµ¬ ë°©ë²•ì€?",
    "ë¶€ë‹¹í•´ê³  êµ¬ì œ ì ˆì°¨ëŠ”?",
    "ë¶€ë™ì‚° ë§¤ë§¤ê³„ì•½ì„œ í•„ìˆ˜ ì¡°í•­ì€?",
    "íŠ¹í—ˆê¶Œ ì¹¨í•´ ì‹œ êµ¬ì œ ë°©ë²•ì€?",
    "ì†Œë“ì„¸ ì‹ ê³  ëˆ„ë½ ì‹œ ê°€ì‚°ì„¸ëŠ”?",
    "ë²•ì •ëŒ€ë¦¬ì¸ì˜ ê¶Œí•œì€?",
    "ì†Œì†¡ ì œê¸° ì‹œ ê´€í•  ë²•ì›ì€?",
    "ê³„ì•½ í•´ì§€ ì¡°ê±´ì€?",
    "ìœ„ìë£Œ ì‚°ì • ê¸°ì¤€ì€?",
    "ì‚¬ê¸°ì£„ì™€ íš¡ë ¹ì£„ì˜ ì°¨ì´ì ì€?",
    "ì†Œë©¸ì‹œíš¨ ì¤‘ë‹¨ ì‚¬ìœ ëŠ”?",
    "ì„ê¸ˆ ì²´ë¶ˆ ì‹œ ëŒ€ì‘ ë°©ë²•ì€?",
    "ì „ì„¸ê¶Œ ì„¤ì • ì ˆì°¨ëŠ”?",
    "ìƒí‘œê¶Œ ë“±ë¡ ì ˆì°¨ëŠ”?",
    "ë²•ì¸ì„¸ ê³„ì‚° ë°©ë²•ì€?",
    "ì¤‘ì¬ ì ˆì°¨ì™€ ë²•ì› ì†Œì†¡ì˜ ì°¨ì´ì ì€?",
    "ë²•ë¥  ìë¬¸ ë¹„ìš©ì€ ì–´ë–»ê²Œ ì‚°ì •ë˜ë‚˜ìš”?"
]

async def test_performance_optimization():
    """ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("LangGraph ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        from source.utils.langgraph_config import LangGraphConfig
        
        # ì„¤ì • ìƒì„±
        config = LangGraphConfig.from_env()
        
        # ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        workflow = OptimizedLegalWorkflow(config)
        print("âœ… ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = []
        total_start_time = time.time()
        
        print(f"\nğŸš€ {len(TEST_QUESTIONS_FAST)}ê°œ ì§ˆë¬¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        for i, question in enumerate(TEST_QUESTIONS_FAST, 1):
            print(f"\n[{i:2d}/{len(TEST_QUESTIONS_FAST)}] {question}")
            
            start_time = time.time()
            result = await workflow.process_query_fast(question)
            processing_time = time.time() - start_time
            
            results.append({
                "question_id": i,
                "question": question,
                "processing_time": processing_time,
                "response_length": len(result["answer"]),
                "confidence": result["confidence"],
                "query_type": result["query_type"]
            })
            
            print(f"    âš¡ ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            print(f"    ğŸ“ ë‹µë³€: {result['answer'][:100]}...")
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if i % 5 == 0:
                avg_time = sum(r["processing_time"] for r in results) / len(results)
                print(f"\nğŸ“Š ì§„í–‰ë¥ : {i}/{len(TEST_QUESTIONS_FAST)} - í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        total_time = time.time() - total_start_time
        
        # ê²°ê³¼ ë¶„ì„
        analyze_performance_results(results, total_time)
        
        return results
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return []

def analyze_performance_results(results: List[Dict[str, Any]], total_time: float):
    """ì„±ëŠ¥ ê²°ê³¼ ë¶„ì„"""
    print("\n" + "=" * 80)
    print("ì„±ëŠ¥ ìµœì í™” ê²°ê³¼ ë¶„ì„")
    print("=" * 80)
    
    if not results:
        print("âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ í†µê³„
    total_questions = len(results)
    avg_processing_time = sum(r["processing_time"] for r in results) / total_questions
    min_time = min(r["processing_time"] for r in results)
    max_time = max(r["processing_time"] for r in results)
    
    print(f"ğŸ“Š ì„±ëŠ¥ í†µê³„:")
    print(f"   - ì´ ì§ˆë¬¸ ìˆ˜: {total_questions}")
    print(f"   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.2f}ì´ˆ")
    print(f"   - ìµœë‹¨ ì²˜ë¦¬ ì‹œê°„: {min_time:.2f}ì´ˆ")
    print(f"   - ìµœì¥ ì²˜ë¦¬ ì‹œê°„: {max_time:.2f}ì´ˆ")
    print(f"   - ì´ˆë‹¹ ì²˜ë¦¬ ì§ˆë¬¸ ìˆ˜: {total_questions/total_time:.2f}ê°œ")
    
    # ì²˜ë¦¬ ì‹œê°„ ë¶„í¬
    fast_tests = [r for r in results if r["processing_time"] < 5]
    medium_tests = [r for r in results if 5 <= r["processing_time"] < 15]
    slow_tests = [r for r in results if r["processing_time"] >= 15]
    
    print(f"\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„ ë¶„í¬:")
    print(f"   - ë§¤ìš° ë¹ ë¦„ (<5ì´ˆ): {len(fast_tests)}ê°œ ({len(fast_tests)/total_questions*100:.1f}%)")
    print(f"   - ë¹ ë¦„ (5-15ì´ˆ): {len(medium_tests)}ê°œ ({len(medium_tests)/total_questions*100:.1f}%)")
    print(f"   - ë³´í†µ (â‰¥15ì´ˆ): {len(slow_tests)}ê°œ ({len(slow_tests)/total_questions*100:.1f}%)")
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥
    query_types = {}
    for r in results:
        qtype = r["query_type"]
        if qtype not in query_types:
            query_types[qtype] = []
        query_types[qtype].append(r["processing_time"])
    
    print(f"\nğŸ“‹ ì§ˆë¬¸ ìœ í˜•ë³„ í‰ê·  ì²˜ë¦¬ ì‹œê°„:")
    for qtype, times in query_types.items():
        avg_time = sum(times) / len(times)
        print(f"   - {qtype}: {avg_time:.2f}ì´ˆ ({len(times)}ê°œ)")
    
    # ì„±ëŠ¥ ê°œì„  í‰ê°€
    print(f"\nğŸ† ì„±ëŠ¥ ê°œì„  í‰ê°€:")
    if avg_processing_time < 5:
        print("   âœ… ìš°ìˆ˜ - í‰ê·  5ì´ˆ ë¯¸ë§Œ")
    elif avg_processing_time < 10:
        print("   âœ… ì–‘í˜¸ - í‰ê·  10ì´ˆ ë¯¸ë§Œ")
    elif avg_processing_time < 20:
        print("   âš ï¸ ë³´í†µ - í‰ê·  20ì´ˆ ë¯¸ë§Œ")
    else:
        print("   âŒ ê°œì„  í•„ìš” - í‰ê·  20ì´ˆ ì´ìƒ")
    
    # ìµœì í™” ê¶Œì¥ì‚¬í•­
    print(f"\nğŸ’¡ ì¶”ê°€ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
    if avg_processing_time > 10:
        print("   1. Ollama ëª¨ë¸ì„ ë” ì‘ì€ ëª¨ë¸ë¡œ ë³€ê²½ (ì˜ˆ: qwen2.5:3b)")
        print("   2. ì‘ë‹µ ê¸¸ì´ë¥¼ ë” ì œí•œ (num_predict=100)")
        print("   3. ìºì‹± ì‹œìŠ¤í…œ ë„ì…")
        print("   4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìµœì í™”")
    
    if len(slow_tests) > total_questions * 0.2:
        print("   5. ëŠë¦° ì§ˆë¬¸ë“¤ì— ëŒ€í•œ íŠ¹ë³„ ì²˜ë¦¬ ë¡œì§ í•„ìš”")
    
    print("   6. ë¹„ë™ê¸° ì²˜ë¦¬ ë° ë³‘ë ¬ ì²˜ë¦¬ ë„ì…")
    print("   7. ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    results = await test_performance_optimization()
    
    if results:
        print(f"\nğŸ‰ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        avg_time = sum(r["processing_time"] for r in results) / len(results)
        print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ (ì´ì „: 80-100ì´ˆ)")
        
        if avg_time < 20:
            print("ğŸš€ ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âš ï¸ ì¶”ê°€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨")

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.WARNING)  # ë¡œê·¸ ë ˆë²¨ ë‚®ì¶¤
    
    asyncio.run(main())
